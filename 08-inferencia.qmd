# Inferencia estad√≠stica {#inferencia}

## Objetivos del cap√≠tulo {.unnumbered}

Al finalizar este cap√≠tulo, ser√°s capaz de:

- Comprender la l√≥gica de la inferencia estad√≠stica: generalizar desde muestras a poblaciones
- Distinguir entre par√°metros poblacionales y estad√≠sticos muestrales
- Entender el concepto de distribuci√≥n muestral y su relaci√≥n con el Teorema del L√≠mite Central
- Calcular e interpretar el error est√°ndar
- Construir e interpretar intervalos de confianza para medias y proporciones
- Evaluar el tama√±o muestral necesario para cierto nivel de precisi√≥n

## De muestras a poblaciones

En ciencias sociales raramente tenemos acceso a poblaciones completas. Queremos saber:

- ¬øCu√°l es el apoyo real a la reforma de pensiones entre todos los chilenos?
- ¬øCu√°l es el ingreso promedio de hogares en Am√©rica Latina?
- ¬øQu√© proporci√≥n de electores cambia su voto entre elecciones?

Pero solo podemos encuestar una **muestra** de cientos o miles de personas, no los millones que componen la poblaci√≥n. La **inferencia estad√≠stica** es el proceso de usar datos de una muestra para hacer afirmaciones sobre una poblaci√≥n, cuantificando la incertidumbre asociada.

### Ejemplo motivador: Encuestas electorales en Chile

Antes de las elecciones presidenciales 2021 (segunda vuelta), m√∫ltiples encuestadoras reportaron:

```{r encuestas-2021, echo=FALSE}
library(ggplot2)
library(dplyr)

encuestas <- data.frame(
  encuestadora = c("Cadem", "Activa", "Data Influye", "Criteria"),
  boric = c(51, 52, 50, 51),
  kast = c(39, 40, 41, 40),
  n = c(1015, 1200, 1400, 1500),
  fecha = c("10-12 dic", "10-12 dic", "9-12 dic", "10-13 dic")
)

encuestas_long <- encuestas %>%
  tidyr::pivot_longer(cols = c(boric, kast),
                      names_to = "candidato",
                      values_to = "porcentaje") %>%
  mutate(candidato = ifelse(candidato == "boric", "Boric", "Kast"))

ggplot(encuestas_long, aes(x = encuestadora, y = porcentaje,
                            fill = candidato, label = porcentaje)) +
  geom_col(position = "dodge", width = 0.7) +
  geom_text(position = position_dodge(width = 0.7), vjust = -0.5) +
  scale_fill_manual(values = c("Boric" = "#3498db", "Kast" = "#e74c3c")) +
  labs(
    title = "Encuestas presidenciales Chile 2021 (2da vuelta)",
    subtitle = "Diferentes muestras producen diferentes estimaciones",
    x = NULL,
    y = "Porcentaje de intenci√≥n de voto (%)",
    fill = "Candidato"
  ) +
  theme_minimal() +
  theme(legend.position = "top")
```

**Preguntas clave:**

1. ¬øPor qu√© las encuestas difieren si todas miden "lo mismo"?
2. ¬øCu√°n confiables son estos n√∫meros?
3. ¬øQu√© tan grande debe ser la muestra?

La inferencia estad√≠stica nos da herramientas para responder estas preguntas.

### Muestras y poblaciones

### Definiciones fundamentales

**Poblaci√≥n**: Conjunto completo de unidades de inter√©s. Tiene **par√°metros** (valores fijos, generalmente desconocidos):
- Media poblacional: $\mu$
- Proporci√≥n poblacional: $p$
- Varianza poblacional: $\sigma^2$

**Muestra**: Subconjunto de la poblaci√≥n que observamos. Tiene **estad√≠sticos** (valores calculados a partir de los datos):
- Media muestral: $\bar{x}$
- Proporci√≥n muestral: $\hat{p}$
- Varianza muestral: $s^2$

Es fundamental distinguir que los **par√°metros** $(\mu, p, \sigma^2)$ son valores fijos (pero desconocidos) de la poblaci√≥n, mientras que los **estad√≠sticos** $(\bar{x}, \hat{p}, s^2)$ son calculados a partir de la muestra y **var√≠an** entre muestras. Usamos estad√≠sticos para **estimar** par√°metros.

Por ejemplo, consideremos el apoyo a una reforma tributaria. La **poblaci√≥n** son 15 millones de votantes chilenos, y el **par√°metro de inter√©s** es $p$ = proporci√≥n que apoya la reforma (desconocida). Si tomamos una **muestra** de 1,200 votantes encuestados y observamos el **estad√≠stico** $\hat{p} = 0.42$ (42% de la muestra apoya), la **pregunta inferencial** es: ¬øQu√© podemos decir sobre $p$ (desconocido) a partir de $\hat{p} = 0.42$ (conocido)?

### Muestreo aleatorio simple

Para que la inferencia sea v√°lida, necesitamos **muestras probabil√≠sticas**. El dise√±o m√°s simple:

**Muestreo Aleatorio Simple (MAS)**: Cada unidad de la poblaci√≥n tiene la misma probabilidad de ser seleccionada.

```{r muestreo-simple, echo=TRUE}
# Simulaci√≥n de poblaci√≥n y muestra
set.seed(2024)

# Poblaci√≥n de 10,000 votantes (40% apoya reforma)
poblacion <- c(rep(1, 4000), rep(0, 6000))  # 1 = apoya, 0 = no apoya
p_verdadero <- mean(poblacion)

cat("Par√°metro poblacional verdadero: p =", p_verdadero, "\n\n")

# Tomamos una muestra aleatoria de n=1000
muestra <- sample(poblacion, size = 1000, replace = FALSE)
p_hat <- mean(muestra)

cat("Estad√≠stico muestral: pÃÇ =", p_hat, "\n")
cat("Error de estimaci√≥n: pÃÇ - p =", p_hat - p_verdadero, "\n")
```

**Propiedades del MAS:**

1. **Insesgado**: En promedio, $E(\hat{p}) = p$ y $E(\bar{x}) = \mu$
2. **Variable**: Diferentes muestras producen diferentes estimaciones
3. **M√°s preciso con muestras grandes**: El error disminuye con $n$

## Distribuciones muestrales

La clave para entender la inferencia es reconocer que los **estad√≠sticos son variables aleatorias**.

### Distribuci√≥n muestral de la media

Si tomamos muchas muestras de tama√±o $n$ y calculamos $\bar{x}$ para cada una, la distribuci√≥n de todos esos $\bar{x}$ es la **distribuci√≥n muestral de la media**.

**Propiedades** (del Teorema del L√≠mite Central, visto en Cap. 7):

$$\bar{X} \sim N\left(\mu, \frac{\sigma^2}{n}\right)$$

- **Media**: $E(\bar{X}) = \mu$ (insesgado)
- **Varianza**: $\text{Var}(\bar{X}) = \frac{\sigma^2}{n}$ (disminuye con $n$)
- **Forma**: Aproximadamente Normal para $n \geq 30$

```{r distribucion-muestral-media, echo=TRUE, fig.cap="Simulaci√≥n de la distribuci√≥n muestral de la media"}
# Poblaci√≥n: Ingresos mensuales (en miles de pesos)
# Distribuci√≥n asim√©trica (lognormal)
set.seed(123)
poblacion_ingresos <- rlnorm(100000, meanlog = log(500), sdlog = 0.6)

mu_real <- mean(poblacion_ingresos)
sigma_real <- sd(poblacion_ingresos)

cat("Poblaci√≥n:\n")
cat("Media (Œº) =", round(mu_real, 1), "mil pesos\n")
cat("SD (œÉ) =", round(sigma_real, 1), "mil pesos\n\n")

# Tomamos 5000 muestras de n=100 y calculamos sus medias
n_muestra <- 100
medias_muestrales <- replicate(5000, mean(sample(poblacion_ingresos, n_muestra)))

cat("Distribuci√≥n muestral de XÃÑ (n=100):\n")
cat("Media =", round(mean(medias_muestrales), 1), " (muy cerca de Œº =", round(mu_real, 1), ")\n")
cat("SD observada =", round(sd(medias_muestrales), 1), "\n")
cat("SD te√≥rica (œÉ/‚àön) =", round(sigma_real/sqrt(n_muestra), 1), "\n")
```

```{r plot-dist-muestral, echo=FALSE, fig.height=6, fig.cap="Distribuci√≥n poblacional vs distribuci√≥n muestral"}
library(gridExtra)

# Gr√°fico 1: Distribuci√≥n poblacional
p1 <- ggplot(data.frame(ingreso = sample(poblacion_ingresos, 10000)),
             aes(x = ingreso)) +
  geom_histogram(aes(y = after_stat(density)), bins = 50,
                 fill = "#3498db", color = "white", alpha = 0.7) +
  geom_vline(xintercept = mu_real, color = "#e74c3c",
             linetype = "dashed", size = 1.2) +
  labs(
    title = "Distribuci√≥n Poblacional",
    subtitle = "Ingresos individuales (asim√©trica)",
    x = "Ingreso mensual (miles de $)",
    y = "Densidad"
  ) +
  theme_minimal()

# Gr√°fico 2: Distribuci√≥n muestral
p2 <- ggplot(data.frame(media = medias_muestrales), aes(x = media)) +
  geom_histogram(aes(y = after_stat(density)), bins = 40,
                 fill = "#2ecc71", color = "white", alpha = 0.7) +
  geom_vline(xintercept = mu_real, color = "#e74c3c",
             linetype = "dashed", size = 1.2) +
  stat_function(fun = dnorm,
                args = list(mean = mu_real, sd = sigma_real/sqrt(n_muestra)),
                color = "#e67e22", size = 1.2) +
  labs(
    title = "Distribuci√≥n Muestral de XÃÑ",
    subtitle = "Medias de 5000 muestras de n=100 (aproximadamente Normal)",
    x = "Media muestral (miles de $)",
    y = "Densidad"
  ) +
  theme_minimal()

grid.arrange(p1, p2, ncol = 1)
```

Aunque la poblaci√≥n de ingresos es altamente asim√©trica, la distribuci√≥n de $\bar{X}$ es aproximadamente Normal. Esto es el Teorema del L√≠mite Central en acci√≥n.

### Distribuci√≥n muestral de la proporci√≥n

Para proporciones, una l√≥gica similar aplica. Si $\hat{p}$ es la proporci√≥n muestral:

$$\hat{p} \sim N\left(p, \frac{p(1-p)}{n}\right)$$

(Aproximaci√≥n v√°lida cuando $np \geq 10$ y $n(1-p) \geq 10$)

Por ejemplo, si en una encuesta electoral el verdadero apoyo es $p = 0.45$ y encuestamos $n = 1000$ personas:

```{r dist-proporcion, echo=TRUE}
p <- 0.45
n <- 1000

# Media y SD de pÃÇ
media_p_hat <- p
sd_p_hat <- sqrt(p * (1 - p) / n)

cat("Distribuci√≥n de pÃÇ:\n")
cat("Media =", media_p_hat, "\n")
cat("SD (error est√°ndar) =", round(sd_p_hat, 4), "\n\n")

# Probabilidad de que nuestra muestra subestime apoyo en >3%
prob_error_grande <- pnorm(0.42, mean = p, sd = sd_p_hat)
cat("P(pÃÇ < 0.42) =", round(prob_error_grande, 3))
```

### Error est√°ndar

El **error est√°ndar** (SE, *standard error*) es la desviaci√≥n est√°ndar de la distribuci√≥n muestral de un estad√≠stico.

### Error est√°ndar de la media

$$\text{SE}(\bar{x}) = \frac{\sigma}{\sqrt{n}}$$

Pero $\sigma$ (SD poblacional) es generalmente desconocido. Lo estimamos con $s$ (SD muestral):

$$\widehat{\text{SE}}(\bar{x}) = \frac{s}{\sqrt{n}}$$

Es importante distinguir entre **error est√°ndar** y **desviaci√≥n est√°ndar**. La desviaci√≥n est√°ndar ($s$) mide variabilidad en los **datos**, mientras que el error est√°ndar ($\text{SE}$) mide variabilidad del **estad√≠stico** (precisi√≥n de la estimaci√≥n). El $\text{SE}$ disminuye con $n$; $s$ NO (permanece constante en promedio).[^se-vs-sd]

[^se-vs-sd]: El error est√°ndar mide qu√© tan precisa es nuestra estimaci√≥n de la media. La desviaci√≥n est√°ndar mide qu√© tan dispersos est√°n los datos individuales. $\text{SE} = s/\sqrt{n}$ siempre es menor que $s$ (excepto cuando $n=1$).

Por ejemplo, consideremos datos de ingreso familiar en una encuesta tipo CASEN:

```{r ejemplo-se, echo=TRUE}
# Datos simulados de ingresos (en miles de $)
set.seed(456)
ingresos <- rlnorm(500, meanlog = log(600), sdlog = 0.7)

n <- length(ingresos)
media <- mean(ingresos)
s <- sd(ingresos)
se <- s / sqrt(n)

cat("Muestra de n =", n, "hogares\n")
cat("Media muestral: $", round(media, 0), " mil\n", sep = "")
cat("SD de ingresos (s): $", round(s, 0), " mil\n", sep = "")
cat("SE de la media: $", round(se, 0), " mil\n\n", sep = "")

cat("Interpretaci√≥n:\n")
cat("- Los ingresos individuales var√≠an t√≠picamente ¬±$", round(s, 0),
    " mil alrededor de la media\n", sep = "")
cat("- Nuestra estimaci√≥n de la media tiene error t√≠pico de ¬±$", round(se, 0),
    " mil\n", sep = "")
```

### Error est√°ndar de la proporci√≥n

$$\text{SE}(\hat{p}) = \sqrt{\frac{p(1-p)}{n}}$$

Como $p$ es desconocido, lo estimamos con $\hat{p}$:

$$\widehat{\text{SE}}(\hat{p}) = \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$$

```{r se-proporcion, echo=TRUE}
# Encuesta: proporci√≥n que apoya pol√≠tica X
n <- 1200
apoyos <- 510
p_hat <- apoyos / n
se_p <- sqrt(p_hat * (1 - p_hat) / n)

cat("n =", n, "encuestados\n")
cat("Apoyan =", apoyos, "(", round(p_hat * 100, 1), "%)\n", sep = "")
cat("SE(pÃÇ) =", round(se_p, 4), "o", round(se_p * 100, 2), "puntos porcentuales\n")
```

### El error est√°ndar disminuye con $\sqrt{n}$

Una implicaci√≥n crucial: para **reducir el SE a la mitad**, necesitas **cuadruplicar** el tama√±o muestral.

```{r se-vs-n, echo=FALSE, fig.cap="Relaci√≥n entre tama√±o muestral y error est√°ndar"}
n_seq <- seq(100, 5000, by = 50)
se_seq <- sqrt(0.5 * 0.5 / n_seq)  # Peor caso: p = 0.5

data.frame(n = n_seq, se = se_seq) %>%
  ggplot(aes(x = n, y = se)) +
  geom_line(color = "#3498db", size = 1.2) +
  geom_hline(yintercept = c(0.01, 0.02, 0.03),
             linetype = "dashed", alpha = 0.5) +
  annotate("text", x = 4500, y = 0.01, label = "SE = 1%", vjust = -0.5) +
  annotate("text", x = 4500, y = 0.02, label = "SE = 2%", vjust = -0.5) +
  annotate("text", x = 4500, y = 0.03, label = "SE = 3%", vjust = -0.5) +
  labs(
    title = "Error Est√°ndar vs Tama√±o Muestral",
    subtitle = "Para proporci√≥n (peor caso: p = 0.5)",
    x = "Tama√±o muestral (n)",
    y = "Error est√°ndar"
  ) +
  scale_y_continuous(labels = scales::percent) +
  theme_minimal()
```

## Intervalos de confianza

Un **intervalo de confianza** (IC) es un rango de valores plausibles para el par√°metro poblacional, construido de tal manera que, si repiti√©ramos el muestreo infinitas veces, el IC contendr√≠a el valor verdadero en (por ejemplo) 95% de las muestras.

### Intervalo de confianza para la media

**F√≥rmula general:**

$$\text{IC}_{95\%} = \bar{x} \pm t_{n-1, 0.975} \cdot \frac{s}{\sqrt{n}}$$

donde $t_{n-1, 0.975}$ es el valor cr√≠tico de la distribuci√≥n $t$ con $n-1$ grados de libertad.

**Cuando $n$ es grande ($n \geq 30$)**, $t \approx 1.96$, as√≠ que:

$$\text{IC}_{95\%} \approx \bar{x} \pm 1.96 \cdot \text{SE}(\bar{x})$$

::: {.callout-warning}
## Error com√∫n: Interpretaci√≥n incorrecta del IC

**INCORRECTO**: "Hay 95% de probabilidad de que $\mu$ est√© en este intervalo."

**CORRECTO**: "Si repiti√©ramos este proceso de muestreo muchas veces, aproximadamente 95% de los intervalos construidos contendr√≠an el verdadero valor de $\mu$."

La diferencia es sutil pero importante: $\mu$ es un valor fijo (aunque desconocido). No es aleatorio. Lo que var√≠a entre muestras es el intervalo, no el par√°metro.
:::

Por ejemplo, consideremos el c√°lculo de un intervalo de confianza para el ingreso promedio:

```{r ic-media, echo=TRUE}
# Datos de ingresos (retomando ejemplo anterior)
set.seed(789)
ingresos <- rlnorm(200, meanlog = log(550), sdlog = 0.65)

n <- length(ingresos)
media <- mean(ingresos)
s <- sd(ingresos)
se <- s / sqrt(n)

# Valor cr√≠tico t para 95% de confianza
t_crit <- qt(0.975, df = n - 1)

# Intervalo de confianza
ic_inferior <- media - t_crit * se
ic_superior <- media + t_crit * se

cat("Ingreso promedio mensual (n =", n, "hogares):\n")
cat("Media muestral: $", round(media, 0), " mil\n", sep = "")
cat("IC 95%: [$", round(ic_inferior, 0), ", $",
    round(ic_superior, 0), "] mil\n\n", sep = "")

cat("Interpretaci√≥n: Estamos 95% confiados de que el ingreso promedio\n")
cat("poblacional est√° entre $", round(ic_inferior, 0), " y $",
    round(ic_superior, 0), " mil.\n", sep = "")
```

::: {.callout-tip}
## Forma r√°pida en R: `t.test()`

En lugar de calcular manualmente, puedes usar la funci√≥n `t.test()`:

```{r}
# Usando los mismos datos de ingresos
resultado <- t.test(ingresos, conf.level = 0.95)

# Ver el intervalo de confianza
resultado$conf.int

# Ver todos los resultados
resultado
```

La funci√≥n `t.test()` calcula autom√°ticamente el IC y adem√°s realiza una prueba de hip√≥tesis (que veremos en el pr√≥ximo cap√≠tulo).
:::

### Intervalo de confianza para la proporci√≥n

$$\text{IC}_{95\%} = \hat{p} \pm 1.96 \cdot \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$$

(V√°lido cuando $n\hat{p} \geq 10$ y $n(1-\hat{p}) \geq 10$)

Por ejemplo, para una encuesta de intenci√≥n de voto:

```{r ic-proporcion, echo=TRUE}
# Encuesta: ¬øVotar√° en pr√≥ximas elecciones?
n <- 1500
votaran <- 780
p_hat <- votaran / n
se_p <- sqrt(p_hat * (1 - p_hat) / n)

# IC 95%
ic_inf <- p_hat - 1.96 * se_p
ic_sup <- p_hat + 1.96 * se_p

cat("Encuesta (n =", n, "):\n")
cat("Declaran que votar√°n:", votaran, "personas (", round(p_hat * 100, 1), "%)\n", sep = "")
cat("IC 95%: [", round(ic_inf * 100, 1), "%, ",
    round(ic_sup * 100, 1), "%]\n\n", sep = "")

cat("Interpretaci√≥n: El verdadero porcentaje de personas que votar√°n\n")
cat("est√° probablemente entre", round(ic_inf * 100, 1), "% y",
    round(ic_sup * 100, 1), "%.\n")
```

::: {.callout-tip}
## IC para proporciones en R: `prop.test()`

```{r}
# Forma directa con prop.test()
prop.test(x = 780, n = 1500, conf.level = 0.95)
```

Nota: `prop.test()` usa una correcci√≥n de continuidad por defecto. Para obtener el IC "cl√°sico", usa `correct = FALSE`.
:::

### Niveles de confianza alternativos

No estamos limitados a 95%. Podemos construir ICs con cualquier nivel de confianza:

| Nivel de Confianza | Valor Cr√≠tico $z$ | Intervalo |
|:------------------:|:-----------------:|:----------|
| 90% | 1.645 | $\bar{x} \pm 1.645 \cdot \text{SE}$ |
| 95% | 1.960 | $\bar{x} \pm 1.960 \cdot \text{SE}$ |
| 99% | 2.576 | $\bar{x} \pm 2.576 \cdot \text{SE}$ |

**Relaci√≥n inversa**: Mayor confianza ‚Üí Intervalo m√°s ancho

```{r ic-niveles, echo=TRUE, fig.cap="Intervalos de confianza con diferentes niveles"}
# Ejemplo con ingreso promedio
media <- 550
se <- 35

niveles <- c(0.90, 0.95, 0.99)
z_valores <- qnorm(1 - (1 - niveles)/2)

resultados <- data.frame(
  nivel = paste0(niveles * 100, "%"),
  z = round(z_valores, 3),
  inferior = round(media - z_valores * se, 0),
  superior = round(media + z_valores * se, 0)
)

resultados$ancho <- resultados$superior - resultados$inferior

print(resultados)
```

```{r plot-ic-niveles, echo=FALSE, fig.cap="Visualizaci√≥n de ICs con diferentes niveles de confianza"}
library(ggplot2)

df_ic <- data.frame(
  nivel = factor(c("90%", "95%", "99%"),
                 levels = c("99%", "95%", "90%")),
  media = rep(media, 3),
  inferior = resultados$inferior,
  superior = resultados$superior
)

ggplot(df_ic, aes(y = nivel)) +
  geom_point(aes(x = media), size = 4, color = "#e74c3c") +
  geom_errorbarh(aes(xmin = inferior, xmax = superior),
                 height = 0.2, size = 1, color = "#3498db") +
  geom_vline(xintercept = media, linetype = "dashed", alpha = 0.5) +
  labs(
    title = "Intervalos de Confianza: Mayor confianza = Intervalo m√°s ancho",
    subtitle = paste0("Media muestral = $", media, " mil, SE = $", se, " mil"),
    x = "Ingreso mensual (miles de $)",
    y = "Nivel de confianza"
  ) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 12, face = "bold"))
```


::: {.callout-note .callout-avanzado collapse="true"}
## üéì M√©todos Cuantitativos Avanzados

### Determinaci√≥n del tama√±o muestral

Para determinar el tama√±o muestral necesario para un margen de error deseado:

**Para proporciones:** $n = \left(\frac{z}{E}\right)^2 \cdot p(1-p)$

Usando $p = 0.5$ (peor caso, m√°xima varianza):

```{r tabla-n, echo=FALSE}
library(knitr)

margenes <- c(0.01, 0.02, 0.03, 0.04, 0.05, 0.10)
confianzas <- c(0.90, 0.95, 0.99)

calcular_n <- function(E, conf) {
  z <- qnorm(1 - (1 - conf)/2)
  ceiling((z / E)^2 * 0.25)
}

tabla <- expand.grid(
  Margen = margenes,
  Confianza = confianzas
)

tabla$n <- mapply(calcular_n, tabla$Margen, tabla$Confianza)

tabla_ancha <- reshape(tabla,
                       idvar = "Margen",
                       timevar = "Confianza",
                       direction = "wide")

colnames(tabla_ancha) <- c("Margen error", "90%", "95%", "99%")
tabla_ancha[, 1] <- paste0("¬±", tabla_ancha[, 1] * 100, "%")

kable(tabla_ancha,
      caption = "Tama√±o muestral necesario para estimar proporci√≥n (p=0.5)",
      align = c("l", "r", "r", "r"))
```

**Para medias:** $n = \left(\frac{z \cdot \sigma}{E}\right)^2$

donde $\sigma$ es la desviaci√≥n est√°ndar poblacional (estimada de estudios previos).
:::

### Simulaci√≥n de ICs

Demostremos con simulaci√≥n qu√© significa "95% de confianza":

```{r simulacion-ic, echo=TRUE, fig.height=7, fig.cap="Simulaci√≥n de 100 intervalos de confianza al 95%"}
# Par√°metros poblacionales conocidos (para la simulaci√≥n)
mu_real <- 500
sigma_real <- 120
n <- 50

# Tomamos 100 muestras y calculamos IC para cada una
set.seed(2025)
n_simulaciones <- 100

resultados_sim <- data.frame(
  muestra = 1:n_simulaciones,
  media = numeric(n_simulaciones),
  ic_inf = numeric(n_simulaciones),
  ic_sup = numeric(n_simulaciones)
)

for (i in 1:n_simulaciones) {
  muestra <- rnorm(n, mean = mu_real, sd = sigma_real)
  media <- mean(muestra)
  se <- sd(muestra) / sqrt(n)
  t_crit <- qt(0.975, df = n - 1)

  resultados_sim$media[i] <- media
  resultados_sim$ic_inf[i] <- media - t_crit * se
  resultados_sim$ic_sup[i] <- media + t_crit * se
}

# ¬øCu√°ntos ICs contienen Œº?
resultados_sim$contiene_mu <- (resultados_sim$ic_inf <= mu_real &
                                 resultados_sim$ic_sup >= mu_real)

prop_contiene <- mean(resultados_sim$contiene_mu)

cat("De", n_simulaciones, "intervalos de confianza al 95%:\n")
cat(sum(resultados_sim$contiene_mu), "contienen el verdadero valor Œº =", mu_real, "\n")
cat("Proporci√≥n:", round(prop_contiene, 3), "\n")
cat("(Esper√°bamos ~0.95)\n")
```

```{r plot-sim-ic, echo=FALSE, fig.height=8, fig.cap="100 intervalos de confianza: los verdes contienen Œº, los rojos no"}
# Mostrar solo primeros 50 para claridad visual
resultados_plot <- resultados_sim[1:50, ]
resultados_plot$muestra <- factor(1:50)

ggplot(resultados_plot, aes(y = muestra)) +
  geom_point(aes(x = media), size = 2) +
  geom_errorbarh(aes(xmin = ic_inf, xmax = ic_sup,
                     color = contiene_mu),
                 height = 0, size = 0.8) +
  geom_vline(xintercept = mu_real, linetype = "dashed",
             color = "black", size = 1.2) +
  scale_color_manual(values = c("FALSE" = "#e74c3c", "TRUE" = "#2ecc71"),
                     labels = c("No contiene Œº", "Contiene Œº")) +
  labs(
    title = "Interpretaci√≥n de Intervalos de Confianza al 95%",
    subtitle = paste0("L√≠nea vertical = Œº verdadero (500). ",
                      sum(resultados_plot$contiene_mu), " de 50 ICs contienen Œº"),
    x = "Valor",
    y = "N√∫mero de muestra",
    color = NULL
  ) +
  theme_minimal() +
  theme(
    legend.position = "top",
    axis.text.y = element_blank()
  )
```

::: {.callout-important}
## Mensaje clave
El "95%" NO se refiere a una muestra individual, sino al **procedimiento**. Si lo repiti√©ramos infinitas veces, 95% de los intervalos contendr√≠an $\mu$. Para cualquier muestra espec√≠fica, o contiene $\mu$ o no (pero no sabemos cu√°l).
:::

## Resumen {.unnumbered}

| Concepto | Descripci√≥n |
|----------|-------------|
| **Par√°metros** ($\mu$, $p$) | Valores poblacionales fijos (desconocidos) |
| **Estad√≠sticos** ($\bar{x}$, $\hat{p}$) | Valores muestrales variables (observados) |
| **Error est√°ndar** | SD de la distribuci√≥n muestral: $\text{SE} = s/\sqrt{n}$ |
| **IC 95%** | $\bar{x} \pm 1.96 \cdot \text{SE}$ |

**F√≥rmulas esenciales:**

| Concepto | Media | Proporci√≥n |
|:---------|:------|:-----------|
| Error est√°ndar | $\text{SE} = s/\sqrt{n}$ | $\text{SE} = \sqrt{\hat{p}(1-\hat{p})/n}$ |
| IC 95% | $\bar{x} \pm 1.96 \cdot \text{SE}$ | $\hat{p} \pm 1.96 \cdot \text{SE}$ |
| Tama√±o muestral | $n = (z\sigma/E)^2$ | $n = (z/E)^2 \cdot 0.25$ |

**Conexi√≥n con pr√≥ximos cap√≠tulos:**

- **Cap. 9** extender√° la l√≥gica de inferencia a **pruebas de hip√≥tesis**
- **Caps. 10-11** aplicar√°n ICs y pruebas para comparar grupos y analizar relaciones

## Lecturas recomendadas {.unnumbered}

**Fundamentos de inferencia estad√≠stica:**

Agresti, A., & Finlay, B. (2009). *Statistical Methods for the Social Sciences* (4th ed.). Pearson.  
‚Üí Cap√≠tulo 5 cubre estimaci√≥n estad√≠stica, intervalos de confianza y error est√°ndar con claridad ejemplar.

**Aplicaciones en an√°lisis de datos sociales:**

Llaudet, E., & Imai, K. (2022). *Data Analysis for Social Science: A Friendly and Practical Introduction*. Princeton University Press.  
‚Üí Cap√≠tulo 7 sobre incertidumbre conecta teor√≠a con aplicaciones pr√°cticas en investigaci√≥n cuantitativa.

**Recurso complementario de acceso libre:**

Diez, D., Barr, C., & √áetinkaya-Rundel, M. (2019). *OpenIntro Statistics* (4th ed.). [Disponible gratis en https://www.openintro.org/book/os/]  
‚Üí Cap√≠tulo 4 sobre fundamentos de inferencia, con ejercicios y ejemplos interactivos.


## Ejercicios {.unnumbered}

::: {.ejercicios}

**1. Error est√°ndar**

Una encuesta con n=900 encuentra que 43% apoya una reforma.

a) Calcula el error est√°ndar de la proporci√≥n
b) ¬øC√≥mo cambiar√≠a el SE si la muestra fuera de n=400?
c) ¬øCu√°ntas personas necesitar√≠as encuestar para reducir el SE a la mitad del original?

**2. Intervalos de confianza para proporciones**

En una encuesta de 1,200 votantes, 528 declaran que votar√°n en las pr√≥ximas elecciones.

a) Calcula la proporci√≥n muestral
b) Construye IC 95% manualmente
c) Verifica con `prop.test()` en R
d) Interpreta el intervalo en lenguaje no t√©cnico

**3. Intervalos de confianza para medias**

Datos de ingreso mensual (en miles de pesos) de 50 hogares:

```{r eval=FALSE}
set.seed(456)
ingresos <- rlnorm(50, meanlog = log(550), sdlog = 0.6)
```

a) Calcula media y desviaci√≥n est√°ndar muestral
b) Construye IC 95% manualmente
c) Verifica con `t.test()` en R
d) Construye IC 90% y 99%. ¬øQu√© observas sobre el ancho de los intervalos?

**4. Tama√±o muestral**

Quieres estimar la proporci√≥n de votantes que apoya una ley, con margen de error de ¬±2 puntos porcentuales y 95% de confianza.

a) ¬øQu√© tama√±o muestral necesitas? (usa f√≥rmula conservadora con p=0.5)
b) Si solo tienes presupuesto para 600 encuestas, ¬øcu√°l ser√° tu margen de error?
c) ¬øC√≥mo cambia el tama√±o muestral necesario si quieres 99% de confianza?

**5. Simulaci√≥n de intervalos de confianza**

```{r eval=FALSE}
# Simula 200 muestras de una poblaci√≥n conocida
set.seed(2024)
mu_real <- 100
sigma_real <- 15
n <- 50

resultados <- data.frame(
  muestra = 1:200,
  media = numeric(200),
  ic_inf = numeric(200),
  ic_sup = numeric(200)
)

for (i in 1:200) {
  muestra <- rnorm(n, mu_real, sigma_real)
  test <- t.test(muestra, conf.level = 0.95)
  resultados$media[i] <- mean(muestra)
  resultados$ic_inf[i] <- test$conf.int[1]
  resultados$ic_sup[i] <- test$conf.int[2]
}
```

a) Ejecuta la simulaci√≥n y calcula: ¬øcu√°ntos ICs contienen Œº = 100?
b) ¬øEl resultado es cercano al 95% esperado?
c) Grafica los primeros 50 ICs (como en el cap√≠tulo)
d) Repite con nivel de confianza 90%. ¬øCu√°ntos contienen Œº ahora?

**6. Interpretaci√≥n cr√≠tica**

Un informe de encuesta reporta: "El 47% de los chilenos aprueba la gesti√≥n del gobierno, con un margen de error de ¬±3 puntos porcentuales."

a) ¬øQu√© tama√±o muestral aproximado tuvo la encuesta?
b) ¬øCu√°l es el IC 95%?
c) ¬øPodemos concluir que "la mayor√≠a desaprueba"? Justifica
d) Si otra encuesta con n=2000 reporta 49% de aprobaci√≥n, ¬øson los resultados "contradictorios"?

:::

::: {#refs}
:::
