# Inferencia estad√≠stica {#inferencia}

## Objetivos del cap√≠tulo {.unnumbered}

Al finalizar este cap√≠tulo, ser√°s capaz de:

- Comprender la l√≥gica de la inferencia: generalizar desde muestras a poblaciones
- Distinguir entre par√°metros poblacionales y estad√≠sticos muestrales
- Entender qu√© es el error est√°ndar y por qu√© importa
- Construir e interpretar intervalos de confianza
- Evaluar qu√© tan grande debe ser una muestra

## El problema central: de muestras a poblaciones

En ciencias sociales casi nunca tenemos acceso a poblaciones completas. Queremos saber cosas como:

- ¬øCu√°l es el apoyo real a la reforma de pensiones entre todos los chilenos?
- ¬øCu√°l es el ingreso promedio de hogares en Am√©rica Latina?
- ¬øQu√© proporci√≥n de electores cambia su voto entre elecciones?

Pero solo podemos encuestar a cientos o miles de personas, no a los millones que componen la poblaci√≥n. La **inferencia estad√≠stica** es el proceso de usar datos de una muestra para hacer afirmaciones sobre una poblaci√≥n, reconociendo la incertidumbre asociada.

### Ejemplo motivador: Encuestas electorales

Antes de las elecciones presidenciales 2021 en Chile (segunda vuelta), m√∫ltiples encuestadoras reportaron resultados diferentes:

```{r encuestas-2021, echo=FALSE}
library(ggplot2)
library(dplyr)

encuestas <- data.frame(
  encuestadora = c("Cadem", "Activa", "Data Influye", "Criteria"),
  boric = c(51, 52, 50, 51),
  kast = c(39, 40, 41, 40),
  n = c(1015, 1200, 1400, 1500),
  fecha = c("10-12 dic", "10-12 dic", "9-12 dic", "10-13 dic")
)

encuestas_long <- encuestas %>%
  tidyr::pivot_longer(cols = c(boric, kast),
                      names_to = "candidato",
                      values_to = "porcentaje") %>%
  mutate(candidato = ifelse(candidato == "boric", "Boric", "Kast"))

ggplot(encuestas_long, aes(x = encuestadora, y = porcentaje,
                            fill = candidato, label = porcentaje)) +
  geom_col(position = "dodge", width = 0.7) +
  geom_text(position = position_dodge(width = 0.7), vjust = -0.5) +
  scale_fill_manual(values = c("Boric" = "#3498db", "Kast" = "#e74c3c")) +
  labs(
    title = "Encuestas presidenciales Chile 2021 (2da vuelta)",
    subtitle = "Diferentes muestras producen diferentes estimaciones",
    x = NULL,
    y = "Porcentaje de intenci√≥n de voto (%)",
    fill = "Candidato"
  ) +
  theme_minimal() +
  theme(legend.position = "top")
```

**Preguntas clave:**

1. ¬øPor qu√© las encuestas difieren si todas miden "lo mismo"?
2. ¬øCu√°n confiables son estos n√∫meros?
3. ¬øQu√© tan grande debe ser la muestra?

## Muestras y poblaciones: Conceptos b√°sicos

### Lo que queremos saber vs. lo que podemos observar

| Concepto | Lo que es | Ejemplo |
|----------|-----------|---------|
| **Poblaci√≥n** | El grupo completo que nos interesa | Todos los votantes de Chile (15 millones) |
| **Muestra** | El subconjunto que realmente observamos | 1,200 personas encuestadas |
| **Par√°metro** | El valor real en la poblaci√≥n (desconocido) | El verdadero apoyo a Boric |
| **Estad√≠stico** | El valor calculado en nuestra muestra | 51% de nuestra muestra apoya a Boric |

::: {.callout-note}
## La idea central de la inferencia

Usamos lo que **observamos** (estad√≠sticos de la muestra) para **estimar** lo que **queremos saber** (par√°metros de la poblaci√≥n).

Pero como la muestra es solo una parte de la poblaci√≥n, nuestra estimaci√≥n tendr√° **incertidumbre**. La inferencia nos ayuda a cuantificar esa incertidumbre.
:::

### ¬øPor qu√© diferentes muestras dan diferentes resultados?

Imagina que la poblaci√≥n tiene 40% de apoyo a cierta pol√≠tica. Si tomas una muestra de 1,000 personas:

```{r muestreo-simple, echo=TRUE}
set.seed(2024)

# Poblaci√≥n de 10,000 votantes (40% apoya)
poblacion <- c(rep(1, 4000), rep(0, 6000))  # 1 = apoya
p_verdadero <- mean(poblacion)

cat("Valor real en la poblaci√≥n: p =", p_verdadero, "(40%)\n\n")

# Tomamos una muestra de n=1000
muestra <- sample(poblacion, size = 1000, replace = FALSE)
p_muestra <- mean(muestra)

cat("Valor en nuestra muestra: pÃÇ =", p_muestra, "\n")
cat("Diferencia con el valor real:", round((p_muestra - p_verdadero) * 100, 1), "puntos\n")
```

Si tomamos otra muestra, obtendremos un resultado diferente:

```{r otra-muestra}
# Otra muestra diferente
muestra2 <- sample(poblacion, size = 1000, replace = FALSE)
cat("Segunda muestra: pÃÇ =", mean(muestra2), "\n")

muestra3 <- sample(poblacion, size = 1000, replace = FALSE)
cat("Tercera muestra: pÃÇ =", mean(muestra3), "\n")
```

Esta variaci√≥n entre muestras es **normal y esperada**. No significa que haya error - es simplemente la naturaleza del muestreo.

## El error est√°ndar: Midiendo la incertidumbre

### ¬øQu√© tan variable es nuestro estad√≠stico?

El **error est√°ndar** mide cu√°nto var√≠a t√≠picamente un estad√≠stico de muestra en muestra.

- Error est√°ndar **peque√±o** = Las muestras dan resultados muy similares = Alta precisi√≥n
- Error est√°ndar **grande** = Las muestras dan resultados muy diferentes = Baja precisi√≥n

### Visualizando la variabilidad

Si tomamos muchas muestras y calculamos la proporci√≥n en cada una, obtenemos una distribuci√≥n:

```{r dist-muestral-prop, echo=TRUE, fig.cap="Distribuci√≥n de proporciones en 1000 muestras diferentes"}
# Tomamos 1000 muestras de n=500 cada una
set.seed(123)
proporciones <- replicate(1000, mean(sample(poblacion, 500)))

# Visualizamos
hist(proporciones, breaks = 30,
     main = "Distribuci√≥n de 1000 proporciones muestrales",
     xlab = "Proporci√≥n observada", ylab = "Frecuencia",
     col = "#3498db", border = "white")
abline(v = 0.40, col = "red", lwd = 2, lty = 2)
legend("topright", "Valor real (0.40)", col = "red", lty = 2, lwd = 2)
```

```{r stats-dist}
cat("Estad√≠sticas de las 1000 proporciones:\n")
cat("Promedio:", round(mean(proporciones), 3), "(muy cerca del valor real 0.40)\n")
cat("Desviaci√≥n est√°ndar:", round(sd(proporciones), 4), "\n")
cat("Esta desviaci√≥n est√°ndar ES el error est√°ndar\n")
```

### Lo que determina el error est√°ndar

El error est√°ndar depende principalmente de **dos factores**:

1. **Tama√±o de muestra (n):** Muestras m√°s grandes = menor error
2. **Variabilidad en la poblaci√≥n:** M√°s variabilidad = mayor error

```{r se-por-n, echo=FALSE, fig.cap="El error est√°ndar disminuye con muestras m√°s grandes"}
n_seq <- seq(100, 2000, by = 50)
se_seq <- sqrt(0.5 * 0.5 / n_seq)

data.frame(n = n_seq, se = se_seq) %>%
  ggplot(aes(x = n, y = se)) +
  geom_line(color = "#3498db", linewidth = 1.2) +
  geom_hline(yintercept = c(0.02, 0.03, 0.04, 0.05),
             linetype = "dashed", alpha = 0.5) +
  labs(
    title = "Error est√°ndar vs. tama√±o de muestra",
    subtitle = "Muestras m√°s grandes producen estimaciones m√°s precisas",
    x = "Tama√±o muestral (n)",
    y = "Error est√°ndar"
  ) +
  scale_y_continuous(labels = scales::percent) +
  theme_minimal()
```

::: {.callout-important}
## La regla del cuatro

Para **reducir el error est√°ndar a la mitad**, necesitas **cuadruplicar** el tama√±o de la muestra.

- n = 400 ‚Üí Error ‚âà 2.5%
- n = 1,600 ‚Üí Error ‚âà 1.25% (mitad)
- n = 6,400 ‚Üí Error ‚âà 0.625% (cuarta parte)

Esto explica por qu√© las encuestas t√≠picamente usan 1,000-1,500 personas: es un buen balance entre precisi√≥n y costo.
:::

### Calculando el error est√°ndar en R

**Para una proporci√≥n:**

```{r se-proporcion-ejemplo}
# Encuesta: proporci√≥n que apoya pol√≠tica X
n <- 1200
apoyos <- 510
p_hat <- apoyos / n

# Error est√°ndar
se_p <- sqrt(p_hat * (1 - p_hat) / n)

cat("Muestra de n =", n, "personas\n")
cat("Proporci√≥n que apoya:", round(p_hat * 100, 1), "%\n")
cat("Error est√°ndar:", round(se_p * 100, 2), "puntos porcentuales\n")
```

**Para una media:**

```{r se-media-ejemplo}
# Datos de ingresos (en miles de pesos)
set.seed(456)
ingresos <- rlnorm(500, meanlog = log(600), sdlog = 0.7)

n <- length(ingresos)
media <- mean(ingresos)
s <- sd(ingresos)
se <- s / sqrt(n)

cat("Muestra de n =", n, "hogares\n")
cat("Ingreso promedio: $", round(media, 0), " mil\n", sep = "")
cat("Desviaci√≥n est√°ndar de ingresos: $", round(s, 0), " mil\n", sep = "")
cat("Error est√°ndar de la media: $", round(se, 0), " mil\n", sep = "")
```

::: {.callout-note}
## Error est√°ndar vs. Desviaci√≥n est√°ndar

No confundas estos conceptos:

| Concepto | Qu√© mide | En nuestro ejemplo |
|----------|----------|-------------------|
| **Desviaci√≥n est√°ndar (s)** | Cu√°nto var√≠an los datos individuales | Los ingresos var√≠an ¬±$480 mil entre hogares |
| **Error est√°ndar (SE)** | Cu√°nto var√≠a nuestra estimaci√≥n del promedio | Nuestra estimaci√≥n del promedio var√≠a ¬±$21 mil |

El SE siempre es menor que s (porque promediar reduce la variabilidad).
:::

::: {.callout-note .callout-avanzado collapse="true"}
## üéì Avanzado: F√≥rmulas del error est√°ndar

**Para la media:**
$$\text{SE}(\bar{x}) = \frac{s}{\sqrt{n}}$$

Donde $s$ es la desviaci√≥n est√°ndar muestral y $n$ el tama√±o de muestra.

**Para una proporci√≥n:**
$$\text{SE}(\hat{p}) = \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$$

### El Teorema del L√≠mite Central

Si tomamos muchas muestras de tama√±o $n$ de cualquier poblaci√≥n, la distribuci√≥n de las medias muestrales:

1. Tendr√° forma aproximadamente Normal (para $n \geq 30$)
2. Estar√° centrada en la media poblacional
3. Tendr√° desviaci√≥n est√°ndar igual al error est√°ndar

Esto es fundamental porque nos permite usar la distribuci√≥n Normal para hacer inferencia, sin importar la forma de la distribuci√≥n original.

```{r tlc-demo, fig.height=6}
# Poblaci√≥n muy asim√©trica
set.seed(123)
poblacion_ingresos <- rlnorm(100000, meanlog = log(500), sdlog = 0.6)

# Distribuci√≥n muestral
medias_muestrales <- replicate(5000, mean(sample(poblacion_ingresos, 100)))

par(mfrow = c(2, 1))
hist(sample(poblacion_ingresos, 5000), breaks = 50,
     main = "Poblaci√≥n (asim√©trica)", xlab = "Ingreso", col = "#3498db")
hist(medias_muestrales, breaks = 40,
     main = "Distribuci√≥n de medias muestrales (Normal)",
     xlab = "Media muestral", col = "#2ecc71")
par(mfrow = c(1, 1))
```
:::

## Intervalos de confianza

### ¬øQu√© es un intervalo de confianza?

En lugar de dar una sola estimaci√≥n ("el apoyo es 45%"), un intervalo de confianza da un **rango de valores plausibles** ("el apoyo est√° entre 42% y 48%").

Este rango incorpora la incertidumbre debida al muestreo.

### La l√≥gica del intervalo de confianza

Un intervalo de confianza al 95% se construye de manera que, si repitieras el muestreo muchas veces:

- Aproximadamente 95% de los intervalos contendr√≠an el valor verdadero
- Aproximadamente 5% no lo contendr√≠an

```{r simulacion-ic, echo=TRUE, fig.height=6, fig.cap="Simulaci√≥n de intervalos de confianza"}
# Par√°metro verdadero
mu_real <- 500
n <- 50

# Tomamos 50 muestras y construimos IC para cada una
set.seed(2025)
resultados <- data.frame(
  muestra = 1:50,
  media = numeric(50),
  ic_inf = numeric(50),
  ic_sup = numeric(50)
)

for (i in 1:50) {
  datos <- rnorm(n, mean = mu_real, sd = 120)
  test <- t.test(datos, conf.level = 0.95)
  resultados$media[i] <- mean(datos)
  resultados$ic_inf[i] <- test$conf.int[1]
  resultados$ic_sup[i] <- test$conf.int[2]
}

resultados$contiene <- (resultados$ic_inf <= mu_real & resultados$ic_sup >= mu_real)

cat("De 50 intervalos de confianza al 95%:\n")
cat(sum(resultados$contiene), "contienen el valor verdadero (Œº = 500)\n")
cat("Eso es el", round(mean(resultados$contiene) * 100), "%\n")
```

```{r plot-ic, echo=FALSE, fig.height=7}
resultados$muestra <- factor(resultados$muestra)

ggplot(resultados, aes(y = muestra)) +
  geom_point(aes(x = media), size = 2) +
  geom_errorbarh(aes(xmin = ic_inf, xmax = ic_sup, color = contiene),
                 height = 0, linewidth = 0.8) +
  geom_vline(xintercept = mu_real, linetype = "dashed",
             color = "black", linewidth = 1.2) +
  scale_color_manual(values = c("FALSE" = "#e74c3c", "TRUE" = "#2ecc71"),
                     labels = c("No contiene Œº", "Contiene Œº")) +
  labs(
    title = "50 intervalos de confianza al 95%",
    subtitle = "La l√≠nea vertical es el valor real. Los intervalos verdes lo contienen.",
    x = "Valor", y = "Muestra",
    color = NULL
  ) +
  theme_minimal() +
  theme(legend.position = "top", axis.text.y = element_blank())
```

::: {.callout-warning}
## Interpretaci√≥n correcta del IC

**INCORRECTO:** "Hay 95% de probabilidad de que el valor real est√© en este intervalo"

**CORRECTO:** "Si repiti√©ramos este proceso muchas veces, aproximadamente 95% de los intervalos contendr√≠an el valor real"

El valor real es fijo (aunque desconocido). Lo que var√≠a es el intervalo de muestra en muestra.
:::

### Calculando intervalos de confianza en R

**Para una media: usar `t.test()`**

```{r ic-media-r}
# Datos de ingresos
set.seed(789)
ingresos <- rlnorm(200, meanlog = log(550), sdlog = 0.65)

# Intervalo de confianza
resultado <- t.test(ingresos, conf.level = 0.95)
resultado
```

**C√≥mo leer el output de `t.test()`:**

| Elemento | Significado |
|----------|-------------|
| `t = 47.066` | Estad√≠stico de prueba (lo usaremos en el pr√≥ximo cap√≠tulo) |
| `df = 199` | Grados de libertad |
| `95 percent confidence interval` | El intervalo de confianza |
| `mean of x` | La media de nuestra muestra |

```{r interpretacion-ic}
cat("Interpretaci√≥n:\n")
cat("El ingreso promedio en nuestra muestra es $", round(mean(ingresos), 0), " mil\n", sep = "")
cat("Estamos 95% confiados de que el promedio poblacional est√° entre\n")
cat("$", round(resultado$conf.int[1], 0), " y $", round(resultado$conf.int[2], 0), " mil\n", sep = "")
```

**Para una proporci√≥n: usar `prop.test()`**

```{r ic-prop-r}
# 780 de 1500 encuestados declaran que votar√°n
resultado_prop <- prop.test(x = 780, n = 1500, conf.level = 0.95)
resultado_prop
```

```{r interpretacion-prop}
cat("Interpretaci√≥n:\n")
cat("El", round(780/1500 * 100, 1), "% de nuestra muestra declara que votar√°\n")
cat("IC 95%: entre", round(resultado_prop$conf.int[1] * 100, 1),
    "% y", round(resultado_prop$conf.int[2] * 100, 1), "%\n")
```

### Diferentes niveles de confianza

No estamos limitados a 95%. Podemos construir intervalos con cualquier nivel:

```{r niveles-confianza}
# El mismo dato con diferentes niveles de confianza
datos <- ingresos

ic_90 <- t.test(datos, conf.level = 0.90)$conf.int
ic_95 <- t.test(datos, conf.level = 0.95)$conf.int
ic_99 <- t.test(datos, conf.level = 0.99)$conf.int

cat("Intervalos de confianza para el ingreso promedio:\n\n")
cat("IC 90%: [", round(ic_90[1], 0), ", ", round(ic_90[2], 0), "] - Ancho:", round(ic_90[2] - ic_90[1], 0), "\n")
cat("IC 95%: [", round(ic_95[1], 0), ", ", round(ic_95[2], 0), "] - Ancho:", round(ic_95[2] - ic_95[1], 0), "\n")
cat("IC 99%: [", round(ic_99[1], 0), ", ", round(ic_99[2], 0), "] - Ancho:", round(ic_99[2] - ic_99[1], 0), "\n")
```

::: {.callout-note}
## El trade-off confianza vs. precisi√≥n

- **Mayor confianza** (99% vs 95%) ‚Üí Intervalo **m√°s ancho** (menos preciso)
- **Menor confianza** (90% vs 95%) ‚Üí Intervalo **m√°s angosto** (m√°s preciso)

El 95% es una convenci√≥n que balancea ambos aspectos.
:::

## ¬øQu√© tan grande debe ser la muestra?

### El margen de error en encuestas

Cuando una encuesta reporta "margen de error ¬±3%", esto se refiere al error est√°ndar multiplicado aproximadamente por 2 (para obtener un IC al 95%).

| Tama√±o de muestra | Margen de error aproximado (IC 95%) |
|-------------------|-------------------------------------|
| 400 | ¬±5% |
| 600 | ¬±4% |
| 1,000 | ¬±3% |
| 1,500 | ¬±2.5% |
| 2,400 | ¬±2% |

### ¬øPor qu√© no encuestar a m√°s personas?

Porque la precisi√≥n aumenta lentamente despu√©s de cierto punto:

- Pasar de n=400 a n=1,600 (√ó4) reduce el error a la mitad
- Pasar de n=1,600 a n=6,400 (√ó4) reduce el error a la mitad otra vez

El costo aumenta linealmente, pero la precisi√≥n mejora con la ra√≠z cuadrada. Por eso 1,000-1,500 es el "punto dulce" para encuestas t√≠picas.

::: {.callout-note .callout-avanzado collapse="true"}
## üéì Avanzado: F√≥rmulas del intervalo de confianza

**Para la media (n grande o datos normales):**
$$\text{IC}_{95\%} = \bar{x} \pm 1.96 \times \frac{s}{\sqrt{n}}$$

**Para la proporci√≥n:**
$$\text{IC}_{95\%} = \hat{p} \pm 1.96 \times \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$$

Donde 1.96 es el valor cr√≠tico de la distribuci√≥n Normal para 95% de confianza.

### Determinaci√≥n del tama√±o muestral

Para proporciones, si quieres un margen de error $E$ con confianza 95%:

$$n = \left(\frac{1.96}{E}\right)^2 \times 0.25$$

Usando $p = 0.5$ (el caso m√°s conservador).

| Margen deseado | n necesario |
|----------------|-------------|
| ¬±5% | 385 |
| ¬±3% | 1,068 |
| ¬±2% | 2,401 |
| ¬±1% | 9,604 |

Para medias:
$$n = \left(\frac{1.96 \times \sigma}{E}\right)^2$$

Donde $\sigma$ es la desviaci√≥n est√°ndar poblacional (estimada de estudios previos).
:::

## Resumen: Conceptos clave {.unnumbered}

### Vocabulario esencial

| Concepto | Significado | Ejemplo |
|----------|-------------|---------|
| Par√°metro | Valor real en la poblaci√≥n | El verdadero % que apoya una pol√≠tica |
| Estad√≠stico | Valor calculado en la muestra | El 45% que observamos en nuestra encuesta |
| Error est√°ndar | Cu√°nto var√≠a el estad√≠stico entre muestras | ¬±3 puntos porcentuales |
| Intervalo de confianza | Rango de valores plausibles para el par√°metro | Entre 42% y 48% |

### Funciones en R

| Situaci√≥n | Funci√≥n | Ejemplo |
|-----------|---------|---------|
| IC para una media | `t.test(datos)` | `t.test(ingresos)` |
| IC para una proporci√≥n | `prop.test(√©xitos, n)` | `prop.test(450, 1000)` |
| Cambiar nivel de confianza | Agregar `conf.level` | `t.test(datos, conf.level = 0.99)` |

### Ideas principales

1. **El muestreo tiene incertidumbre:** Diferentes muestras dan diferentes resultados
2. **El error est√°ndar cuantifica esa incertidumbre:** Mide cu√°nto var√≠an los estad√≠sticos
3. **Muestras m√°s grandes = menos incertidumbre:** Pero con rendimientos decrecientes
4. **El intervalo de confianza da un rango:** M√°s informativo que un solo n√∫mero

## Lecturas recomendadas {.unnumbered}

**Fundamentos de inferencia estad√≠stica:**

Agresti, A., & Finlay, B. (2009). *Statistical Methods for the Social Sciences* (4th ed.). Pearson.
‚Üí Cap√≠tulo 5 cubre estimaci√≥n estad√≠stica e intervalos de confianza con claridad ejemplar.

**Aplicaciones en an√°lisis de datos sociales:**

Llaudet, E., & Imai, K. (2022). *Data Analysis for Social Science: A Friendly and Practical Introduction*. Princeton University Press.
‚Üí Cap√≠tulo 7 sobre incertidumbre conecta teor√≠a con aplicaciones pr√°cticas.

**Recurso complementario de acceso libre:**

Diez, D., Barr, C., & √áetinkaya-Rundel, M. (2019). *OpenIntro Statistics* (4th ed.). [Disponible gratis en https://www.openintro.org/book/os/]
‚Üí Cap√≠tulo 4 sobre fundamentos de inferencia, con ejercicios interactivos.

## Ejercicios {.unnumbered}

::: {.ejercicios}

**1. Error est√°ndar**

Una encuesta con n=900 encuentra que 43% apoya una reforma.

a) Calcula el error est√°ndar de la proporci√≥n
b) ¬øC√≥mo cambiar√≠a el SE si la muestra fuera de n=400?
c) ¬øCu√°ntas personas necesitar√≠as encuestar para reducir el SE a la mitad?

**2. Intervalos de confianza para proporciones**

En una encuesta de 1,200 votantes, 528 declaran que votar√°n en las pr√≥ximas elecciones.

a) Usa `prop.test()` para calcular el IC 95%
b) Interpreta el intervalo en lenguaje no t√©cnico
c) ¬øPodemos afirmar que "menos de la mitad votar√°"?

**3. Intervalos de confianza para medias**

```{r eval=FALSE}
set.seed(456)
ingresos <- rlnorm(50, meanlog = log(550), sdlog = 0.6)
```

a) Usa `t.test()` para calcular el IC 95%
b) Calcula tambi√©n el IC 90% y 99%
c) ¬øQu√© observas sobre el ancho de los intervalos?

**4. Interpretaci√≥n de resultados**

Un informe de encuesta reporta: "El 47% de los chilenos aprueba la gesti√≥n del gobierno, con un margen de error de ¬±3 puntos porcentuales."

a) ¬øCu√°l es el intervalo de confianza impl√≠cito?
b) ¬øPodemos concluir que "la mayor√≠a desaprueba"? Justifica
c) Si otra encuesta reporta 49% de aprobaci√≥n, ¬øson los resultados contradictorios?

**5. Simulaci√≥n**

```{r eval=FALSE}
set.seed(2024)
mu_real <- 100

# Toma 100 muestras y construye IC para cada una
resultados <- replicate(100, {
  muestra <- rnorm(50, mean = mu_real, sd = 15)
  t.test(muestra)$conf.int
})
```

a) ¬øCu√°ntos de los 100 ICs contienen el valor real (Œº = 100)?
b) ¬øEs este resultado cercano al 95% esperado?

:::
