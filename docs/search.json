[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Métodos Cuantitativos para Ciencias Sociales",
    "section": "",
    "text": "Prefacio",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#objetivo-de-este-manual",
    "href": "index.html#objetivo-de-este-manual",
    "title": "Métodos Cuantitativos para Ciencias Sociales",
    "section": "Objetivo de este manual",
    "text": "Objetivo de este manual\nEste es un manual de preparación para el examen del curso Métodos Cuantitativos Introductorios. Su propósito es presentar de forma clara y concisa los conceptos fundamentales que necesitas dominar para aprobar el curso.\nEl manual está diseñado para ser una guía de estudio práctica: cada capítulo cubre los temas esenciales, con ejemplos concretos y ejercicios para practicar. Úsalo como referencia rápida para repasar antes del examen.\n\n\n\n\n\n\nNotaContenido avanzado\n\n\n\nLas secciones marcadas como “Avanzado” contienen material complementario que va más allá de lo requerido para el examen. Puedes omitirlas en tu primera lectura y volver a ellas si deseas profundizar.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#por-qué-este-libro",
    "href": "index.html#por-qué-este-libro",
    "title": "Métodos Cuantitativos para Ciencias Sociales",
    "section": "¿Por qué este libro?",
    "text": "¿Por qué este libro?\nEste libro fue desarrollado como material del curso Métodos Cuantitativos Introductorios para estudiantes de Ciencia Política de la Universidad Diego Portales, 2025.\nA diferencia de textos que enfatizan la mecánica estadística, aquí privilegiamos la lógica de la investigación: cómo formular preguntas, operacionalizar conceptos, diseñar estrategias empíricas y evaluar evidencia. Los ejemplos provienen de la realidad política y social latinoamericana, utilizando datos de Chile y la región.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#organización-del-libro",
    "href": "index.html#organización-del-libro",
    "title": "Métodos Cuantitativos para Ciencias Sociales",
    "section": "Organización del libro",
    "text": "Organización del libro\nEl libro está organizado en cinco unidades:\n\nPrerequisitos (Caps 1-2): Repaso del método científico y diseño de investigación.\nUnidad 1 - Generalidades (Caps 3-4): Medición y trabajo con datos.\nUnidad 2 - Estadística Descriptiva (Caps 5-6): Medidas de resumen y visualización de datos.\nUnidad 3 - Inferencia Estadística (Caps 7-9): Probabilidad, muestreo y pruebas de hipótesis.\nUnidad 4 - Análisis Bivariado (Caps 10-11): Comparación de medias y regresión simple.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#software-y-convenciones",
    "href": "index.html#software-y-convenciones",
    "title": "Métodos Cuantitativos para Ciencias Sociales",
    "section": "Software y convenciones",
    "text": "Software y convenciones\nTodo el análisis se realiza con R, lenguaje de código abierto estándar en ciencias sociales cuantitativas. Los códigos aparecen en fuente monoespaciada con su output, los conceptos clave en negritas, y las referencias en formato APA.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#agradecimientos",
    "href": "index.html#agradecimientos",
    "title": "Métodos Cuantitativos para Ciencias Sociales",
    "section": "Agradecimientos",
    "text": "Agradecimientos\nEste proyecto es resultado de años de docencia en metodología cuantitativa. Agradezco a estudiantes que con sus preguntas obligaron a clarificar argumentos, y a colegas cuyas conversaciones enriquecieron este material.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "01-introduccion.html",
    "href": "01-introduccion.html",
    "title": "1  Introducción: El método científico en ciencias sociales",
    "section": "",
    "text": "Objetivos del capítulo\nAl finalizar este capítulo, serás capaz de:",
    "crumbs": [
      "I. Prerequisitos",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción: El método científico en ciencias sociales</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#objetivos-del-capítulo",
    "href": "01-introduccion.html#objetivos-del-capítulo",
    "title": "1  Introducción: El método científico en ciencias sociales",
    "section": "",
    "text": "Distinguir conocimiento científico de otras formas de conocimiento sobre la realidad social\nIdentificar los elementos del método científico aplicado a fenómenos políticos\nComprender la relación entre teoría y análisis empírico en ciencias sociales\nReconocer fortalezas y límites del enfoque cuantitativo para estudiar política",
    "crumbs": [
      "I. Prerequisitos",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción: El método científico en ciencias sociales</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#el-método-científico",
    "href": "01-introduccion.html#el-método-científico",
    "title": "1  Introducción: El método científico en ciencias sociales",
    "section": "1.1 El método científico",
    "text": "1.1 El método científico\nEl método científico es un procedimiento sistemático para producir conocimiento confiable sobre el mundo. No es exclusivo de las ciencias naturales. Las ciencias sociales —incluida la ciencia política— lo emplean para generar afirmaciones empíricas verificables sobre fenómenos sociales.\nTres características distinguen el conocimiento científico de otras formas de conocer:\n\nSistematicidad: Sigue procedimientos explícitos y replicables. Otro investigador, con los mismos datos y métodos, debería llegar a conclusiones similares.\nFalsabilidad: Las afirmaciones científicas pueden ser, en principio, refutadas por evidencia empírica (Popper, 1959). Una proposición que no puede ser contrastada con datos no es científica.1\nAcumulación: El conocimiento científico es acumulativo. Se construye sobre investigación previa, refinando teorías y mejorando mediciones (Kuhn, 1962).\n\n1 “El alma humana es inmortal” no es falsable empíricamente. “Las personas religiosas votan más por candidatos conservadores” sí es falsable mediante encuestas. Solo la segunda afirmación es científica en sentido metodológico.Esto no implica que el conocimiento científico sea “objetivo” en sentido ingenuo. Toda investigación parte de supuestos teóricos y decisiones metodológicas que reflejan posiciones epistemológicas. Pero estas decisiones deben ser transparentes y sometidas a escrutinio.\n\n\n\n\n\n\nNotaLas tres preguntas clave del método científico\n\n\n\nAntes de creer cualquier afirmación sobre el mundo social, pregúntate:\n\n¿Es sistemático? ¿Sigue procedimientos explícitos que otro podría replicar?\n¿Es falsable? ¿Qué evidencia lo refutaría? Si ninguna evidencia posible lo podría refutar, no es ciencia.\n¿Se basa en evidencia acumulada? ¿Dialoga con investigación previa o es una afirmación aislada?\n\nEstas preguntas aplican tanto para evaluar investigación ajena como para diseñar la propia.\n\n\nKing et al. (1994) argumentan que la lógica de inferencia en ciencias sociales es fundamentalmente la misma que en ciencias naturales: observar el mundo y extraer conclusiones válidas sobre patrones que trascienden las observaciones particulares.\n\nDesafíos específicos de las ciencias sociales\nLas ciencias sociales enfrentan desafíos específicos como la reflexividad —los sujetos modifican su comportamiento al conocer teorías sobre ellos (Giddens, 1984)—, la complejidad causal —fenómenos con múltiples causas interdependientes—, la imposibilidad de experimentación —frecuentemente no podemos manipular variables por razones éticas o prácticas—, y la dependencia del contexto —las regularidades sociales son históricamente contingentes (Abbott, 2001)—. Estos desafíos no invalidan la empresa científica en ciencias sociales, pero exigen rigurosidad metodológica y conciencia de los límites de nuestras inferencias.2\n2 Durante el estallido social de octubre 2019, académicos publicaron estudios sobre tácticas de movilización efectivas. Los movimientos sociales leyeron estos estudios y adaptaron sus estrategias, haciendo que las teorías iniciales quedaran desactualizadas.\n\n1.1.0.1 Ciencia social y cuantificación\nLa cuantificación —convertir conceptos en números— es una estrategia metodológica, no un fin en sí mismo. Su utilidad depende del tipo de pregunta que formulamos.\nLazarsfeld & Rosenberg (1955) identificó que cuantificar permite:\n\nPrecisión: Especificar exactamente qué grado de una propiedad exhibe un caso.\nComparabilidad: Evaluar sistemáticamente similitudes y diferencias entre casos.\nAgregación: Resumir patrones en poblaciones grandes.\nTesteo de relaciones: Evaluar si dos variables covarían de manera consistente con una hipótesis teórica.\n\nSin embargo, no todo fenómeno político es susceptible de cuantificación útil. Algunos objetos de estudio —como significados culturales profundos, procesos deliberativos, o lógicas institucionales— pueden empobrecerse al ser reducidos a números.\nLa decisión de cuantificar debe responder a la pregunta de investigación, no a preferencias metodológicas preconcebidas. Como afirma Abbott (1988), “los métodos son herramientas, no paradigmas”. El investigador competente domina múltiples herramientas y selecciona la apropiada para cada problema.\nEn ciencia política, cuantificamos actitudes y opiniones —preferencias electorales, apoyo a políticas, confianza institucional—, comportamiento —participación electoral, protesta, corrupción declarada—, atributos institucionales —sistemas electorales, grado de federalismo, independencia judicial—, y resultados agregados —nivel de democracia, desigualdad de ingresos, gasto público—. Cada medición implica decisiones conceptuales. Por ejemplo, ¿cómo medimos “democracia”? Munck (2009) muestran que distintos índices operacionalizan el concepto de forma diferente, produciendo clasificaciones divergentes de los mismos países.3 Esta tensión entre concepto y medición es constitutiva de la investigación cuantitativa.\n3 En 2022, Freedom House clasificó a Chile como “Libre” con 94/100 puntos, mientras V-Dem lo ubicó ligeramente por debajo de Costa Rica. Estas diferencias reflejan distintas conceptualizaciones de qué aspectos de la democracia importan más. No hay medición perfecta, solo mediciones más o menos adecuadas a nuestro propósito teórico.\n\n1.1.0.2 El papel de la teoría\nUn error común en estudiantes principiantes es creer que la investigación cuantitativa consiste en “dejar que los datos hablen”. Los datos nunca hablan solos. Requieren un marco teórico que los haga inteligibles.\nLa teoría cumple tres funciones en investigación cuantitativa:\n\nOrienta la observación: Indica qué aspectos de la realidad son relevantes para nuestra pregunta. Sin teoría, todo es igualmente importante (y nada lo es).\nGenera hipótesis: Especifica relaciones esperadas entre variables. Una hipótesis es una conjetura derivada de la teoría sobre qué patrón observaremos en los datos.\nInterpreta hallazgos: Permite dotar de sentido a los patrones estadísticos. Una correlación es solo eso —covariación— hasta que la teoría la conecta con un mecanismo causal.\n\nKing et al. (1994) insisten en que “diseñar investigación social es diseñar un test de teoría”. No existe investigación “ateórica”. Incluso el análisis exploratorio más inductivo parte de intuiciones teóricas sobre qué buscar.\n\nNiveles de teoría\nLas teorías varían en su nivel de abstracción: gran teoría (marcos conceptuales amplios como marxismo o funcionalismo estructural), teorías de rango medio que explican clases específicas de fenómenos sin pretensión de aplicabilidad universal (Merton, 1949) (ej: teoría de la modernización para democratización), y modelos formales que representan matemáticamente mecanismos causales específicos (ej: modelos de teoría de juegos sobre negociación legislativa). En investigación cuantitativa en ciencias políticas predominan teorías de rango medio: suficientemente específicas para generar hipótesis testeables, pero suficientemente generales para trascender casos únicos.\n\nEl objetivo último de la investigación cuantitativa explicativa es establecer relaciones causales: identificar si cambios en X producen cambios en Y. No basta mostrar que X e Y covarían; necesitamos argumentar que X causa Y.\n\nTradiciones de inferencia causal\nMahoney & Goertz (2006) distinguen dos tradiciones: el enfoque neopositivista —dominante en economía y partes de la ciencia política— que privilegia identificación de efectos causales promedio mediante diseños experimentales o cuasi-experimentales, y el enfoque interpretativo-mecanísmico que privilegia comprensión de los procesos mediante los cuales X produce Y.4 Ambos enfoques son legítimos pero implican estrategias metodológicas distintas.\n4 El enfoque neopositivista pregunta “¿cuánto aumenta la probabilidad de votar si una persona es contactada telefónicamente?” y responde con experimentos aleatorios. El enfoque mecanísmico pregunta “¿cómo funciona ese contacto?” y responde con entrevistas sobre recordatorios y presión social. Este libro enfatiza el primero, aunque reconocemos la importancia de teorizar mecanismos.",
    "crumbs": [
      "I. Prerequisitos",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción: El método científico en ciencias sociales</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#lógica-de-la-investigación-cuantitativa",
    "href": "01-introduccion.html#lógica-de-la-investigación-cuantitativa",
    "title": "1  Introducción: El método científico en ciencias sociales",
    "section": "1.2 Lógica de la investigación cuantitativa",
    "text": "1.2 Lógica de la investigación cuantitativa\nLa investigación cuantitativa sigue una secuencia lógica, aunque no siempre cronológica. Todo comienza con una pregunta de investigación específica, empíricamente respondible y relevante. Luego hacemos una revisión de literatura que identifica teorías existentes, hallazgos previos, debates no resueltos y limitaciones de investigación previa, posicionando nuestra contribución en una conversación académica en curso. Con base en literatura, desarrollamos teoría e hipótesis —afirmaciones sobre relaciones entre variables que esperamos observar si la teoría es correcta—.5\n5 La teoría de Duverger predice que sistemas proporcionales facilitan nuevos partidos. Tras el cambio del binominal al proporcional en Chile, el número efectivo de partidos en la Cámara pasó de 5.6 a 8.2, consistente con la teoría.El diseño de investigación y medición especifica cómo testearemos las hipótesis: qué casos observaremos (muestra/población), cómo mediremos nuestras variables (operacionalización), y qué técnica analítica usaremos (estadística descriptiva, regresión, etc.). Estas decisiones tienen consecuencias: un mismo concepto puede medirse de múltiples formas, y cada medición captura aspectos distintos. La recolección de datos obtiene la información (encuestas propias, datos administrativos, fuentes secundarias); la calidad del dato es crítica porque análisis sofisticado de datos malos produce conclusiones incorrectas con alta precisión. El análisis aplica técnicas estadísticas para evaluar hipótesis, resumiendo información en datos para detectar patrones sistemáticos.\nLa interpretación evalúa qué implican los resultados para nuestra teoría: resultados consistentes fortalecen confianza (sin probarla definitivamente), resultados inconsistentes debilitan la teoría (sin refutarla definitivamente), resultados ambiguos pueden deberse a problemas de datos, medición o especificación del modelo. La investigación científica nunca “prueba” teorías; solo puede refutarlas o fallar en refutarlas. Las teorías sobreviven hasta que evidencia acumulada las hace insostenibles. Finalmente, la comunicación presenta los hallazgos de forma que otros puedan evaluarlos y replicarlos.\n\n1.2.0.1 Fortalezas y limitaciones\nEl enfoque cuantitativo tiene fortalezas importantes: permite generalización (inferir de 1,500 encuestados a 15 millones de votantes si muestreamos correctamente), precisión (no solo “X y Y se relacionan”, sino “un aumento de una desviación estándar en X se asocia con un incremento de 0.23 desviaciones estándar en Y”), testeo sistemático (evaluar si un patrón podría deberse al azar o refleja una relación real), comparabilidad (estandarización de mediciones permite comparaciones rigurosas entre casos, países o períodos), y transparencia (procedimientos explícitos y replicables que otros pueden verificar o cuestionar).\nTambién tiene limitaciones: reducción de complejidad —cuantificar exige simplificar y aspectos importantes pueden perderse—, el hecho de que correlación no es causalidad6 —observar que X e Y covarían no implica que X cause Y—, dependencia de supuestos —las técnicas estadísticas asumen propiedades de los datos—, decontextualización —al agregar muchos casos podemos perder especificidades contextuales importantes (Ragin, 1987)—, y “dictadura de las variables disponibles” —la investigación puede ser determinada por qué datos existen, no por qué preguntas son importantes—. Estas limitaciones no invalidan el enfoque cuantitativo, pero exigen humildad interpretativa. Los resultados estadísticos son insumos para argumentación teórica, no veredictos finales. Goertz & Mahoney (2012) argumentan que métodos cuantitativos y cualitativos tienen fortalezas complementarias; los mejores estudios frecuentemente combinan ambos.\n6 En comunas chilenas, el número de templos evangélicos correlaciona positivamente con tasas de crimen. ¿Los templos causan crimen? No. Ambos son causados por el tamaño poblacional: comunas grandes tienen más templos y más crimen. Esta es una variable confusora.",
    "crumbs": [
      "I. Prerequisitos",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción: El método científico en ciencias sociales</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#resumen",
    "href": "01-introduccion.html#resumen",
    "title": "1  Introducción: El método científico en ciencias sociales",
    "section": "Resumen",
    "text": "Resumen\nEste capítulo introdujo la lógica del método científico aplicado a ciencias sociales. El conocimiento científico se distingue por su sistematicidad, falsabilidad y acumulación. Las ciencias sociales enfrentan desafíos específicos (reflexividad, complejidad causal, imposibilidad de experimentación), pero esto no invalida la empresa científica.\nLa cuantificación es una estrategia metodológica útil para ciertos propósitos: permite precisión, comparabilidad, agregación y testeo sistemático de hipótesis. Sin embargo, no todo fenómeno político debería cuantificarse.\nLa teoría es indispensable en investigación cuantitativa. Orienta qué observar, genera hipótesis testeables, e interpreta hallazgos. Sin teoría, los datos son ininteligibles.\nLa investigación cuantitativa sigue una secuencia: pregunta → literatura → teoría/hipótesis → diseño → datos → análisis → interpretación → comunicación. Cada paso implica decisiones metodológicas que afectan las conclusiones.\nEl enfoque cuantitativo tiene fortalezas (generalización, precisión, testeo sistemático) y límites (reducción de complejidad, correlación ≠ causalidad, dependencia de supuestos). Reconocer ambos es condición de investigación rigurosa.",
    "crumbs": [
      "I. Prerequisitos",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción: El método científico en ciencias sociales</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#lecturas-recomendadas",
    "href": "01-introduccion.html#lecturas-recomendadas",
    "title": "1  Introducción: El método científico en ciencias sociales",
    "section": "Lecturas recomendadas",
    "text": "Lecturas recomendadas\nFundamentos de inferencia en ciencias sociales:\nKing, G., Keohane, R. O., & Verba, S. (1994). Designing Social Inquiry: Scientific Inference in Qualitative Research. Princeton University Press.\n→ Discusión clásica sobre lógica de inferencia aplicable a investigación cualitativa y cuantitativa.\nFilosofía de la ciencia para ciencias sociales:\nGerring, J. (2012). Social Science Methodology: A Unified Framework (2nd ed.). Cambridge University Press.\n→ Visión comprehensiva de debates metodológicos en ciencias sociales.\nDefensa del pluralismo metodológico:\nBrady, H. E., & Collier, D. (Eds.). (2010). Rethinking Social Inquiry: Diverse Tools, Shared Standards (2nd ed.). Rowman & Littlefield.\n→ Debate sobre relación entre métodos cuantitativos y cualitativos, con énfasis en complementariedad.\nPara profundizar en medición:\nAdcock, R., & Collier, D. (2001). Measurement Validity: A Shared Standard for Qualitative and Quantitative Research. American Political Science Review, 95(3), 529-546.\n→ Artículo seminal sobre conceptualización y operacionalización.",
    "crumbs": [
      "I. Prerequisitos",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción: El método científico en ciencias sociales</span>"
    ]
  },
  {
    "objectID": "01-introduccion.html#ejercicios",
    "href": "01-introduccion.html#ejercicios",
    "title": "1  Introducción: El método científico en ciencias sociales",
    "section": "Ejercicios",
    "text": "Ejercicios\nLos ejercicios para este capítulo se encuentran en el Anexo de Ejercicios.\n\n\nAbbott, A. (1988). Transcending general linear reality. Sociological\nTheory, 6(2), 169–186.\n\n\nAbbott, A. (2001). What do cases do? In Time matters: On theory and\nmethod. University of Chicago Press.\n\n\nAdcock, R., & Collier, D. (2001). Measurement validity: A shared\nstandard for qualitative and quantitative research. American\nPolitical Science Review, 95(3), 529–546.\n\n\nCampbell, D. T., & Stanley, J. C. (1963). Experimental and\nquasi-experimental designs for research. Rand McNally &\nCompany.\n\n\nFlores, T. E., & Nooruddin, I. (2016). Experimentation in the\nsocial sciences. Cambridge University Press.\n\n\nGerber, A. S., & Green, D. P. (2008). Get out the vote: How to\nincrease voter turnout (2nd ed.). Brookings Institution Press.\n\n\nGiddens, A. (1984). The constitution of society: Outline of the\ntheory of structuration. Polity Press.\n\n\nGoertz, G., & Mahoney, J. (2012). A tale of two cultures:\nQualitative and quantitative research in the social sciences.\nPrinceton University Press.\n\n\nKing, G. (1997). A solution to the ecological inference problem:\nReconstructing individual behavior from aggregate data. American\nJournal of Political Science, 41(4), 1027–1053.\n\n\nKing, G., Keohane, R. O., & Verba, S. (1994). Designing social\ninquiry: Scientific inference in qualitative research. Princeton\nUniversity Press.\n\n\nKuhn, T. S. (1962). The structure of scientific revolutions.\nUniversity of Chicago Press.\n\n\nLazarsfeld, P. F., & Rosenberg, M. (Eds.). (1955). The language\nof social research: A reader in the methodology of social research.\nFree Press.\n\n\nLijphart, A. (1994). Electoral systems and party systems: A study of\ntwenty-seven democracies, 1945-1990. Oxford University Press.\n\n\nLinz, J. J., & Stepan, A. (1996). Problems of democratic\ntransition and consolidation: Southern europe, south america, and\npost-communist europe. Johns Hopkins University Press.\n\n\nMahoney, J., & Goertz, G. (2006). A tale of two cultures:\nContrasting quantitative and qualitative research. Political\nAnalysis, 14(3), 227–249. https://doi.org/10.1093/pan/mpj017\n\n\nMerton, R. K. (1949). Social theory and social structure. The\nFree Press.\n\n\nMunck, G. L. (2009). Measuring democracy: A bridge between\nscholarship and politics. Johns Hopkins University Press.\n\n\nPopper, K. R. (1959). The logic of scientific discovery.\nRoutledge.\n\n\nPrzeworski, A., Alvarez, M. E., Cheibub, J. A., & Limongi, F.\n(2000). Democracy and development: Political institutions and\nwell-being in the world, 1950-1990. Cambridge University Press.\n\n\nRagin, C. C. (1987). The comparative method: Moving beyond\nqualitative and quantitative strategies. University of California\nPress.\n\n\nRobinson, W. S. (1950). Ecological correlations and the behavior of\nindividuals. American Sociological Review, 15(3),\n351–357.\n\n\nSartori, G. (1970). Concept misformation in comparative politics.\nAmerican Political Science Review, 64(4), 1033–1053.\n\n\nShadish, W. R., Cook, T. D., & Campbell, D. T. (2002).\nExperimental and quasi-experimental designs for generalized causal\ninference. Houghton Mifflin.\n\n\nTufte, E. R. (1983). The visual display of quantitative\ninformation. Graphics Press.\n\n\nWilkinson, L. (2005). The grammar of graphics (2nd ed.).\nSpringer-Verlag.",
    "crumbs": [
      "I. Prerequisitos",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción: El método científico en ciencias sociales</span>"
    ]
  },
  {
    "objectID": "02-diseno-investigacion.html",
    "href": "02-diseno-investigacion.html",
    "title": "2  Diseño de investigación",
    "section": "",
    "text": "Objetivos del capítulo\nAl finalizar este capítulo, serás capaz de:",
    "crumbs": [
      "I. Prerequisitos",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Diseño de investigación</span>"
    ]
  },
  {
    "objectID": "02-diseno-investigacion.html#objetivos-del-capítulo",
    "href": "02-diseno-investigacion.html#objetivos-del-capítulo",
    "title": "2  Diseño de investigación",
    "section": "",
    "text": "Formular preguntas de investigación empíricamente respondibles\nDistinguir entre hipótesis descriptivas, relacionales y causales\nComprender el marco contrafactual de causalidad\nIdentificar fortalezas y debilidades de diseños experimentales y observacionales\nEvaluar validez interna y externa de diseños de investigación",
    "crumbs": [
      "I. Prerequisitos",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Diseño de investigación</span>"
    ]
  },
  {
    "objectID": "02-diseno-investigacion.html#preguntas-hipótesis-y-causalidad",
    "href": "02-diseno-investigacion.html#preguntas-hipótesis-y-causalidad",
    "title": "2  Diseño de investigación",
    "section": "2.1 Preguntas, hipótesis y causalidad",
    "text": "2.1 Preguntas, hipótesis y causalidad\nToda investigación comienza con una pregunta, pero no cualquier pregunta es una pregunta de investigación útil.1\n1 La pregunta de investigación debe ser empíricamente respondible, a diferencia de preguntas normativas como “¿Debería Chile tener sistema parlamentario?”. Las buenas preguntas tienen tres características: especificidad, posibilidad de respuesta empírica, y relevancia teórica o sustantiva.Las preguntas se clasifican según su propósito: preguntas descriptivas caracterizan fenómenos (“¿Cuál es la tasa de participación electoral en Chile 2021?”), preguntas relacionales identifican asociaciones entre variables (“¿Se relaciona el nivel educativo con la participación electoral?”), y preguntas causales buscan establecer relaciones de causa-efecto (“¿La inscripción automática aumenta la participación electoral?”). La distinción importa porque cada tipo exige estrategias metodológicas distintas: responder preguntas descriptivas requiere medición cuidadosa y muestreo representativo; responder preguntas causales requiere, además, estrategias para descartar explicaciones alternativas.\n\n2.1.0.1 Hipótesis y teoría\nUna vez formulada la pregunta, necesitamos una respuesta tentativa —una hipótesis: afirmación específica, derivada de teoría, sobre relaciones esperadas entre variables que debe ser falsable (Popper, 1959).2\n2 “Los partidos de izquierda son mejores” no es falsable porque “mejores” es ambiguo. “Los partidos de izquierda gastan más en políticas sociales” sí es falsable mediante datos de gasto público. Por ejemplo: “A mayor magnitud de distrito electoral, mayor fragmentación partidaria en el parlamento” es específica, falsable, y se deriva de la teoría de Duverger sobre efectos de sistemas electorales.Las hipótesis provienen de teorías sobre cómo funciona el mundo social mediante un proceso deductivo: Teoría → Mecanismo causal → Implicación observable → Hipótesis. Por ejemplo: la teoría de que los sistemas electorales proporcionales reducen barreras de entrada para partidos pequeños (Lijphart, 1994) implica que en distritos grandes, partidos pequeños pueden obtener escaños con porcentajes bajos de votos, incentivando su formación, por lo que deberíamos observar más partidos en parlamentos elegidos con distritos grandes, generando la hipótesis testeable “a mayor magnitud promedio de distrito, mayor número efectivo de partidos parlamentarios”. Este encadenamiento lógico es crucial: cuando testeamos hipótesis, estamos evaluando indirectamente la teoría subyacente.\nEn estadística inferencial (Capítulo @ref(hipotesis)), formalizamos dos tipos de hipótesis: la hipótesis nula (H₀) que afirma ausencia de relación o efecto, y la hipótesis alternativa (H₁) que afirma existencia de relación o efecto.3 El procedimiento estadístico evalúa si los datos son suficientemente inconsistentes con H₀ como para rechazarla en favor de H₁.\n3 H₀ no es “la hipótesis que queremos refutar”. Es simplemente el escenario de referencia. No “probamos” H₁; solo rechazamos o fallamos en rechazar H₀. Esta lógica asimétrica es fundamental para entender tests de hipótesis.\n\n2.1.0.2 Causalidad\nEl objetivo de mucha investigación cuantitativa es establecer relaciones causales. Queremos saber no solo si X e Y covarían, sino si cambios en X producen cambios en Y.",
    "crumbs": [
      "I. Prerequisitos",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Diseño de investigación</span>"
    ]
  },
  {
    "objectID": "02-diseno-investigacion.html#diseños-de-investigación",
    "href": "02-diseno-investigacion.html#diseños-de-investigación",
    "title": "2  Diseño de investigación",
    "section": "2.2 Diseños de investigación",
    "text": "2.2 Diseños de investigación\nLos diseños de investigación varían según cuánto control tenemos sobre la asignación del tratamiento y la recolección de datos.\n\n2.2.0.1 Diseños experimentales\nEn un experimento, el investigador asigna aleatoriamente el tratamiento. Esto garantiza que, en expectativa, grupos tratados y control son idénticos excepto por el tratamiento. Cualquier diferencia sistemática en resultados es atribuible al efecto causal del tratamiento.\nEjemplo: Gerber & Green (2008) realizaron experimentos de campo sobre movilización electoral en Estados Unidos. Asignaron aleatoriamente hogares a recibir llamadas telefónicas, visitas puerta a puerta, o ningún contacto (control). Compararon tasas de participación electoral entre grupos.\nVentajas: - Identificación causal clara - No requiere supuestos sobre confusores - Alta validez interna\nLimitaciones: - Muchas preguntas políticas no permiten experimentación —no podemos asignar aleatoriamente tipo de régimen político—.4\n4 No podemos asignar experimentalmente “democracia” vs “dictadura” a países. Estos límites éticos obligan a usar datos observacionales con estrategias cuasi-experimentales o control estadístico. - Posibles problemas éticos - Efectos pueden ser específicos al contexto experimental (baja validez externa) - En ciencia política, solo ciertas preguntas son experimentables\n\n2.2.0.2 Diseños observacionales\nLa mayoría de investigación en ciencias políticas usa datos observacionales —datos donde el investigador no controla la asignación del tratamiento. Aquí, inferencia causal es más problemática.\nEstudios de corte transversal\nObservan muchos casos en un punto temporal. Útiles para descripción y exploración de asociaciones, pero problemáticos para causalidad por confusores no observados.\nEjemplo: Analizar si democracias tienen menor desigualdad que autocracias usando datos de 150 países en 2020. El problema: democracia no es aleatoria —correlaciona con desarrollo económico, historia colonial, estructura social, etc.\nSeries de tiempo\nObservan un caso (o pocos casos) en múltiples momentos. Permiten explotar variación temporal, pero requieren supuestos sobre qué cambió y qué permaneció constante.\nEjemplo: Estudiar efecto de una reforma electoral en Chile analizando fragmentación partidaria antes y después. El problema: otros factores también cambiaron simultáneamente.\nPanel (longitudinal)\nCombinan ventajas de corte transversal (muchos casos) y series de tiempo (variación temporal). Permiten controlar características fijas no observadas de unidades.\n\nLos datos de panel permiten usar efectos fijos, una técnica que controla automáticamente todas las características permanentes de cada unidad (observadas o no). Por ejemplo, Flores & Nooruddin (2016) usan datos de panel de municipios mexicanos para estudiar efecto de presencia militar sobre violencia del crimen organizado, controlando características permanentes de municipios como geografía, historia y cultura local.\n\nEstrategias para fortalecer inferencia causal en diseños observacionales:\n\nControles estadísticos: Incluir covariables que eliminan confusión. Problema: solo funciona para confusores observados.\nTriangulación: Combinar múltiples fuentes de evidencia (cuantitativa + cualitativa).\n\n\nTécnicas avanzadas de inferencia causal:\n\nMatching: Emparejar casos tratados con controles similares en variables observables. Aproxima balance experimental, pero depende de calidad del emparejamiento.\nDiseños cuasi-experimentales: Incluyen diferencias-en-diferencias, regresión discontinua, y variables instrumentales. Explotan variación “natural” que aproxima aleatorización.\nAnálisis de sensibilidad: Evalúa qué tan fuerte tendría que ser un confusor no observado para invalidar las conclusiones.\n\n\n\n\n2.2.0.3 Validez interna y externa\nTodo diseño de investigación enfrenta tensiones entre dos tipos de validez (Campbell & Stanley, 1963). Validez interna es el grado en que podemos confiar que el efecto estimado es genuinamente causal, no espurio (¿X realmente causa Y, o la asociación se debe a confusores?). Las amenazas incluyen variables confusoras (que afectan tanto el tratamiento como el resultado; ej: países con más carreteras son más ricos, pero ¿las carreteras causan riqueza o la riqueza permite construir carreteras?), causalidad inversa (Y puede causar X en vez de X causar Y; ej: Przeworski et al. (2000) argumentan que el desarrollo no causa transiciones democráticas, pero sí hace que las democracias sobrevivan), y sesgo de selección (la asignación al tratamiento no es aleatoria y se relaciona sistemáticamente con el resultado potencial; ej: comparar salarios de quienes asistieron a universidad vs. quienes no ignora que difieren en habilidad, motivación y recursos familiares). Estrategias para mejorar validez interna: aleatorización, diseños cuasi-experimentales rigurosos, controlar estadísticamente confusores observados, análisis de sensibilidad a confusores no observados.\nValidez externa es el grado en que resultados generalizan más allá del contexto específico estudiado (¿los hallazgos aplican a otras poblaciones, contextos o tiempos?). Las amenazas incluyen muestras no representativas (estudiar estudiantes universitarios no permite generalizar a la población general), especificidad contextual (efectos varían sistemáticamente según contexto; un experimento de movilización electoral en Estados Unidos puede no tener el mismo efecto en Chile), efectos de Hawthorne (sujetos modifican comportamiento porque saben que están siendo estudiados), y dependencia temporal (relaciones causales cambian con el tiempo; teorías sobre comportamiento electoral en los 1960s pueden no aplicar en 2020).\nExiste tensión fundamental: los diseños con mejor validez interna (experimentos de laboratorio) a menudo tienen peor validez externa; los diseños con muestras más representativas (encuestas nacionales) tienen peor validez interna. Shadish et al. (2002) argumentan que el objetivo no es maximizar una validez a costa de la otra, sino encontrar equilibrios apropiados según la pregunta de investigación: preguntas sobre mecanismos causales priorizan validez interna; preguntas sobre magnitud de efectos en poblaciones priorizan validez externa.\n\n\n2.2.0.4 Casos y unidades de análisis\nUna decisión crucial en diseño de investigación es qué constituye un “caso” —la unidad de análisis: individuos (votantes, legisladores, activistas), agregados subnacionales (municipios, provincias, circunscripciones electorales), países (estados nacionales), eventos (elecciones, protestas, golpes de estado), legislación (leyes, políticas públicas), u organizaciones (partidos políticos, grupos de interés). La unidad de análisis determina qué variación podemos explotar y qué afirmaciones podemos hacer.\n\nFalacias de nivel de análisis:\nDebemos evitar dos falacias al cambiar de nivel de análisis. La falacia ecológica (Robinson, 1950) ocurre al inferir relaciones individuales desde datos agregados: si comunas con más inmigrantes votan más por la derecha, ¿significa que los inmigrantes votan derecha? No necesariamente; puede ser que nativos en comunas con inmigración voten derecha reactivamente. La falacia atómica es el error inverso: inferir patrones agregados desde datos individuales; si individuos religiosos son más conservadores, ¿países más religiosos son más conservadores? No necesariamente, puede haber efectos contextuales.\nEl problema de “muchas variables, pocas observaciones”:\nKing et al. (1994) enfatizan que si estudio 20 países con 15 variables explicativas, casi cualquier patrón puede ser ajustado sin suficientes grados de libertad para distinguir señal de ruido. Soluciones: aumentar observaciones (datos de panel), reducir parámetros (selección teórica), o combinar enfoques cuantitativos y cualitativos.",
    "crumbs": [
      "I. Prerequisitos",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Diseño de investigación</span>"
    ]
  },
  {
    "objectID": "02-diseno-investigacion.html#resumen",
    "href": "02-diseno-investigacion.html#resumen",
    "title": "2  Diseño de investigación",
    "section": "Resumen",
    "text": "Resumen\nEl diseño de investigación es el plan para responder preguntas de investigación. Buenas preguntas son específicas, empíricamente respondibles, y relevantes teórica o prácticamente. Pueden ser descriptivas, relacionales o causales.\nLas hipótesis son afirmaciones falsables derivadas de teoría sobre relaciones esperadas entre variables. Conectan teoría abstracta con implicaciones observables.\nLa inferencia causal enfrenta el problema fundamental: nunca observamos resultados contrafactuales. El marco de resultados potenciales formaliza este problema. Para inferir causalidad, necesitamos que grupos tratados y control sean comparables.\nLos diseños experimentales garantizan comparabilidad mediante aleatorización, logrando alta validez interna. Los diseños cuasi-experimentales explotan situaciones “naturalmente” aleatorias. Los diseños observacionales dependen de supuestos más fuertes y técnicas estadísticas para aproximar inferencia causal.\nToda investigación enfrenta tensión entre validez interna (¿el efecto es causal?) y validez externa (¿generaliza?). No hay diseño perfecto; cada diseño implica compromisos.\nLa unidad de análisis determina qué variación explotamos y qué afirmaciones justificamos. Inferir relaciones en un nivel desde datos de otro nivel (falacias ecológicas/atómicas) es problemático.",
    "crumbs": [
      "I. Prerequisitos",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Diseño de investigación</span>"
    ]
  },
  {
    "objectID": "02-diseno-investigacion.html#lecturas-recomendadas",
    "href": "02-diseno-investigacion.html#lecturas-recomendadas",
    "title": "2  Diseño de investigación",
    "section": "Lecturas recomendadas",
    "text": "Lecturas recomendadas\nFundamentos de diseño de investigación:\nShadish, W. R., Cook, T. D., & Campbell, D. T. (2002). Experimental and Quasi-Experimental Designs for Generalized Causal Inference. Houghton Mifflin.\n→ Tratamiento comprehensivo de validez y diseños experimentales/cuasi-experimentales.\nMarco contrafactual de causalidad:\nMorgan, S. L., & Winship, C. (2015). Counterfactuals and Causal Inference: Methods and Principles for Social Research (2nd ed.). Cambridge University Press.\n→ Introducción accesible al marco de resultados potenciales y métodos de inferencia causal.\nDiseños observacionales en ciencia política:\nAngrist, J. D., & Pischke, J.-S. (2009). Mostly Harmless Econometrics: An Empiricist’s Companion. Princeton University Press.\n→ Enfoque práctico sobre identificación causal en datos observacionales.\nSobre validez de medición:\nAdcock, R., & Collier, D. (2001). Measurement validity: A shared standard for qualitative and quantitative research. American Political Science Review, 95(3), 529-546.\n→ Discusión conceptual sobre operacionalización y validez.\nExperimentos de campo en ciencia política:\nGerber, A. S., & Green, D. P. (2012). Field Experiments: Design, Analysis, and Interpretation. W.W. Norton.\n→ Guía práctica para diseñar y analizar experimentos de campo.",
    "crumbs": [
      "I. Prerequisitos",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Diseño de investigación</span>"
    ]
  },
  {
    "objectID": "02-diseno-investigacion.html#ejercicios",
    "href": "02-diseno-investigacion.html#ejercicios",
    "title": "2  Diseño de investigación",
    "section": "Ejercicios",
    "text": "Ejercicios\nLos ejercicios para este capítulo se encuentran en el Anexo de Ejercicios.\n\n\nCampbell, D. T., & Stanley, J. C. (1963). Experimental and Quasi-Experimental Designs for Research. Rand McNally & Company.\n\n\nFlores, T. E., & Nooruddin, I. (2016). Experimentation in the Social Sciences. Cambridge University Press.\n\n\nGerber, A. S., & Green, D. P. (2008). Get Out the Vote: How to Increase Voter Turnout (2nd ed.). Brookings Institution Press.\n\n\nKing, G., Keohane, R. O., & Verba, S. (1994). Designing Social Inquiry: Scientific Inference in Qualitative Research. Princeton University Press.\n\n\nLijphart, A. (1994). Electoral Systems and Party Systems: A Study of Twenty-Seven Democracies, 1945-1990. Oxford University Press.\n\n\nPopper, K. R. (1959). The Logic of Scientific Discovery. Routledge.\n\n\nPrzeworski, A., Alvarez, M. E., Cheibub, J. A., & Limongi, F. (2000). Democracy and Development: Political Institutions and Well-Being in the World, 1950-1990. Cambridge University Press.\n\n\nRobinson, W. S. (1950). Ecological Correlations and the Behavior of Individuals. American Sociological Review, 15(3), 351-357.\n\n\nShadish, W. R., Cook, T. D., & Campbell, D. T. (2002). Experimental and Quasi-Experimental Designs for Generalized Causal Inference. Houghton Mifflin.",
    "crumbs": [
      "I. Prerequisitos",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Diseño de investigación</span>"
    ]
  },
  {
    "objectID": "03-medicion.html",
    "href": "03-medicion.html",
    "title": "3  Medición: de conceptos a variables",
    "section": "",
    "text": "Objetivos del capítulo\nAl finalizar este capítulo, serás capaz de:",
    "crumbs": [
      "II. Unidad 1: Generalidades de la Investigación Cuantitativa",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medición: de conceptos a variables</span>"
    ]
  },
  {
    "objectID": "03-medicion.html#objetivos-del-capítulo",
    "href": "03-medicion.html#objetivos-del-capítulo",
    "title": "3  Medición: de conceptos a variables",
    "section": "",
    "text": "Distinguir entre conceptos teóricos y definiciones operacionales\nIdentificar niveles de medición y sus implicaciones para análisis\nEvaluar validez y confiabilidad de mediciones\nComprender estrategias para construir índices y escalas\nReconocer problemas comunes de medición en ciencias políticas",
    "crumbs": [
      "II. Unidad 1: Generalidades de la Investigación Cuantitativa",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medición: de conceptos a variables</span>"
    ]
  },
  {
    "objectID": "03-medicion.html#conceptos-y-operacionalización",
    "href": "03-medicion.html#conceptos-y-operacionalización",
    "title": "3  Medición: de conceptos a variables",
    "section": "3.1 Conceptos y operacionalización",
    "text": "3.1 Conceptos y operacionalización\nLos conceptos centrales de la ciencia política —democracia, legitimidad, participación, corrupción— no son directamente observables. Son abstracciones teóricas que requieren traducción a indicadores empíricos. Esta traducción es el problema de la medición.\nAdcock & Collier (2001) distinguen cuatro niveles en el proceso de medición:\n\nConcepto de fondo: La idea abstracta en su totalidad teórica (ej: “democracia”)\nConcepto sistematizado: Definición precisa del concepto para propósitos analíticos (ej: “régimen político donde gobernantes son seleccionados mediante elecciones competitivas”)\nIndicadores: Observables específicos relacionados con el concepto (ej: alternancia en el poder, competitividad electoral, libertades civiles)\nPuntajes: Valores numéricos asignados a casos en los indicadores (ej: Chile = 8.5 en escala de democracia)\n\nCada transición entre niveles implica decisiones. No hay una única forma “correcta” de medir democracia, capital social, o polarización. Las mediciones son construcciones que reflejan decisiones conceptuales y pragmáticas.1\n1 Cuando lees “Chile tiene un puntaje de democracia de 8.5”, pregúntate qué definición de democracia usa ese índice. ¿Incluye solo elecciones o también estado de derecho y libertades civiles? Índices diferentes producen puntajes diferentes. No hay una medición “verdadera” de democracia, solo mediciones más o menos útiles para propósitos específicos.\n3.1.0.1 Definiciones operacionales\nLa conceptualización especifica qué entendemos por un término; sin ella, la medición carece de fundamento. Sartori (1970) advirtió sobre el “estiramiento conceptual”: usar un concepto en contextos donde no aplica, diluyendo su utilidad analítica. Por ejemplo, ¿qué es “participación política”? Una conceptualización minimalista —acciones dirigidas a influir en la selección de gobernantes como votar y hacer campaña— exige solo datos electorales, mientras una expansiva —cualquier acción dirigida a influir en decisiones colectivas, incluyendo protesta y activismo comunitario— requiere información sobre múltiples formas de acción.2\n2 Si usas definición minimalista, Chile tendría participación “baja” con 45-50% en elecciones recientes. Si usas definición expansiva incluyendo protestas y cabildos, Chile podría tener participación “alta”. La elección depende de tu pregunta de investigación.La operacionalización traduce el concepto en procedimientos específicos de medición, siendo el puente entre teoría y datos.\n\nCriterios para buena operacionalización\nAdcock & Collier (2001) identifican tres criterios para buena operacionalización: validez de fondo (los indicadores capturan el significado teórico del concepto; si conceptualizamos democracia como “gobierno del pueblo”, un indicador basado solo en elecciones es insuficiente), convergencia (múltiples indicadores del mismo concepto deberían correlacionar positivamente; si medimos “confianza institucional” con preguntas sobre Congreso, Poder Judicial y policía, estas medidas deberían correlacionar aunque imperfectamente), y discriminación (el indicador debe distinguir entre casos que difieren conceptualmente; una medida de democracia que asigna puntajes similares a Noruega y Venezuela tiene poca validez discriminante).",
    "crumbs": [
      "II. Unidad 1: Generalidades de la Investigación Cuantitativa",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medición: de conceptos a variables</span>"
    ]
  },
  {
    "objectID": "03-medicion.html#niveles-de-medición",
    "href": "03-medicion.html#niveles-de-medición",
    "title": "3  Medición: de conceptos a variables",
    "section": "3.2 Niveles de medición",
    "text": "3.2 Niveles de medición\nLas variables se clasifican según su nivel de medición, que determina qué operaciones matemáticas y estadísticas son apropiadas. Las variables nominales clasifican casos en categorías mutuamente excluyentes sin ordenamiento —religión, región geográfica, tipo de sistema electoral—; las únicas operaciones válidas son contar frecuencias y comparar igualdad/diferencia. Las variables ordinales ordenan casos sin especificar distancias entre categorías —nivel educativo, acuerdo en escala Likert—; podemos ordenar, pero no sabemos si la distancia entre “primaria” y “secundaria” es igual a la entre “secundaria” y “universitaria”.3 Técnicamente, calcular promedios con datos ordinales es problemático, aunque en práctica se hace frecuentemente con escalas Likert.\n3 Si preguntas “¿Cuán satisfecho está con la democracia?” en escala 1-5, no sabemos si la distancia entre 1 y 2 es igual a la entre 4 y 5. Calcular promedios es técnicamente inapropiado, pero en práctica todos los estudios de opinión pública lo hacen asumiendo equidistancia. Si te preocupa, usa medianas y tests no-paramétricos.Las variables de intervalo tienen distancias constantes entre valores pero carecen de cero absoluto (ej: temperatura en Celsius donde la diferencia entre 10°C y 20°C es igual a la entre 20°C y 30°C, pero 0°C no significa “ausencia de temperatura”); en ciencias sociales son raras, y la mayoría de escalas (puntajes de democracia, índices de ideología) deberían tratarse como ordinales aunque frecuentemente las tratamos “como si” fueran de intervalo. Las variables de razón tienen distancias constantes y cero absoluto (ej: ingresos, población, porcentaje de votos, edad); aquí podemos decir que alguien con $2 millones gana el doble que alguien con $1 millón, y todas las operaciones matemáticas son válidas.\nEl nivel de medición determina qué estadísticos son apropiados: nominal usa moda, frecuencias y chi-cuadrado; ordinal usa mediana, rangos y correlación de Spearman; intervalo/razón usa media, desviación estándar, correlación de Pearson y regresión. Usar estadísticos inapropiados produce resultados sin sentido: calcular “ingreso promedio” tiene sentido; calcular “religión promedio” no.4\n4 Si codificas religión como Católico=1, Evangélico=2, Ateo=3, y calculas “promedio = 2.3”, el resultado carece de significado. Los números son solo etiquetas. En cambio, “ingreso promedio = $650,000” sí tiene sentido porque los números representan cantidades reales.\n\n\n\n\n\nImportanteResumen: ¿Qué estadísticos puedo usar?\n\n\n\n\n\n\n\n\n\n\n\nNivel\nEjemplos\nEstadísticos válidos\n\n\n\n\nNominal\nReligión, partido político, región\nModa, frecuencias, %\n\n\nOrdinal\nNivel educativo, satisfacción (Likert)\nMediana, percentiles, rangos\n\n\nIntervalo/Razón\nIngresos, edad, % de votos\nMedia, SD, correlación, regresión\n\n\n\nRegla práctica: Siempre puedes usar estadísticos de niveles inferiores, pero nunca de niveles superiores.",
    "crumbs": [
      "II. Unidad 1: Generalidades de la Investigación Cuantitativa",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medición: de conceptos a variables</span>"
    ]
  },
  {
    "objectID": "03-medicion.html#validez-y-confiabilidad",
    "href": "03-medicion.html#validez-y-confiabilidad",
    "title": "3  Medición: de conceptos a variables",
    "section": "3.3 Validez y confiabilidad",
    "text": "3.3 Validez y confiabilidad\nUna buena medición debe ser válida (¿la medida captura el concepto que pretende medir?) y confiable (¿la medición es consistente?). La validez de contenido evalúa si los indicadores cubren el dominio del concepto: si conceptualizamos “calidad democrática” incluyendo libertades civiles, procedimientos electorales y rendición de cuentas, una medida basada solo en elecciones tiene baja validez de contenido.\n\nTipos de validez\nAdcock & Collier (2001) distinguen varios tipos adicionales de validez:\n\nValidez de constructo: La medida se relaciona como esperado con otras variables. Si teorizamos que confianza institucional reduce protesta pero nuestra medida predice más protesta, hay un problema de validez.\nValidez convergente: Diferentes mediciones del mismo concepto deberían correlacionar. Índices de democracia de Polity, Freedom House y V-Dem miden el mismo concepto; deberían correlacionar fuertemente (y lo hacen, aunque imperfectamente).\nValidez discriminante: La medida no debería correlacionar fuertemente con conceptos distintos. Una medida de “participación política” que correlaciona 0.95 con “ingreso” probablemente está midiendo ingreso, no participación.\n\n\n\n3.3.0.1 Confiabilidad\nLa confiabilidad pregunta: ¿la medición es consistente? Una medida confiable produce resultados similares cuando se aplica repetidamente al mismo fenómeno.\n\nTipos de confiabilidad\n\nTest-retest: Aplicar la misma medición en dos momentos cercanos. Si puntajes cambian dramáticamente sin razón sustantiva, la medición es poco confiable.\nConfiabilidad inter-codificadores: Cuando codificadores humanos clasifican datos (ej: codificar manifiestos partidarios), ¿acuerdan? El coeficiente kappa de Cohen mide esto.\nConsistencia interna: Para escalas multi-ítem, ¿los ítems correlacionan entre sí? El alfa de Cronbach mide consistencia interna.\n\n\n\n\n3.3.0.2 Relación entre validez y confiabilidad\nEs posible tener alta confiabilidad pero baja validez. Si medimos “democracia” solo con PIB per cápita, la medida será confiable —el PIB se mide consistentemente— pero inválida —el PIB no es democracia—.5\n5 Imagina una balanza que consistentemente marca 5kg más de lo real. Es confiable porque siempre da el mismo error, pero inválida porque no mide el peso verdadero. Lo mismo ocurre si medimos “calidad democrática” solo con número de partidos en el Congreso: la medida es confiable pero conceptualmente inválida.También es posible tener alta validez conceptual pero baja confiabilidad. Mediciones de conceptos complejos mediante juicio experto pueden ser válidas pero inconsistentes si expertos desacuerdan.\nIdealmente, queremos ambas. Pero si debemos priorizar, King et al. (1994) argumentan que validez importa más: una medición inválida es inútil sin importar cuán confiable sea.\n\n\n\n\n\n\nTipAnalogía: El arquero y el blanco\n\n\n\nImagina un arquero disparando flechas a un blanco:\n\nAlta validez + Alta confiabilidad: Todas las flechas dan en el centro (ideal)\nBaja validez + Alta confiabilidad: Todas las flechas dan juntas, pero lejos del centro (sesgo sistemático)\nAlta validez + Baja confiabilidad: Las flechas se dispersan alrededor del centro (imprecisión)\nBaja validez + Baja confiabilidad: Las flechas se dispersan lejos del centro (el peor caso)\n\nEn investigación, preferimos alta confiabilidad (consistencia) Y alta validez (medir lo correcto), pero si debemos elegir, es mejor ser válido que consistentemente equivocado.\n\n\n\n\n3.3.0.3 Problemas comunes\nLa medición en ciencias sociales enfrenta problemas sistemáticos que amenazan validez e inferencia.\n\n\n3.3.0.4 Sesgo de deseabilidad social\nLos encuestados pueden responder lo que perciben como socialmente aceptable en lugar de sus verdaderas actitudes. Esto es particularmente problemático para temas sensibles: racismo, corrupción personal, comportamiento antisocial.\n\n\n3.3.0.5 Sesgo de aquiescencia\nTendencia a estar de acuerdo con afirmaciones independientemente de su contenido. Particularmente problemático en culturas donde contradecir es descortés.\nMitigación: Incluir ítems con dirección invertida.\n\n\n3.3.0.6 No-respuesta diferencial\nCuando quienes no responden difieren sistemáticamente de quienes responden, las estimaciones se sesgan. Si en una encuesta sobre confianza institucional, los más desconfiados no responden, sobrestimamos confianza.",
    "crumbs": [
      "II. Unidad 1: Generalidades de la Investigación Cuantitativa",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medición: de conceptos a variables</span>"
    ]
  },
  {
    "objectID": "03-medicion.html#resumen",
    "href": "03-medicion.html#resumen",
    "title": "3  Medición: de conceptos a variables",
    "section": "Resumen",
    "text": "Resumen\nLa medición traduce conceptos abstractos en indicadores empíricos. Este proceso involucra conceptualización (definir el concepto) y operacionalización (especificar procedimientos de medición). Cada paso implica decisiones que afectan qué capturamos.\nLas variables tienen niveles de medición (nominal, ordinal, intervalo, razón) que determinan qué operaciones estadísticas son apropiadas. Confundir niveles produce resultados sin sentido.\nBuenas mediciones son válidas (capturan el concepto teórico) y confiables (consistentes). Es posible tener una sin la otra, pero idealmente queremos ambas.\nLos conceptos latentes y multidimensionales requieren índices o escalas. Estos pueden construirse mediante agregación simple, ponderación, o análisis factorial. Los índices existentes en ciencias políticas ofrecen comparabilidad pero imponen conceptualizaciones.\nLa medición enfrenta problemas sistemáticos: sesgos de deseabilidad social y aquiescencia, no-respuesta diferencial, efectos de modo de encuesta, y errores de medición aleatorios o sistemáticos. Reconocer y, cuando es posible, mitigar estos problemas es responsabilidad del investigador.",
    "crumbs": [
      "II. Unidad 1: Generalidades de la Investigación Cuantitativa",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medición: de conceptos a variables</span>"
    ]
  },
  {
    "objectID": "03-medicion.html#lecturas-recomendadas",
    "href": "03-medicion.html#lecturas-recomendadas",
    "title": "3  Medición: de conceptos a variables",
    "section": "Lecturas recomendadas",
    "text": "Lecturas recomendadas\nFundamentos conceptuales de medición:\nAdcock, R., & Collier, D. (2001). Measurement validity: A shared standard for qualitative and quantitative research. American Political Science Review, 95(3), 529-546.\n→ Artículo seminal sobre niveles de medición y validez.\nConstrucción de escalas e índices:\nDeVellis, R. F. (2017). Scale Development: Theory and Applications (4th ed.). SAGE.\n→ Guía práctica para desarrollar escalas de medición confiables y válidas.\nMedición en encuestas:\nGroves, R. M., et al. (2009). Survey Methodology (2nd ed.). Wiley.\n→ Tratamiento comprehensivo de todos los aspectos de medición mediante encuestas.\nProblemas de medición en ciencias políticas:\nTreier, S., & Jackman, S. (2008). Democracy as a latent variable. American Journal of Political Science, 52(1), 201-217.\n→ Análisis del error de medición en índices de democracia y sus consecuencias.\nSobre conceptualización:\nGoertz, G. (2006). Social Science Concepts: A User’s Guide. Princeton University Press.\n→ Discusión profunda sobre formación y uso de conceptos en ciencias sociales.",
    "crumbs": [
      "II. Unidad 1: Generalidades de la Investigación Cuantitativa",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medición: de conceptos a variables</span>"
    ]
  },
  {
    "objectID": "03-medicion.html#ejercicios",
    "href": "03-medicion.html#ejercicios",
    "title": "3  Medición: de conceptos a variables",
    "section": "Ejercicios",
    "text": "Ejercicios\nLos ejercicios para este capítulo se encuentran en el Anexo de Ejercicios.\n\n\nAdcock, R., & Collier, D. (2001). Measurement validity: A shared standard for qualitative and quantitative research. American Political Science Review, 95(3), 529-546.\n\n\nKing, G., Keohane, R. O., & Verba, S. (1994). Designing Social Inquiry: Scientific Inference in Qualitative Research. Princeton University Press.\n\n\nSartori, G. (1970). Concept Misformation in Comparative Politics. American Political Science Review, 64(4), 1033-1053.",
    "crumbs": [
      "II. Unidad 1: Generalidades de la Investigación Cuantitativa",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medición: de conceptos a variables</span>"
    ]
  },
  {
    "objectID": "04-datos.html",
    "href": "04-datos.html",
    "title": "4  Trabajando con datos",
    "section": "",
    "text": "Objetivos del capítulo\nAl finalizar este capítulo, serás capaz de:",
    "crumbs": [
      "II. Unidad 1: Generalidades de la Investigación Cuantitativa",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Trabajando con datos</span>"
    ]
  },
  {
    "objectID": "04-datos.html#objetivos-del-capítulo",
    "href": "04-datos.html#objetivos-del-capítulo",
    "title": "4  Trabajando con datos",
    "section": "",
    "text": "Distinguir entre tipos de datos según estructura y fuente\nEvaluar calidad de datos y detectar problemas comunes\nNavegar el entorno de R y RStudio\nImportar datos desde múltiples formatos\nRealizar operaciones básicas de manipulación de datos en R\nExportar resultados para análisis posterior o publicación",
    "crumbs": [
      "II. Unidad 1: Generalidades de la Investigación Cuantitativa",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Trabajando con datos</span>"
    ]
  },
  {
    "objectID": "04-datos.html#tipos-y-fuentes-de-datos",
    "href": "04-datos.html#tipos-y-fuentes-de-datos",
    "title": "4  Trabajando con datos",
    "section": "4.1 Tipos y fuentes de datos",
    "text": "4.1 Tipos y fuentes de datos\nLos datos que usamos en ciencias políticas varían en estructura, granularidad y fuente. Entender estas diferencias es crucial para seleccionar estrategias analíticas apropiadas.\n\n4.1.0.1 Según estructura\nDatos de corte transversal (cross-sectional)\nObservaciones de múltiples unidades en un solo momento. Ejemplo: encuesta a 1,500 votantes en octubre 2024. Cada fila es un individuo; columnas son variables (edad, educación, intención de voto).\nVentaja: Simplicidad analítica. Limitación: No observamos cambio temporal. No podemos distinguir efectos de período de efectos de cohorte.\nDatos de series temporales (time series)\nObservaciones de una unidad a través del tiempo. Ejemplo: tasa de desempleo mensual en Chile 2000-2024. Cada fila es un mes; columnas son variables económicas.\nVentaja: Captura dinámica temporal. Limitación: Una sola unidad limita generalización. Difícil controlar confusores que varían en el tiempo.\nDatos de panel (longitudinal)\nObservaciones de múltiples unidades a través del tiempo. Ejemplo: datos electorales de 346 comunas chilenas en 8 elecciones presidenciales. Cada fila es comuna-año; columnas son variables.\nVentaja: Controla diferencias persistentes entre unidades (efectos fijos). Observa cambios. Limitación: Complejidad analítica. Requiere supuestos sobre errores correlacionados.\nDatos jerárquicos (nested/multilevel)\nObservaciones anidadas en estructuras de múltiples niveles. Ejemplo: estudiantes (nivel 1) dentro de escuelas (nivel 2) dentro de comunas (nivel 3).\nVentaja: Modela variación en múltiples niveles simultáneamente. Limitación: Requiere técnicas multinivel (más allá del alcance de este libro introductorio).\n\n\n4.1.0.2 Según granularidad\nDatos micro (individuales)\nLa unidad de observación es el individuo: persona, votante, legislador, manifestante. Estos datos permiten analizar comportamiento individual y heterogeneidad.\nDatos meso (organizacionales/locales)\nLa unidad es un agregado intermedio: municipios, distritos electorales, partidos políticos, organizaciones. Balance entre detalle y manejo de volumen.\nDatos macro (nacionales/internacionales)\nLa unidad es el país o la región. Permiten comparación internacional pero pierden variación subnacional. Además, típicamente N es pequeño (196 países en el mundo).\nLa elección de granularidad no es neutral. King (1997) advierten sobre la falacia ecológica: inferir comportamiento individual desde patrones agregados puede ser erróneo si composición de agregados varía.\n\n\n4.1.0.3 Según fuente\nDatos primarios\nRecolectados por el investigador para el proyecto específico. Encuestas propias, experimentos, observación directa, entrevistas codificadas.\nVentaja: Control total sobre qué se mide y cómo. Limitación: Costoso en tiempo y recursos.\nDatos secundarios\nRecolectados por otros, usados por el investigador. Censos, estadísticas oficiales, encuestas de opinión pública, datos administrativos.\nVentaja: Eficiencia. Acceso a muestras grandes y representativas. Limitación: No se diseñaron para nuestras preguntas específicas. Debemos aceptar decisiones de medición ajenas.\nDatos administrativos\nGenerados por procesos burocráticos: registros de votantes, datos tributarios, registros judiciales, historiales legislativos.\nVentaja: Cobertura completa (no muestral), alta confiabilidad. Limitación: Reflejan categorías burocráticas, no conceptos teóricos. Problemas de acceso y privacidad.\nDatos digitales\nGenerados por actividad en línea: tweets, posts de Facebook, búsquedas en Google, patrones de navegación. Creciente uso en ciencias sociales computacionales.\nVentaja: Volumen masivo, observación de comportamiento real (no reportado). Limitación: Representatividad problemática (no todos están en línea). Inferir actitudes desde comportamiento digital es complicado.\n\n\n4.1.0.4 Principales fuentes de datos\nPara ciencias sociales en Chile y América Latina, las fuentes más utilizadas incluyen:\n\nEncuestas: CEP, CASEN, Latinobarómetro, LAPOP\nDatos electorales: SERVEL (Chile), International IDEA\nDatos económicos: Banco Mundial, INE, CEPAL\nDatos de instituciones: V-Dem, Polity V\n\n\nCatálogo completo de fuentes de datos:\nEncuestas de opinión pública internacionales: - World Values Survey: Actitudes y valores en ~100 países - Latinobarómetro: 18 países latinoamericanos - AmericasBarometer (LAPOP): Actitudes políticas en las Américas\nDatos sobre instituciones políticas: - Polity V: Características de regímenes políticos - V-Dem: Variedades de democracia, múltiples dimensiones - Database of Political Institutions (DPI): Sistemas electorales - Comparative Constitutions Project: Contenido de constituciones\nDatos legislativos: - VoteView: Votaciones nominales del Congreso de EE.UU. - Manifesto Project: Contenido de manifiestos partidarios\n\n\n\n4.1.0.5 Calidad de datos\nNo todos los datos son igualmente útiles. Evaluar calidad es responsabilidad del investigador.\n\n\n4.1.0.6 Dimensiones de calidad\n\nValidez: ¿Los datos miden lo que pretenden medir? Vimos validez de medición en Capítulo @ref(medicion). Aquí, evaluar si las categorías y procedimientos de recolección capturan conceptos teóricos relevantes.\nConfiabilidad: ¿Los datos son consistentes? ¿Diferentes aplicaciones del mismo procedimiento producen resultados similares? En encuestas, verificar si preguntas se formulan igual en diferentes olas.\nCobertura: ¿Qué población representan los datos? Si una encuesta solo contacta teléfonos fijos, subrepresenta jóvenes. Si datos administrativos solo cubren sector formal, omiten informalidad.\nPrecisión: ¿Cuán exactas son las mediciones? Encuestas con muestras pequeñas tienen márgenes de error grandes. Datos administrativos pueden tener errores de digitación o categorización.\nActualidad (timeliness): ¿Cuán recientes son los datos? Para fenómenos que cambian rápido, datos de hace 5 años pueden ser obsoletos.\nAccesibilidad: ¿Los datos están disponibles? ¿En qué formato? ¿Con qué restricciones? Algunos datos excelentes son inaccesibles por razones legales o políticas.\n\n\n\n4.1.0.7 Problemas comunes\nDatos faltantes (missing data)\nLos valores faltantes son ubicuos. Pueden ser:\n\nCompletamente aleatorios (MCAR): La probabilidad de faltar no depende de nada. Raro en práctica.\nAleatorios condicional (MAR): La probabilidad depende de variables observadas. Manejable estadísticamente.\nNo aleatorios (MNAR): La probabilidad depende del valor no observado. Problemático.\n\nEstrategias: eliminación listwise (perder casos), imputación, modelar explícitamente los datos faltantes.\nErrores de medición\nDiscrepancias entre valor real y valor registrado. Pueden ser aleatorios (ruido) o sistemáticos (sesgo). Errores sistemáticos son más graves porque sesgan estimaciones.\nCodificación inconsistente\nVariables categóricas pueden codificarse de forma diferente en distintas partes del dataset. Ejemplo: género como “Masculino/Femenino”, “M/F”, “1/2”, “Hombre/Mujer” en diferentes variables. Esto complica análisis.\nValores atípicos (outliers)\nObservaciones extremas. Pueden ser errores de digitación o casos genuinos inusuales. Antes de eliminarlos, investigar.\nDuplicados\nObservaciones repetidas erróneamente. Común cuando múltiples fuentes se fusionan sin cuidado.",
    "crumbs": [
      "II. Unidad 1: Generalidades de la Investigación Cuantitativa",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Trabajando con datos</span>"
    ]
  },
  {
    "objectID": "04-datos.html#trabajando-con-r",
    "href": "04-datos.html#trabajando-con-r",
    "title": "4  Trabajando con datos",
    "section": "4.2 Trabajando con R",
    "text": "4.2 Trabajando con R\nR es un lenguaje de programación estadística y entorno para análisis de datos. RStudio es un entorno de desarrollo integrado (IDE) que hace más amigable trabajar con R.\n\n4.2.0.1 ¿Por qué R?\nVentajas: - Gratuito y de código abierto: Sin costos de licencia - Reproducible: Scripts documentan exactamente qué se hizo - Extensible: Miles de paquetes para técnicas especializadas - Comunidad activa: Foros, tutoriales, ayuda abundante - Estándar en ciencias sociales cuantitativas: Facilita colaboración y replicación\nDesventajas: - Curva de aprendizaje: Programar requiere práctica - Múltiples formas de hacer lo mismo: Puede ser confuso para principiantes\n\n\n4.2.0.2 Instalación\n\nDescargar R: https://cran.r-project.org/\nDescargar RStudio: https://posit.co/download/rstudio-desktop/\nInstalar ambos (primero R, luego RStudio)\n\n\n\n4.2.0.3 Anatomía de RStudio\nRStudio tiene cuatro paneles principales:\n\nEditor de scripts (arriba izquierda): Donde escribes código para guardar y ejecutar\nConsola (abajo izquierda): Donde se ejecuta el código y aparecen resultados\nEnvironment (arriba derecha): Muestra objetos en memoria (datasets, variables)\nFiles/Plots/Packages/Help (abajo derecha): Navegación de archivos, gráficos, ayuda\n\n\n\n4.2.0.4 Paquetes\nR base es poderoso, pero paquetes extienden funcionalidad. Instalación (una vez):\n\ninstall.packages(\"tidyverse\")  # Suite de paquetes para manipulación de datos\ninstall.packages(\"haven\")      # Leer archivos SPSS, Stata, SAS\ninstall.packages(\"readxl\")     # Leer archivos Excel\ninstall.packages(\"foreign\")    # Leer múltiples formatos\n\nCargar paquetes (cada sesión):\n\nlibrary(tidyverse)\nlibrary(haven)\n\n\n\n4.2.0.5 Objetos básicos en R\nVectores: Secuencias de elementos del mismo tipo\n\nedades &lt;- c(23, 45, 67, 34, 29)\npartidos &lt;- c(\"PS\", \"UDI\", \"RN\", \"PC\", \"PPD\")\n\nData frames: Tablas con filas (observaciones) y columnas (variables)\n\ndatos &lt;- data.frame(\n  id = 1:5,\n  edad = c(23, 45, 67, 34, 29),\n  partido = c(\"PS\", \"UDI\", \"RN\", \"PC\", \"PPD\"),\n  voto = c(\"Apruebo\", \"Rechazo\", \"Rechazo\", \"Apruebo\", \"Apruebo\")\n)\n\nFunciones: Operaciones que transforman inputs en outputs\n\nmean(edades)        # Promedio\n\n[1] 39.6\n\nsd(edades)          # Desviación estándar\n\n[1] 17.31473\n\ntable(datos$voto)   # Tabla de frecuencias\n\n\nApruebo Rechazo \n      3       2 \n\n\n\n\n4.2.0.6 Directorios de trabajo\nR busca y guarda archivos en el “directorio de trabajo”. Verificar:\n\ngetwd()  # ¿Dónde estoy?\n\nCambiar (ajustar ruta según tu computador):\n\nsetwd(\"~/Documentos/Investigacion/datos\")\n\nMejor práctica: usar proyectos de RStudio (.Rproj). Esto establece automáticamente el directorio de trabajo en la carpeta del proyecto.\n\n\n4.2.0.7 Importar datos\nLos datos pueden venir en múltiples formatos. R puede leer la mayoría.\n\n\n4.2.0.8 Archivos de texto: CSV\nLos archivos CSV (comma-separated values) son universales. Formato simple:\nid,edad,partido\n1,23,PS\n2,45,UDI\n3,67,RN\nImportar con R base:\n\ndatos &lt;- read.csv(\"encuesta.csv\")\n\nImportar con readr (parte de tidyverse, más rápido):\n\nlibrary(readr)\ndatos &lt;- read_csv(\"encuesta.csv\")\n\nParámetros comunes: - sep: Separador (, por defecto, ; en algunos países) - header: ¿Primera fila son nombres de variables? (TRUE por defecto) - na.strings: Cómo se codifican valores faltantes (“NA”, “.”, ““)\nEjemplo:\n\ndatos &lt;- read_csv(\"encuesta.csv\", \n                  na = c(\"\", \"NA\", \"No sabe\"),\n                  col_types = cols(edad = col_integer(),\n                                   partido = col_character()))\n\n\n\n4.2.0.9 Archivos de Excel\nExcel es ubicuo en administración pública. Paquete readxl:\n\nlibrary(readxl)\ndatos &lt;- read_excel(\"resultados_electorales.xlsx\", \n                    sheet = \"Presidenciales_2021\")\n\nEspecificar rango:\n\ndatos &lt;- read_excel(\"archivo.xlsx\", \n                    sheet = 2, \n                    range = \"A1:F100\")\n\n\n\n4.2.0.10 Archivos de software estadístico\nStata (.dta):\n\nlibrary(haven)\ndatos &lt;- read_dta(\"encuesta_casen.dta\")\n\nSPSS (.sav):\n\ndatos &lt;- read_sav(\"estudio_cep.sav\")\n\nSAS:\n\ndatos &lt;- read_sas(\"datos.sas7bdat\")\n\nEl paquete haven preserva etiquetas de valores, muy común en encuestas. Ejemplo:\n\ndatos &lt;- read_dta(\"encuesta.dta\")\n# Variable \"educ\" tiene valores 1,2,3 con etiquetas \"Primaria\",\"Secundaria\",\"Universitaria\"\nattributes(datos$educ)$labels\n\n\n\n4.2.0.11 Datos en línea y bases de datos\nMuchos datos están en URLs. Importar directamente:\n\nurl &lt;- \"https://ejemplo.com/datos.csv\"\ndatos &lt;- read_csv(url)\n\nPara datos de APIs, usar paquetes especializados: WDI (Banco Mundial), quantmod (datos financieros).\nPara bases SQL, usar DBI:\n\nlibrary(DBI)\ncon &lt;- dbConnect(RSQLite::SQLite(), \"mi_base.db\")\ndatos &lt;- dbGetQuery(con, \"SELECT * FROM votaciones WHERE year = 2021\")\ndbDisconnect(con)",
    "crumbs": [
      "II. Unidad 1: Generalidades de la Investigación Cuantitativa",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Trabajando con datos</span>"
    ]
  },
  {
    "objectID": "04-datos.html#manipulación-de-datos",
    "href": "04-datos.html#manipulación-de-datos",
    "title": "4  Trabajando con datos",
    "section": "4.3 Manipulación de datos",
    "text": "4.3 Manipulación de datos\nUna vez importados, los datos rara vez están listos para análisis. Necesitan limpieza y transformación.\n\n4.3.0.1 Inspeccionar datos\nPrimeros y últimos casos:\n\nhead(datos)       # Primeros 6 casos\ntail(datos, 10)   # Últimos 10 casos\n\nEstructura:\n\nstr(datos)        # Tipo de cada variable\nsummary(datos)    # Resumen estadístico\nglimpse(datos)    # Vista compacta (tidyverse)\n\nNombres de variables:\n\nnames(datos)\ncolnames(datos)\n\nDimensiones:\n\ndim(datos)        # Filas y columnas\nnrow(datos)       # Número de filas\nncol(datos)       # Número de columnas\n\n\n\n4.3.0.2 Seleccionar variables\nR base:\n\ndatos_reducido &lt;- datos[, c(\"id\", \"edad\", \"partido\")]\n\nTidyverse (dplyr):\n\nlibrary(dplyr)\ndatos_reducido &lt;- select(datos, id, edad, partido)\n\nSeleccionar por criterio:\n\n# Todas las variables que empiezan con \"voto_\"\ndatos_reducido &lt;- select(datos, starts_with(\"voto_\"))\n\n# Todas las variables numéricas\ndatos_reducido &lt;- select(datos, where(is.numeric))\n\n\n\n4.3.0.3 Filtrar casos\nR base:\n\njovenes &lt;- datos[datos$edad &lt; 30, ]\n\nTidyverse:\n\njovenes &lt;- filter(datos, edad &lt; 30)\njovenes_izquierda &lt;- filter(datos, edad &lt; 30 & partido %in% c(\"PS\", \"PC\", \"FA\"))\n\n\n\n4.3.0.4 Crear y transformar variables\nR base:\n\ndatos$edad_decadas &lt;- datos$edad / 10\ndatos$mayor_edad &lt;- ifelse(datos$edad &gt;= 18, \"Sí\", \"No\")\n\nTidyverse:\n\ndatos &lt;- mutate(datos, \n                edad_decadas = edad / 10,\n                mayor_edad = if_else(edad &gt;= 18, \"Sí\", \"No\"),\n                edad_cat = case_when(\n                  edad &lt; 30 ~ \"Joven\",\n                  edad &lt; 60 ~ \"Adulto\",\n                  TRUE ~ \"Mayor\"\n                ))\n\n\n\n4.3.0.5 Recodificar variables\nCambiar categorías:\n\ndatos &lt;- mutate(datos,\n                partido_bloques = case_when(\n                  partido %in% c(\"PS\", \"PC\", \"PPD\", \"FA\") ~ \"Izquierda\",\n                  partido %in% c(\"UDI\", \"RN\", \"EVOPOLI\") ~ \"Derecha\",\n                  TRUE ~ \"Centro/Otros\"\n                ))\n\n\n\n4.3.0.6 Renombrar variables\nR base:\n\nnames(datos)[names(datos) == \"p1\"] &lt;- \"confianza_congreso\"\n\nTidyverse:\n\ndatos &lt;- rename(datos, \n                confianza_congreso = p1,\n                confianza_gobierno = p2)\n\n\n\n4.3.0.7 Ordenar datos\nPor edad (ascendente):\n\ndatos_ordenado &lt;- arrange(datos, edad)\n\nPor edad (descendente):\n\ndatos_ordenado &lt;- arrange(datos, desc(edad))\n\nPor múltiples variables:\n\ndatos_ordenado &lt;- arrange(datos, partido, edad)\n\n\n\n\n4.3.0.8 Agregar datos por grupos\nResumir por grupos usando el operador pipe (%&gt;%):\n\nlibrary(dplyr)\nresumen_partido &lt;- datos %&gt;%\n  group_by(partido) %&gt;%\n  summarise(\n    n = n(),\n    edad_promedio = mean(edad, na.rm = TRUE),\n    edad_sd = sd(edad, na.rm = TRUE)\n  )\n\nEl operador %&gt;% pasa el resultado de una función a la siguiente.\n\n\n4.3.0.9 Unir datasets\nLeft join: Mantener todos los casos del dataset izquierdo\n\ndatos_completo &lt;- left_join(encuesta, resultados_electorales,\n                             by = \"comuna_id\")\n\nInner join: Mantener solo casos presentes en ambos datasets\n\ndatos_completo &lt;- inner_join(encuesta, resultados_electorales,\n                              by = \"comuna_id\")",
    "crumbs": [
      "II. Unidad 1: Generalidades de la Investigación Cuantitativa",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Trabajando con datos</span>"
    ]
  },
  {
    "objectID": "04-datos.html#exportar-datos",
    "href": "04-datos.html#exportar-datos",
    "title": "4  Trabajando con datos",
    "section": "4.4 Exportar datos",
    "text": "4.4 Exportar datos\nDespués de limpiar y transformar datos, es útil guardarlos.\n\n4.4.0.1 CSV\n\nwrite_csv(datos_limpios, \"datos_procesados.csv\")\n\n\n\n4.4.0.2 Formato de R\nGuardar como .RDS (R Data Serialization) preserva estructura completa:\n\nsaveRDS(datos_limpios, \"datos_procesados.rds\")\n\nLeer después:\n\ndatos &lt;- readRDS(\"datos_procesados.rds\")\n\n\n\n4.4.0.3 Stata\n\nlibrary(haven)\nwrite_dta(datos_limpios, \"datos_procesados.dta\")\n\n\n\n4.4.0.4 Excel\n\nlibrary(writexl)\nwrite_xlsx(datos_limpios, \"datos_procesados.xlsx\")\n\n\n\n4.4.0.5 Flujo reproducible\nLa reproducibilidad es esencial en ciencia. Otros (y tu yo futuro) deben poder replicar exactamente lo que hiciste.\n\n\n4.4.0.6 Principios\n\nUsa scripts, no clics: Todo debe estar en código. No hacer transformaciones manualmente en Excel que no queden documentadas.\nNunca modifiques datos originales: Lee los datos crudos, transfórmalos en R, guarda la versión procesada. Mantén los originales intactos.\nDocumenta tu código: Comentarios explican por qué hiciste algo:\n\n\n# Recodifico educación en tres categorías para simplificar análisis\n# La categoría \"técnica\" es pequeña y la combino con \"secundaria\"\ndatos &lt;- mutate(datos,\n                educ_cat = case_when(\n                  educ &lt;= 2 ~ \"Básica\",\n                  educ %in% c(3,4) ~ \"Media\",\n                  educ &gt;= 5 ~ \"Superior\"\n                ))\n\n\nOrganiza tu proyecto: Estructura de carpetas clara:\n\nproyecto/\n  datos/\n    crudos/\n    procesados/\n  scripts/\n    01_limpieza.R\n    02_analisis.R\n  resultados/\n    tablas/\n    graficos/\n  documento/\n\nUsa control de versiones: Git y GitHub permiten rastrear cambios y colaborar. No es obligatorio para principiantes, pero altamente recomendable a medida que proyectos crecen.\n\n\n\n4.4.0.7 R Markdown y Quarto\nR Markdown y Quarto integran código, resultados y texto en un solo documento. Permiten generar reportes reproducibles en HTML, PDF o Word.\n---\ntitle: \"Análisis de participación electoral\"\nauthor: \"Tu Nombre\"\noutput: html_document\n---\n\n## Introducción\n\nEste análisis examina factores asociados a participación electoral.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ndatos &lt;- read_csv(\"datos/encuesta.csv\")\nsummary(datos)\n\n```\nAl compilar (“Knit” o “Render”), R ejecuta el código e inserta resultados en el documento final. Si los datos cambian, el documento se actualiza automáticamente. :::",
    "crumbs": [
      "II. Unidad 1: Generalidades de la Investigación Cuantitativa",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Trabajando con datos</span>"
    ]
  },
  {
    "objectID": "04-datos.html#resumen",
    "href": "04-datos.html#resumen",
    "title": "4  Trabajando con datos",
    "section": "Resumen",
    "text": "Resumen\nLos datos de ciencias políticas varían en estructura (corte transversal, series temporales, panel, jerárquicos), granularidad (micro, meso, macro) y fuente (primarios, secundarios, administrativos, digitales). Cada tipo tiene ventajas y limitaciones.\nEvaluar calidad de datos es crucial: validez, confiabilidad, cobertura, precisión, actualidad, accesibilidad. Problemas comunes incluyen datos faltantes, errores de medición, codificación inconsistente, outliers y duplicados.\nR y RStudio proveen un entorno poderoso y reproducible para análisis cuantitativo. Los datos pueden importarse desde múltiples formatos (CSV, Excel, Stata, SPSS, bases de datos, URLs). Los paquetes readr, haven, readxl y foreign facilitan importación.\nLa manipulación de datos involucra inspeccionar, seleccionar variables, filtrar casos, crear nuevas variables, recodificar, ordenar, agregar y unir datasets. El paquete dplyr (parte de tidyverse) provee funciones intuitivas para estas operaciones.\nExportar datos procesados en formatos apropiados preserva trabajo y facilita colaboración. El flujo de trabajo reproducible —usando scripts, documentando código, manteniendo organización clara, nunca modificando datos originales— es esencial para investigación rigurosa.",
    "crumbs": [
      "II. Unidad 1: Generalidades de la Investigación Cuantitativa",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Trabajando con datos</span>"
    ]
  },
  {
    "objectID": "04-datos.html#lecturas-recomendadas",
    "href": "04-datos.html#lecturas-recomendadas",
    "title": "4  Trabajando con datos",
    "section": "Lecturas recomendadas",
    "text": "Lecturas recomendadas\nManipulación de datos en R:\nWickham, H., & Grolemund, G. (2017). R for Data Science. O’Reilly. [Disponible gratis en https://r4ds.had.co.nz/]\n→ Guía comprehensiva y accesible sobre tidyverse.\nReproducibilidad:\nGandrud, C. (2015). Reproducible Research with R and RStudio (2nd ed.). CRC Press.\n→ Prácticas y herramientas para investigación reproducible.\nCalidad de datos:\nKarr, A. F., Sanil, A. P., & Banks, D. L. (2006). Data quality: A statistical perspective. Statistical Methodology, 3(2), 137-173.\n→ Perspectiva estadística sobre dimensiones de calidad de datos.\nDatos faltantes:\nLittle, R. J., & Rubin, D. B. (2019). Statistical Analysis with Missing Data (3rd ed.). Wiley.\n→ Tratado técnico sobre manejo de datos faltantes.\nRecursos en línea:\n\nDocumentación de tidyverse: https://www.tidyverse.org/\nRStudio cheatsheets: https://posit.co/resources/cheatsheets/\nStack Overflow (para preguntas específicas): https://stackoverflow.com/questions/tagged/r",
    "crumbs": [
      "II. Unidad 1: Generalidades de la Investigación Cuantitativa",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Trabajando con datos</span>"
    ]
  },
  {
    "objectID": "04-datos.html#ejercicios",
    "href": "04-datos.html#ejercicios",
    "title": "4  Trabajando con datos",
    "section": "Ejercicios",
    "text": "Ejercicios\nLos ejercicios para este capítulo se encuentran en el Anexo de Ejercicios.\n\n\nKing, G. (1997). A Solution to the Ecological Inference Problem: Reconstructing Individual Behavior from Aggregate Data. American Journal of Political Science, 41(4), 1027-1053.",
    "crumbs": [
      "II. Unidad 1: Generalidades de la Investigación Cuantitativa",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Trabajando con datos</span>"
    ]
  },
  {
    "objectID": "05-estadistica-descriptiva.html",
    "href": "05-estadistica-descriptiva.html",
    "title": "5  Estadística descriptiva",
    "section": "",
    "text": "Objetivos del capítulo\nAl finalizar este capítulo, serás capaz de:",
    "crumbs": [
      "III. Unidad 2: Fundamentos de Estadística Descriptiva",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estadística descriptiva</span>"
    ]
  },
  {
    "objectID": "05-estadistica-descriptiva.html#objetivos-del-capítulo",
    "href": "05-estadistica-descriptiva.html#objetivos-del-capítulo",
    "title": "5  Estadística descriptiva",
    "section": "",
    "text": "Calcular e interpretar medidas de tendencia central\nCalcular e interpretar medidas de dispersión\nDescribir la forma de distribuciones\nIdentificar cuándo usar cada medida descriptiva\nGenerar gráficos exploratorios en R\nDetectar valores atípicos mediante métodos gráficos y numéricos",
    "crumbs": [
      "III. Unidad 2: Fundamentos de Estadística Descriptiva",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estadística descriptiva</span>"
    ]
  },
  {
    "objectID": "05-estadistica-descriptiva.html#describiendo-datos",
    "href": "05-estadistica-descriptiva.html#describiendo-datos",
    "title": "5  Estadística descriptiva",
    "section": "5.1 Describiendo datos",
    "text": "5.1 Describiendo datos\nAntes de calcular estadísticos, conviene visualizar cómo se distribuyen los datos. Una distribución de frecuencia muestra cuántas observaciones caen en cada valor o rango.\n\n5.1.0.1 Tablas de frecuencia\nPara variables categóricas, contamos casos en cada categoría:\n\n# Simulamos orientación política en encuesta\nset.seed(123)\nencuesta &lt;- data.frame(\n  orientacion = sample(c(\"Izquierda\", \"Centro\", \"Derecha\", \"Ninguna\"), \n                       800, replace = TRUE, \n                       prob = c(0.30, 0.25, 0.28, 0.17))\n)\n\n# Frecuencias absolutas\ntable(encuesta$orientacion)\n\n\n   Centro   Derecha Izquierda   Ninguna \n      199       230       238       133 \n\n# Frecuencias relativas (proporciones)\nprop.table(table(encuesta$orientacion))\n\n\n   Centro   Derecha Izquierda   Ninguna \n  0.24875   0.28750   0.29750   0.16625 \n\n# Porcentajes\nprop.table(table(encuesta$orientacion)) * 100\n\n\n   Centro   Derecha Izquierda   Ninguna \n   24.875    28.750    29.750    16.625 \n\n\nCon tidyverse:\n\nencuesta %&gt;%\n  count(orientacion) %&gt;%\n  mutate(porcentaje = n / sum(n) * 100)\n\n  orientacion   n porcentaje\n1      Centro 199     24.875\n2     Derecha 230     28.750\n3   Izquierda 238     29.750\n4     Ninguna 133     16.625\n\n\n\n\n5.1.0.2 Histogramas\nPara variables continuas, agrupamos en intervalos (bins):\n\nggplot(comunas, aes(x = participacion)) +\n  geom_histogram(bins = 30, fill = \"steelblue\", color = \"white\") +\n  labs(x = \"Participación electoral (%)\", \n       y = \"Número de comunas\",\n       title = \"Distribución de participación electoral\") +\n  theme_minimal()\n\n\n\n\nDistribución de participación electoral en comunas\n\n\n\n\nEl número de bins afecta la visualización:\n\np1 &lt;- ggplot(comunas, aes(x = participacion)) +\n  geom_histogram(bins = 10, fill = \"steelblue\", alpha = 0.7) +\n  labs(title = \"10 bins\") + theme_minimal()\n\np2 &lt;- ggplot(comunas, aes(x = participacion)) +\n  geom_histogram(bins = 50, fill = \"steelblue\", alpha = 0.7) +\n  labs(title = \"50 bins\") + theme_minimal()\n\nlibrary(patchwork)\np1 | p2\n\n\n\n\nHistogramas con diferentes números de bins\n\n\n\n\nMuy pocos bins ocultan detalles; demasiados bins generan ruido.\n\nRegla de Sturges\nLa regla de Sturges sugiere \\(k = 1 + 3.322 \\log(n)\\) bins, donde \\(n\\) es el número de observaciones.\n\n\n\n5.1.0.3 Medidas de tendencia central\nLas medidas de tendencia central resumen la ubicación “típica” de los datos. La media (\\(\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i\\)) es el promedio que usa toda la información pero es sensible a valores extremos, siendo apropiada para distribuciones simétricas.1 La mediana es el valor que divide la distribución en dos mitades iguales, es robusta a outliers, apropiada para distribuciones asimétricas, y tiene interpretación intuitiva. La moda es el valor más frecuente; para variables continuas tiene sentido solo con categorías o bins, siendo poco informativa sin agrupar pero útil para identificar multimodalidad.\n1 En 2022, el ingreso promedio en Chile era aproximadamente $650,000, pero la mediana era aproximadamente $420,000. La diferencia ocurre porque pocos súper-ricos jalan la media hacia arriba. Por eso reportes de desigualdad siempre usan mediana, no media.\nmean(comunas$participacion)\n\n[1] 46.75662\n\nmedian(comunas$participacion)\n\n[1] 46.79276\n\n# Ejemplo de sensibilidad a outliers\ningresos &lt;- c(500, 550, 600, 650, 700, 750, 800, 5000)\nmean(ingresos)  # La media se dispara por el valor extremo\n\n[1] 1193.75\n\n\n\n# Moda en variable categórica\ntabla &lt;- table(encuesta$orientacion)\nnames(tabla)[which.max(tabla)]\n\n[1] \"Izquierda\"\n\n\n\n# Simulamos distribución bimodal (dos grupos distintos)\nset.seed(456)\nbimodal &lt;- c(rnorm(200, mean = 30, sd = 5),\n             rnorm(200, mean = 55, sd = 5))\n\nggplot(data.frame(x = bimodal), aes(x = x)) +\n  geom_histogram(bins = 40, fill = \"coral\", alpha = 0.7) +\n  labs(title = \"Distribución bimodal\") +\n  theme_minimal()\n\n\n\n\nDistribución bimodal\n\n\n\n\nRegla general para elegir: distribuciones simétricas usa media porque usa toda la información; distribuciones asimétricas usa mediana porque es robusta a extremos;2 variables ordinales usa mediana porque la media no tiene sentido para categorías ordenadas; variables nominales usa moda porque es la única medida con sentido.\n2 Para saber si tu distribución es asimétrica: haz un histograma y observa si tiene “cola” larga a un lado, o compara media y mediana. Si media es mucho mayor que mediana, hay asimetría a la derecha. Variables que no pueden ser negativas frecuentemente son asimétricas a la derecha.\n# Distribución asimétrica a la derecha\nset.seed(789)\nasimetrica &lt;- rgamma(1000, shape = 2, rate = 0.5)\n\nmedia &lt;- mean(asimetrica)\nmediana &lt;- median(asimetrica)\n\nggplot(data.frame(x = asimetrica), aes(x = x)) +\n  geom_histogram(bins = 40, fill = \"lightblue\", alpha = 0.7) +\n  geom_vline(aes(xintercept = media, color = \"Media\"), \n             linewidth = 1, linetype = \"dashed\") +\n  geom_vline(aes(xintercept = mediana, color = \"Mediana\"), \n             linewidth = 1, linetype = \"dashed\") +\n  scale_color_manual(values = c(\"Media\" = \"red\", \"Mediana\" = \"blue\")) +\n  labs(title = \"Distribución asimétrica: media &gt; mediana\",\n       color = \"\") +\n  theme_minimal()\n\n\n\n\nMedia vs. mediana en distribución asimétrica\n\n\n\n\nEn distribuciones asimétricas a la derecha, la media excede la mediana (arrastrada por valores altos). En asimétricas a la izquierda, la media es menor que la mediana.",
    "crumbs": [
      "III. Unidad 2: Fundamentos de Estadística Descriptiva",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estadística descriptiva</span>"
    ]
  },
  {
    "objectID": "05-estadistica-descriptiva.html#medidas-de-dispersión",
    "href": "05-estadistica-descriptiva.html#medidas-de-dispersión",
    "title": "5  Estadística descriptiva",
    "section": "5.2 Medidas de dispersión",
    "text": "5.2 Medidas de dispersión\nLas medidas de tendencia central resumen “dónde” están los datos. Las medidas de dispersión resumen cuánto varían.\n\n5.2.0.1 Rango\nEl rango es la diferencia entre el máximo y el mínimo:\n\nrange(comunas$participacion)\n\n[1] 23.05528 68.61513\n\ndiff(range(comunas$participacion))\n\n[1] 45.55985\n\n\nSimple pero sensible a outliers. Un solo valor extremo determina el rango.\n\n\n5.2.0.2 Rango intercuartílico (IQR)\nEl IQR es la diferencia entre el tercer cuartil (Q3) y el primer cuartil (Q1). Captura el 50% central de los datos.\n\nquantile(comunas$participacion, probs = c(0.25, 0.75))\n\n     25%      75% \n41.68235 51.96510 \n\nIQR(comunas$participacion)\n\n[1] 10.28275\n\n\nInterpretación: El 50% central de comunas tiene participación entre 41.7% y 52%.\nIQR es robusto a outliers—solo usa el 50% central.\n\n\n5.2.0.3 Varianza\nLa varianza (\\(s^2\\)) mide la dispersión promedio al cuadrado respecto a la media:\n\\[s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n}(x_i - \\bar{x})^2\\]\n\nvar(comunas$participacion)\n\n[1] 58.69646\n\n\n\n¿Por qué \\(n-1\\) y no \\(n\\)? La corrección de Bessel ajusta por usar la media muestral en lugar de la media poblacional. Esto hace que la varianza muestral sea un estimador insesgado de la varianza poblacional.\n\nProblema: La varianza está en unidades al cuadrado (% al cuadrado), difícil de interpretar.\n\n\n5.2.0.4 Desviación estándar\nLa desviación estándar (\\(s\\)) es la raíz cuadrada de la varianza:\n\\[s = \\sqrt{s^2}\\]\n\nsd(comunas$participacion)\n\n[1] 7.661361\n\n\nInterpretación: En promedio, las comunas se desvían 7.7 puntos porcentuales de la participación media.\nLa desviación estándar está en las mismas unidades que los datos originales, facilitando interpretación.\n\n\n5.2.0.5 Coeficiente de variación\nEl coeficiente de variación (CV) es la desviación estándar relativa a la media:\n\\[CV = \\frac{s}{\\bar{x}} \\times 100\\%\\]\n\ncv &lt;- (sd(comunas$participacion) / mean(comunas$participacion)) * 100\ncv\n\n[1] 16.38562\n\n\nCV permite comparar variabilidad entre variables con diferentes escalas. Participación electoral (%) y años de educación tienen unidades incomparables, pero sus CVs son comparables.\n\n# Comparar variabilidad de dos variables\ncv_participacion &lt;- sd(comunas$participacion) / mean(comunas$participacion)\ncv_educacion &lt;- sd(comunas$educ_superior) / mean(comunas$educ_superior)\n\ndata.frame(\n  Variable = c(\"Participación\", \"Educación superior\"),\n  CV = c(cv_participacion, cv_educacion)\n) %&gt;% kable(digits = 3)\n\n\n\n\nVariable\nCV\n\n\n\n\nParticipación\n0.164\n\n\nEducación superior\n0.417\n\n\n\n\n\n\n\n5.2.0.6 Comparación de medidas de dispersión\n\n# Resumen de dispersión\ndata.frame(\n  Medida = c(\"Rango\", \"IQR\", \"Varianza\", \"Desv. Estándar\", \"CV (%)\"),\n  Valor = c(\n    diff(range(comunas$participacion)),\n    IQR(comunas$participacion),\n    var(comunas$participacion),\n    sd(comunas$participacion),\n    cv\n  )\n) %&gt;% kable(digits = 2)\n\n\n\n\nMedida\nValor\n\n\n\n\nRango\n45.56\n\n\nIQR\n10.28\n\n\nVarianza\n58.70\n\n\nDesv. Estándar\n7.66\n\n\nCV (%)\n16.39\n\n\n\n\n\n\n\n5.2.0.7 Percentiles y cuartiles\nLos percentiles dividen la distribución en 100 partes iguales. El percentil \\(p\\) es el valor por debajo del cual cae el \\(p\\)% de observaciones.\n\n# Percentiles importantes\nquantile(comunas$participacion, probs = c(0.05, 0.25, 0.50, 0.75, 0.95))\n\n      5%      25%      50%      75%      95% \n34.70348 41.68235 46.79276 51.96510 58.54432 \n\n\nCuartiles son percentiles específicos:\n\nQ1 (primer cuartil): Percentil 25\nQ2 (segundo cuartil): Mediana (percentil 50)\nQ3 (tercer cuartil): Percentil 75\n\nInterpretación: El 25% de comunas tiene participación ≤ 41.7%. El 75% tiene participación ≤ 52%.\n\n\n5.2.0.8 Resumen de cinco números\nEl resumen de cinco números (five-number summary) incluye:\n\nMínimo\nQ1\nMediana\nQ3\nMáximo\n\n\nsummary(comunas$participacion)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  23.06   41.68   46.79   46.76   51.97   68.62 \n\n\nEste resumen captura ubicación, dispersión y extremos. Es la base del boxplot.\n\n\n5.2.0.9 Forma de la distribución\n\n\n5.2.0.10 Asimetría (skewness)\nLa asimetría mide si la distribución se inclina hacia un lado:\n\nAsimetría positiva (derecha): Cola larga hacia la derecha. Media &gt; Mediana.\nAsimetría negativa (izquierda): Cola larga hacia la izquierda. Media &lt; Mediana.\nSimétrica: Colas balanceadas. Media ≈ Mediana.",
    "crumbs": [
      "III. Unidad 2: Fundamentos de Estadística Descriptiva",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estadística descriptiva</span>"
    ]
  },
  {
    "objectID": "05-estadistica-descriptiva.html#gráficos-exploratorios",
    "href": "05-estadistica-descriptiva.html#gráficos-exploratorios",
    "title": "5  Estadística descriptiva",
    "section": "5.3 Gráficos exploratorios",
    "text": "5.3 Gráficos exploratorios\n\n5.3.0.1 Boxplot (diagrama de caja)\nEl boxplot visualiza el resumen de cinco números:\n\nggplot(comunas, aes(y = participacion)) +\n  geom_boxplot(fill = \"lightblue\", width = 0.5) +\n  labs(y = \"Participación electoral (%)\",\n       title = \"Distribución de participación electoral\") +\n  theme_minimal() +\n  theme(axis.text.x = element_blank())\n\n\n\n\nBoxplot de participación electoral\n\n\n\n\nComponentes:\n\nCaja: IQR (Q1 a Q3)\nLínea dentro de caja: Mediana\nBigotes (whiskers): Extienden hasta 1.5×IQR desde Q1/Q3\nPuntos: Outliers (valores más allá de bigotes)\n\nComparar distribuciones entre grupos:\n\n# Crear categorías de pobreza\ncomunas &lt;- comunas %&gt;%\n  mutate(pobreza_cat = cut(pobreza, \n                            breaks = quantile(pobreza, probs = c(0, 1/3, 2/3, 1)),\n                            labels = c(\"Baja\", \"Media\", \"Alta\"),\n                            include.lowest = TRUE))\n\nggplot(comunas, aes(x = pobreza_cat, y = participacion, fill = pobreza_cat)) +\n  geom_boxplot(alpha = 0.7) +\n  labs(x = \"Nivel de pobreza\", \n       y = \"Participación electoral (%)\",\n       title = \"Participación electoral según nivel de pobreza\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\nParticipación electoral por nivel de pobreza (terciles)\n\n\n\n\n\n\n5.3.0.2 Violin plot\nCombina boxplot con densidad:\n\nggplot(comunas, aes(x = pobreza_cat, y = participacion, fill = pobreza_cat)) +\n  geom_violin(alpha = 0.7) +\n  geom_boxplot(width = 0.2, fill = \"white\", alpha = 0.8) +\n  labs(x = \"Nivel de pobreza\", \n       y = \"Participación electoral (%)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\nViolin plot de participación por pobreza\n\n\n\n\n\n\n5.3.0.3 Gráfico de densidad\nAlternativa suave al histograma:\n\nggplot(comunas, aes(x = participacion)) +\n  geom_density(fill = \"steelblue\", alpha = 0.5) +\n  geom_vline(aes(xintercept = mean(participacion)), \n             color = \"red\", linetype = \"dashed\", linewidth = 1) +\n  geom_vline(aes(xintercept = median(participacion)), \n             color = \"blue\", linetype = \"dashed\", linewidth = 1) +\n  annotate(\"text\", x = mean(comunas$participacion) + 2, \n           y = 0.045, label = \"Media\", color = \"red\") +\n  annotate(\"text\", x = median(comunas$participacion) - 2, \n           y = 0.045, label = \"Mediana\", color = \"blue\") +\n  labs(x = \"Participación electoral (%)\", \n       y = \"Densidad\") +\n  theme_minimal()\n\n\n\n\nDensidad de participación electoral\n\n\n\n\n\n\n5.3.0.4 Detección de valores atípicos\nLos outliers son observaciones inusualmente extremas. Pueden ser errores de medición o casos genuinamente inusuales.\n\n\n5.3.0.5 Método IQR\nCriterio estándar: outliers están más allá de \\(Q1 - 1.5 \\times IQR\\) o \\(Q3 + 1.5 \\times IQR\\):\n\nQ1 &lt;- quantile(comunas$participacion, 0.25)\nQ3 &lt;- quantile(comunas$participacion, 0.75)\nIQR_val &lt;- IQR(comunas$participacion)\n\nlimite_inferior &lt;- Q1 - 1.5 * IQR_val\nlimite_superior &lt;- Q3 + 1.5 * IQR_val\n\n# Identificar outliers\noutliers &lt;- comunas %&gt;%\n  filter(participacion &lt; limite_inferior | participacion &gt; limite_superior)\n\nnrow(outliers)\n\n[1] 4\n\n\nHay 4 comunas con participación atípica.\n\n# Ver outliers\noutliers %&gt;%\n  select(comuna, participacion) %&gt;%\n  arrange(participacion) %&gt;%\n  head(10) %&gt;%\n  kable(digits = 1)\n\n\n\n\ncomuna\nparticipacion\n\n\n\n\nComuna 59\n23.1\n\n\nComuna 269\n25.4\n\n\nComuna 18\n25.7\n\n\nComuna 118\n68.6",
    "crumbs": [
      "III. Unidad 2: Fundamentos de Estadística Descriptiva",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estadística descriptiva</span>"
    ]
  },
  {
    "objectID": "05-estadistica-descriptiva.html#relaciones-entre-variables",
    "href": "05-estadistica-descriptiva.html#relaciones-entre-variables",
    "title": "5  Estadística descriptiva",
    "section": "5.4 Relaciones entre variables",
    "text": "5.4 Relaciones entre variables\nFrecuentemente queremos describir relaciones entre variables.\n\n5.4.0.1 Tablas de contingencia\nPara dos variables categóricas:\n\n# Simulamos datos\nset.seed(222)\nencuesta &lt;- encuesta %&gt;%\n  mutate(voto = sample(c(\"Apruebo\", \"Rechazo\"), \n                       nrow(encuesta), replace = TRUE,\n                       prob = c(0.52, 0.48)))\n\n# Tabla de contingencia\ntabla &lt;- table(encuesta$orientacion, encuesta$voto)\ntabla\n\n           \n            Apruebo Rechazo\n  Centro        108      91\n  Derecha       114     116\n  Izquierda     112     126\n  Ninguna        74      59\n\n\nCon proporciones:\n\n# Proporciones por fila\nprop.table(tabla, margin = 1)\n\n           \n              Apruebo   Rechazo\n  Centro    0.5427136 0.4572864\n  Derecha   0.4956522 0.5043478\n  Izquierda 0.4705882 0.5294118\n  Ninguna   0.5563910 0.4436090\n\n# Proporciones por columna\nprop.table(tabla, margin = 2)\n\n           \n              Apruebo   Rechazo\n  Centro    0.2647059 0.2321429\n  Derecha   0.2794118 0.2959184\n  Izquierda 0.2745098 0.3214286\n  Ninguna   0.1813725 0.1505102\n\n\n\n\n5.4.0.2 Covarianza\nLa covarianza mide cómo dos variables varían conjuntamente:\n\\[\\text{Cov}(X, Y) = \\frac{1}{n-1}\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})\\]\n\ncov(comunas$participacion, comunas$educ_superior)\n\n[1] -4.409441\n\n\n\nCovarianza positiva: Variables tienden a moverse juntas\nCovarianza negativa: Variables tienden a moverse en direcciones opuestas\nCovarianza ≈ 0: No hay relación lineal\n\nProblema: La magnitud depende de las escalas. Difícil interpretar.\n\n\n5.4.0.3 Correlación\nLa correlación de Pearson (\\(r\\)) es la covarianza estandarizada:\n\\[r = \\frac{\\text{Cov}(X, Y)}{s_X s_Y}\\]\n\ncor(comunas$participacion, comunas$educ_superior)\n\n[1] -0.05572996\n\n\nPropiedades:\n\nRango: \\(-1 \\leq r \\leq 1\\)\n\\(r = 1\\): Correlación positiva perfecta\n\\(r = -1\\): Correlación negativa perfecta\n\\(r = 0\\): No hay correlación lineal\nNo depende de escalas\n\n\nggplot(comunas, aes(x = educ_superior, y = participacion)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(x = \"Población con educación superior (%)\",\n       y = \"Participación electoral (%)\",\n       title = paste0(\"Correlación: r = \", \n                     round(cor(comunas$educ_superior, comunas$participacion), 2))) +\n  theme_minimal()\n\n\n\n\nCorrelación entre participación y educación superior\n\n\n\n\nImportante: Correlación mide asociación lineal, no causalidad. Alta correlación no implica que X causa Y.\n\n\n5.4.0.4 Matriz de correlaciones\nPara múltiples variables:\n\n# Seleccionar variables numéricas\nvars_numericas &lt;- comunas %&gt;%\n  select(participacion, pobreza, educ_superior)\n\n# Matriz de correlación\ncor_matrix &lt;- cor(vars_numericas)\ncor_matrix %&gt;% \n  kable(digits = 2)\n\n\n\n\n\nparticipacion\npobreza\neduc_superior\n\n\n\n\nparticipacion\n1.00\n0.00\n-0.06\n\n\npobreza\n0.00\n1.00\n0.08\n\n\neduc_superior\n-0.06\n0.08\n1.00\n\n\n\n\n\nVisualización:\n\nlibrary(corrplot)\ncorrplot(cor_matrix, method = \"color\", type = \"upper\", \n         addCoef.col = \"black\", number.cex = 0.8,\n         tl.col = \"black\", tl.srt = 45)\n\n\n\n\nMatriz de correlaciones\n\n\n\n\n\n\n5.4.0.5 Estadística por grupos\nComparar estadísticos entre grupos:\n\ncomunas %&gt;%\n  group_by(pobreza_cat) %&gt;%\n  summarise(\n    n = n(),\n    participacion_media = mean(participacion),\n    participacion_mediana = median(participacion),\n    participacion_sd = sd(participacion),\n    educ_media = mean(educ_superior)\n  ) %&gt;%\n  kable(digits = 1)\n\n\n\n\n\n\n\n\n\n\n\n\npobreza_cat\nn\nparticipacion_media\nparticipacion_mediana\nparticipacion_sd\neduc_media\n\n\n\n\nBaja\n116\n47.0\n46.6\n8.1\n24.0\n\n\nMedia\n115\n46.7\n46.9\n7.9\n24.8\n\n\nAlta\n115\n46.5\n46.8\n7.0\n25.6\n\n\n\n\n\nVisualización de múltiples estadísticos:\n\nresumen &lt;- comunas %&gt;%\n  group_by(pobreza_cat) %&gt;%\n  summarise(\n    Media = mean(participacion),\n    Mediana = median(participacion)\n  ) %&gt;%\n  pivot_longer(cols = c(Media, Mediana), \n               names_to = \"Estadistico\", \n               values_to = \"Valor\")\n\nggplot(resumen, aes(x = pobreza_cat, y = Valor, fill = Estadistico)) +\n  geom_col(position = \"dodge\") +\n  labs(x = \"Nivel de pobreza\",\n       y = \"Participación electoral (%)\",\n       fill = \"Estadístico\") +\n  theme_minimal()\n\n\n\n\nComparación de grupos",
    "crumbs": [
      "III. Unidad 2: Fundamentos de Estadística Descriptiva",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estadística descriptiva</span>"
    ]
  },
  {
    "objectID": "05-estadistica-descriptiva.html#resumen",
    "href": "05-estadistica-descriptiva.html#resumen",
    "title": "5  Estadística descriptiva",
    "section": "Resumen",
    "text": "Resumen\nLa estadística descriptiva resume datos mediante medidas numéricas y gráficos. Las medidas de tendencia central (media, mediana, moda) capturan la ubicación típica. Para distribuciones simétricas, usar la media; para asimétricas, la mediana es más robusta.\nLas medidas de dispersión (rango, IQR, varianza, desviación estándar) cuantifican variabilidad. La desviación estándar es la más usada por estar en unidades originales. El coeficiente de variación permite comparar dispersión entre variables con diferentes escalas.\nLos percentiles y cuartiles dividen la distribución en partes iguales. El resumen de cinco números (mínimo, Q1, mediana, Q3, máximo) captura ubicación y dispersión, visualizado en boxplots.\nLa forma de la distribución se caracteriza por asimetría (skewness) y curtosis. Distribuciones asimétricas tienen colas desbalanceadas; la curtosis mide peso de las colas.\nLos gráficos exploratorios (histogramas, boxplots, densidades, violin plots) revelan patrones que los estadísticos numéricos pueden ocultar. Los outliers requieren investigación—nunca eliminarlos automáticamente.\nPara relaciones bivariadas, la covarianza mide asociación conjunta pero depende de escalas. La correlación de Pearson estandariza la covarianza y varía entre -1 y 1, midiendo asociación lineal.\nLa estadística descriptiva es exploratoria. Revela patrones, sugiere hipótesis, detecta problemas de datos. Pero no prueba nada—eso requiere inferencia estadística (Capítulos siguientes).",
    "crumbs": [
      "III. Unidad 2: Fundamentos de Estadística Descriptiva",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estadística descriptiva</span>"
    ]
  },
  {
    "objectID": "05-estadistica-descriptiva.html#lecturas-recomendadas",
    "href": "05-estadistica-descriptiva.html#lecturas-recomendadas",
    "title": "5  Estadística descriptiva",
    "section": "Lecturas recomendadas",
    "text": "Lecturas recomendadas\nFundamentos de estadística descriptiva:\nAgresti, A., & Finlay, B. (2018). Statistical Methods for the Social Sciences (5th ed.). Pearson.\n→ Capítulos 2-4 cubren estadística descriptiva con ejemplos de ciencias sociales.\nVisualización de datos:\nHealy, K. (2018). Data Visualization: A Practical Introduction. Princeton University Press.\n→ Principios de visualización efectiva con énfasis en ggplot2.\nEstadística exploratoria:\nTukey, J. W. (1977). Exploratory Data Analysis. Addison-Wesley.\n→ Clásico sobre análisis exploratorio y visualización.\nPara profundizar en R:\nWickham, H., & Grolemund, G. (2017). R for Data Science. O’Reilly. [https://r4ds.had.co.nz/]\n→ Capítulos 5 y 7 sobre transformación y análisis exploratorio.",
    "crumbs": [
      "III. Unidad 2: Fundamentos de Estadística Descriptiva",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estadística descriptiva</span>"
    ]
  },
  {
    "objectID": "05-estadistica-descriptiva.html#ejercicios",
    "href": "05-estadistica-descriptiva.html#ejercicios",
    "title": "5  Estadística descriptiva",
    "section": "Ejercicios",
    "text": "Ejercicios\nLos ejercicios para este capítulo se encuentran en el Anexo de Ejercicios.",
    "crumbs": [
      "III. Unidad 2: Fundamentos de Estadística Descriptiva",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estadística descriptiva</span>"
    ]
  },
  {
    "objectID": "06-visualizacion.html",
    "href": "06-visualizacion.html",
    "title": "6  Visualización de datos",
    "section": "",
    "text": "Objetivos del capítulo\nAl finalizar este capítulo, serás capaz de:",
    "crumbs": [
      "III. Unidad 2: Fundamentos de Estadística Descriptiva",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Visualización de datos</span>"
    ]
  },
  {
    "objectID": "06-visualizacion.html#objetivos-del-capítulo",
    "href": "06-visualizacion.html#objetivos-del-capítulo",
    "title": "6  Visualización de datos",
    "section": "",
    "text": "Aplicar principios de diseño gráfico efectivo\nUsar la gramática de gráficos (grammar of graphics) con ggplot2\nCrear y personalizar múltiples tipos de gráficos\nIdentificar visualizaciones problemáticas y mejorarlas\nCombinar múltiples gráficos en una figura\nExportar gráficos para publicación",
    "crumbs": [
      "III. Unidad 2: Fundamentos de Estadística Descriptiva",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Visualización de datos</span>"
    ]
  },
  {
    "objectID": "06-visualizacion.html#principios-y-gramática-de-gráficos",
    "href": "06-visualizacion.html#principios-y-gramática-de-gráficos",
    "title": "6  Visualización de datos",
    "section": "6.1 Principios y gramática de gráficos",
    "text": "6.1 Principios y gramática de gráficos\nTufte (1983) estableció principios fundamentales de diseño gráfico que permanecen vigentes:\n\n6.1.0.1 1. Maximizar el ratio datos-tinta\nEliminar elementos innecesarios. Cada elemento gráfico debe comunicar información.\nMal ejemplo (chartjunk):\n\n# Gráfico sobrecargado\nggplot(comunas %&gt;% slice(1:10), aes(x = reorder(region, -izquierda_2021), y = izquierda_2021)) +\n  geom_bar(stat = \"identity\", fill = \"red\", color = \"gold\", linewidth = 2) +\n  geom_text(aes(label = round(izquierda_2021, 0)), vjust = -0.5, size = 6, color = \"blue\") +\n  labs(title = \"!!!VOTO DE IZQUIERDA POR REGIÓN!!!\", \n       x = \"REGIÓN\", y = \"PORCENTAJE (%)\") +\n  theme_dark() +\n  theme(\n    plot.background = element_rect(fill = \"yellow\"),\n    panel.grid.major = element_line(color = \"purple\", linewidth = 2),\n    axis.text = element_text(size = 14, face = \"bold\", color = \"red\")\n  )\n\n\n\n\nGráfico con elementos innecesarios\n\n\n\n\nBuen ejemplo (limpio):\n\ncomunas %&gt;%\n  group_by(region) %&gt;%\n  summarise(izquierda_media = mean(izquierda_2021)) %&gt;%\n  ggplot(aes(x = reorder(region, izquierda_media), y = izquierda_media)) +\n  geom_col(fill = \"steelblue\", width = 0.7) +\n  coord_flip() +\n  labs(x = NULL, y = \"Voto izquierda (%)\", \n       title = \"Promedio de voto izquierda por región, 2021\") +\n  theme_minimal()\n\n\n\n\nGráfico limpio y efectivo\n\n\n\n\n\n\n6.1.0.2 2. Usar el canal visual apropiado\nLa percepción humana procesa algunos atributos visuales mejor que otros:\nJerarquía de canales visuales (de más a menos preciso): 1. Posición en eje común 2. Longitud 3. Ángulo/pendiente 4. Área 5. Volumen 6. Color (saturación) 7. Color (tono)\nEsto explica por qué gráficos de barras son más precisos que gráficos de torta.\n\ndatos_partidos &lt;- data.frame(\n  partido = c(\"PS\", \"DC\", \"RN\", \"UDI\", \"Otros\"),\n  votos = c(23, 18, 22, 19, 18)\n)\n\np1 &lt;- ggplot(datos_partidos, aes(x = reorder(partido, votos), y = votos)) +\n  geom_col(fill = \"steelblue\") +\n  coord_flip() +\n  labs(x = NULL, y = \"Votos (%)\", title = \"Gráfico de barras\") +\n  theme_minimal()\n\np2 &lt;- ggplot(datos_partidos, aes(x = \"\", y = votos, fill = partido)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(\"y\") +\n  labs(title = \"Gráfico de torta\") +\n  theme_void() +\n  theme(legend.position = \"right\")\n\np1 | p2\n\n\n\n\nComparación: barras vs. torta\n\n\n\n\nEl gráfico de barras permite comparaciones precisas. El gráfico de torta dificulta distinguir diferencias pequeñas.\n\n\n6.1.0.3 3. Mostrar comparaciones\nLos datos adquieren significado mediante comparación. Comparar contra: - Otros grupos - Otros momentos - Un estándar o objetivo\n\ncomunas_muestra &lt;- comunas %&gt;%\n  slice_sample(n = 20)\n\nggplot(comunas_muestra, aes(x = izquierda_2017, xend = izquierda_2021, \n                             y = reorder(comuna_id, izquierda_2021))) +\n  geom_segment(aes(yend = comuna_id), color = \"gray70\", linewidth = 1) +\n  geom_point(aes(x = izquierda_2017, color = \"2017\"), size = 3) +\n  geom_point(aes(x = izquierda_2021, color = \"2021\"), size = 3) +\n  scale_color_manual(values = c(\"2017\" = \"coral\", \"2021\" = \"steelblue\")) +\n  labs(x = \"Voto izquierda (%)\", y = \"Comuna (ID)\",\n       title = \"Cambio en voto de izquierda entre elecciones\",\n       color = \"Año\") +\n  theme_minimal()\n\n\n\n\nComparación de cambio electoral 2017-2021\n\n\n\n\n\n\n6.1.0.4 4. Mostrar causalidad y explicación\nLos gráficos deben sugerir explicaciones, no solo describir.\n\nggplot(comunas, aes(x = urbano, y = cambio_izquierda, fill = urbano)) +\n  geom_violin(alpha = 0.7, show.legend = FALSE) +\n  geom_boxplot(width = 0.2, fill = \"white\", alpha = 0.8, show.legend = FALSE) +\n  scale_x_discrete(labels = c(\"FALSE\" = \"Rural\", \"TRUE\" = \"Urbana\")) +\n  labs(x = \"Tipo de comuna\", y = \"Cambio en voto izquierda (puntos porcentuales)\",\n       title = \"Cambio electoral según urbanización\",\n       subtitle = \"Las comunas urbanas experimentaron mayor crecimiento del voto de izquierda\") +\n  theme_minimal()\n\n\n\n\nRelación entre urbanización y cambio electoral\n\n\n\n\n\n\n6.1.0.5 5. Integrar evidencia\nCombinar palabras, números y gráficos para una narrativa coherente.\n\n\n6.1.0.6 Grammar of Graphics y ggplot2\nWilkinson (2005) propuso que los gráficos estadísticos tienen una gramática—componentes sistemáticos que se combinan para producir visualizaciones.\n\n\n6.1.0.7 Componentes de ggplot2\n\nDatos: El dataset\nAesthetics (aes): Mapeo de variables a propiedades visuales (x, y, color, tamaño)\nGeometrías (geom): Representación visual (puntos, líneas, barras)\nEscalas (scales): Cómo se traducen valores de datos a valores visuales\nFacetas (facets): Paneles múltiples\nTemas (themes): Elementos no relacionados con datos (títulos, fondos)\n\n\n\n6.1.0.8 Estructura básica\n\nggplot(data = &lt;DATOS&gt;, aes(x = &lt;VAR_X&gt;, y = &lt;VAR_Y&gt;)) +\n  geom_&lt;TIPO&gt;() +\n  scale_&lt;...&gt;() +\n  facet_&lt;...&gt;() +\n  labs(...) +\n  theme_&lt;...&gt;()\n\n\n\n6.1.0.9 Ejemplo paso a paso\n\n# Paso 1: Solo datos y aesthetics (nada se dibuja)\np1 &lt;- ggplot(comunas, aes(x = izquierda_2017, y = izquierda_2021))\n\n# Paso 2: Agregar geometría\np2 &lt;- p1 + geom_point(alpha = 0.5)\n\n# Paso 3: Agregar línea de referencia\np3 &lt;- p2 + geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"red\")\n\n# Paso 4: Mejorar etiquetas\np4 &lt;- p3 + labs(x = \"Voto izquierda 2017 (%)\", \n                y = \"Voto izquierda 2021 (%)\",\n                title = \"Cambio electoral entre elecciones\")\n\n# Combinar para mostrar progresión\n(p1 + ggtitle(\"Paso 1: Solo aesthetics\")) / \n  (p2 + ggtitle(\"Paso 2: + geometría\")) /\n  (p3 + ggtitle(\"Paso 3: + línea de referencia\")) /\n  (p4 + ggtitle(\"Paso 4: + etiquetas\"))\n\n\n\n\nConstrucción progresiva de un gráfico",
    "crumbs": [
      "III. Unidad 2: Fundamentos de Estadística Descriptiva",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Visualización de datos</span>"
    ]
  },
  {
    "objectID": "06-visualizacion.html#tipos-de-gráficos",
    "href": "06-visualizacion.html#tipos-de-gráficos",
    "title": "6  Visualización de datos",
    "section": "6.2 Tipos de gráficos",
    "text": "6.2 Tipos de gráficos\n\n6.2.0.1 Variables continuas\nHistograma con densidad superpuesta:\n\nggplot(comunas, aes(x = cambio_izquierda)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 30, \n                 fill = \"lightblue\", color = \"white\") +\n  geom_density(color = \"darkblue\", linewidth = 1) +\n  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"red\", linewidth = 1) +\n  labs(x = \"Cambio en voto izquierda (puntos porcentuales)\",\n       y = \"Densidad\",\n       title = \"Distribución del cambio electoral 2017-2021\",\n       subtitle = \"La mayoría de comunas experimentó crecimiento del voto de izquierda\") +\n  theme_minimal()\n\n\n\n\nDistribución del cambio electoral\n\n\n\n\nRidgeline plot (montañas):\n\nlibrary(ggridges)\n\nggplot(comunas, aes(x = cambio_izquierda, y = region, fill = region)) +\n  geom_density_ridges(alpha = 0.7, show.legend = FALSE) +\n  labs(x = \"Cambio en voto izquierda (puntos porcentuales)\",\n       y = NULL,\n       title = \"Cambio electoral por región\") +\n  theme_minimal()\n\n\n\n\nDistribuciones por región\n\n\n\n\n\n\n6.2.0.2 Variables categóricas\nGráfico de barras ordenado:\n\ncomunas %&gt;%\n  count(region) %&gt;%\n  ggplot(aes(x = reorder(region, n), y = n)) +\n  geom_col(fill = \"steelblue\") +\n  geom_text(aes(label = n), hjust = -0.2, size = 3.5) +\n  coord_flip() +\n  labs(x = NULL, y = \"Número de comunas\",\n       title = \"Comunas por región en la muestra\") +\n  theme_minimal()\n\n\n\n\nFrecuencias ordenadas\n\n\n\n\nDot plot (preferible cuando muchas categorías):\n\ncomunas %&gt;%\n  count(region) %&gt;%\n  ggplot(aes(x = n, y = reorder(region, n))) +\n  geom_point(size = 4, color = \"steelblue\") +\n  geom_segment(aes(x = 0, xend = n, yend = region), color = \"gray70\") +\n  labs(x = \"Número de comunas\", y = NULL,\n       title = \"Comunas por región\") +\n  theme_minimal()\n\n\n\n\nDot plot como alternativa\n\n\n\n\n\n\n6.2.0.3 Gráficos bivariados\n\n\n6.2.0.4 Dos variables continuas: scatter plots\nBásico con línea de tendencia:\n\nggplot(comunas, aes(x = izquierda_2017, y = izquierda_2021)) +\n  geom_point(alpha = 0.4) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"red\") +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"blue\") +\n  labs(x = \"Voto izquierda 2017 (%)\", \n       y = \"Voto izquierda 2021 (%)\",\n       title = \"Relación entre apoyo de izquierda en dos elecciones\",\n       subtitle = \"Línea roja: regresión | Línea azul: sin cambio\") +\n  theme_minimal()\n\n\n\n\nRelación entre voto 2017 y 2021\n\n\n\n\nCon tercera variable (color/tamaño):\n\nggplot(comunas, aes(x = izquierda_2017, y = izquierda_2021)) +\n  geom_point(aes(color = region, size = poblacion), alpha = 0.6) +\n  scale_size_continuous(labels = comma, range = c(1, 8)) +\n  labs(x = \"Voto izquierda 2017 (%)\", \n       y = \"Voto izquierda 2021 (%)\",\n       size = \"Población\", color = \"Región\",\n       title = \"Cambio electoral según región y tamaño\") +\n  theme_minimal()\n\n\n\n\nScatter plot con tercera variable\n\n\n\n\nEtiquetado selectivo con ggrepel:\n\n# Identificar casos extremos para etiquetar\nextremos &lt;- comunas %&gt;%\n  filter(abs(cambio_izquierda) &gt; 15) %&gt;%\n  mutate(label = paste0(\"Comuna \", comuna_id))\n\nggplot(comunas, aes(x = izquierda_2017, y = cambio_izquierda)) +\n  geom_point(alpha = 0.3) +\n  geom_point(data = extremos, color = \"red\", size = 3) +\n  geom_text_repel(data = extremos, aes(label = label), \n                  size = 3, max.overlaps = 15) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"blue\") +\n  labs(x = \"Voto izquierda 2017 (%)\",\n       y = \"Cambio 2017-2021 (puntos porcentuales)\",\n       title = \"Cambio electoral desde baseline 2017\",\n       subtitle = \"Comunas con cambios extremos etiquetadas en rojo\") +\n  theme_minimal()\n\n\n\n\nScatter plot con etiquetas\n\n\n\n\n\n\n6.2.0.5 Variable continua vs. categórica\nBoxplots comparativos:\n\nggplot(comunas, aes(x = region, y = cambio_izquierda, fill = region)) +\n  geom_boxplot(alpha = 0.7, show.legend = FALSE) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  labs(x = NULL, y = \"Cambio en voto izquierda (puntos porcentuales)\",\n       title = \"Cambio electoral por región\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\nDistribuciones por grupo\n\n\n\n\nViolin plots con puntos:\n\nggplot(comunas, aes(x = region, y = cambio_izquierda, fill = region)) +\n  geom_violin(alpha = 0.5, show.legend = FALSE) +\n  geom_jitter(width = 0.2, alpha = 0.2, size = 0.8, show.legend = FALSE) +\n  stat_summary(fun = median, geom = \"point\", size = 3, color = \"red\") +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"blue\") +\n  labs(x = NULL, y = \"Cambio en voto izquierda (p.p.)\",\n       title = \"Distribución del cambio electoral por región\",\n       subtitle = \"Punto rojo: mediana\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\nViolin plot con datos individuales\n\n\n\n\n\n\n6.2.0.6 Dos variables categóricas\nHeatmap de tabla de contingencia:\n\n# Crear categorías\ncomunas_cat &lt;- comunas %&gt;%\n  mutate(\n    cambio_cat = cut(cambio_izquierda, \n                     breaks = c(-Inf, -5, 5, Inf),\n                     labels = c(\"Bajó\", \"Estable\", \"Subió\")),\n    urbano_lab = ifelse(urbano, \"Urbana\", \"Rural\")\n  )\n\ntabla_cont &lt;- table(comunas_cat$urbano_lab, comunas_cat$cambio_cat)\n\n# Convertir a data frame para ggplot\ntabla_df &lt;- as.data.frame(tabla_cont)\nnames(tabla_df) &lt;- c(\"Urbano\", \"Cambio\", \"Freq\")\n\nggplot(tabla_df, aes(x = Cambio, y = Urbano, fill = Freq)) +\n  geom_tile(color = \"white\") +\n  geom_text(aes(label = Freq), color = \"white\", size = 5) +\n  scale_fill_gradient(low = \"lightblue\", high = \"darkblue\") +\n  labs(x = \"Cambio electoral\", y = \"Tipo de comuna\",\n       fill = \"Frecuencia\",\n       title = \"Cambio electoral según urbanización\") +\n  theme_minimal()\n\n\n\n\nHeatmap de frecuencias\n\n\n\n\n\n\n6.2.0.7 Series temporales\nGráfico de líneas simple:\n\nggplot(aprobacion, aes(x = mes, y = aprobacion)) +\n  geom_line(color = \"steelblue\", linewidth = 1) +\n  geom_point(color = \"steelblue\", size = 2) +\n  scale_x_date(date_labels = \"%b %Y\", date_breaks = \"3 months\") +\n  scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, 20)) +\n  labs(x = NULL, y = \"Aprobación (%)\",\n       title = \"Evolución de aprobación presidencial\",\n       subtitle = \"Marzo 2022 - Febrero 2024\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\nSerie temporal de aprobación presidencial\n\n\n\n\nMúltiples series:\n\n# Convertir a formato largo\naprobacion_long &lt;- aprobacion %&gt;%\n  pivot_longer(cols = c(aprobacion, desaprobacion, indeciso),\n               names_to = \"categoria\", values_to = \"porcentaje\")\n\nggplot(aprobacion_long, aes(x = mes, y = porcentaje, color = categoria)) +\n  geom_line(linewidth = 1) +\n  geom_point(size = 1.5) +\n  scale_color_manual(values = c(\"aprobacion\" = \"darkgreen\", \n                                 \"desaprobacion\" = \"darkred\",\n                                 \"indeciso\" = \"gray60\"),\n                     labels = c(\"Aprueba\", \"Desaprueba\", \"Indeciso\")) +\n  scale_x_date(date_labels = \"%b %Y\", date_breaks = \"3 months\") +\n  scale_y_continuous(limits = c(0, 100)) +\n  labs(x = NULL, y = \"Porcentaje (%)\", color = NULL,\n       title = \"Evaluación presidencial a lo largo del tiempo\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\nMúltiples series temporales\n\n\n\n\nÁrea apilada:\n\nggplot(aprobacion_long, aes(x = mes, y = porcentaje, fill = categoria)) +\n  geom_area(alpha = 0.8) +\n  scale_fill_manual(values = c(\"aprobacion\" = \"darkgreen\", \n                                \"desaprobacion\" = \"darkred\",\n                                \"indeciso\" = \"gray60\"),\n                    labels = c(\"Aprueba\", \"Desaprueba\", \"Indeciso\")) +\n  scale_x_date(date_labels = \"%b %Y\", date_breaks = \"3 months\") +\n  scale_y_continuous(limits = c(0, 100), expand = c(0, 0)) +\n  labs(x = NULL, y = \"Porcentaje (%)\", fill = NULL,\n       title = \"Composición de evaluación presidencial\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\nGráfico de área apilada\n\n\n\n\n\n\n6.2.0.8 Facetas\nDividir gráficos en paneles según una variable categórica.\n\n\n6.2.0.9 facet_wrap\n\nggplot(comunas, aes(x = izquierda_2017, y = izquierda_2021)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"blue\") +\n  facet_wrap(~region, ncol = 2) +\n  labs(x = \"Voto izquierda 2017 (%)\", \n       y = \"Voto izquierda 2021 (%)\",\n       title = \"Cambio electoral por región\") +\n  theme_minimal()\n\n\n\n\nFacet wrap por región\n\n\n\n\n\n\n6.2.0.10 facet_grid\n\ncomunas_cat &lt;- comunas %&gt;%\n  mutate(\n    urbano_lab = ifelse(urbano, \"Urbana\", \"Rural\"),\n    cambio_cat = cut(cambio_izquierda, \n                     breaks = quantile(cambio_izquierda, c(0, 0.5, 1)),\n                     labels = c(\"Bajo crecimiento\", \"Alto crecimiento\"),\n                     include.lowest = TRUE)\n  )\n\nggplot(comunas_cat, aes(x = izquierda_2017, y = izquierda_2021)) +\n  geom_point(alpha = 0.4) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  facet_grid(urbano_lab ~ cambio_cat) +\n  labs(x = \"Voto izquierda 2017 (%)\", \n       y = \"Voto izquierda 2021 (%)\",\n       title = \"Patrones electorales según urbanización y magnitud de cambio\") +\n  theme_minimal()\n\n\n\n\nFacet grid con dos variables\n\n\n\n\n\n\n6.2.0.11 Personalización\n\n\n6.2.0.12 Temas predefinidos\n\np_base &lt;- ggplot(comunas %&gt;% slice_sample(n = 100), \n                 aes(x = izquierda_2017, y = izquierda_2021)) +\n  geom_point() +\n  labs(title = \"Tema: \")\n\n(p_base + theme_minimal() + ggtitle(\"theme_minimal\")) |\n(p_base + theme_bw() + ggtitle(\"theme_bw\")) /\n(p_base + theme_classic() + ggtitle(\"theme_classic\")) |\n(p_base + theme_light() + ggtitle(\"theme_light\"))\n\n\n\n\nComparación de temas\n\n\n\n\n\n\n6.2.0.13 Personalización de elementos\n\nggplot(comunas %&gt;% group_by(region) %&gt;% \n         summarise(cambio_promedio = mean(cambio_izquierda)),\n       aes(x = reorder(region, cambio_promedio), y = cambio_promedio)) +\n  geom_col(aes(fill = cambio_promedio &gt; 0), width = 0.7, show.legend = FALSE) +\n  scale_fill_manual(values = c(\"TRUE\" = \"darkgreen\", \"FALSE\" = \"darkred\")) +\n  geom_hline(yintercept = 0, linewidth = 0.8) +\n  coord_flip() +\n  labs(\n    x = NULL, \n    y = \"Cambio promedio en voto izquierda (puntos porcentuales)\",\n    title = \"Cambio electoral promedio por región\",\n    subtitle = \"Comparación 2021 vs. 2017\",\n    caption = \"Fuente: Datos simulados para fines pedagógicos\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 14, face = \"bold\"),\n    plot.subtitle = element_text(size = 11, color = \"gray30\"),\n    plot.caption = element_text(size = 8, color = \"gray50\", hjust = 0),\n    axis.title.x = element_text(size = 10),\n    axis.text = element_text(size = 9),\n    panel.grid.minor = element_blank(),\n    panel.grid.major.y = element_blank()\n  )\n\n\n\n\nGráfico altamente personalizado\n\n\n\n\n\n\n6.2.0.14 Paletas de colores\n\np_color &lt;- ggplot(comunas, aes(x = region, fill = region)) +\n  geom_bar() +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 45, hjust = 1))\n\np1 &lt;- p_color + scale_fill_brewer(palette = \"Set2\") + \n  ggtitle(\"Brewer: Set2\")\np2 &lt;- p_color + scale_fill_viridis_d() + \n  ggtitle(\"Viridis (accesible)\")\np3 &lt;- p_color + scale_fill_manual(values = c(\"#E41A1C\", \"#377EB8\", \"#4DAF4A\", \"#984EA3\")) +\n  ggtitle(\"Manual\")\n\np1 / p2 / p3\n\n\n\n\nDiferentes paletas de colores\n\n\n\n\n\n\n6.2.0.15 Combinando gráficos\nEl paquete patchwork permite combinar gráficos fácilmente.\n\n# Crear gráficos individuales\np1 &lt;- ggplot(comunas, aes(x = cambio_izquierda)) +\n  geom_histogram(bins = 30, fill = \"steelblue\", color = \"white\") +\n  labs(x = \"Cambio electoral\", y = \"Frecuencia\", title = \"A) Distribución\") +\n  theme_minimal()\n\np2 &lt;- ggplot(comunas, aes(x = izquierda_2017, y = izquierda_2021)) +\n  geom_point(alpha = 0.4) +\n  geom_smooth(method = \"lm\", color = \"red\") +\n  labs(x = \"2017\", y = \"2021\", title = \"B) Relación temporal\") +\n  theme_minimal()\n\np3 &lt;- ggplot(comunas, aes(x = region, y = cambio_izquierda, fill = region)) +\n  geom_boxplot(show.legend = FALSE) +\n  labs(x = NULL, y = \"Cambio electoral\", title = \"C) Por región\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\np4 &lt;- ggplot(comunas, aes(x = urbano, y = cambio_izquierda, fill = urbano)) +\n  geom_violin(show.legend = FALSE, alpha = 0.7) +\n  scale_x_discrete(labels = c(\"FALSE\" = \"Rural\", \"TRUE\" = \"Urbano\")) +\n  labs(x = NULL, y = \"Cambio electoral\", title = \"D) Por tipo\") +\n  theme_minimal()\n\n# Combinar con layout específico\n(p1 | p2) / (p3 | p4)\n\n\n\n\nCombinación compleja de gráficos\n\n\n\n\n\n\n6.2.0.16 Anotaciones\nAgregar texto, flechas y formas para destacar patrones.\n\nggplot(aprobacion, aes(x = mes, y = aprobacion)) +\n  geom_line(color = \"steelblue\", linewidth = 1) +\n  geom_point(color = \"steelblue\", size = 2) +\n  # Anotar punto específico\n  annotate(\"point\", x = as.Date(\"2023-06-01\"), y = 65, \n           color = \"red\", size = 4) +\n  annotate(\"text\", x = as.Date(\"2023-06-01\"), y = 68, \n           label = \"Pico máximo\\n(Junio 2023)\", size = 3.5, color = \"red\") +\n  annotate(\"segment\", x = as.Date(\"2023-06-01\"), xend = as.Date(\"2023-06-01\"),\n           y = 66.5, yend = 65.5, arrow = arrow(length = unit(0.2, \"cm\")),\n           color = \"red\") +\n  # Área de interés\n  annotate(\"rect\", xmin = as.Date(\"2023-03-01\"), xmax = as.Date(\"2023-09-01\"),\n           ymin = -Inf, ymax = Inf, alpha = 0.1, fill = \"yellow\") +\n  scale_x_date(date_labels = \"%b %Y\", date_breaks = \"3 months\") +\n  labs(x = NULL, y = \"Aprobación (%)\",\n       title = \"Aprobación presidencial con anotaciones\",\n       subtitle = \"Período destacado: marzo-septiembre 2023\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\nGráfico con anotaciones\n\n\n\n\n\n\n6.2.0.17 Exportar gráficos\nGuardar gráficos para publicación.\n\n# Crear gráfico\np &lt;- ggplot(comunas, aes(x = izquierda_2017, y = izquierda_2021)) +\n  geom_point() +\n  theme_minimal()\n\n# Guardar en diferentes formatos\nggsave(\"grafico.png\", p, width = 8, height = 6, dpi = 300)\nggsave(\"grafico.pdf\", p, width = 8, height = 6)\nggsave(\"grafico.svg\", p, width = 8, height = 6)\n\n# Especificar unidades\nggsave(\"grafico_cm.png\", p, width = 20, height = 15, units = \"cm\", dpi = 300)\n\nRecomendaciones:\n\nPNG: Para web y presentaciones (300 dpi para calidad)\nPDF: Para publicaciones académicas (vectorial, escalable)\nSVG: Para edición posterior en Illustrator/Inkscape\nDimensiones: Verificar requisitos de revista (ej: ancho máximo 180mm)",
    "crumbs": [
      "III. Unidad 2: Fundamentos de Estadística Descriptiva",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Visualización de datos</span>"
    ]
  },
  {
    "objectID": "06-visualizacion.html#errores-comunes-en-visualización",
    "href": "06-visualizacion.html#errores-comunes-en-visualización",
    "title": "6  Visualización de datos",
    "section": "6.3 Errores comunes en visualización",
    "text": "6.3 Errores comunes en visualización\n\n6.3.0.1 Problema 1: Eje Y truncado\n\ndatos_ejemplo &lt;- data.frame(\n  año = 2019:2023,\n  valor = c(50, 52, 51, 53, 54)\n)\n\np_malo &lt;- ggplot(datos_ejemplo, aes(x = año, y = valor)) +\n  geom_col(fill = \"steelblue\") +\n  coord_cartesian(ylim = c(48, 55)) +\n  labs(title = \"Problemático: Eje truncado exagera diferencias\") +\n  theme_minimal()\n\np_bueno &lt;- ggplot(datos_ejemplo, aes(x = año, y = valor)) +\n  geom_col(fill = \"steelblue\") +\n  coord_cartesian(ylim = c(0, 60)) +\n  labs(title = \"Mejor: Eje desde cero muestra escala real\") +\n  theme_minimal()\n\np_malo | p_bueno\n\n\n\n\nEje truncado vs. completo\n\n\n\n\n\n\n6.3.0.2 Problema 2: Demasiadas categorías\n\n# Simular datos con muchas categorías\nset.seed(456)\nmuchas_cat &lt;- data.frame(\n  partido = paste(\"Partido\", 1:15),\n  votos = runif(15, 2, 12)\n)\n\np_malo &lt;- ggplot(muchas_cat, aes(x = partido, y = votos)) +\n  geom_col(fill = \"steelblue\") +\n  labs(title = \"Problemático: Demasiadas categorías\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, size = 6))\n\n# Agrupar categorías menores\nmuchas_cat_agrup &lt;- muchas_cat %&gt;%\n  mutate(\n    partido_agrup = ifelse(votos &lt; 5, \"Otros (menor 5%)\", partido)\n  ) %&gt;%\n  group_by(partido_agrup) %&gt;%\n  summarise(votos = sum(votos)) %&gt;%\n  arrange(desc(votos))\n\np_bueno &lt;- ggplot(muchas_cat_agrup, aes(x = reorder(partido_agrup, votos), y = votos)) +\n  geom_col(fill = \"steelblue\") +\n  coord_flip() +\n  labs(title = \"Mejor: Categorías agrupadas\", x = NULL) +\n  theme_minimal()\n\np_malo | p_bueno\n\n\n\n\nReducción de categorías\n\n\n\n\n\n\n6.3.0.3 Problema 3: Dobles ejes Y\nLos dobles ejes Y pueden ser engañosos—la escala de cada eje puede manipularse para sugerir relaciones inexistentes.\nMejor práctica: Usar facetas o gráficos separados.",
    "crumbs": [
      "III. Unidad 2: Fundamentos de Estadística Descriptiva",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Visualización de datos</span>"
    ]
  },
  {
    "objectID": "06-visualizacion.html#resumen",
    "href": "06-visualizacion.html#resumen",
    "title": "6  Visualización de datos",
    "section": "Resumen",
    "text": "Resumen\nLa visualización efectiva comunica patrones de datos clara y honestamente. Los principios de Tufte—maximizar ratio datos-tinta, usar canales visuales apropiados, mostrar comparaciones, sugerir causalidad—guían el diseño.\nLa gramática de gráficos (implementada en ggplot2) descompone visualizaciones en componentes sistemáticos: datos, aesthetics, geometrías, escalas, facetas, temas. Esta estructura permite crear gráficos complejos mediante combinación de capas.\nPara variables continuas, histogramas y densidades muestran distribución; boxplots comparan grupos. Scatter plots revelan relaciones bivariadas. Series temporales usan gráficos de línea; múltiples series requieren codificación cuidadosa mediante color.\nFacetas (facet_wrap, facet_grid) dividen datos en paneles, facilitando comparaciones entre grupos. Temas y personalización permiten adaptar estética a contextos (publicación, presentación, web).\nCombinar gráficos (patchwork) y agregar anotaciones (annotate) crean narrativas visuales comprehensivas. Exportar en formatos apropiados (PNG para web, PDF para publicación) asegura calidad.\nEvitar visualizaciones problemáticas—ejes truncados, demasiadas categorías, dobles ejes Y engañosos—es responsabilidad del investigador. La visualización no solo describe datos; argumenta e informa decisiones.",
    "crumbs": [
      "III. Unidad 2: Fundamentos de Estadística Descriptiva",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Visualización de datos</span>"
    ]
  },
  {
    "objectID": "06-visualizacion.html#lecturas-recomendadas",
    "href": "06-visualizacion.html#lecturas-recomendadas",
    "title": "6  Visualización de datos",
    "section": "Lecturas recomendadas",
    "text": "Lecturas recomendadas\nFundamentos de visualización:\nTufte, E. R. (1983). The Visual Display of Quantitative Information. Graphics Press.\n→ Clásico sobre principios de diseño gráfico efectivo.\nAplicación práctica con ggplot2:\nHealy, K. (2018). Data Visualization: A Practical Introduction. Princeton University Press.\n→ Guía accesible con énfasis en ciencias sociales.\nReferencia técnica de ggplot2:\nWickham, H. (2016). ggplot2: Elegant Graphics for Data Analysis (2nd ed.). Springer.\n→ Documentación comprehensiva del creador de ggplot2.\nVisualización crítica:\nCairo, A. (2016). The Truthful Art: Data, Charts, and Maps for Communication. New Riders.\n→ Énfasis en honestidad y ética en visualización.\nRecursos en línea:\n\nR Graph Gallery: https://www.r-graph-gallery.com/\nggplot2 documentation: https://ggplot2.tidyverse.org/\nColorBrewer (paletas): https://colorbrewer2.org/",
    "crumbs": [
      "III. Unidad 2: Fundamentos de Estadística Descriptiva",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Visualización de datos</span>"
    ]
  },
  {
    "objectID": "06-visualizacion.html#ejercicios",
    "href": "06-visualizacion.html#ejercicios",
    "title": "6  Visualización de datos",
    "section": "Ejercicios",
    "text": "Ejercicios\nLos ejercicios para este capítulo se encuentran en el Anexo de Ejercicios.\n\n\nTufte, E. R. (1983). The Visual Display of Quantitative Information. Graphics Press.\n\n\nWilkinson, L. (2005). The Grammar of Graphics (2nd ed.). Springer-Verlag.",
    "crumbs": [
      "III. Unidad 2: Fundamentos de Estadística Descriptiva",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Visualización de datos</span>"
    ]
  },
  {
    "objectID": "07-probabilidad.html",
    "href": "07-probabilidad.html",
    "title": "7  Introducción a probabilidad",
    "section": "",
    "text": "Objetivos del capítulo\nAl finalizar este capítulo, serás capaz de:",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introducción a probabilidad</span>"
    ]
  },
  {
    "objectID": "07-probabilidad.html#objetivos-del-capítulo",
    "href": "07-probabilidad.html#objetivos-del-capítulo",
    "title": "7  Introducción a probabilidad",
    "section": "",
    "text": "Comprender el concepto de probabilidad y su relación con la incertidumbre\nDistinguir entre interpretaciones frecuentista y bayesiana de probabilidad\nCalcular probabilidades básicas y aplicar reglas fundamentales\nIdentificar y trabajar con variables aleatorias discretas y continuas\nReconocer distribuciones de probabilidad comunes en ciencias sociales\nComprender el Teorema del Límite Central y su importancia para la inferencia",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introducción a probabilidad</span>"
    ]
  },
  {
    "objectID": "07-probabilidad.html#fundamentos-de-probabilidad",
    "href": "07-probabilidad.html#fundamentos-de-probabilidad",
    "title": "7  Introducción a probabilidad",
    "section": "7.1 Fundamentos de probabilidad",
    "text": "7.1 Fundamentos de probabilidad\nLa investigación social cuantitativa enfrenta invariablemente la incertidumbre. Cuando encuestamos 1,500 votantes chilenos para estimar apoyo a un candidato presidencial, no conocemos las preferencias de los millones que no fueron encuestados. Cuando comparamos tasas de homicidio entre países con y sin pena de muerte, no podemos asegurar que la diferencia observada no sea producto del azar.\nLa teoría de probabilidad nos proporciona un lenguaje matemático riguroso para cuantificar esta incertidumbre. No elimina la incertidumbre (esto es imposible cuando trabajamos con muestras), pero nos permite hacer afirmaciones precisas sobre qué tan confiables son nuestras conclusiones.1\n1 La probabilidad no predice el futuro ni elimina la incertidumbre. Nos permite cuantificarla y tomar decisiones informadas bajo condiciones de información imperfecta.\n7.1.0.1 Conceptos básicos\n\n\n7.1.0.2 Definición y notación\nUna probabilidad es un número entre 0 y 1 que cuantifica qué tan probable es que ocurra un evento:\n\n\\(P(A) = 0\\) significa que el evento \\(A\\) es imposible\n\\(P(A) = 1\\) significa que el evento \\(A\\) es seguro\n\\(P(A) = 0.5\\) significa que \\(A\\) tiene la misma probabilidad de ocurrir que de no ocurrir\n\nPor ejemplo, si en una encuesta con 1,200 entrevistados, 360 declaran que votarán por candidatos del Frente Amplio en elecciones legislativas chilenas, podemos estimar: \\(P(\\text{Voto FA}) = \\frac{360}{1200} = 0.30\\). Esto NO significa que exactamente 30% de los votantes votará por el FA el día de la elección. Significa que, basándonos en nuestra muestra, estimamos esa probabilidad con cierto nivel de incertidumbre (que cuantificaremos en el próximo capítulo con intervalos de confianza).\n\n\n7.1.0.3 Interpretaciones de probabilidad\nExisten dos interpretaciones fundamentales de qué significa “probabilidad”:\nInterpretación frecuentista:2 La probabilidad es el límite de la frecuencia relativa cuando un experimento se repite infinitas veces. Por ejemplo, \\(P(\\text{Cara}) = 0.5\\) al lanzar una moneda significa que, si lanzamos la moneda millones de veces, aproximadamente 50% serán caras. Esta es la interpretación estándar en ciencias sociales cuantitativas.\n2 Cuando un artículo reporta “p &lt; 0.05”, está usando lógica frecuentista: si no hubiera efecto real, veríamos un resultado tan extremo menos de 5% de las veces.\nInterpretación bayesiana: La probabilidad cuantifica grado de creencia o certeza subjetiva sobre un evento. Permite asignar probabilidades a eventos únicos (como “¿cuál es la probabilidad de que Chile tenga una nueva Constitución en 2026?”). La estadística bayesiana actualiza creencias previas (prior) con nueva evidencia usando el teorema de Bayes. Es cada vez más usada en ciencias sociales, pero requiere fundamentos matemáticos adicionales.\n\n\n\n\n\n\nComparación de interpretaciones de probabilidad\n\n\n\n\n\n\n7.1.0.4 Reglas fundamentales de probabilidad\nRegla de la suma (eventos mutuamente excluyentes)\nSi \\(A\\) y \\(B\\) no pueden ocurrir simultáneamente: \\[P(A \\text{ o } B) = P(A) + P(B)\\]\nPor ejemplo, en las elecciones municipales 2024 en Santiago, si un votante puede elegir solo un candidato: \\(P(\\text{Izquierda o Derecha}) = P(\\text{Izquierda}) + P(\\text{Derecha})\\).\nRegla del complemento\n\\[P(\\text{no } A) = 1 - P(A)\\]\nPor ejemplo, si \\(P(\\text{Voto})=0.52\\) en elecciones legislativas chilenas: \\(P(\\text{Abstención}) = 1 - 0.52 = 0.48\\).\nRegla del producto (eventos independientes)\nSi \\(A\\) y \\(B\\) son independientes (la ocurrencia de uno no afecta la probabilidad del otro): \\[P(A \\text{ y } B) = P(A) \\times P(B)\\]\nPor ejemplo, si encuestamos a dos votantes al azar y queremos saber la probabilidad de que ambos voten por la izquierda, asumiendo independencia y \\(P(\\text{Izquierda})=0.30\\): \\(P(\\text{ambos izquierda}) = 0.30 \\times 0.30 = 0.09\\).\nProbabilidad condicional\nLa probabilidad de \\(A\\) dado que ya sabemos que \\(B\\) ocurrió: \\[P(A|B) = \\frac{P(A \\text{ y } B)}{P(B)}\\]\nPor ejemplo, consideremos voto por género en una encuesta chilena. Supongamos que en una encuesta: 30% vota Apruebo, 60% son mujeres, y 20% del total son mujeres que votan Apruebo. Entonces \\(P(\\text{Apruebo}|\\text{Mujer}) = \\frac{P(\\text{Apruebo y Mujer})}{P(\\text{Mujer})} = \\frac{0.20}{0.60} = 0.33\\). Es decir, entre las mujeres, 33% vota Apruebo (mientras que en la población general es 30%).\n\n\n\n\n\n\nTipEjemplo paso a paso: Calculando probabilidades\n\n\n\nUna encuesta de 500 personas recopiló información sobre género y preferencia de voto:\n\n\n\n\nAprueba\nRechaza\nTotal\n\n\n\n\nHombres\n80\n120\n200\n\n\nMujeres\n150\n150\n300\n\n\nTotal\n230\n270\n500\n\n\n\nCalculemos algunas probabilidades:\n\n# Definir los datos\ntotal &lt;- 500\nhombres &lt;- 200\nmujeres &lt;- 300\naprueba &lt;- 230\nrechaza &lt;- 270\nhombres_aprueba &lt;- 80\nmujeres_aprueba &lt;- 150\n\n# P(Aprueba) - probabilidad marginal\nP_aprueba &lt;- aprueba / total\ncat(\"P(Aprueba) =\", P_aprueba, \"\\n\")\n\nP(Aprueba) = 0.46 \n\n# P(Mujer) - probabilidad marginal\nP_mujer &lt;- mujeres / total\ncat(\"P(Mujer) =\", P_mujer, \"\\n\")\n\nP(Mujer) = 0.6 \n\n# P(Mujer Y Aprueba) - probabilidad conjunta\nP_mujer_y_aprueba &lt;- mujeres_aprueba / total\ncat(\"P(Mujer Y Aprueba) =\", P_mujer_y_aprueba, \"\\n\")\n\nP(Mujer Y Aprueba) = 0.3 \n\n# P(Aprueba | Mujer) - probabilidad condicional\nP_aprueba_dado_mujer &lt;- P_mujer_y_aprueba / P_mujer\ncat(\"P(Aprueba | Mujer) =\", P_aprueba_dado_mujer, \"\\n\")\n\nP(Aprueba | Mujer) = 0.5 \n\n# Verificación directa\ncat(\"Verificación: 150/300 =\", 150/300, \"\\n\")\n\nVerificación: 150/300 = 0.5 \n\n\n\n\n\n\n\n\n\n\nAdvertenciaError común: Confundir P(A|B) con P(B|A)\n\n\n\n\\(P(\\text{Aprueba}|\\text{Mujer}) \\neq P(\\text{Mujer}|\\text{Aprueba})\\)\n\n\\(P(\\text{Aprueba}|\\text{Mujer}) = 150/300 = 0.50\\) → “De las mujeres, ¿qué proporción aprueba?”\n\\(P(\\text{Mujer}|\\text{Aprueba}) = 150/230 = 0.65\\) → “De quienes aprueban, ¿qué proporción son mujeres?”\n\nEste error es muy común y puede llevar a conclusiones incorrectas. Siempre pregúntate: “¿Cuál es mi población de referencia?”",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introducción a probabilidad</span>"
    ]
  },
  {
    "objectID": "07-probabilidad.html#variables-aleatorias-y-distribuciones",
    "href": "07-probabilidad.html#variables-aleatorias-y-distribuciones",
    "title": "7  Introducción a probabilidad",
    "section": "7.2 Variables aleatorias y distribuciones",
    "text": "7.2 Variables aleatorias y distribuciones\nUna variable aleatoria es una función que asigna un valor numérico a cada resultado posible de un fenómeno aleatorio. Son la conexión entre probabilidad y estadística.\n\n7.2.0.1 Variables aleatorias discretas\nToman valores específicos y contables (generalmente enteros).3\n3 Ejemplos en ciencias sociales: número de partidos en el Congreso, número de protestas en un mes, respuesta en escala Likert, número de votantes en una mesa.Función de masa de probabilidad (PMF)\nPara una variable aleatoria discreta \\(X\\), la PMF especifica la probabilidad de cada valor: \\[P(X = x)\\]\n\n# Simulación: Número de protestas por mes en una ciudad\n# (Distribución Poisson con promedio = 2.5)\nset.seed(456)\nprotestas &lt;- rpois(1000, lambda = 2.5)\n\n# Tabla de frecuencias\ntable(protestas) / 1000\n\nprotestas\n    0     1     2     3     4     5     6     7     8 \n0.074 0.194 0.242 0.217 0.154 0.074 0.030 0.013 0.002 \n\n\n\n\n\n\n\nDistribución de variable aleatoria discreta: Número de protestas\n\n\n\n\n\n\n7.2.0.2 Variables aleatorias continuas\nPueden tomar cualquier valor en un intervalo (infinitos valores posibles).4\n4 Ejemplos en ciencias sociales: porcentaje de votos obtenido, ingreso mensual, índice de democracia, tiempo hasta próxima protesta.Función de densidad de probabilidad (PDF)\nPara variables continuas, \\(P(X = x) = 0\\) (la probabilidad de un valor exacto es cero). En su lugar, trabajamos con intervalos:\n\\[P(a &lt; X &lt; b) = \\int_a^b f(x)dx\\]\ndonde \\(f(x)\\) es la función de densidad.\n\n# Simulación: Porcentaje de votos para alcalde\n# (Distribución aproximadamente Normal)\nset.seed(789)\nvotos &lt;- rnorm(1000, mean = 35, sd = 5)\n\n# Probabilidad de obtener entre 30% y 40%\nmean(votos &gt;= 30 & votos &lt;= 40)\n\n[1] 0.686\n\n\n\n\n\n\n\nDistribución de variable aleatoria continua: Porcentaje de votos\n\n\n\n\n\n\n7.2.0.3 Valor esperado y varianza\nValor esperado (media poblacional): \\(E(X) = \\mu\\)\nEl valor esperado es el promedio “teórico” de una variable aleatoria si pudiéramos observarla infinitas veces. Para variables discretas, se calcula sumando cada valor multiplicado por su probabilidad.\nVarianza: \\(\\text{Var}(X) = \\sigma^2\\) mide la dispersión alrededor del valor esperado.\nDesviación estándar: \\(\\sigma = \\sqrt{\\text{Var}(X)}\\)\nEs importante distinguir que estos son parámetros poblacionales (generalmente desconocidos). Los estimamos a partir de muestras usando \\(\\bar{x}\\) y \\(s^2\\).\n\nFórmulas matemáticas del valor esperado:\n\nPara variable discreta: \\(E(X) = \\sum x \\cdot P(X=x)\\)\nPara variable continua: \\(E(X) = \\int x \\cdot f(x)dx\\)\nVarianza: \\(\\text{Var}(X) = E[(X - \\mu)^2] = E(X^2) - [E(X)]^2\\)\n\n\n\n\n7.2.0.4 Distribuciones comunes\n\n\n7.2.0.5 Distribución Normal (Gaussiana)\nLa distribución más importante en estadística inferencial. Una variable \\(X\\) sigue una distribución Normal con media \\(\\mu\\) y varianza \\(\\sigma^2\\):\n\\[X \\sim N(\\mu, \\sigma^2)\\]\nPropiedades:\n\nSimétrica alrededor de \\(\\mu\\)\nForma de campana\n68% de observaciones dentro de \\(\\mu \\pm 1\\sigma\\)\n95% dentro de \\(\\mu \\pm 1.96\\sigma\\)\n99.7% dentro de \\(\\mu \\pm 3\\sigma\\)\n\n\n\n\n\n\nDistribución Normal estándar con regla 68-95-99.7\n\n\n\n\nLas alturas de hombres adultos chilenos se distribuyen aproximadamente \\(N(170, 7^2)\\) cm. Podemos usar esta distribución para responder preguntas como: ¿Qué proporción de hombres mide más de 180 cm? o ¿Qué proporción mide entre 165 y 175 cm?\n\n# ¿Qué proporción de hombres mide más de 180 cm?\n1 - pnorm(180, mean = 170, sd = 7)\n\n[1] 0.07656373\n\n# ¿Qué proporción mide entre 165 y 175 cm?\npnorm(175, mean = 170, sd = 7) - pnorm(165, mean = 170, sd = 7)\n\n[1] 0.5249495\n\n\n\n\n\n\n\n\nNotaFunciones de R para distribución Normal\n\n\n\nR tiene cuatro funciones para trabajar con la distribución Normal:\n\n\n\n\n\n\n\n\nFunción\nQué hace\nEjemplo\n\n\n\n\ndnorm(x)\nDensidad en el punto x\ndnorm(0) = 0.399 (altura de la curva en x=0)\n\n\npnorm(x)\nProbabilidad acumulada P(X ≤ x)\npnorm(0) = 0.5 (50% está por debajo de la media)\n\n\nqnorm(p)\nCuantil: ¿qué valor tiene probabilidad p por debajo?\nqnorm(0.975) = 1.96\n\n\nrnorm(n)\nGenera n valores aleatorios\nrnorm(100) genera 100 valores\n\n\n\n\n# Ejemplo práctico: ¿Cuál es el percentil 90 de alturas?\n# Es decir, ¿qué altura es mayor que el 90% de los hombres?\nqnorm(0.90, mean = 170, sd = 7)\n\n[1] 178.9709\n\n\n\n\n\n\n7.2.0.6 Distribución Binomial\nModela el número de “éxitos” en \\(n\\) ensayos independientes, cada uno con probabilidad \\(p\\) de éxito:\n\\[X \\sim \\text{Binomial}(n, p)\\]\n\n\\(E(X) = np\\)\n\\(\\text{Var}(X) = np(1-p)\\)\n\nPor ejemplo, si encuestamos \\(n=1000\\) votantes y la verdadera proporción que apoya un candidato es \\(p=0.40\\), el número de encuestados que declaran apoyo sigue \\(X \\sim \\text{Binomial}(1000, 0.40)\\):\n\n# Probabilidad de observar exactamente 400 apoyos\ndbinom(400, size = 1000, prob = 0.40)\n\n[1] 0.02574482\n\n# Probabilidad de observar entre 380 y 420 apoyos\nsum(dbinom(380:420, size = 1000, prob = 0.40))\n\n[1] 0.814288\n\n# Valor esperado y desviación estándar\nn &lt;- 1000; p &lt;- 0.40\nc(media = n*p, sd = sqrt(n*p*(1-p)))\n\n    media        sd \n400.00000  15.49193 \n\n\n\n\n\n\n\nDistribución Binomial: Número de votantes que apoyan candidato (n=1000, p=0.40)",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introducción a probabilidad</span>"
    ]
  },
  {
    "objectID": "07-probabilidad.html#teorema-del-límite-central",
    "href": "07-probabilidad.html#teorema-del-límite-central",
    "title": "7  Introducción a probabilidad",
    "section": "7.3 Teorema del Límite Central",
    "text": "7.3 Teorema del Límite Central\nEl Teorema del Límite Central (TLC) es posiblemente el resultado más importante de la estadística. Fundamenta toda la inferencia estadística basada en muestras. El teorema establece que si tomamos muestras aleatorias de tamaño \\(n\\) de cualquier población con media \\(\\mu\\) y varianza finita \\(\\sigma^2\\), entonces conforme \\(n\\) aumenta, la distribución de la media muestral \\(\\bar{X}\\) se aproxima a una distribución Normal: \\(\\bar{X} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)\\). Esto ocurre independientemente de la forma de la distribución original, siempre que \\(n\\) sea suficientemente grande (típicamente \\(n \\geq 30\\)).\n\n7.3.0.1 Implicaciones para ciencias sociales\n\nPodemos usar la distribución Normal para hacer inferencias sobre medias muestrales, incluso si la variable original no es Normal\nLa varianza de \\(\\bar{X}\\) disminuye con \\(n\\): Muestras más grandes producen estimaciones más precisas\nJustifica el uso de pruebas t y intervalos de confianza (próximos capítulos)\n\n\n\n7.3.0.2 Simulación del TLC\nDemostremos el TLC con un ejemplo de ciencias políticas:\n\n# Población NO normal: Participación en protestas (variable muy asimétrica)\n# Mayoría no participa (0), algunos participan ocasionalmente\nset.seed(2024)\npoblacion &lt;- c(rep(0, 7000), rep(1, 2000), rep(2, 700),\n               rep(3, 200), rep(4, 80), rep(5, 20))\n\n# Media y SD poblacionales\nmu_poblacion &lt;- mean(poblacion)\nsigma_poblacion &lt;- sd(poblacion)\n\ncat(\"Distribución poblacional:\\n\")\n\nDistribución poblacional:\n\ncat(\"Media:\", mu_poblacion, \"\\n\")\n\nMedia: 0.442 \n\ncat(\"SD:\", sigma_poblacion, \"\\n\\n\")\n\nSD: 0.8016859 \n\n# Tomamos 5000 muestras de diferentes tamaños y calculamos sus medias\nsimular_medias &lt;- function(n, n_muestras = 5000) {\n  replicate(n_muestras, mean(sample(poblacion, n, replace = TRUE)))\n}\n\nmedias_n10 &lt;- simular_medias(10)\nmedias_n30 &lt;- simular_medias(30)\nmedias_n100 &lt;- simular_medias(100)\n\n# Comparación\nresultados &lt;- data.frame(\n  tamaño = c(\"n=10\", \"n=30\", \"n=100\"),\n  media = c(mean(medias_n10), mean(medias_n30), mean(medias_n100)),\n  sd_observada = c(sd(medias_n10), sd(medias_n30), sd(medias_n100)),\n  sd_teorica = sigma_poblacion / sqrt(c(10, 30, 100))\n)\n\nprint(resultados)\n\n  tamaño     media sd_observada sd_teorica\n1   n=10 0.4436600   0.25167533 0.25351534\n2   n=30 0.4415867   0.14769120 0.14636715\n3  n=100 0.4427280   0.08018356 0.08016859\n\n\n\n\n\n\n\nConvergencia a la Normal según el Teorema del Límite Central\n\n\n\n\nAunque la población original es extremadamente asimétrica (la mayoría tiene valor 0), las medias muestrales se distribuyen cada vez más normalmente conforme aumenta \\(n\\). Con \\(n=100\\), la distribución de \\(\\bar{X}\\) es prácticamente Normal.",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introducción a probabilidad</span>"
    ]
  },
  {
    "objectID": "07-probabilidad.html#resumen",
    "href": "07-probabilidad.html#resumen",
    "title": "7  Introducción a probabilidad",
    "section": "Resumen",
    "text": "Resumen\nConceptos clave:\n\nProbabilidad cuantifica incertidumbre; permite hacer inferencias rigurosas desde muestras\nVariables aleatorias (discretas y continuas) conectan probabilidad con datos observables\nDistribuciones importantes: Normal (continua, base de la inferencia), Binomial (conteos de éxitos), Poisson (eventos raros)\nTeorema del Límite Central: Las medias muestrales se distribuyen normalmente, independientemente de la distribución original\nTLC justifica el uso de métodos basados en la Normal para inferencia (intervalos de confianza, pruebas de hipótesis)\n\nConexión con próximos capítulos:\n\nCap. 8 usará el TLC para construir intervalos de confianza\nCap. 9 aplicará distribuciones de probabilidad para pruebas de hipótesis\nCaps. 10-11 usarán la distribución Normal para comparar medias y hacer regresión",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introducción a probabilidad</span>"
    ]
  },
  {
    "objectID": "07-probabilidad.html#lecturas-recomendadas",
    "href": "07-probabilidad.html#lecturas-recomendadas",
    "title": "7  Introducción a probabilidad",
    "section": "Lecturas recomendadas",
    "text": "Lecturas recomendadas\nFundamentos de teoría de probabilidad:\nAgresti, A., & Finlay, B. (2009). Statistical Methods for the Social Sciences (4th ed.). Pearson.\n→ Capítulo 4 ofrece una introducción accesible a distribuciones de probabilidad con ejemplos de ciencias sociales.\nAplicaciones en ciencias sociales:\nLlaudet, E., & Imai, K. (2022). Data Analysis for Social Science: A Friendly and Practical Introduction. Princeton University Press.\n→ Capítulo 6 conecta teoría de probabilidad con aplicaciones en investigación social y política.\nRecurso complementario de acceso libre:\nDiez, D., Barr, C., & Çetinkaya-Rundel, M. (2019). OpenIntro Statistics (4th ed.). [Disponible gratis en https://www.openintro.org/book/os/]\n→ Capítulo 3 sobre distribuciones de variables aleatorias, con ejercicios interactivos.",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introducción a probabilidad</span>"
    ]
  },
  {
    "objectID": "07-probabilidad.html#ejercicios",
    "href": "07-probabilidad.html#ejercicios",
    "title": "7  Introducción a probabilidad",
    "section": "Ejercicios",
    "text": "Ejercicios\nLos ejercicios para este capítulo se encuentran en el Anexo de Ejercicios.",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introducción a probabilidad</span>"
    ]
  },
  {
    "objectID": "08-inferencia.html",
    "href": "08-inferencia.html",
    "title": "8  Inferencia estadística",
    "section": "",
    "text": "Objetivos del capítulo\nAl finalizar este capítulo, serás capaz de:",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Inferencia estadística</span>"
    ]
  },
  {
    "objectID": "08-inferencia.html#objetivos-del-capítulo",
    "href": "08-inferencia.html#objetivos-del-capítulo",
    "title": "8  Inferencia estadística",
    "section": "",
    "text": "Comprender la lógica de la inferencia estadística: generalizar desde muestras a poblaciones\nDistinguir entre parámetros poblacionales y estadísticos muestrales\nEntender el concepto de distribución muestral y su relación con el Teorema del Límite Central\nCalcular e interpretar el error estándar\nConstruir e interpretar intervalos de confianza para medias y proporciones\nEvaluar el tamaño muestral necesario para cierto nivel de precisión",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Inferencia estadística</span>"
    ]
  },
  {
    "objectID": "08-inferencia.html#de-muestras-a-poblaciones",
    "href": "08-inferencia.html#de-muestras-a-poblaciones",
    "title": "8  Inferencia estadística",
    "section": "8.1 De muestras a poblaciones",
    "text": "8.1 De muestras a poblaciones\nEn ciencias sociales raramente tenemos acceso a poblaciones completas. Queremos saber:\n\n¿Cuál es el apoyo real a la reforma de pensiones entre todos los chilenos?\n¿Cuál es el ingreso promedio de hogares en América Latina?\n¿Qué proporción de electores cambia su voto entre elecciones?\n\nPero solo podemos encuestar una muestra de cientos o miles de personas, no los millones que componen la población. La inferencia estadística es el proceso de usar datos de una muestra para hacer afirmaciones sobre una población, cuantificando la incertidumbre asociada.\n\n8.1.0.1 Ejemplo motivador: Encuestas electorales en Chile\nAntes de las elecciones presidenciales 2021 (segunda vuelta), múltiples encuestadoras reportaron:\n\n\n\n\n\n\n\n\n\nPreguntas clave:\n\n¿Por qué las encuestas difieren si todas miden “lo mismo”?\n¿Cuán confiables son estos números?\n¿Qué tan grande debe ser la muestra?\n\nLa inferencia estadística nos da herramientas para responder estas preguntas.\n\n\n8.1.0.2 Muestras y poblaciones\n\n\n8.1.0.3 Definiciones fundamentales\nPoblación: Conjunto completo de unidades de interés. Tiene parámetros (valores fijos, generalmente desconocidos): - Media poblacional: \\(\\mu\\) - Proporción poblacional: \\(p\\) - Varianza poblacional: \\(\\sigma^2\\)\nMuestra: Subconjunto de la población que observamos. Tiene estadísticos (valores calculados a partir de los datos): - Media muestral: \\(\\bar{x}\\) - Proporción muestral: \\(\\hat{p}\\) - Varianza muestral: \\(s^2\\)\nEs fundamental distinguir que los parámetros \\((\\mu, p, \\sigma^2)\\) son valores fijos (pero desconocidos) de la población, mientras que los estadísticos \\((\\bar{x}, \\hat{p}, s^2)\\) son calculados a partir de la muestra y varían entre muestras. Usamos estadísticos para estimar parámetros.\nPor ejemplo, consideremos el apoyo a una reforma tributaria. La población son 15 millones de votantes chilenos, y el parámetro de interés es \\(p\\) = proporción que apoya la reforma (desconocida). Si tomamos una muestra de 1,200 votantes encuestados y observamos el estadístico \\(\\hat{p} = 0.42\\) (42% de la muestra apoya), la pregunta inferencial es: ¿Qué podemos decir sobre \\(p\\) (desconocido) a partir de \\(\\hat{p} = 0.42\\) (conocido)?\n\n\n8.1.0.4 Muestreo aleatorio simple\nPara que la inferencia sea válida, necesitamos muestras probabilísticas. El diseño más simple:\nMuestreo Aleatorio Simple (MAS): Cada unidad de la población tiene la misma probabilidad de ser seleccionada.\n\n# Simulación de población y muestra\nset.seed(2024)\n\n# Población de 10,000 votantes (40% apoya reforma)\npoblacion &lt;- c(rep(1, 4000), rep(0, 6000))  # 1 = apoya, 0 = no apoya\np_verdadero &lt;- mean(poblacion)\n\ncat(\"Parámetro poblacional verdadero: p =\", p_verdadero, \"\\n\\n\")\n\nParámetro poblacional verdadero: p = 0.4 \n\n# Tomamos una muestra aleatoria de n=1000\nmuestra &lt;- sample(poblacion, size = 1000, replace = FALSE)\np_hat &lt;- mean(muestra)\n\ncat(\"Estadístico muestral: p̂ =\", p_hat, \"\\n\")\n\nEstadístico muestral: p̂ = 0.418 \n\ncat(\"Error de estimación: p̂ - p =\", p_hat - p_verdadero, \"\\n\")\n\nError de estimación: p̂ - p = 0.018 \n\n\nPropiedades del MAS:\n\nInsesgado: En promedio, \\(E(\\hat{p}) = p\\) y \\(E(\\bar{x}) = \\mu\\)\nVariable: Diferentes muestras producen diferentes estimaciones\nMás preciso con muestras grandes: El error disminuye con \\(n\\)",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Inferencia estadística</span>"
    ]
  },
  {
    "objectID": "08-inferencia.html#distribuciones-muestrales",
    "href": "08-inferencia.html#distribuciones-muestrales",
    "title": "8  Inferencia estadística",
    "section": "8.2 Distribuciones muestrales",
    "text": "8.2 Distribuciones muestrales\nLa clave para entender la inferencia es reconocer que los estadísticos son variables aleatorias.\n\n8.2.0.1 Distribución muestral de la media\nSi tomamos muchas muestras de tamaño \\(n\\) y calculamos \\(\\bar{x}\\) para cada una, la distribución de todos esos \\(\\bar{x}\\) es la distribución muestral de la media.\nPropiedades (del Teorema del Límite Central, visto en Cap. 7):\n\\[\\bar{X} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)\\]\n\nMedia: \\(E(\\bar{X}) = \\mu\\) (insesgado)\nVarianza: \\(\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\) (disminuye con \\(n\\))\nForma: Aproximadamente Normal para \\(n \\geq 30\\)\n\n\n# Población: Ingresos mensuales (en miles de pesos)\n# Distribución asimétrica (lognormal)\nset.seed(123)\npoblacion_ingresos &lt;- rlnorm(100000, meanlog = log(500), sdlog = 0.6)\n\nmu_real &lt;- mean(poblacion_ingresos)\nsigma_real &lt;- sd(poblacion_ingresos)\n\ncat(\"Población:\\n\")\n\nPoblación:\n\ncat(\"Media (μ) =\", round(mu_real, 1), \"mil pesos\\n\")\n\nMedia (μ) = 598.8 mil pesos\n\ncat(\"SD (σ) =\", round(sigma_real, 1), \"mil pesos\\n\\n\")\n\nSD (σ) = 393.1 mil pesos\n\n# Tomamos 5000 muestras de n=100 y calculamos sus medias\nn_muestra &lt;- 100\nmedias_muestrales &lt;- replicate(5000, mean(sample(poblacion_ingresos, n_muestra)))\n\ncat(\"Distribución muestral de X̄ (n=100):\\n\")\n\nDistribución muestral de X̄ (n=100):\n\ncat(\"Media =\", round(mean(medias_muestrales), 1), \" (muy cerca de μ =\", round(mu_real, 1), \")\\n\")\n\nMedia = 598.9  (muy cerca de μ = 598.8 )\n\ncat(\"SD observada =\", round(sd(medias_muestrales), 1), \"\\n\")\n\nSD observada = 39.3 \n\ncat(\"SD teórica (σ/√n) =\", round(sigma_real/sqrt(n_muestra), 1), \"\\n\")\n\nSD teórica (σ/√n) = 39.3 \n\n\n\n\n\n\n\nDistribución poblacional vs distribución muestral\n\n\n\n\nAunque la población de ingresos es altamente asimétrica, la distribución de \\(\\bar{X}\\) es aproximadamente Normal. Esto es el Teorema del Límite Central en acción.\n\n\n8.2.0.2 Distribución muestral de la proporción\nPara proporciones, una lógica similar aplica. Si \\(\\hat{p}\\) es la proporción muestral:\n\\[\\hat{p} \\sim N\\left(p, \\frac{p(1-p)}{n}\\right)\\]\n(Aproximación válida cuando \\(np \\geq 10\\) y \\(n(1-p) \\geq 10\\))\nPor ejemplo, si en una encuesta electoral el verdadero apoyo es \\(p = 0.45\\) y encuestamos \\(n = 1000\\) personas:\n\np &lt;- 0.45\nn &lt;- 1000\n\n# Media y SD de p̂\nmedia_p_hat &lt;- p\nsd_p_hat &lt;- sqrt(p * (1 - p) / n)\n\ncat(\"Distribución de p̂:\\n\")\n\nDistribución de p̂:\n\ncat(\"Media =\", media_p_hat, \"\\n\")\n\nMedia = 0.45 \n\ncat(\"SD (error estándar) =\", round(sd_p_hat, 4), \"\\n\\n\")\n\nSD (error estándar) = 0.0157 \n\n# Probabilidad de que nuestra muestra subestime apoyo en &gt;3%\nprob_error_grande &lt;- pnorm(0.42, mean = p, sd = sd_p_hat)\ncat(\"P(p̂ &lt; 0.42) =\", round(prob_error_grande, 3))\n\nP(p̂ &lt; 0.42) = 0.028\n\n\n\n\n8.2.0.3 Error estándar\nEl error estándar (SE, standard error) es la desviación estándar de la distribución muestral de un estadístico.\n\n\n8.2.0.4 Error estándar de la media\n\\[\\text{SE}(\\bar{x}) = \\frac{\\sigma}{\\sqrt{n}}\\]\nPero \\(\\sigma\\) (SD poblacional) es generalmente desconocido. Lo estimamos con \\(s\\) (SD muestral):\n\\[\\widehat{\\text{SE}}(\\bar{x}) = \\frac{s}{\\sqrt{n}}\\]\nEs importante distinguir entre error estándar y desviación estándar. La desviación estándar (\\(s\\)) mide variabilidad en los datos, mientras que el error estándar (\\(\\text{SE}\\)) mide variabilidad del estadístico (precisión de la estimación). El \\(\\text{SE}\\) disminuye con \\(n\\); \\(s\\) NO (permanece constante en promedio).1\n1 El error estándar mide qué tan precisa es nuestra estimación de la media. La desviación estándar mide qué tan dispersos están los datos individuales. \\(\\text{SE} = s/\\sqrt{n}\\) siempre es menor que \\(s\\) (excepto cuando \\(n=1\\)).Por ejemplo, consideremos datos de ingreso familiar en una encuesta tipo CASEN:\n\n# Datos simulados de ingresos (en miles de $)\nset.seed(456)\ningresos &lt;- rlnorm(500, meanlog = log(600), sdlog = 0.7)\n\nn &lt;- length(ingresos)\nmedia &lt;- mean(ingresos)\ns &lt;- sd(ingresos)\nse &lt;- s / sqrt(n)\n\ncat(\"Muestra de n =\", n, \"hogares\\n\")\n\nMuestra de n = 500 hogares\n\ncat(\"Media muestral: $\", round(media, 0), \" mil\\n\", sep = \"\")\n\nMedia muestral: $810 mil\n\ncat(\"SD de ingresos (s): $\", round(s, 0), \" mil\\n\", sep = \"\")\n\nSD de ingresos (s): $606 mil\n\ncat(\"SE de la media: $\", round(se, 0), \" mil\\n\\n\", sep = \"\")\n\nSE de la media: $27 mil\n\ncat(\"Interpretación:\\n\")\n\nInterpretación:\n\ncat(\"- Los ingresos individuales varían típicamente ±$\", round(s, 0),\n    \" mil alrededor de la media\\n\", sep = \"\")\n\n- Los ingresos individuales varían típicamente ±$606 mil alrededor de la media\n\ncat(\"- Nuestra estimación de la media tiene error típico de ±$\", round(se, 0),\n    \" mil\\n\", sep = \"\")\n\n- Nuestra estimación de la media tiene error típico de ±$27 mil\n\n\n\n\n8.2.0.5 Error estándar de la proporción\n\\[\\text{SE}(\\hat{p}) = \\sqrt{\\frac{p(1-p)}{n}}\\]\nComo \\(p\\) es desconocido, lo estimamos con \\(\\hat{p}\\):\n\\[\\widehat{\\text{SE}}(\\hat{p}) = \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\]\n\n# Encuesta: proporción que apoya política X\nn &lt;- 1200\napoyos &lt;- 510\np_hat &lt;- apoyos / n\nse_p &lt;- sqrt(p_hat * (1 - p_hat) / n)\n\ncat(\"n =\", n, \"encuestados\\n\")\n\nn = 1200 encuestados\n\ncat(\"Apoyan =\", apoyos, \"(\", round(p_hat * 100, 1), \"%)\\n\", sep = \"\")\n\nApoyan =510(42.5%)\n\ncat(\"SE(p̂) =\", round(se_p, 4), \"o\", round(se_p * 100, 2), \"puntos porcentuales\\n\")\n\nSE(p̂) = 0.0143 o 1.43 puntos porcentuales\n\n\n\n\n8.2.0.6 El error estándar disminuye con \\(\\sqrt{n}\\)\nUna implicación crucial: para reducir el SE a la mitad, necesitas cuadruplicar el tamaño muestral.\n\n\n\n\n\nRelación entre tamaño muestral y error estándar",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Inferencia estadística</span>"
    ]
  },
  {
    "objectID": "08-inferencia.html#intervalos-de-confianza",
    "href": "08-inferencia.html#intervalos-de-confianza",
    "title": "8  Inferencia estadística",
    "section": "8.3 Intervalos de confianza",
    "text": "8.3 Intervalos de confianza\nUn intervalo de confianza (IC) es un rango de valores plausibles para el parámetro poblacional, construido de tal manera que, si repitiéramos el muestreo infinitas veces, el IC contendría el valor verdadero en (por ejemplo) 95% de las muestras.\n\n8.3.0.1 Intervalo de confianza para la media\nFórmula general:\n\\[\\text{IC}_{95\\%} = \\bar{x} \\pm t_{n-1, 0.975} \\cdot \\frac{s}{\\sqrt{n}}\\]\ndonde \\(t_{n-1, 0.975}\\) es el valor crítico de la distribución \\(t\\) con \\(n-1\\) grados de libertad.\nCuando \\(n\\) es grande (\\(n \\geq 30\\)), \\(t \\approx 1.96\\), así que:\n\\[\\text{IC}_{95\\%} \\approx \\bar{x} \\pm 1.96 \\cdot \\text{SE}(\\bar{x})\\]\n\n\n\n\n\n\nAdvertenciaError común: Interpretación incorrecta del IC\n\n\n\nINCORRECTO: “Hay 95% de probabilidad de que \\(\\mu\\) esté en este intervalo.”\nCORRECTO: “Si repitiéramos este proceso de muestreo muchas veces, aproximadamente 95% de los intervalos construidos contendrían el verdadero valor de \\(\\mu\\).”\nLa diferencia es sutil pero importante: \\(\\mu\\) es un valor fijo (aunque desconocido). No es aleatorio. Lo que varía entre muestras es el intervalo, no el parámetro.\n\n\nPor ejemplo, consideremos el cálculo de un intervalo de confianza para el ingreso promedio:\n\n# Datos de ingresos (retomando ejemplo anterior)\nset.seed(789)\ningresos &lt;- rlnorm(200, meanlog = log(550), sdlog = 0.65)\n\nn &lt;- length(ingresos)\nmedia &lt;- mean(ingresos)\ns &lt;- sd(ingresos)\nse &lt;- s / sqrt(n)\n\n# Valor crítico t para 95% de confianza\nt_crit &lt;- qt(0.975, df = n - 1)\n\n# Intervalo de confianza\nic_inferior &lt;- media - t_crit * se\nic_superior &lt;- media + t_crit * se\n\ncat(\"Ingreso promedio mensual (n =\", n, \"hogares):\\n\")\n\nIngreso promedio mensual (n = 200 hogares):\n\ncat(\"Media muestral: $\", round(media, 0), \" mil\\n\", sep = \"\")\n\nMedia muestral: $653 mil\n\ncat(\"IC 95%: [$\", round(ic_inferior, 0), \", $\",\n    round(ic_superior, 0), \"] mil\\n\\n\", sep = \"\")\n\nIC 95%: [$588, $719] mil\n\ncat(\"Interpretación: Estamos 95% confiados de que el ingreso promedio\\n\")\n\nInterpretación: Estamos 95% confiados de que el ingreso promedio\n\ncat(\"poblacional está entre $\", round(ic_inferior, 0), \" y $\",\n    round(ic_superior, 0), \" mil.\\n\", sep = \"\")\n\npoblacional está entre $588 y $719 mil.\n\n\n\n\n\n\n\n\nTipForma rápida en R: t.test()\n\n\n\nEn lugar de calcular manualmente, puedes usar la función t.test():\n\n# Usando los mismos datos de ingresos\nresultado &lt;- t.test(ingresos, conf.level = 0.95)\n\n# Ver el intervalo de confianza\nresultado$conf.int\n\n[1] 587.9537 718.5166\nattr(,\"conf.level\")\n[1] 0.95\n\n# Ver todos los resultados\nresultado\n\n\n    One Sample t-test\n\ndata:  ingresos\nt = 19.732, df = 199, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 587.9537 718.5166\nsample estimates:\nmean of x \n 653.2351 \n\n\nLa función t.test() calcula automáticamente el IC y además realiza una prueba de hipótesis (que veremos en el próximo capítulo).\n\n\n\n\n8.3.0.2 Intervalo de confianza para la proporción\n\\[\\text{IC}_{95\\%} = \\hat{p} \\pm 1.96 \\cdot \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\]\n(Válido cuando \\(n\\hat{p} \\geq 10\\) y \\(n(1-\\hat{p}) \\geq 10\\))\nPor ejemplo, para una encuesta de intención de voto:\n\n# Encuesta: ¿Votará en próximas elecciones?\nn &lt;- 1500\nvotaran &lt;- 780\np_hat &lt;- votaran / n\nse_p &lt;- sqrt(p_hat * (1 - p_hat) / n)\n\n# IC 95%\nic_inf &lt;- p_hat - 1.96 * se_p\nic_sup &lt;- p_hat + 1.96 * se_p\n\ncat(\"Encuesta (n =\", n, \"):\\n\")\n\nEncuesta (n = 1500 ):\n\ncat(\"Declaran que votarán:\", votaran, \"personas (\", round(p_hat * 100, 1), \"%)\\n\", sep = \"\")\n\nDeclaran que votarán:780personas (52%)\n\ncat(\"IC 95%: [\", round(ic_inf * 100, 1), \"%, \",\n    round(ic_sup * 100, 1), \"%]\\n\\n\", sep = \"\")\n\nIC 95%: [49.5%, 54.5%]\n\ncat(\"Interpretación: El verdadero porcentaje de personas que votarán\\n\")\n\nInterpretación: El verdadero porcentaje de personas que votarán\n\ncat(\"está probablemente entre\", round(ic_inf * 100, 1), \"% y\",\n    round(ic_sup * 100, 1), \"%.\\n\")\n\nestá probablemente entre 49.5 % y 54.5 %.\n\n\n\n\n\n\n\n\nTipIC para proporciones en R: prop.test()\n\n\n\n\n# Forma directa con prop.test()\nprop.test(x = 780, n = 1500, conf.level = 0.95)\n\n\n    1-sample proportions test with continuity correction\n\ndata:  780 out of 1500, null probability 0.5\nX-squared = 2.3207, df = 1, p-value = 0.1277\nalternative hypothesis: true p is not equal to 0.5\n95 percent confidence interval:\n 0.4943652 0.5455312\nsample estimates:\n   p \n0.52 \n\n\nNota: prop.test() usa una corrección de continuidad por defecto. Para obtener el IC “clásico”, usa correct = FALSE.\n\n\n\n\n8.3.0.3 Niveles de confianza alternativos\nNo estamos limitados a 95%. Podemos construir ICs con cualquier nivel de confianza:\n\n\n\nNivel de Confianza\nValor Crítico \\(z\\)\nIntervalo\n\n\n\n\n90%\n1.645\n\\(\\bar{x} \\pm 1.645 \\cdot \\text{SE}\\)\n\n\n95%\n1.960\n\\(\\bar{x} \\pm 1.960 \\cdot \\text{SE}\\)\n\n\n99%\n2.576\n\\(\\bar{x} \\pm 2.576 \\cdot \\text{SE}\\)\n\n\n\nRelación inversa: Mayor confianza → Intervalo más ancho\n\n# Ejemplo con ingreso promedio\nmedia &lt;- 550\nse &lt;- 35\n\nniveles &lt;- c(0.90, 0.95, 0.99)\nz_valores &lt;- qnorm(1 - (1 - niveles)/2)\n\nresultados &lt;- data.frame(\n  nivel = paste0(niveles * 100, \"%\"),\n  z = round(z_valores, 3),\n  inferior = round(media - z_valores * se, 0),\n  superior = round(media + z_valores * se, 0)\n)\n\nresultados$ancho &lt;- resultados$superior - resultados$inferior\n\nprint(resultados)\n\n  nivel     z inferior superior ancho\n1   90% 1.645      492      608   116\n2   95% 1.960      481      619   138\n3   99% 2.576      460      640   180\n\n\n\n\n\n\n\nVisualización de ICs con diferentes niveles de confianza\n\n\n\n\n\n\n8.3.0.4 Determinación del tamaño muestral\nPara determinar el tamaño muestral necesario para un margen de error deseado:\nPara proporciones: \\(n = \\left(\\frac{z}{E}\\right)^2 \\cdot p(1-p)\\)\nUsando \\(p = 0.5\\) (peor caso, máxima varianza):\n\n\n\nTamaño muestral necesario para estimar proporción (p=0.5)\n\n\nMargen error\n90%\n95%\n99%\n\n\n\n\n±1%\n6764\n9604\n16588\n\n\n±2%\n1691\n2401\n4147\n\n\n±3%\n752\n1068\n1844\n\n\n±4%\n423\n601\n1037\n\n\n±5%\n271\n385\n664\n\n\n±10%\n68\n97\n166\n\n\n\n\n\nPara medias: \\(n = \\left(\\frac{z \\cdot \\sigma}{E}\\right)^2\\)\ndonde \\(\\sigma\\) es la desviación estándar poblacional (estimada de estudios previos).\n\n\n8.3.0.5 Simulación de ICs\nDemostremos con simulación qué significa “95% de confianza”:\n\n# Parámetros poblacionales conocidos (para la simulación)\nmu_real &lt;- 500\nsigma_real &lt;- 120\nn &lt;- 50\n\n# Tomamos 100 muestras y calculamos IC para cada una\nset.seed(2025)\nn_simulaciones &lt;- 100\n\nresultados_sim &lt;- data.frame(\n  muestra = 1:n_simulaciones,\n  media = numeric(n_simulaciones),\n  ic_inf = numeric(n_simulaciones),\n  ic_sup = numeric(n_simulaciones)\n)\n\nfor (i in 1:n_simulaciones) {\n  muestra &lt;- rnorm(n, mean = mu_real, sd = sigma_real)\n  media &lt;- mean(muestra)\n  se &lt;- sd(muestra) / sqrt(n)\n  t_crit &lt;- qt(0.975, df = n - 1)\n\n  resultados_sim$media[i] &lt;- media\n  resultados_sim$ic_inf[i] &lt;- media - t_crit * se\n  resultados_sim$ic_sup[i] &lt;- media + t_crit * se\n}\n\n# ¿Cuántos ICs contienen μ?\nresultados_sim$contiene_mu &lt;- (resultados_sim$ic_inf &lt;= mu_real &\n                                 resultados_sim$ic_sup &gt;= mu_real)\n\nprop_contiene &lt;- mean(resultados_sim$contiene_mu)\n\ncat(\"De\", n_simulaciones, \"intervalos de confianza al 95%:\\n\")\n\nDe 100 intervalos de confianza al 95%:\n\ncat(sum(resultados_sim$contiene_mu), \"contienen el verdadero valor μ =\", mu_real, \"\\n\")\n\n93 contienen el verdadero valor μ = 500 \n\ncat(\"Proporción:\", round(prop_contiene, 3), \"\\n\")\n\nProporción: 0.93 \n\ncat(\"(Esperábamos ~0.95)\\n\")\n\n(Esperábamos ~0.95)\n\n\n\n\n\n\n\n100 intervalos de confianza: los verdes contienen μ, los rojos no\n\n\n\n\n\nMensaje clave: El “95%” NO se refiere a una muestra individual, sino al procedimiento. Si lo repitiéramos infinitas veces, 95% de los intervalos contendrían \\(\\mu\\). Para cualquier muestra específica, o contiene \\(\\mu\\) o no (pero no sabemos cuál).",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Inferencia estadística</span>"
    ]
  },
  {
    "objectID": "08-inferencia.html#resumen",
    "href": "08-inferencia.html#resumen",
    "title": "8  Inferencia estadística",
    "section": "Resumen",
    "text": "Resumen\nConceptos clave:\n\nInferencia estadística: Usar muestras para hacer afirmaciones sobre poblaciones\nParámetros vs estadísticos: \\(\\mu, p\\) (poblacionales, fijos, desconocidos) vs \\(\\bar{x}, \\hat{p}\\) (muestrales, variables, observables)\nDistribución muestral: Distribución de un estadístico a través de todas las muestras posibles\nError estándar: SD de la distribución muestral; mide precisión de la estimación; \\(\\text{SE} = s/\\sqrt{n}\\)\nIntervalos de confianza: Rango plausible para el parámetro; nivel de confianza se refiere al procedimiento, no a un intervalo específico\nTamaño muestral: Determinar \\(n\\) necesario para lograr margen de error deseado\n\nFórmulas esenciales:\n\n\n\n\n\n\n\n\nConcepto\nMedia\nProporción\n\n\n\n\nError estándar\n\\(\\text{SE} = s/\\sqrt{n}\\)\n\\(\\text{SE} = \\sqrt{\\hat{p}(1-\\hat{p})/n}\\)\n\n\nIC 95%\n\\(\\bar{x} \\pm 1.96 \\cdot \\text{SE}\\)\n\\(\\hat{p} \\pm 1.96 \\cdot \\text{SE}\\)\n\n\nTamaño muestral\n\\(n = (z\\sigma/E)^2\\)\n\\(n = (z/E)^2 \\cdot 0.25\\)\n\n\n\nConexión con próximos capítulos:\n\nCap. 9 extenderá la lógica de inferencia a pruebas de hipótesis\nCaps. 10-11 aplicarán ICs y pruebas para comparar grupos y analizar relaciones",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Inferencia estadística</span>"
    ]
  },
  {
    "objectID": "08-inferencia.html#lecturas-recomendadas",
    "href": "08-inferencia.html#lecturas-recomendadas",
    "title": "8  Inferencia estadística",
    "section": "Lecturas recomendadas",
    "text": "Lecturas recomendadas\nFundamentos de inferencia estadística:\nAgresti, A., & Finlay, B. (2009). Statistical Methods for the Social Sciences (4th ed.). Pearson.\n→ Capítulo 5 cubre estimación estadística, intervalos de confianza y error estándar con claridad ejemplar.\nAplicaciones en análisis de datos sociales:\nLlaudet, E., & Imai, K. (2022). Data Analysis for Social Science: A Friendly and Practical Introduction. Princeton University Press.\n→ Capítulo 7 sobre incertidumbre conecta teoría con aplicaciones prácticas en investigación cuantitativa.\nRecurso complementario de acceso libre:\nDiez, D., Barr, C., & Çetinkaya-Rundel, M. (2019). OpenIntro Statistics (4th ed.). [Disponible gratis en https://www.openintro.org/book/os/]\n→ Capítulo 4 sobre fundamentos de inferencia, con ejercicios y ejemplos interactivos.",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Inferencia estadística</span>"
    ]
  },
  {
    "objectID": "08-inferencia.html#ejercicios",
    "href": "08-inferencia.html#ejercicios",
    "title": "8  Inferencia estadística",
    "section": "Ejercicios",
    "text": "Ejercicios\nLos ejercicios para este capítulo se encuentran en el Anexo de Ejercicios.",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Inferencia estadística</span>"
    ]
  },
  {
    "objectID": "09-pruebas-hipotesis.html",
    "href": "09-pruebas-hipotesis.html",
    "title": "9  Pruebas de hipótesis",
    "section": "",
    "text": "Objetivos del capítulo\nAl finalizar este capítulo, serás capaz de:",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pruebas de hipótesis</span>"
    ]
  },
  {
    "objectID": "09-pruebas-hipotesis.html#objetivos-del-capítulo",
    "href": "09-pruebas-hipotesis.html#objetivos-del-capítulo",
    "title": "9  Pruebas de hipótesis",
    "section": "",
    "text": "Comprender la lógica de las pruebas de hipótesis estadísticas\nFormular correctamente hipótesis nula (\\(H_0\\)) y alternativa (\\(H_1\\))\nInterpretar valores p y niveles de significancia\nDistinguir entre significancia estadística y sustantiva\nReconocer y evitar errores tipo I y tipo II\nRealizar pruebas de hipótesis para medias y proporciones\nEntender las limitaciones y mal usos comunes de las pruebas de hipótesis",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pruebas de hipótesis</span>"
    ]
  },
  {
    "objectID": "09-pruebas-hipotesis.html#lógica-de-pruebas-de-hipótesis",
    "href": "09-pruebas-hipotesis.html#lógica-de-pruebas-de-hipótesis",
    "title": "9  Pruebas de hipótesis",
    "section": "9.1 Lógica de pruebas de hipótesis",
    "text": "9.1 Lógica de pruebas de hipótesis\nLas pruebas de hipótesis responden a una pregunta fundamental en investigación: ¿Este patrón que observo en mis datos es real, o podría ser producto del azar? Consideremos un caso concreto: en una encuesta antes de una campaña publicitaria, 42% de 800 encuestados apoyaba al Candidato A. Después de la campaña, en otra muestra de 800 personas, 47% lo apoya. La pregunta relevante es: ¿la campaña fue efectiva, o esta diferencia de 5 puntos porcentuales podría deberse simplemente a error muestral?\n\n9.1.0.1 La lógica de prueba por contradicción\nLas pruebas de hipótesis usan un argumento de reducción al absurdo:\n\nAsumimos que NO hay efecto (hipótesis nula: \\(H_0\\))\nPreguntamos: ¿Qué tan probable es observar nuestros datos si \\(H_0\\) fuera cierta?\nSi esa probabilidad es muy baja, rechazamos \\(H_0\\) como implausible\nSi la probabilidad no es tan baja, no rechazamos \\(H_0\\) (no tenemos evidencia suficiente contra ella)\n\nEs crucial entender la asimetría fundamental de este razonamiento: nunca “aceptamos” o “probamos” \\(H_0\\). Solo podemos rechazar \\(H_0\\) (cuando hay evidencia contra ella) o no rechazar \\(H_0\\) (cuando no hay evidencia suficiente contra ella). Esto es análogo a un juicio judicial: no “probamos inocencia”, solo establecemos que “no hay evidencia suficiente de culpabilidad”.\n\n\n9.1.0.2 Hipótesis nula y alternativa\n\n\n9.1.0.3 Formulación de hipótesis\nHipótesis nula (\\(H_0\\)): Afirmación de “no efecto” o “no diferencia”. Es lo que asumimos como cierto inicialmente.\nHipótesis alternativa (\\(H_1\\)): Lo que esperamos encontrar si rechazamos \\(H_0\\). Puede ser: - Bilateral (dos colas): \\(H_1: \\mu \\neq \\mu_0\\) (hay diferencia, en cualquier dirección) - Unilateral (una cola): \\(H_1: \\mu &gt; \\mu_0\\) o \\(H_1: \\mu &lt; \\mu_0\\) (dirección específica)\nConsideremos algunos casos concretos en ciencias sociales. Si evaluamos el efecto de una política pública sobre desempleo, podríamos plantear \\(H_0: \\mu = 8\\%\\) (el desempleo se mantiene en 8%) versus \\(H_1: \\mu &lt; 8\\%\\) (la política redujo el desempleo), usando una prueba unilateral. Para comparar participación electoral entre géneros, formularíamos \\(H_0: p_{\\text{hombres}} = p_{\\text{mujeres}}\\) (no hay diferencia) contra \\(H_1: p_{\\text{hombres}} \\neq p_{\\text{mujeres}}\\) (hay diferencia), usando una prueba bilateral. Finalmente, al comparar el ingreso promedio de una región con el nacional, plantearíamos \\(H_0: \\mu_{\\text{región}} = 550\\) mil pesos (igual al promedio nacional) versus \\(H_1: \\mu_{\\text{región}} \\neq 550\\) mil (diferente al nacional).1\n1 Otros ejemplos en ciencias políticas: evaluar si una reforma electoral aumentó la participación, o comparar aprobación presidencial entre regiones urbanas y rurales.",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pruebas de hipótesis</span>"
    ]
  },
  {
    "objectID": "09-pruebas-hipotesis.html#valores-p-y-errores",
    "href": "09-pruebas-hipotesis.html#valores-p-y-errores",
    "title": "9  Pruebas de hipótesis",
    "section": "9.2 Valores p y errores",
    "text": "9.2 Valores p y errores\n\n9.2.0.1 ¿Qué es un valor p?\nEl valor p (p-value) es la probabilidad de observar datos tan extremos como los nuestros (o más), asumiendo que \\(H_0\\) es cierta.\n\\[\\text{valor } p = P(\\text{datos tan extremos} \\mid H_0 \\text{ es cierta})\\]\nLa interpretación correcta del valor p es fundamental para evitar errores comunes.2 Cuando observamos \\(p = 0.03\\), debemos interpretar: “Si no hubiera efecto real, veríamos resultados tan extremos solo 3% de las veces.”\n2 Error común: “p = 0.03 significa 3% de probabilidad de que \\(H_0\\) sea cierta”. Falso. El valor p es \\(P(\\text{datos} | H_0)\\), no \\(P(H_0 | \\text{datos})\\). La hipótesis nula no es una variable aleatoria.Un valor \\(p = 0.001\\) indica: “Si \\(H_0\\) fuera cierta, estos datos serían extremadamente raros (1 en 1000).” Por el contrario, \\(p = 0.45\\) significa: “Estos datos son muy compatibles con \\(H_0\\); no hay evidencia contra ella.” El valor p NO representa la probabilidad de que \\(H_0\\) sea cierta.\n\n\n9.2.0.2 Nivel de significancia (\\(\\alpha\\))\nEl nivel de significancia \\(\\alpha\\) es el umbral que elegimos antes de analizar los datos para decidir cuándo rechazar \\(H_0\\). Convencionalmente se usa \\(\\alpha = 0.05\\), pero esta elección es arbitraria.3\n3 ¿Por qué 0.05? R.A. Fisher lo propuso como “conveniente” en los años 1920. No hay nada mágico en este número. En física de partículas usan \\(\\alpha = 0.0000003\\) (5 sigmas). En estudios exploratorios, algunos usan \\(\\alpha = 0.10\\). La elección debería depender del costo relativo de los errores tipo I y II.La regla de decisión es:\n\nSi \\(p &lt; \\alpha\\): Rechazamos \\(H_0\\) (resultado “estadísticamente significativo”)\nSi \\(p \\geq \\alpha\\): No rechazamos \\(H_0\\) (no hay evidencia suficiente)\n\n\n\n\n\n\n\nAdvertenciaCuidado con el término “significativo”\n\n\n\n“Estadísticamente significativo” NO significa “importante” o “relevante”. Solo significa que el resultado es improbable bajo \\(H_0\\). Un efecto puede ser estadísticamente significativo pero prácticamente irrelevante (especialmente con muestras grandes), o puede ser sustantivamente importante pero no alcanzar significancia estadística (con muestras pequeñas).\n\n\n\n\n9.2.0.3 Errores tipo I y tipo II\nEn pruebas de hipótesis, existen dos tipos de error posibles:\n\n\n\n\n\n\n\n\n\n\\(H_0\\) es verdadera\n\\(H_0\\) es falsa\n\n\n\n\nRechazar \\(H_0\\)\nError Tipo I (\\(\\alpha\\))\nDecisión correcta (Poder)\n\n\nNo rechazar \\(H_0\\)\nDecisión correcta\nError Tipo II (\\(\\beta\\))\n\n\n\nError Tipo I (falso positivo): Rechazar \\(H_0\\) cuando es cierta. Es como condenar a un inocente. La probabilidad de cometerlo es \\(\\alpha\\), que nosotros controlamos al elegir el nivel de significancia.\nError Tipo II (falso negativo): No rechazar \\(H_0\\) cuando es falsa. Es como absolver a un culpable. La probabilidad de cometerlo es \\(\\beta\\), que depende del tamaño del efecto real y del tamaño muestral.\nPoder estadístico: \\(1 - \\beta\\) es la probabilidad de detectar un efecto real cuando existe. Un estudio con poder de 0.80 detectará el efecto en 80% de las réplicas.\n\n\nCódigo\nlibrary(ggplot2)\n\n# Crear datos para dos distribuciones\nx &lt;- seq(-4, 8, length.out = 1000)\nh0 &lt;- dnorm(x, mean = 0, sd = 1)  # Distribución bajo H0\nh1 &lt;- dnorm(x, mean = 3, sd = 1)  # Distribución bajo H1 (efecto real)\n\ndatos &lt;- data.frame(\n  x = rep(x, 2),\n  densidad = c(h0, h1),\n  hipotesis = rep(c(\"H0: No hay efecto\", \"H1: Hay efecto real\"), each = 1000)\n)\n\n# Valor crítico para alpha = 0.05 (una cola)\nvalor_critico &lt;- qnorm(0.95, mean = 0, sd = 1)\n\nggplot(datos, aes(x = x, y = densidad, color = hipotesis, fill = hipotesis)) +\n  geom_line(linewidth = 1) +\n  geom_area(data = subset(datos, hipotesis == \"H0: No hay efecto\" & x &gt; valor_critico),\n            alpha = 0.4) +\n  geom_area(data = subset(datos, hipotesis == \"H1: Hay efecto real\" & x &lt; valor_critico),\n            alpha = 0.4) +\n  geom_vline(xintercept = valor_critico, linetype = \"dashed\", color = \"black\") +\n  annotate(\"text\", x = valor_critico + 0.3, y = 0.35,\n           label = \"Valor crítico\", hjust = 0, size = 3) +\n  annotate(\"text\", x = 2.5, y = 0.05,\n           label = \"Error Tipo I\\n(α)\", size = 3, color = \"#E41A1C\") +\n  annotate(\"text\", x = 0.5, y = 0.05,\n           label = \"Error Tipo II\\n(β)\", size = 3, color = \"#377EB8\") +\n  scale_color_manual(values = c(\"#E41A1C\", \"#377EB8\")) +\n  scale_fill_manual(values = c(\"#E41A1C\", \"#377EB8\")) +\n  labs(x = \"Estadístico de prueba\", y = \"Densidad\",\n       color = \"\", fill = \"\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nFigura 9.1: Visualización de errores Tipo I y Tipo II\n\n\n\n\n\n\n\n\n\n\n\nTipAnalogía judicial\n\n\n\nPiensa en un juicio criminal:\n\n\\(H_0\\): El acusado es inocente (presunción de inocencia)\n\\(H_1\\): El acusado es culpable\nError Tipo I: Condenar a un inocente (grave)\nError Tipo II: Absolver a un culpable (también malo, pero el sistema prefiere este error)\n\\(\\alpha\\) bajo: Exigimos mucha evidencia para condenar, protegiendo a inocentes\n\nEl sistema judicial prefiere errores Tipo II sobre Tipo I (“mejor 10 culpables libres que un inocente preso”). En investigación, la elección de \\(\\alpha\\) refleja una decisión similar sobre qué error es más costoso.",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pruebas de hipótesis</span>"
    ]
  },
  {
    "objectID": "09-pruebas-hipotesis.html#prueba-t-para-una-media",
    "href": "09-pruebas-hipotesis.html#prueba-t-para-una-media",
    "title": "9  Pruebas de hipótesis",
    "section": "9.3 Prueba t para una media",
    "text": "9.3 Prueba t para una media\nLa prueba t evalúa si la media de una población difiere de un valor específico. Se usa cuando la desviación estándar poblacional es desconocida (el caso habitual).\n\n9.3.0.1 Ejemplo: Satisfacción con la democracia\nSupongamos que queremos evaluar si los chilenos tienen una satisfacción con la democracia diferente al promedio latinoamericano, que según datos regionales es 5.0 en una escala de 1 a 10. Recopilamos una muestra de 150 personas.\n\n# Simulamos datos de una encuesta\nset.seed(2024)\nsatisfaccion &lt;- rnorm(150, mean = 4.2, sd = 2.1)\nsatisfaccion &lt;- pmax(1, pmin(10, satisfaccion))  # Limitar a escala 1-10\n\nPaso 1: Formular hipótesis\n\n\\(H_0: \\mu = 5.0\\) (satisfacción igual al promedio regional)\n\\(H_1: \\mu \\neq 5.0\\) (satisfacción diferente al promedio regional)\n\nPaso 2: Calcular estadístico de prueba\n\\[t = \\frac{\\bar{x} - \\mu_0}{s / \\sqrt{n}}\\]\n\n# Cálculo manual\nmedia_muestral &lt;- mean(satisfaccion)\ndesv_estandar &lt;- sd(satisfaccion)\nn &lt;- length(satisfaccion)\nmu_0 &lt;- 5.0\n\nt_calculado &lt;- (media_muestral - mu_0) / (desv_estandar / sqrt(n))\n\ncat(\"Media muestral:\", round(media_muestral, 2), \"\\n\")\n\nMedia muestral: 4.17 \n\ncat(\"Desviación estándar:\", round(desv_estandar, 2), \"\\n\")\n\nDesviación estándar: 1.97 \n\ncat(\"Estadístico t:\", round(t_calculado, 2), \"\\n\")\n\nEstadístico t: -5.16 \n\n\nPaso 3: Obtener valor p\n\n# Valor p (bilateral)\nvalor_p &lt;- 2 * pt(abs(t_calculado), df = n - 1, lower.tail = FALSE)\ncat(\"Valor p:\", round(valor_p, 4), \"\\n\")\n\nValor p: 0 \n\n\nPaso 4: Usar la función t.test() de R\n\n# Forma directa en R\nresultado &lt;- t.test(satisfaccion, mu = 5.0)\nresultado\n\n\n    One Sample t-test\n\ndata:  satisfaccion\nt = -5.1589, df = 149, p-value = 7.8e-07\nalternative hypothesis: true mean is not equal to 5\n95 percent confidence interval:\n 3.854508 4.488992\nsample estimates:\nmean of x \n  4.17175 \n\n\nPaso 5: Interpretar resultados\n\n\nConclusión: Con p = 0 &lt; 0.05, rechazamos H0.\nHay evidencia estadística de que la satisfacción promedio difiere de 5.0.\nEl intervalo de confianza al 95% es [ 3.85 , 4.49 ].",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pruebas de hipótesis</span>"
    ]
  },
  {
    "objectID": "09-pruebas-hipotesis.html#prueba-t-para-dos-muestras-independientes",
    "href": "09-pruebas-hipotesis.html#prueba-t-para-dos-muestras-independientes",
    "title": "9  Pruebas de hipótesis",
    "section": "9.4 Prueba t para dos muestras independientes",
    "text": "9.4 Prueba t para dos muestras independientes\nFrecuentemente queremos comparar medias entre dos grupos. Por ejemplo: ¿hay diferencia en confianza institucional entre hombres y mujeres?\n\n# Simulamos datos de encuesta sobre confianza en el Congreso (1-10)\nset.seed(2024)\nconfianza_hombres &lt;- rnorm(120, mean = 3.8, sd = 1.8)\nconfianza_mujeres &lt;- rnorm(130, mean = 3.2, sd = 1.9)\n\n# Limitar a escala 1-10\nconfianza_hombres &lt;- pmax(1, pmin(10, confianza_hombres))\nconfianza_mujeres &lt;- pmax(1, pmin(10, confianza_mujeres))\n\nHipótesis:\n\n\\(H_0: \\mu_H = \\mu_M\\) (no hay diferencia entre géneros)\n\\(H_1: \\mu_H \\neq \\mu_M\\) (hay diferencia)\n\n\n# Prueba t para dos muestras\nresultado_2muestras &lt;- t.test(confianza_hombres, confianza_mujeres)\nresultado_2muestras\n\n\n    Welch Two Sample t-test\n\ndata:  confianza_hombres and confianza_mujeres\nt = 1.2201, df = 243.65, p-value = 0.2236\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.1585234  0.6745380\nsample estimates:\nmean of x mean of y \n 3.773631  3.515623 \n\n\n\n\nCódigo\n# Visualización\ndatos_genero &lt;- data.frame(\n  confianza = c(confianza_hombres, confianza_mujeres),\n  genero = factor(c(rep(\"Hombres\", length(confianza_hombres)),\n                    rep(\"Mujeres\", length(confianza_mujeres))))\n)\n\nggplot(datos_genero, aes(x = genero, y = confianza, fill = genero)) +\n  geom_boxplot(alpha = 0.7) +\n  geom_jitter(width = 0.2, alpha = 0.3, size = 1) +\n  stat_summary(fun = mean, geom = \"point\", shape = 18, size = 4, color = \"red\") +\n  scale_fill_manual(values = c(\"#4ECDC4\", \"#FF6B6B\")) +\n  labs(x = \"\", y = \"Confianza en el Congreso (1-10)\",\n       caption = \"El diamante rojo indica la media de cada grupo\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nFigura 9.2: Confianza en el Congreso por género",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pruebas de hipótesis</span>"
    ]
  },
  {
    "objectID": "09-pruebas-hipotesis.html#prueba-chi-cuadrado-para-independencia",
    "href": "09-pruebas-hipotesis.html#prueba-chi-cuadrado-para-independencia",
    "title": "9  Pruebas de hipótesis",
    "section": "9.5 Prueba chi-cuadrado para independencia",
    "text": "9.5 Prueba chi-cuadrado para independencia\nCuando ambas variables son categóricas, usamos la prueba chi-cuadrado (\\(\\chi^2\\)) para evaluar si están asociadas.\n\n9.5.0.1 Ejemplo: Voto y nivel educativo\n¿Existe asociación entre nivel educativo y preferencia de voto?\n\n# Crear tabla de contingencia\nset.seed(2024)\nvoto_educacion &lt;- matrix(c(\n  45, 35, 20,   # Educación básica: Izquierda, Centro, Derecha\n  40, 45, 35,   # Educación media\n  25, 40, 50    # Educación superior\n), nrow = 3, byrow = TRUE)\n\nrownames(voto_educacion) &lt;- c(\"Básica\", \"Media\", \"Superior\")\ncolnames(voto_educacion) &lt;- c(\"Izquierda\", \"Centro\", \"Derecha\")\n\n# Mostrar tabla\nvoto_educacion\n\n         Izquierda Centro Derecha\nBásica          45     35      20\nMedia           40     45      35\nSuperior        25     40      50\n\n\nHipótesis:\n\n\\(H_0\\): Nivel educativo y preferencia de voto son independientes\n\\(H_1\\): Existe asociación entre nivel educativo y preferencia de voto\n\n\n# Prueba chi-cuadrado\nresultado_chi &lt;- chisq.test(voto_educacion)\nresultado_chi\n\n\n    Pearson's Chi-squared test\n\ndata:  voto_educacion\nX-squared = 18.665, df = 4, p-value = 0.0009143\n\n\n\n\nCódigo\n# Convertir a data frame para visualización\nlibrary(tidyr)\ndatos_voto &lt;- as.data.frame(as.table(voto_educacion))\nnames(datos_voto) &lt;- c(\"Educacion\", \"Voto\", \"Frecuencia\")\n\nggplot(datos_voto, aes(x = Educacion, y = Frecuencia, fill = Voto)) +\n  geom_bar(stat = \"identity\", position = \"fill\") +\n  scale_fill_manual(values = c(\"#E41A1C\", \"#984EA3\", \"#377EB8\")) +\n  scale_y_continuous(labels = scales::percent) +\n  labs(x = \"Nivel educativo\", y = \"Proporción\", fill = \"Preferencia\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nFigura 9.3: Relación entre nivel educativo y preferencia de voto\n\n\n\n\n\n\n# Residuos estandarizados (qué celdas contribuyen más)\ncat(\"Residuos estandarizados:\\n\")\n\nResiduos estandarizados:\n\nround(resultado_chi$residuals, 2)\n\n         Izquierda Centro Derecha\nBásica        2.12  -0.14   -2.03\nMedia         0.10   0.31   -0.43\nSuperior     -2.08  -0.19    2.32\n\n\n\n\n\n\n\n\nNotaInterpretando residuos\n\n\n\nLos residuos estandarizados mayores a 2 (o menores a -2) indican celdas donde hay más (o menos) casos de los esperados bajo independencia. En este ejemplo, personas con educación básica votan más por la izquierda de lo esperado, mientras personas con educación superior votan más por la derecha.",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pruebas de hipótesis</span>"
    ]
  },
  {
    "objectID": "09-pruebas-hipotesis.html#significancia-estadística-vs.-sustantiva",
    "href": "09-pruebas-hipotesis.html#significancia-estadística-vs.-sustantiva",
    "title": "9  Pruebas de hipótesis",
    "section": "9.6 Significancia estadística vs. sustantiva",
    "text": "9.6 Significancia estadística vs. sustantiva\n\n\n\n\n\n\nImportanteLa distinción más importante del capítulo\n\n\n\nSignificancia estadística (\\(p &lt; 0.05\\)) solo indica que el efecto probablemente no es cero. No dice nada sobre si el efecto es importante o relevante.\nSignificancia sustantiva pregunta: ¿el efecto es lo suficientemente grande como para importar en la práctica?\n\n\nConsideremos un ejemplo. Supongamos que un programa de educación cívica aumenta el conocimiento político de 50.0 a 50.5 puntos (en escala de 0-100). Con una muestra de 10,000 personas, este efecto de 0.5 puntos podría ser estadísticamente significativo (\\(p &lt; 0.001\\)). Pero ¿importa prácticamente una diferencia de medio punto en 100?\n\n# Demostración: efecto pequeño pero \"significativo\" con n grande\nset.seed(2024)\ncontrol &lt;- rnorm(5000, mean = 50, sd = 15)\ntratamiento &lt;- rnorm(5000, mean = 50.5, sd = 15)  # Diferencia de 0.5 puntos\n\nt.test(tratamiento, control)\n\n\n    Welch Two Sample t-test\n\ndata:  tratamiento and control\nt = 0.75173, df = 9994.7, p-value = 0.4522\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.3626333  0.8137819\nsample estimates:\nmean of x mean of y \n 50.26756  50.04198 \n\n\nEl resultado es “significativo” (\\(p &lt; 0.05\\)), pero la diferencia de medias es solo 0.5 puntos. Esto ilustra por qué siempre debemos reportar:\n\nEl tamaño del efecto (diferencia de medias, odds ratio, etc.)\nEl intervalo de confianza (rango plausible del efecto)\nLa significancia práctica (¿este efecto importa en el mundo real?)\n\n\n9.6.0.1 Tamaño del efecto: d de Cohen\nUna medida estandarizada del tamaño del efecto es la d de Cohen:\n\\[d = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_{pooled}}\\]\n\n\\(d = 0.2\\): efecto pequeño\n\\(d = 0.5\\): efecto mediano\n\\(d = 0.8\\): efecto grande\n\n\n# Calcular d de Cohen\ndiferencia &lt;- mean(tratamiento) - mean(control)\ns_pooled &lt;- sqrt((var(tratamiento) + var(control)) / 2)\nd_cohen &lt;- diferencia / s_pooled\n\ncat(\"d de Cohen:\", round(d_cohen, 3), \"\\n\")\n\nd de Cohen: 0.015 \n\ncat(\"Interpretación: efecto\",\n    ifelse(abs(d_cohen) &lt; 0.2, \"trivial\",\n           ifelse(abs(d_cohen) &lt; 0.5, \"pequeño\",\n                  ifelse(abs(d_cohen) &lt; 0.8, \"mediano\", \"grande\"))))\n\nInterpretación: efecto trivial",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pruebas de hipótesis</span>"
    ]
  },
  {
    "objectID": "09-pruebas-hipotesis.html#errores-comunes-y-malas-prácticas",
    "href": "09-pruebas-hipotesis.html#errores-comunes-y-malas-prácticas",
    "title": "9  Pruebas de hipótesis",
    "section": "9.7 Errores comunes y malas prácticas",
    "text": "9.7 Errores comunes y malas prácticas\n\n\n\n\n\n\nPrecauciónErrores que debes evitar\n\n\n\n\nConfundir valor p con probabilidad de \\(H_0\\): \\(p = 0.03\\) NO significa “3% de probabilidad de que \\(H_0\\) sea cierta”\nDicotomizar en “significativo/no significativo”: \\(p = 0.049\\) y \\(p = 0.051\\) son prácticamente idénticos, pero uno es “significativo” y otro no\nP-hacking: Probar múltiples análisis y reportar solo los significativos\nInterpretar “no significativo” como “no hay efecto”: Ausencia de evidencia no es evidencia de ausencia\nIgnorar el tamaño del efecto: Un efecto significativo puede ser irrelevante prácticamente\n\n\n\n\n9.7.0.1 El problema de las comparaciones múltiples\nSi pruebas 20 hipótesis independientes con \\(\\alpha = 0.05\\), esperarías encontrar 1 resultado “significativo” por azar puro, incluso si todas las \\(H_0\\) son ciertas.\n\n# Simulación: 20 pruebas cuando H0 es siempre cierta\nset.seed(2024)\nvalores_p &lt;- replicate(20, {\n  x &lt;- rnorm(50)  # Datos puramente aleatorios\n  y &lt;- rnorm(50)\n  t.test(x, y)$p.value\n})\n\ncat(\"Valores p de 20 pruebas (H0 siempre cierta):\\n\")\n\nValores p de 20 pruebas (H0 siempre cierta):\n\nround(sort(valores_p), 3)\n\n [1] 0.021 0.027 0.076 0.157 0.169 0.195 0.216 0.302 0.313 0.340 0.429 0.432\n[13] 0.461 0.482 0.586 0.754 0.928 0.936 0.987 0.998\n\ncat(\"\\n\\nNúmero de 'significativos' (p &lt; 0.05):\", sum(valores_p &lt; 0.05))\n\n\n\nNúmero de 'significativos' (p &lt; 0.05): 2\n\n\nCorrección de Bonferroni: Si haces \\(m\\) pruebas, usa \\(\\alpha' = \\alpha / m\\). Para 20 pruebas con \\(\\alpha = 0.05\\), usarías \\(\\alpha' = 0.0025\\).\nOtras correcciones: Holm, Benjamini-Hochberg (FDR), que son menos conservadoras que Bonferroni.",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pruebas de hipótesis</span>"
    ]
  },
  {
    "objectID": "09-pruebas-hipotesis.html#resumen",
    "href": "09-pruebas-hipotesis.html#resumen",
    "title": "9  Pruebas de hipótesis",
    "section": "Resumen",
    "text": "Resumen\nLas pruebas de hipótesis evalúan si un patrón observado en los datos podría deberse al azar. La lógica es de reducción al absurdo: asumimos que no hay efecto (\\(H_0\\)) y preguntamos qué tan probable sería observar nuestros datos bajo ese supuesto.\nEl valor p es la probabilidad de observar datos tan extremos como los nuestros si \\(H_0\\) fuera cierta. NO es la probabilidad de que \\(H_0\\) sea cierta. Si \\(p &lt; \\alpha\\) (usualmente 0.05), rechazamos \\(H_0\\); si no, no la rechazamos (pero tampoco la “aceptamos”).\nExisten dos tipos de error: Tipo I (rechazar \\(H_0\\) cuando es cierta, controlado por \\(\\alpha\\)) y Tipo II (no rechazar \\(H_0\\) cuando es falsa, probabilidad \\(\\beta\\)). El poder (\\(1-\\beta\\)) es nuestra capacidad de detectar efectos reales.\nLas pruebas más comunes incluyen la prueba t (para comparar medias) y chi-cuadrado (para asociación entre variables categóricas). En R, usamos t.test() y chisq.test().\nLa distinción crucial es entre significancia estadística (el efecto probablemente no es cero) y significancia sustantiva (el efecto es lo suficientemente grande para importar). Siempre reporta el tamaño del efecto y los intervalos de confianza, no solo el valor p",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pruebas de hipótesis</span>"
    ]
  },
  {
    "objectID": "09-pruebas-hipotesis.html#lecturas-recomendadas",
    "href": "09-pruebas-hipotesis.html#lecturas-recomendadas",
    "title": "9  Pruebas de hipótesis",
    "section": "Lecturas recomendadas",
    "text": "Lecturas recomendadas\nFundamentos de pruebas de hipótesis:\nAgresti, A., & Finlay, B. (2009). Statistical Methods for the Social Sciences (4th ed.). Pearson.\n→ Capítulo 6 ofrece explicación rigurosa pero accesible de la lógica de pruebas de significancia estadística.\nAplicaciones en ciencias sociales:\nLlaudet, E., & Imai, K. (2022). Data Analysis for Social Science: A Friendly and Practical Introduction. Princeton University Press.\n→ Sección 7.5 conecta pruebas de hipótesis con aplicaciones prácticas en investigación social y política.\nSobre problemas y mal uso de valores p:\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA’s statement on p-values: Context, process, and purpose. The American Statistician, 70(2), 129-133.\n→ Declaración oficial de la Asociación Americana de Estadística sobre interpretación correcta de valores p y errores comunes.",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pruebas de hipótesis</span>"
    ]
  },
  {
    "objectID": "09-pruebas-hipotesis.html#ejercicios",
    "href": "09-pruebas-hipotesis.html#ejercicios",
    "title": "9  Pruebas de hipótesis",
    "section": "Ejercicios",
    "text": "Ejercicios\nLos ejercicios para este capítulo se encuentran en el Anexo de Ejercicios.",
    "crumbs": [
      "IV. Unidad 3: Principios de Inferencia Estadística",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Pruebas de hipótesis</span>"
    ]
  },
  {
    "objectID": "10-comparacion-medias.html",
    "href": "10-comparacion-medias.html",
    "title": "10  Comparación de medias",
    "section": "",
    "text": "Objetivos del capítulo\nAl finalizar este capítulo, serás capaz de:",
    "crumbs": [
      "V. Unidad 4: Análisis Bivariado",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Comparación de medias</span>"
    ]
  },
  {
    "objectID": "10-comparacion-medias.html#objetivos-del-capítulo",
    "href": "10-comparacion-medias.html#objetivos-del-capítulo",
    "title": "10  Comparación de medias",
    "section": "",
    "text": "Realizar pruebas t para comparar medias entre dos grupos\nDistinguir entre pruebas t para muestras independientes y pareadas\nComprender los supuestos de las pruebas paramétricas\nUsar ANOVA para comparar medias de más de dos grupos\nIdentificar cuándo usar alternativas no paramétricas",
    "crumbs": [
      "V. Unidad 4: Análisis Bivariado",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Comparación de medias</span>"
    ]
  },
  {
    "objectID": "10-comparacion-medias.html#prueba-t-para-una-muestra",
    "href": "10-comparacion-medias.html#prueba-t-para-una-muestra",
    "title": "10  Comparación de medias",
    "section": "10.1 Prueba t para una muestra",
    "text": "10.1 Prueba t para una muestra\nLa prueba t para una muestra compara la media de una muestra con un valor teórico o poblacional.\nHipótesis: - \\(H_0: \\mu = \\mu_0\\) - \\(H_1: \\mu \\neq \\mu_0\\)\nEstadístico t: \\[t = \\frac{\\bar{x} - \\mu_0}{s / \\sqrt{n}}\\]",
    "crumbs": [
      "V. Unidad 4: Análisis Bivariado",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Comparación de medias</span>"
    ]
  },
  {
    "objectID": "10-comparacion-medias.html#prueba-t-para-dos-muestras",
    "href": "10-comparacion-medias.html#prueba-t-para-dos-muestras",
    "title": "10  Comparación de medias",
    "section": "10.2 Prueba t para dos muestras",
    "text": "10.2 Prueba t para dos muestras\n\n10.2.0.1 Muestras independientes\nComparamos las medias de dos grupos independientes.\nHipótesis: - \\(H_0: \\mu_1 = \\mu_2\\) - \\(H_1: \\mu_1 \\neq \\mu_2\\)\nEstadístico t: \\[t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\\]\nConsideremos un caso concreto para ilustrar esta prueba: la comparación de ingresos promedio entre hombres y mujeres en Chile.\n\n# Datos simulados: Diferencia salarial por género\nset.seed(2024)\ningresos_hombres &lt;- rlnorm(150, meanlog = log(750), sdlog = 0.6)\ningresos_mujeres &lt;- rlnorm(150, meanlog = log(650), sdlog = 0.6)\n\n# Prueba t para dos muestras independientes\nresultado &lt;- t.test(ingresos_hombres, ingresos_mujeres)\nprint(resultado)\n\n\n    Welch Two Sample t-test\n\ndata:  ingresos_hombres and ingresos_mujeres\nt = 0.7294, df = 297.17, p-value = 0.4663\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -71.76787 156.29638\nsample estimates:\nmean of x mean of y \n 865.2076  822.9434 \n\n\n\n\n10.2.0.2 Muestras pareadas\nPara datos pareados (mismo sujeto medido dos veces, o pares emparejados) se requiere una prueba t específica que reconoce la dependencia entre observaciones. Consideremos el caso de evaluación de una intervención policial sobre percepción de seguridad, donde medimos a los mismos individuos antes y después de la intervención:\n\n# Datos: Percepción de seguridad antes y después de intervención policial\nset.seed(123)\nantes &lt;- rnorm(50, mean = 4.2, sd = 1.5)\ndespues &lt;- antes + rnorm(50, mean = 0.8, sd = 1.0)  # Mejora promedio\n\n# Prueba t pareada\nresultado &lt;- t.test(despues, antes, paired = TRUE)\nprint(resultado)\n\n\n    Paired t-test\n\ndata:  despues and antes\nt = 7.391, df = 49, p-value = 1.649e-09\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.689083 1.203734\nsample estimates:\nmean difference \n      0.9464083",
    "crumbs": [
      "V. Unidad 4: Análisis Bivariado",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Comparación de medias</span>"
    ]
  },
  {
    "objectID": "10-comparacion-medias.html#anova-comparar-más-de-dos-grupos",
    "href": "10-comparacion-medias.html#anova-comparar-más-de-dos-grupos",
    "title": "10  Comparación de medias",
    "section": "10.3 ANOVA: Comparar más de dos grupos",
    "text": "10.3 ANOVA: Comparar más de dos grupos\nCuando queremos comparar las medias de tres o más grupos, la prueba t no es apropiada porque haríamos múltiples comparaciones, aumentando la probabilidad de error tipo I. El ANOVA (Analysis of Variance) resuelve esto comparando todos los grupos simultáneamente.\nHipótesis:\n\n\\(H_0\\): Todas las medias son iguales (\\(\\mu_1 = \\mu_2 = \\mu_3 = ...\\))\n\\(H_1\\): Al menos una media es diferente\n\nEjemplo: Comparamos la satisfacción con la democracia según orientación política (izquierda, centro, derecha).\n\n# Datos simulados: satisfacción con democracia por orientación política\nset.seed(2024)\nn_grupo &lt;- 100\n\ndatos_anova &lt;- data.frame(\n  satisfaccion = c(\n    rnorm(n_grupo, mean = 4.5, sd = 1.2),  # Izquierda\n    rnorm(n_grupo, mean = 5.2, sd = 1.1),  # Centro\n    rnorm(n_grupo, mean = 4.0, sd = 1.3)   # Derecha\n  ),\n  orientacion = rep(c(\"Izquierda\", \"Centro\", \"Derecha\"), each = n_grupo)\n)\n\n# ANOVA de una vía\nmodelo_anova &lt;- aov(satisfaccion ~ orientacion, data = datos_anova)\nsummary(modelo_anova)\n\n             Df Sum Sq Mean Sq F value  Pr(&gt;F)    \norientacion   2   84.1   42.06   30.65 7.9e-13 ***\nResiduals   297  407.6    1.37                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nInterpretación: Si el valor p es menor a 0.05, rechazamos \\(H_0\\) y concluimos que al menos un grupo tiene una media significativamente diferente.\n\nlibrary(ggplot2)\n\nggplot(datos_anova, aes(x = orientacion, y = satisfaccion, fill = orientacion)) +\n  geom_boxplot(alpha = 0.7, show.legend = FALSE) +\n  stat_summary(fun = mean, geom = \"point\", shape = 18, size = 4, color = \"red\") +\n  labs(x = \"Orientación política\",\n       y = \"Satisfacción con la democracia (1-7)\",\n       title = \"Satisfacción según orientación política\",\n       subtitle = \"Punto rojo = media del grupo\") +\n  theme_minimal()\n\n\n\n\nSatisfacción con democracia por orientación política\n\n\n\n\n\n10.3.0.1 Comparaciones post-hoc\nSi ANOVA indica diferencias significativas, ¿entre qué grupos están las diferencias? Las pruebas post-hoc (como Tukey HSD) comparan todos los pares de grupos controlando el error tipo I.\n\n# Comparaciones post-hoc de Tukey\nTukeyHSD(modelo_anova)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = satisfaccion ~ orientacion, data = datos_anova)\n\n$orientacion\n                        diff         lwr        upr     p adj\nDerecha-Centro    -1.2410478 -1.63127340 -0.8508221 0.0000000\nIzquierda-Centro  -0.9471902 -1.33741581 -0.5569645 0.0000001\nIzquierda-Derecha  0.2938576 -0.09636805  0.6840832 0.1801856\n\n\nInterpretación: El intervalo de confianza que no incluye 0 indica diferencia significativa entre esos dos grupos.",
    "crumbs": [
      "V. Unidad 4: Análisis Bivariado",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Comparación de medias</span>"
    ]
  },
  {
    "objectID": "10-comparacion-medias.html#supuestos-de-las-pruebas-paramétricas",
    "href": "10-comparacion-medias.html#supuestos-de-las-pruebas-paramétricas",
    "title": "10  Comparación de medias",
    "section": "10.4 Supuestos de las pruebas paramétricas",
    "text": "10.4 Supuestos de las pruebas paramétricas\nLas pruebas t y ANOVA asumen:\n\nIndependencia: Las observaciones son independientes entre sí\nNormalidad: Los datos en cada grupo se distribuyen normalmente\nHomogeneidad de varianzas: Las varianzas de los grupos son similares\n\n\n\n\n\n\n\nTip¿Qué tan importantes son los supuestos?\n\n\n\nEn la práctica:\n\nIndependencia es el supuesto más importante. Si no se cumple, los resultados pueden ser muy sesgados.\nNormalidad es menos crítica con muestras grandes (n &gt; 30 por grupo) gracias al teorema del límite central.\nHomogeneidad puede relajarse usando versiones corregidas de las pruebas (como el ajuste de Welch en t.test).\n\n\n\n\n10.4.0.1 Alternativas no paramétricas\nCuando los supuestos no se cumplen, especialmente con muestras pequeñas, usamos pruebas no paramétricas:\n\n\n\nPrueba paramétrica\nAlternativa no paramétrica\n\n\n\n\nt de una muestra\nWilcoxon signed-rank\n\n\nt de dos muestras independientes\nMann-Whitney U\n\n\nt pareada\nWilcoxon signed-rank pareada\n\n\nANOVA\nKruskal-Wallis\n\n\n\n\n# Ejemplo: Mann-Whitney U (alternativa a t de dos muestras)\nwilcox.test(ingresos_hombres, ingresos_mujeres)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  ingresos_hombres and ingresos_mujeres\nW = 11687, p-value = 0.5612\nalternative hypothesis: true location shift is not equal to 0\n\n# Ejemplo: Kruskal-Wallis (alternativa a ANOVA)\nkruskal.test(satisfaccion ~ orientacion, data = datos_anova)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  satisfaccion by orientacion\nKruskal-Wallis chi-squared = 51.231, df = 2, p-value = 7.506e-12",
    "crumbs": [
      "V. Unidad 4: Análisis Bivariado",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Comparación de medias</span>"
    ]
  },
  {
    "objectID": "10-comparacion-medias.html#qué-prueba-usar",
    "href": "10-comparacion-medias.html#qué-prueba-usar",
    "title": "10  Comparación de medias",
    "section": "10.5 ¿Qué prueba usar?",
    "text": "10.5 ¿Qué prueba usar?\n\n\n\nSituación\nPrueba recomendada\n\n\n\n\nComparar una media con un valor teórico\nt de una muestra\n\n\nComparar medias de 2 grupos independientes\nt de dos muestras\n\n\nComparar medias antes/después (mismos sujetos)\nt pareada\n\n\nComparar medias de 3+ grupos\nANOVA",
    "crumbs": [
      "V. Unidad 4: Análisis Bivariado",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Comparación de medias</span>"
    ]
  },
  {
    "objectID": "10-comparacion-medias.html#resumen",
    "href": "10-comparacion-medias.html#resumen",
    "title": "10  Comparación de medias",
    "section": "Resumen",
    "text": "Resumen\nConceptos clave:\n\nPrueba t: Compara medias entre grupos\nMuestras independientes vs pareadas: Requieren diferentes pruebas\nANOVA: Compara más de dos grupos simultáneamente\nSupuestos: Normalidad, homogeneidad, independencia\nAlternativas no paramétricas: Para cuando no se cumplen supuestos",
    "crumbs": [
      "V. Unidad 4: Análisis Bivariado",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Comparación de medias</span>"
    ]
  },
  {
    "objectID": "10-comparacion-medias.html#lecturas-recomendadas",
    "href": "10-comparacion-medias.html#lecturas-recomendadas",
    "title": "10  Comparación de medias",
    "section": "Lecturas recomendadas",
    "text": "Lecturas recomendadas\nFundamentos de comparación de grupos:\nAgresti, A., & Finlay, B. (2009). Statistical Methods for the Social Sciences (4th ed.). Pearson.\n→ Capítulo 7 cubre pruebas t y comparación de medias entre dos grupos con claridad y ejemplos aplicados.\nInferencia causal mediante comparación de grupos:\nLlaudet, E., & Imai, K. (2022). Data Analysis for Social Science: A Friendly and Practical Introduction. Princeton University Press.\n→ Capítulo 3 sobre causalidad conecta comparación de medias con diseños experimentales y cuasi-experimentales.\nANOVA y diseños más complejos:\nMaxwell, S. E., Delaney, H. D., & Kelley, K. (2018). Designing Experiments and Analyzing Data: A Model Comparison Perspective (3rd ed.). Routledge.\n→ Tratamiento comprehensivo de ANOVA y diseños factoriales para investigadores avanzados.",
    "crumbs": [
      "V. Unidad 4: Análisis Bivariado",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Comparación de medias</span>"
    ]
  },
  {
    "objectID": "10-comparacion-medias.html#ejercicios",
    "href": "10-comparacion-medias.html#ejercicios",
    "title": "10  Comparación de medias",
    "section": "Ejercicios",
    "text": "Ejercicios\nLos ejercicios para este capítulo se encuentran en el Anexo de Ejercicios.",
    "crumbs": [
      "V. Unidad 4: Análisis Bivariado",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Comparación de medias</span>"
    ]
  },
  {
    "objectID": "11-regresion-bivariada.html",
    "href": "11-regresion-bivariada.html",
    "title": "11  Regresión bivariada",
    "section": "",
    "text": "Objetivos del capítulo\nAl finalizar este capítulo, serás capaz de:",
    "crumbs": [
      "V. Unidad 4: Análisis Bivariado",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regresión bivariada</span>"
    ]
  },
  {
    "objectID": "11-regresion-bivariada.html#objetivos-del-capítulo",
    "href": "11-regresion-bivariada.html#objetivos-del-capítulo",
    "title": "11  Regresión bivariada",
    "section": "",
    "text": "Calcular e interpretar coeficientes de correlación\nComprender la diferencia entre correlación y causalidad\nEstimar modelos de regresión lineal simple usando mínimos cuadrados ordinarios\nInterpretar coeficientes de regresión e intercepto\nEvaluar la bondad de ajuste usando \\(R^2\\)\nRealizar pruebas de hipótesis sobre coeficientes de regresión",
    "crumbs": [
      "V. Unidad 4: Análisis Bivariado",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regresión bivariada</span>"
    ]
  },
  {
    "objectID": "11-regresion-bivariada.html#correlación-y-regresión",
    "href": "11-regresion-bivariada.html#correlación-y-regresión",
    "title": "11  Regresión bivariada",
    "section": "11.1 Correlación y regresión",
    "text": "11.1 Correlación y regresión\nLa correlación mide la fuerza y dirección de la relación lineal entre dos variables.\nCoeficiente de correlación de Pearson: \\[r = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum (x_i - \\bar{x})^2} \\sqrt{\\sum (y_i - \\bar{y})^2}}\\]\n\n\\(-1 \\leq r \\leq 1\\)\n\\(r = 1\\): Correlación positiva perfecta\n\\(r = 0\\): Sin correlación lineal\n\\(r = -1\\): Correlación negativa perfecta\n\nPara ilustrar el uso de la correlación, consideremos la relación entre desarrollo económico y democracia, un tema clásico en ciencia política. Analizamos datos de PIB per cápita y nivel de democracia en una muestra de países:\n\n# Datos simulados: PIB per cápita y nivel de democracia\nset.seed(2024)\nn &lt;- 50\npib &lt;- rnorm(n, mean = 15000, sd = 8000)\ndemocracia &lt;- 3 + 0.0003 * pib + rnorm(n, mean = 0, sd = 1.5)\n\n# Correlación de Pearson\ncor_pearson &lt;- cor(pib, democracia)\ncat(\"Correlación de Pearson:\", round(cor_pearson, 3), \"\\n\")\n\nCorrelación de Pearson: 0.865 \n\n# Test de significancia\ncor.test(pib, democracia)\n\n\n    Pearson's product-moment correlation\n\ndata:  pib and democracia\nt = 11.931, df = 48, p-value = 5.76e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.7723183 0.9213409\nsample estimates:\n      cor \n0.8647649 \n\n\nEs fundamental recordar que una correlación fuerte NO implica que una variable cause la otra. Pueden existir variables confusoras, causalidad inversa, o relaciones espurias.1\n1 Correlación no implica causalidad. Por ejemplo, ventas de helado y ahogamientos correlacionan, pero ambas son causadas por una tercera variable (temperatura). Establecer causalidad requiere teoría, diseños apropiados y control de confusores.\n11.1.0.1 El modelo de regresión\nLa regresión lineal modela la relación entre una variable dependiente \\(Y\\) y una variable independiente \\(X\\):\n\\[Y_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i\\]\ndonde: - \\(\\beta_0\\) = intercepto (valor de \\(Y\\) cuando \\(X = 0\\)) - \\(\\beta_1\\) = pendiente (cambio en \\(Y\\) por unidad de cambio en \\(X\\)) - \\(\\epsilon_i\\) = error (variación no explicada por el modelo)\n\n\n11.1.0.2 Mínimos cuadrados ordinarios\nEl método de mínimos cuadrados ordinarios (OLS, Ordinary Least Squares) estima \\(\\beta_0\\) y \\(\\beta_1\\) minimizando la suma de errores al cuadrado:\n\\[\\min_{\\beta_0, \\beta_1} \\sum_{i=1}^n (Y_i - \\hat{Y}_i)^2\\]\n\nFórmulas OLS:\n\\[\\hat{\\beta}_1 = \\frac{\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum (X_i - \\bar{X})^2} = r \\cdot \\frac{s_Y}{s_X}\\]\n\\[\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1 \\bar{X}\\]\n\nIlustremos la estimación OLS con un ejemplo de economía política: la relación entre gasto público y crecimiento económico.\n\n# Datos simulados: Gasto público y crecimiento económico\nset.seed(456)\ngasto_publico &lt;- runif(40, min = 15, max = 40)  # % del PIB\ncrecimiento &lt;- 5 - 0.15 * gasto_publico + rnorm(40, mean = 0, sd = 1.2)\n\n# Modelo de regresión lineal simple\nmodelo &lt;- lm(crecimiento ~ gasto_publico)\nsummary(modelo)\n\n\nCall:\nlm(formula = crecimiento ~ gasto_publico)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.60682 -0.55133 -0.02959  0.53668  2.21695 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    4.07893    0.69853   5.839 9.46e-07 ***\ngasto_publico -0.11667    0.02305  -5.061 1.10e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.063 on 38 degrees of freedom\nMultiple R-squared:  0.4027,    Adjusted R-squared:  0.3869 \nF-statistic: 25.62 on 1 and 38 DF,  p-value: 1.097e-05\n\n\n\n\n\n\n\nRegresión lineal: Gasto público y crecimiento",
    "crumbs": [
      "V. Unidad 4: Análisis Bivariado",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regresión bivariada</span>"
    ]
  },
  {
    "objectID": "11-regresion-bivariada.html#interpretación-y-ajuste",
    "href": "11-regresion-bivariada.html#interpretación-y-ajuste",
    "title": "11  Regresión bivariada",
    "section": "11.2 Interpretación y ajuste",
    "text": "11.2 Interpretación y ajuste\nIntercepto (\\(\\hat{\\beta}_0\\)): Valor predicho de \\(Y\\) cuando \\(X = 0\\)\nPendiente (\\(\\hat{\\beta}_1\\)): Cambio promedio en \\(Y\\) asociado con un incremento de una unidad en \\(X\\)\nEn el modelo anterior, si obtuviéramos \\(\\hat{\\beta}_1 = -0.15\\), interpretaríamos: “Por cada punto porcentual adicional de gasto público, el crecimiento económico disminuye en promedio 0.15 puntos porcentuales.”2\n2 El coeficiente indica asociación, no necesariamente causalidad. La unidad de medida importa: siempre especifica las unidades y evita lenguaje causal a menos que el diseño lo justifique.\n11.2.0.1 Bondad de ajuste\n\n\n11.2.0.2 R cuadrado (\\(R^2\\))\nEl coeficiente de determinación mide qué proporción de la variabilidad en \\(Y\\) es explicada por \\(X\\):\n\n\\[R^2 = 1 - \\frac{\\sum (Y_i - \\hat{Y}_i)^2}{\\sum (Y_i - \\bar{Y})^2}\\]\n\n\n\\(0 \\leq R^2 \\leq 1\\)\n\\(R^2 = 0\\): El modelo no explica nada\n\\(R^2 = 1\\): El modelo explica perfectamente\n\nPor ejemplo, si \\(R^2 = 0.42\\), interpretamos: “El 42% de la variabilidad en el crecimiento económico es explicada por el gasto público. El 58% restante se debe a otros factores.”\nEs crucial entender que un \\(R^2\\) alto NO implica relación causal. Puede haber variables omitidas importantes, relaciones espurias, o causalidad inversa.3\n3 Un modelo puede tener \\(R^2\\) alto y ser inválido para inferencia causal si omite confusores. En ciencias sociales, valores bajos de \\(R^2\\) (0.10-0.30) son frecuentes y no indican un modelo “malo”.",
    "crumbs": [
      "V. Unidad 4: Análisis Bivariado",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regresión bivariada</span>"
    ]
  },
  {
    "objectID": "11-regresion-bivariada.html#resumen",
    "href": "11-regresion-bivariada.html#resumen",
    "title": "11  Regresión bivariada",
    "section": "Resumen",
    "text": "Resumen\nConceptos clave:\n\nCorrelación: Mide fuerza y dirección de relación lineal (no implica causalidad)\nRegresión lineal: Modela \\(Y\\) como función lineal de \\(X\\)\nOLS: Método para estimar coeficientes minimizando errores al cuadrado\nInterpretación: \\(\\beta_0\\) = intercepto, \\(\\beta_1\\) = pendiente\n\\(R^2\\): Proporción de variabilidad explicada por el modelo\n\nFórmulas clave:\n\nCorrelación: \\(r = \\frac{\\text{Cov}(X,Y)}{s_X s_Y}\\)\nPendiente: \\(\\hat{\\beta}_1 = r \\cdot \\frac{s_Y}{s_X}\\)\nIntercepto: \\(\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1 \\bar{X}\\)\nBondad de ajuste: \\(R^2 = 1 - \\frac{\\text{SSR}}{\\text{SST}}\\)",
    "crumbs": [
      "V. Unidad 4: Análisis Bivariado",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regresión bivariada</span>"
    ]
  },
  {
    "objectID": "11-regresion-bivariada.html#lecturas-recomendadas",
    "href": "11-regresion-bivariada.html#lecturas-recomendadas",
    "title": "11  Regresión bivariada",
    "section": "Lecturas recomendadas",
    "text": "Lecturas recomendadas\nFundamentos de regresión lineal:\nAgresti, A., & Finlay, B. (2009). Statistical Methods for the Social Sciences (4th ed.). Pearson.\n→ Capítulo 9 ofrece introducción clara y accesible a regresión lineal y correlación con ejemplos de ciencias sociales.\nPredicción y modelos lineales:\nLlaudet, E., & Imai, K. (2022). Data Analysis for Social Science: A Friendly and Practical Introduction. Princeton University Press.\n→ Capítulo 4 sobre predicción conecta regresión con aplicaciones prácticas en análisis de datos sociales.\nTratamiento más técnico:\nWooldridge, J. M. (2020). Introductory Econometrics: A Modern Approach (7th ed.). Cengage Learning.\n→ Capítulos 2-3 cubren regresión simple con mayor rigor técnico y énfasis en interpretación causal.",
    "crumbs": [
      "V. Unidad 4: Análisis Bivariado",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regresión bivariada</span>"
    ]
  },
  {
    "objectID": "11-regresion-bivariada.html#ejercicios",
    "href": "11-regresion-bivariada.html#ejercicios",
    "title": "11  Regresión bivariada",
    "section": "Ejercicios",
    "text": "Ejercicios\nLos ejercicios para este capítulo se encuentran en el Anexo de Ejercicios.",
    "crumbs": [
      "V. Unidad 4: Análisis Bivariado",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Regresión bivariada</span>"
    ]
  },
  {
    "objectID": "anexo-ejercicios.html",
    "href": "anexo-ejercicios.html",
    "title": "(APPENDIX) Anexos",
    "section": "",
    "text": "Ejercicios\nEste anexo reúne todos los ejercicios del libro, organizados por capítulo. Cada sección corresponde a un capítulo y puede consultarse de forma independiente.",
    "crumbs": [
      "Anexos",
      "(APPENDIX) Anexos"
    ]
  },
  {
    "objectID": "anexo-ejercicios.html#ejercicios-cap1",
    "href": "anexo-ejercicios.html#ejercicios-cap1",
    "title": "(APPENDIX) Anexos",
    "section": "Capítulo 1: Introducción",
    "text": "Capítulo 1: Introducción\n1. Identificar elementos del método científico\nLee el resumen (abstract) de un artículo cuantitativo reciente en Latin American Politics and Society o Revista de Ciencia Política. Identifica:\n\nLa pregunta de investigación\n\nLa teoría o argumento central\n\nLas hipótesis principales\n\nEl tipo de datos usados\n\nLa técnica de análisis\n\n2. Evaluar mensurabilidad\nPara cada uno de los siguientes conceptos, discute: (a) ¿Es posible cuantificarlo? (b) ¿Qué se ganaría y qué se perdería al cuantificarlo?\n\nCalidad de la democracia\nPolarización afectiva\nIdentidad nacional\nLegitimidad institucional\nClientelismo político\n\n3. Teoría e hipótesis\nSelecciona un fenómeno político reciente en tu país (ej: baja en confianza institucional, cambio en participación electoral, polarización).\n\nFormula una pregunta de investigación específica sobre ese fenómeno\n\nPropón una teoría de rango medio que lo explique\n\nDeriva al menos dos hipótesis testeables de esa teoría\n\nEspecifica cómo medirías las variables de tus hipótesis\n\n4. Análisis crítico\nUn titular de prensa afirma: “Estudio demuestra que uso de redes sociales causa polarización política”.\n\n¿Qué tipo de evidencia se necesitaría para sostener causalmente esa afirmación?\n\n¿Qué explicaciones alternativas podrían dar cuenta de una correlación entre uso de redes y polarización?\n\n¿Qué diseño de investigación permitiría distinguir entre estas explicaciones?\n\n5. Reflexión metodológica\nPiensa en tu propio proyecto de tesis o tema de interés.\n\n¿Tu pregunta de investigación es más adecuada para métodos cuantitativos, cualitativos, o mixtos? ¿Por qué?\n\n¿Qué tipo de datos necesitarías?\n\n¿Qué limitaciones enfrentarías al cuantificar los conceptos centrales de tu investigación?",
    "crumbs": [
      "Anexos",
      "(APPENDIX) Anexos"
    ]
  },
  {
    "objectID": "anexo-ejercicios.html#ejercicios-cap2",
    "href": "anexo-ejercicios.html#ejercicios-cap2",
    "title": "(APPENDIX) Anexos",
    "section": "Capítulo 2: Diseño de investigación",
    "text": "Capítulo 2: Diseño de investigación\n1. Evaluar preguntas de investigación\nPara cada pregunta, identifica: (a) ¿Es específica? (b) ¿Es empíricamente respondible? (c) ¿Es descriptiva, relacional o causal? (d) ¿Cómo la mejorarías?\n\n“¿Por qué hay desigualdad?”\n“¿Los jóvenes participan menos en política?”\n“¿Debería Chile tener voto obligatorio?”\n“¿El voto obligatorio aumenta la participación electoral?”\n\n2. De teoría a hipótesis\nTeoría: Los sistemas presidenciales son más propensos a crisis democráticas que los parlamentarios porque generan competencia de suma cero entre ejecutivo y legislativo (Linz & Stepan, 1996).\n\nIdentifica el mecanismo causal propuesto\n\nDeriva dos hipótesis testeables\n\n¿Qué evidencia falsificaría cada hipótesis?\n\n3. Identificar amenazas a validez interna\nUn estudio encuentra que municipios que implementaron presupuesto participativo tienen menor corrupción. El estudio compara municipios con presupuesto participativo vs. sin él, controlando por población, PIB per cápita y nivel educativo.\n\n¿Qué confusores no observados podrían explicar la asociación?\n\n¿Podría haber causalidad inversa? ¿Cómo?\n\nPropón un diseño alternativo con mejor validez interna\n\n4. Evaluar validez externa\nUn experimento en Suecia muestra que recibir información sobre uso de impuestos aumenta disposición a pagar impuestos. Los investigadores quieren saber si el resultado aplica a América Latina.\n\n¿Qué diferencias contextuales podrían hacer que el efecto varíe?\n\n¿Cómo evaluarías si el resultado generaliza?\n\n¿Qué diseño permitiría estudiar variación contextual del efecto?\n\n5. Problema de investigación propio\nSelecciona un fenómeno político que te interese:\n\nFormula una pregunta causal específica\n\nPropón una teoría que la responda y deriva hipótesis\n\nDescribe un diseño observacional para testearla\n\nIdentifica las principales amenazas a validez interna\n\n¿Qué diseño cuasi-experimental podría mejorar la identificación causal?\n\n6. Análisis de artículo\nLee un artículo cuantitativo de una revista de ciencia política. Identifica:\n\nLa pregunta de investigación y su tipo\n\nEl diseño de investigación usado\n\nLa unidad de análisis\n\nDos fortalezas del diseño para validez interna\n\nDos limitaciones para validez externa\n\nUna estrategia alternativa que los autores podrían haber usado",
    "crumbs": [
      "Anexos",
      "(APPENDIX) Anexos"
    ]
  },
  {
    "objectID": "anexo-ejercicios.html#ejercicios-cap3",
    "href": "anexo-ejercicios.html#ejercicios-cap3",
    "title": "(APPENDIX) Anexos",
    "section": "Capítulo 3: Medición",
    "text": "Capítulo 3: Medición\n1. Conceptualización y operacionalización\nSelecciona un concepto abstracto (ej: “legitimidad política”, “clientelismo”, “movilización social”):\n\nPropón una definición conceptual clara\n\nIdentifica al menos tres indicadores empíricos\n\nPara cada indicador, especifica el procedimiento de medición\n\nEvalúa la validez de contenido de tu operacionalización\n\n2. Niveles de medición\nClasifica las siguientes variables según nivel de medición y justifica:\n\nRegión de residencia (Norte/Centro/Sur)\nSatisfacción con la democracia (escala 1-10)\nIngreso mensual en pesos\nReligión (Católica/Protestante/Sin religión/Otra)\nNivel educativo (Primaria/Secundaria/Universitaria)\nTemperatura de termómetro de sentimiento hacia partidos políticos (0-100)\n\n3. Evaluar validez\nUn investigador mide “capital social” preguntando: “¿Cuántas organizaciones sociales existen en su comuna?”\n\n¿Qué dimensión de capital social captura esta medida?\n\n¿Qué dimensiones omite?\n\nPropón indicadores adicionales para mejorar validez de contenido\n\n¿Cómo evaluarías la validez convergente de estas medidas?\n\n4. Construir un índice\nTienes datos de encuesta con estas preguntas sobre confianza institucional (escala 1-5):\n\n¿Cuánto confía en el Congreso?\n¿Cuánto confía en el Presidente?\n¿Cuánto confía en la Corte Suprema?\n¿Cuánto confía en la policía?\n\n\nConstruye un índice aditivo simple de “confianza institucional”\n\n¿Tiene sentido incluir los cuatro ítems en un solo índice? ¿Por qué?\n\n¿Cómo evaluarías la consistencia interna del índice?\n\n¿Qué ponderación alternativa podrías justificar teóricamente?\n\n5. Problemas de medición\nImagina que encuestas sobre actitudes hacia la inmigración en Santiago, Chile:\n\n¿Qué sesgo de deseabilidad social podrías esperar? ¿En qué dirección?\n\nPropón una estrategia para mitigar ese sesgo\n\nSi administras la encuesta por teléfono, ¿qué diferencias esperarías vs. encuesta autoaplicada por internet?\n\n¿Qué grupos podrían tener tasas más altas de no-respuesta? ¿Cómo afectaría tus estimaciones?\n\n6. Análisis crítico de índice existente\nRevisa la metodología de uno de estos índices (disponibles en línea):\n\nPolity IV (democracia)\nTransparency International CPI (corrupción percibida)\nV-Dem (variedades de democracia)\n\n\n¿Cómo conceptualiza el fenómeno?\n\n¿Qué indicadores usa?\n\n¿Cómo agrega los indicadores?\n\nIdentifica una fortaleza y una debilidad de la medición\n\n¿Para qué preguntas de investigación sería apropiado usar este índice? ¿Para cuáles no?",
    "crumbs": [
      "Anexos",
      "(APPENDIX) Anexos"
    ]
  },
  {
    "objectID": "anexo-ejercicios.html#ejercicios-cap4",
    "href": "anexo-ejercicios.html#ejercicios-cap4",
    "title": "(APPENDIX) Anexos",
    "section": "Capítulo 4: Trabajando con datos",
    "text": "Capítulo 4: Trabajando con datos\n1. Evaluación de calidad\nDescarga datos del CEP (https://www.cepchile.cl/opinion-publica/encuesta-cep/) o Latinobarómetro (https://www.latinobarometro.org/).\n\n¿Qué población representa la muestra?\n\n¿Cuál es el tamaño muestral y margen de error?\n\nIdentifica tres variables. Para cada una, evalúa: ¿Es válida para medir el concepto que pretende? ¿Qué problemas de medición podrían existir?\n\n¿Qué información sobre calidad de datos provee la documentación?\n\n2. Importar y explorar\nImporta un dataset de tu elección en R:\n\n# Tu código aquí\n\n\n¿Cuántos casos y variables tiene?\n\n¿Qué tipos de variables contiene (numéricas, categóricas)?\n\n¿Cuántos valores faltantes hay en cada variable?\n\nIdentifica y describe un valor atípico\n\n3. Limpieza de datos\nCon el dataset del ejercicio 2:\n\nSelecciona 5-10 variables relevantes para una pregunta de investigación que formules\n\nFiltra casos para incluir solo observaciones completas (sin valores faltantes en variables clave)\n\nCrea al menos dos variables nuevas mediante transformación o recodificación\n\nGenera un resumen estadístico de tus variables\n\n4. Datos faltantes\n\n# Crea un dataset con valores faltantes\nset.seed(123)\ndatos &lt;- data.frame(\n  id = 1:100,\n  edad = sample(18:80, 100, replace = TRUE),\n  ingreso = rnorm(100, 500000, 150000)\n)\n# Introduce valores faltantes no aleatorios:\n# Personas mayores de 60 tienen 50% probabilidad de no reportar ingreso\ndatos$ingreso[datos$edad &gt; 60 & runif(100) &lt; 0.5] &lt;- NA\n\n\n¿Cuántos valores faltantes hay en ingreso?\n\nCalcula ingreso promedio: (1) eliminando casos con valores faltantes, (2) solo entre quienes reportaron. ¿Difieren las estimaciones? ¿Por qué?\n\n¿Qué tipo de datos faltantes son estos (MCAR, MAR, MNAR)?\n\n¿Cómo afecta esto las inferencias sobre ingreso promedio en la población?\n\n5. Combinar datasets\nTienes dos datasets:\n\n# Resultados electorales por comuna\nresultados &lt;- data.frame(\n  comuna_id = 1:5,\n  comuna = c(\"Santiago\", \"Valparaíso\", \"Concepción\", \"La Serena\", \"Temuco\"),\n  votos_derecha = c(45, 38, 42, 50, 35),\n  votos_izquierda = c(40, 48, 43, 35, 50)\n)\n\n# Características socioeconómicas\nsocioeconomico &lt;- data.frame(\n  comuna_id = c(1, 2, 3, 6),\n  ingreso_promedio = c(800000, 650000, 700000, 600000),\n  desigualdad_gini = c(0.48, 0.45, 0.47, 0.50)\n)\n\n\nCombina los datasets manteniendo todas las comunas de resultados\n\n¿Qué problema de datos observas después de combinar?\n\n¿Cómo manejarías ese problema para análisis posterior?\n\n6. Proyecto propio\nIdentifica un dataset relevante para tu tesis o interés de investigación:\n\nDescríbelo: fuente, estructura (corte transversal/panel/etc), unidad de análisis, N\n\nImporta a R y documenta el proceso\n\nRealiza una limpieza básica: seleccionar variables relevantes, verificar valores faltantes y outliers, crear variables derivadas si es necesario\n\nGenera un reporte en R Markdown que documente: tu pregunta de investigación, descripción de los datos, proceso de limpieza, y estadísticas descriptivas básicas\n\nExporta la versión limpia de los datos",
    "crumbs": [
      "Anexos",
      "(APPENDIX) Anexos"
    ]
  },
  {
    "objectID": "anexo-ejercicios.html#ejercicios-cap5",
    "href": "anexo-ejercicios.html#ejercicios-cap5",
    "title": "(APPENDIX) Anexos",
    "section": "Capítulo 5: Estadística descriptiva",
    "text": "Capítulo 5: Estadística descriptiva\n1. Cálculo manual\nCon estos datos de participación electoral en 10 comunas: 45, 52, 48, 51, 39, 55, 47, 50, 44, 49\n\nCalcula media, mediana y moda manualmente\n\nCalcula rango, varianza y desviación estándar manualmente\n\n¿La distribución es simétrica o asimétrica? ¿Cómo lo sabes?\n\nVerifica tus cálculos en R\n\n2. Análisis exploratorio con datos reales\nDescarga datos de CEP o CASEN. Selecciona una variable continua de interés:\n\n# Tu código aquí\n\n\nCalcula media, mediana, desviación estándar e IQR\n\nCrea un histograma y un boxplot\n\nIdentifica outliers (si los hay) usando el método IQR\n\n¿La distribución es simétrica o asimétrica? Calcula el coeficiente de asimetría\n\nEscribe un párrafo interpretando los resultados\n\n3. Comparación de grupos\nCon el dataset comunas del capítulo:\n\n# Datos disponibles\ncomunas\n\n\nCompara participación electoral entre comunas con alta vs. baja educación superior (define umbral apropiado)\n\nCalcula media, mediana y desviación estándar para cada grupo\n\nCrea boxplots comparando ambos grupos\n\n¿Qué grupo tiene mayor variabilidad? ¿Por qué?\n\n4. Relaciones bivariadas\n\n# Usa datos de comunas\n\n\nCalcula la correlación entre participación y pobreza\n\nCalcula la correlación entre participación y educación superior\n\nCrea scatterplots para ambas relaciones\n\nInterpreta: ¿Las correlaciones son consistentes con tus expectativas teóricas? ¿Por qué?\n\n5. Detectar problemas de datos\n\n# Dataset con problemas\nset.seed(999)\nproblemas &lt;- data.frame(\n  id = 1:100,\n  edad = c(sample(18:80, 95, replace = TRUE), 150, 12, -5, 200, NA),\n  ingreso = c(rnorm(95, 500000, 150000), 50000000, NA, NA, -100000, 0)\n)\n\n\nIdentifica valores imposibles o improbables en cada variable\n\nIdentifica valores faltantes\n\nCalcula media y mediana de ingreso con y sin outliers. ¿Cómo afecta la media?\n\nPropón una estrategia para limpiar estos datos justificando cada decisión\n\n6. Estadística descriptiva comprehensiva\nElige un dataset de tu proyecto de tesis o interés:\n\nIdentifica 3-5 variables clave\n\nPara cada variable, genera:\n\nTabla de estadísticos descriptivos\nGráfico apropiado (histograma, boxplot, o barras según tipo)\nInterpretación de 2-3 oraciones\n\nCalcula correlaciones entre variables numéricas\n\nEscribe un reporte de una página resumiendo patrones principales en tus datos\n\nIdentifica al menos un hallazgo inesperado que requiera investigación adicional",
    "crumbs": [
      "Anexos",
      "(APPENDIX) Anexos"
    ]
  },
  {
    "objectID": "anexo-ejercicios.html#ejercicios-cap6",
    "href": "anexo-ejercicios.html#ejercicios-cap6",
    "title": "(APPENDIX) Anexos",
    "section": "Capítulo 6: Visualización de datos",
    "text": "Capítulo 6: Visualización de datos\n1. Replicar y mejorar\nEste gráfico problemático:\n\nggplot(comunas, aes(x = region, y = cambio_izquierda)) +\n  geom_bar(stat = \"identity\", fill = rainbow(4)) +\n  labs(title = \"CAMBIO!!!\")\n\n\nIdentifica al menos 4 problemas\n\nCrea una versión mejorada aplicando principios del capítulo\n\nJustifica cada decisión de diseño\n\n2. Exploración visual de datos propios\nCon un dataset de tu proyecto:\n\nCrea histograma/densidad de variable continua clave\n\nCrea boxplot comparando grupos relevantes\n\nCrea scatter plot de dos variables con línea de tendencia\n\nCombina los tres gráficos en una figura con patchwork\n\nExporta en formato apropiado (300 dpi PNG)\n\n3. Series temporales\nDescarga datos de aprobación presidencial real (ej: CEP, Cadem).\n\nCrea gráfico de línea con aprobación y desaprobación\n\nAgrega anotaciones para eventos importantes (ej: estallido social, pandemia)\n\nUsa facetas para comparar períodos presidenciales\n\n4. Visualización multivariada\n\n# Usa datos de comunas\n\n\nCrea scatter plot con tres variables (x, y, color o tamaño)\n\nAgrega facetas por una cuarta variable categórica\n\nPersonaliza completamente (tema, colores, etiquetas)\n\nEscribe interpretación de 100 palabras de patrones observados\n\n5. Del mal al buen gráfico\nBusca un gráfico problemático en medios (Twitter, periódicos, reportes).\n\nCaptura/descarga el gráfico original\n\nLista todos los problemas que identificas\n\nSi tienes acceso a los datos, recréalo correctamente en ggplot2\n\nSi no, crea un gráfico similar con datos simulados que demuestre la mejora\n\nEscribe explicación de 150 palabras sobre qué cambió y por qué\n\n6. Proyecto de visualización completo\nCrea un “dashboard” de una página con 4-6 gráficos que cuenten una historia sobre tu tema de tesis:\n\nDiseña layout con patchwork\n\nIncluye diferentes tipos de gráficos (univariados, bivariados, temporal si aplica)\n\nUsa un tema coherente en todos los gráficos\n\nAgrega título general y caption con fuente\n\nExporta en alta resolución\n\nPresenta a colegas y solicita feedback sobre claridad",
    "crumbs": [
      "Anexos",
      "(APPENDIX) Anexos"
    ]
  },
  {
    "objectID": "anexo-ejercicios.html#ejercicios-cap7",
    "href": "anexo-ejercicios.html#ejercicios-cap7",
    "title": "(APPENDIX) Anexos",
    "section": "Capítulo 7: Introducción a probabilidad",
    "text": "Capítulo 7: Introducción a probabilidad\nConceptuales:\n\nExplica con tus propias palabras por qué es imposible que la probabilidad de un evento sea negativa o mayor que 1.\n¿Cuál es la diferencia entre \\(P(A|B)\\) y \\(P(B|A)\\)? Proporciona un ejemplo de ciencias políticas donde estas dos probabilidades sean distintas.\nUn investigador afirma: “La probabilidad de que Chile tenga una nueva Constitución en 2026 es 0.40”. ¿Qué interpretación de probabilidad está usando: frecuentista o bayesiana? Justifica.\nExplica por qué la distribución Normal es tan importante en estadística, incluso cuando muchas variables en ciencias sociales no son normales.\n\nAplicados:\n\nEn una encuesta, 45% declara intención de votar. Si encuestamos 800 personas:\n\n¿Cuál es la probabilidad de que exactamente 360 declaren intención de votar?\n¿Cuál es la probabilidad de que entre 340 y 380 lo hagan?\n¿Cuál sería el número esperado y la desviación estándar?\n\nHistóricamente, ocurren en promedio 2.8 huelgas por mes en un sector industrial. Asumiendo distribución Poisson:\n\n¿Probabilidad de 0 huelgas este mes?\n¿Probabilidad de más de 4 huelgas?\n¿Cuál es la varianza del número de huelgas?\n\nSimulación del TLC: Replica la simulación del Teorema del Límite Central usando una distribución poblacional diferente (por ejemplo, uniforme o exponencial). Compara la convergencia a la Normal para \\(n = 5, 30, 100\\).\nEl índice de democracia V-Dem para países latinoamericanos tiene media 0.52 y SD 0.18. Si tomamos muestras aleatorias de 40 países con reemplazo:\n\n¿Cuál es la distribución esperada de \\(\\bar{X}\\)?\n¿Probabilidad de que \\(\\bar{X} &gt; 0.55\\)?\n¿Probabilidad de que \\(\\bar{X}\\) esté entre 0.50 y 0.54?",
    "crumbs": [
      "Anexos",
      "(APPENDIX) Anexos"
    ]
  },
  {
    "objectID": "anexo-ejercicios.html#ejercicios-cap8",
    "href": "anexo-ejercicios.html#ejercicios-cap8",
    "title": "(APPENDIX) Anexos",
    "section": "Capítulo 8: Inferencia estadística",
    "text": "Capítulo 8: Inferencia estadística\nConceptuales:\n\nExplica la diferencia entre error estándar y desviación estándar. ¿Por qué el error estándar disminuye con \\(n\\) pero la desviación estándar no?\nUn estudiante afirma: “Calculé un IC 95% de [45%, 51%] para la intención de voto. Esto significa que hay 95% de probabilidad de que el verdadero porcentaje esté en ese rango.” ¿Es correcta esta interpretación? Corrige si es necesario.\n¿Por qué un IC 99% es más ancho que un IC 95% para los mismos datos? ¿Cuál es el trade-off?\nSi duplicas el tamaño de tu muestra, ¿en cuánto se reduce el error estándar?\n\nAplicados:\n\nUna encuesta con \\(n=800\\) encuentra que 55% apoya una reforma constitucional.\n\nCalcula el error estándar de \\(\\hat{p}\\)\nConstruye un IC 95% para la proporción poblacional\n¿Es razonable concluir que la mayoría de la población apoya la reforma?\n\nEl ingreso promedio en una muestra de \\(n=150\\) hogares es \\(\\bar{x} = 680\\) mil pesos, con \\(s = 210\\) mil.\n\nCalcula el error estándar de \\(\\bar{x}\\)\nConstruye un IC 95% para el ingreso promedio poblacional\nConstruye un IC 99% y compara el ancho\n\nPlanificación de encuesta: Quieres estimar el porcentaje de estudiantes que aprueban un curso con margen de error de ±5% (IC 95%). ¿Cuántos estudiantes debes encuestar?\nSimulación: Replica la simulación de 100 ICs del capítulo, pero usando un IC 90% en lugar de 95%. ¿Aproximadamente cuántos intervalos esperarías que NO contengan \\(\\mu\\)? Verifica con código.\nUna encuestadora reporta: “Candidato A: 48% ± 3%”.\n\nInterpreta este resultado en términos de IC\n¿Aproximadamente cuál fue el tamaño muestral?\n¿Podemos concluir que el candidato perdería (&lt; 50%)?",
    "crumbs": [
      "Anexos",
      "(APPENDIX) Anexos"
    ]
  },
  {
    "objectID": "anexo-ejercicios.html#ejercicios-cap9",
    "href": "anexo-ejercicios.html#ejercicios-cap9",
    "title": "(APPENDIX) Anexos",
    "section": "Capítulo 9: Pruebas de hipótesis",
    "text": "Capítulo 9: Pruebas de hipótesis\n\nExplica la diferencia entre “no rechazar \\(H_0\\)” y “aceptar \\(H_0\\)”.\nUn investigador reporta: “El valor p fue 0.08, por lo tanto no hay efecto.” ¿Qué está mal?\n¿Qué es más grave: Error Tipo I o Error Tipo II? Discute según el contexto.",
    "crumbs": [
      "Anexos",
      "(APPENDIX) Anexos"
    ]
  },
  {
    "objectID": "anexo-ejercicios.html#ejercicios-cap10",
    "href": "anexo-ejercicios.html#ejercicios-cap10",
    "title": "(APPENDIX) Anexos",
    "section": "Capítulo 10: Comparación de medias",
    "text": "Capítulo 10: Comparación de medias\n\nCompara los ingresos promedio entre dos regiones de Chile usando una prueba t.\nRealiza un ANOVA para comparar niveles de participación electoral entre 4 países latinoamericanos.\nVerifica los supuestos de normalidad y homogeneidad de varianzas para tus datos.",
    "crumbs": [
      "Anexos",
      "(APPENDIX) Anexos"
    ]
  },
  {
    "objectID": "anexo-ejercicios.html#ejercicios-cap11",
    "href": "anexo-ejercicios.html#ejercicios-cap11",
    "title": "(APPENDIX) Anexos",
    "section": "Capítulo 11: Regresión bivariada",
    "text": "Capítulo 11: Regresión bivariada\n\nCalcula la correlación entre años de educación e ingreso. Interpreta el resultado.\nEstima un modelo de regresión para predecir participación electoral a partir de nivel educacional promedio por comuna.\nInterpreta los coeficientes y el \\(R^2\\) del modelo estimado en el ejercicio 2.\nDiscute por qué una correlación alta entre helado y ahogamientos NO implica causalidad.",
    "crumbs": [
      "Anexos",
      "(APPENDIX) Anexos"
    ]
  }
]