[["index.html", "Métodos Cuantitativos para Ciencias Políticas y Sociales Prefacio ¿Por qué este libro? Organización del libro Software y convenciones Agradecimientos", " Métodos Cuantitativos para Ciencias Políticas y Sociales Fabián Belmar 2025-11-17 Prefacio VERSIÓN BETA: Este manual se encuentra en desarrollo activo. Algunos capítulos están pendientes de completar y el contenido puede modificarse durante el semestre 2025. Agradecemos reportar errores o sugerencias. Este libro fue desarrollado como material del curso Métodos Cuantitativos Introductorios para estudiantes de Ciencia Política de la Universidad Diego Portales, 2025. También puede servir como referencia para cursos más avanzados. ¿Por qué este libro? La mayoría de manuales de métodos cuantitativos están escritos pensando en contextos anglosajones. Este libro integra ejemplos de la realidad política y social latinoamericana, utilizando datos de Chile y la región. A diferencia de textos que enfatizan la mecánica estadística, aquí privilegiamos la lógica de la investigación: cómo formular preguntas, operacionalizar conceptos, diseñar estrategias empíricas y evaluar evidencia. Las técnicas estadísticas son herramientas al servicio de responder preguntas sustantivas sobre el mundo social. Organización del libro El libro tiene tres niveles: Prerequisitos (Caps 1-2): Repaso del curso “Introducción a Métodos” que cubre método científico y diseño de investigación. Contenido MCI (Caps 3-11): Sigue el programa oficial del curso con cinco unidades: Generalidades (medición y datos), Fundamentos Descriptivos (clasificación de datos, tablas y gráficos), Estadística Descriptiva (medidas de tendencia central y dispersión), Inferencia Estadística (probabilidad, muestreo, pruebas de hipótesis), y Análisis Bivariado (comparación de medias, correlación, regresión simple). Contenido Avanzado (Caps 12-14): Regresión múltiple, diagnóstico OLS y modelos lineales generalizados para cursos posteriores. Software y convenciones Todo el análisis se realiza con R, lenguaje de código abierto estándar en ciencias sociales cuantitativas. Los códigos aparecen en fuente monoespaciada con su output, los conceptos clave en negritas, y las referencias en formato APA. Agradecimientos Este proyecto es resultado de años de docencia en metodología cuantitativa. Agradezco a estudiantes que con sus preguntas obligaron a clarificar argumentos, y a colegas cuyas conversaciones enriquecieron este material. "],["introduccion.html", "Capítulo 1 Introducción: El método científico en ciencias sociales 1.1 Objetivos del capítulo 1.2 ¿Qué es el método científico? 1.3 Ciencia social y cuantificación 1.4 El papel de la teoría 1.5 Lógica de la investigación cuantitativa 1.6 Fortalezas y limitaciones del enfoque cuantitativo 1.7 Resumen del capítulo 1.8 Lecturas recomendadas 1.9 Ejercicios", " Capítulo 1 Introducción: El método científico en ciencias sociales 1.1 Objetivos del capítulo Al finalizar este capítulo, serás capaz de: Distinguir conocimiento científico de otras formas de conocimiento sobre la realidad social Identificar los elementos del método científico aplicado a fenómenos políticos Comprender la relación entre teoría y análisis empírico en ciencias sociales Reconocer fortalezas y límites del enfoque cuantitativo para estudiar política 1.2 ¿Qué es el método científico? El método científico es un procedimiento sistemático para producir conocimiento confiable sobre el mundo. No es exclusivo de las ciencias naturales. Las ciencias sociales —incluida la ciencia política— lo emplean para generar afirmaciones empíricas verificables sobre fenómenos sociales. Tres características distinguen el conocimiento científico de otras formas de conocer: 1. Sistematicidad: Sigue procedimientos explícitos y replicables. Otro investigador, con los mismos datos y métodos, debería llegar a conclusiones similares. 2. Falsabilidad: Las afirmaciones científicas pueden ser, en principio, refutadas por evidencia empírica (Popper 1959). Una proposición que no puede ser contrastada con datos no es científica.1 3. Acumulación: El conocimiento científico es acumulativo. Se construye sobre investigación previa, refinando teorías y mejorando mediciones (Kuhn 1962). Esto no implica que el conocimiento científico sea “objetivo” en sentido ingenuo. Toda investigación parte de supuestos teóricos y decisiones metodológicas que reflejan posiciones epistemológicas. Pero estas decisiones deben ser transparentes y sometidas a escrutinio. King, Keohane, and Verba (1994) argumentan que la lógica de inferencia en ciencias sociales es fundamentalmente la misma que en ciencias naturales: observar el mundo y extraer conclusiones válidas sobre patrones que trascienden las observaciones particulares. Sin embargo, las ciencias sociales enfrentan desafíos específicos como la reflexividad2 (los sujetos modifican su comportamiento al conocer teorías sobre ellos (Giddens 1984)), la complejidad causal (fenómenos con múltiples causas interdependientes), la imposibilidad de experimentación (frecuentemente no podemos manipular variables por razones éticas o prácticas), y la dependencia del contexto (las regularidades sociales son históricamente contingentes (Abbott 2001)). Estos desafíos no invalidan la empresa científica en ciencias sociales, pero exigen rigurosidad metodológica y conciencia de los límites de nuestras inferencias. 1.3 Ciencia social y cuantificación La cuantificación —convertir conceptos en números— es una estrategia metodológica, no un fin en sí mismo. Su utilidad depende del tipo de pregunta que formulamos. Lazarsfeld and Rosenberg (1955) identificó que cuantificar permite: Precisión: Especificar exactamente qué grado de una propiedad exhibe un caso. Comparabilidad: Evaluar sistemáticamente similitudes y diferencias entre casos. Agregación: Resumir patrones en poblaciones grandes. Testeo de relaciones: Evaluar si dos variables covarían de manera consistente con una hipótesis teórica. Sin embargo, no todo fenómeno político es susceptible de cuantificación útil. Algunos objetos de estudio —como significados culturales profundos, procesos deliberativos, o lógicas institucionales— pueden empobrecerse al ser reducidos a números. La decisión de cuantificar debe responder a la pregunta de investigación, no a preferencias metodológicas preconcebidas. Como afirma Abbott (1988), “los métodos son herramientas, no paradigmas”. El investigador competente domina múltiples herramientas y selecciona la apropiada para cada problema. En ciencia política, cuantificamos actitudes y opiniones (preferencias electorales, apoyo a políticas, confianza institucional), comportamiento (participación electoral, protesta, corrupción declarada), atributos institucionales (sistemas electorales, grado de federalismo, independencia judicial), y resultados agregados (nivel de democracia, desigualdad de ingresos, gasto público). Cada medición implica decisiones conceptuales. Por ejemplo, ¿cómo medimos “democracia”? Munck (2009) muestran que distintos índices (Polity, Freedom House, V-Dem) operacionalizan el concepto de forma diferente, produciendo clasificaciones divergentes de los mismos países.3 Esta tensión entre concepto y medición es constitutiva de la investigación cuantitativa. No hay medición perfecta, solo mediciones más o menos adecuadas a nuestro propósito teórico. 1.4 El papel de la teoría Un error común en estudiantes principiantes es creer que la investigación cuantitativa consiste en “dejar que los datos hablen”. Los datos nunca hablan solos. Requieren un marco teórico que los haga inteligibles. La teoría cumple tres funciones en investigación cuantitativa: 1. Orienta la observación: Indica qué aspectos de la realidad son relevantes para nuestra pregunta. Sin teoría, todo es igualmente importante (y nada lo es). 2. Genera hipótesis: Especifica relaciones esperadas entre variables. Una hipótesis es una conjetura derivada de la teoría sobre qué patrón observaremos en los datos. 3. Interpreta hallazgos: Permite dotar de sentido a los patrones estadísticos. Una correlación es solo eso —covariación— hasta que la teoría la conecta con un mecanismo causal. King, Keohane, and Verba (1994) insisten en que “diseñar investigación social es diseñar un test de teoría”. No existe investigación “ateórica”. Incluso el análisis exploratorio más inductivo parte de intuiciones teóricas sobre qué buscar. Las teorías varían en su nivel de abstracción: gran teoría (marcos conceptuales amplios como marxismo o funcionalismo estructural), teorías de rango medio que explican clases específicas de fenómenos sin pretensión de aplicabilidad universal (Merton 1949) (ej: teoría de la modernización para democratización), y modelos formales que representan matemáticamente mecanismos causales específicos (ej: modelos de teoría de juegos sobre negociación legislativa). En investigación cuantitativa en ciencias políticas predominan teorías de rango medio: suficientemente específicas para generar hipótesis testeables, pero suficientemente generales para trascender casos únicos. El objetivo último de la investigación cuantitativa explicativa es establecer relaciones causales: identificar si cambios en X producen cambios en Y. No basta mostrar que X e Y covarían; necesitamos argumentar que X causa Y. Mahoney and Goertz (2006) distinguen dos tradiciones: el enfoque neopositivista4 (dominante en economía y partes de la ciencia política) que privilegia identificación de efectos causales promedio mediante diseños experimentales o cuasi-experimentales preguntando “¿cuál es el efecto causal de X sobre Y?”, y el enfoque interpretativo-mecanísmico que privilegia comprensión de mecanismos causales —los procesos mediante los cuales X produce Y— preguntando “¿cómo X causa Y?”. Ambos enfoques son legítimos pero implican estrategias metodológicas distintas. Este libro enfatiza el primero, aunque reconocemos la importancia de teorizar mecanismos. 1.5 Lógica de la investigación cuantitativa La investigación cuantitativa sigue una secuencia lógica (aunque no siempre cronológica). Todo comienza con una pregunta de investigación específica, empíricamente respondible y relevante (por ejemplo: “¿En qué medida la desigualdad de ingresos explica la intensidad de protestas en comunas chilenas durante octubre-diciembre 2019?”). Luego hacemos una revisión de literatura que identifica teorías existentes, hallazgos previos, debates no resueltos y limitaciones de investigación previa, posicionando nuestra contribución en una conversación académica en curso. Con base en literatura, desarrollamos teoría e hipótesis5 —afirmaciones sobre relaciones entre variables que esperamos observar si la teoría es correcta (ej: si la desigualdad económica genera frustración relativa que reduce legitimidad (Gurr 1970), entonces a mayor desigualdad en una comuna, mayor tasa de participación en protestas). El diseño de investigación y medición especifica cómo testearemos las hipótesis: qué casos observaremos (muestra/población), cómo mediremos nuestras variables (operacionalización), y qué técnica analítica usaremos (estadística descriptiva, regresión, etc.). Estas decisiones tienen consecuencias: un mismo concepto puede medirse de múltiples formas, y cada medición captura aspectos distintos. La recolección de datos obtiene la información (encuestas propias, datos administrativos, fuentes secundarias); la calidad del dato es crítica porque análisis sofisticado de datos malos produce conclusiones incorrectas con alta precisión. El análisis aplica técnicas estadísticas para evaluar hipótesis, resumiendo información en datos para detectar patrones sistemáticos. La interpretación evalúa qué implican los resultados para nuestra teoría: resultados consistentes fortalecen confianza (sin probarla definitivamente), resultados inconsistentes debilitan la teoría (sin refutarla definitivamente), resultados ambiguos pueden deberse a problemas de datos, medición o especificación del modelo. La investigación científica nunca “prueba” teorías; solo puede refutarlas o fallar en refutarlas. Las teorías sobreviven hasta que evidencia acumulada las hace insostenibles. Finalmente, la comunicación presenta los hallazgos de forma que otros puedan evaluarlos y replicarlos. 1.6 Fortalezas y limitaciones del enfoque cuantitativo El enfoque cuantitativo tiene fortalezas importantes: permite generalización (inferir de 1,500 encuestados a 15 millones de votantes si muestreamos correctamente), precisión (no solo “X y Y se relacionan”, sino “un aumento de una desviación estándar en X se asocia con un incremento de 0.23 desviaciones estándar en Y”), testeo sistemático (evaluar si un patrón podría deberse al azar o refleja una relación real), comparabilidad (estandarización de mediciones permite comparaciones rigurosas entre casos, países o períodos), y transparencia (procedimientos explícitos y replicables que otros pueden verificar o cuestionar). También tiene limitaciones: reducción de complejidad (cuantificar exige simplificar; aspectos importantes pueden perderse al convertir fenómenos complejos en números), correlación no es causalidad6 (observar que X e Y covarían no implica que X cause Y; puede haber causalidad inversa, variables confusoras, o mera coincidencia), dependencia de supuestos (las técnicas estadísticas asumen propiedades de los datos; violar estos supuestos compromete las inferencias), decontextualización (al agregar muchos casos podemos perder especificidades contextuales teóricamente importantes (Ragin 1987)), y “dictadura de las variables disponibles” (la investigación puede ser determinada por qué datos existen, no por qué preguntas son importantes). Estas limitaciones no invalidan el enfoque cuantitativo, pero exigen humildad interpretativa. Los resultados estadísticos son insumos para argumentación teórica, no veredictos finales. Goertz and Mahoney (2012) argumentan persuasivamente que métodos cuantitativos y cualitativos tienen fortalezas complementarias; los mejores estudios frecuentemente combinan ambos. 1.7 Resumen del capítulo Este capítulo introdujo la lógica del método científico aplicado a ciencias sociales. El conocimiento científico se distingue por su sistematicidad, falsabilidad y acumulación. Las ciencias sociales enfrentan desafíos específicos (reflexividad, complejidad causal, imposibilidad de experimentación), pero esto no invalida la empresa científica. La cuantificación es una estrategia metodológica útil para ciertos propósitos: permite precisión, comparabilidad, agregación y testeo sistemático de hipótesis. Sin embargo, no todo fenómeno político debería cuantificarse. La teoría es indispensable en investigación cuantitativa. Orienta qué observar, genera hipótesis testeables, e interpreta hallazgos. Sin teoría, los datos son ininteligibles. La investigación cuantitativa sigue una secuencia: pregunta → literatura → teoría/hipótesis → diseño → datos → análisis → interpretación → comunicación. Cada paso implica decisiones metodológicas que afectan las conclusiones. El enfoque cuantitativo tiene fortalezas (generalización, precisión, testeo sistemático) y límites (reducción de complejidad, correlación ≠ causalidad, dependencia de supuestos). Reconocer ambos es condición de investigación rigurosa. 1.8 Lecturas recomendadas Fundamentos de inferencia en ciencias sociales: King, G., Keohane, R. O., &amp; Verba, S. (1994). Designing Social Inquiry: Scientific Inference in Qualitative Research. Princeton University Press. → Discusión clásica sobre lógica de inferencia aplicable a investigación cualitativa y cuantitativa. Filosofía de la ciencia para ciencias sociales: Gerring, J. (2012). Social Science Methodology: A Unified Framework (2nd ed.). Cambridge University Press. → Visión comprehensiva de debates metodológicos en ciencias sociales. Defensa del pluralismo metodológico: Brady, H. E., &amp; Collier, D. (Eds.). (2010). Rethinking Social Inquiry: Diverse Tools, Shared Standards (2nd ed.). Rowman &amp; Littlefield. → Debate sobre relación entre métodos cuantitativos y cualitativos, con énfasis en complementariedad. Para profundizar en medición: Adcock, R., &amp; Collier, D. (2001). Measurement Validity: A Shared Standard for Qualitative and Quantitative Research. American Political Science Review, 95(3), 529-546. → Artículo seminal sobre conceptualización y operacionalización. 1.9 Ejercicios 1. Identificar elementos del método científico Lee el resumen (abstract) de un artículo cuantitativo reciente en Latin American Politics and Society o Revista de Ciencia Política. Identifica: La pregunta de investigación La teoría o argumento central Las hipótesis principales El tipo de datos usados La técnica de análisis 2. Evaluar mensurabilidad Para cada uno de los siguientes conceptos, discute: (a) ¿Es posible cuantificarlo? (b) ¿Qué se ganaría y qué se perdería al cuantificarlo? Calidad de la democracia Polarización afectiva Identidad nacional Legitimidad institucional Clientelismo político 3. Teoría e hipótesis Selecciona un fenómeno político reciente en tu país (ej: baja en confianza institucional, cambio en participación electoral, polarización). Formula una pregunta de investigación específica sobre ese fenómeno Propón una teoría de rango medio que lo explique Deriva al menos dos hipótesis testeables de esa teoría Especifica cómo medirías las variables de tus hipótesis 4. Análisis crítico Un titular de prensa afirma: “Estudio demuestra que uso de redes sociales causa polarización política”. ¿Qué tipo de evidencia se necesitaría para sostener causalmente esa afirmación? ¿Qué explicaciones alternativas podrían dar cuenta de una correlación entre uso de redes y polarización? ¿Qué diseño de investigación permitiría distinguir entre estas explicaciones? 5. Reflexión metodológica Piensa en tu propio proyecto de tesis o tema de interés. ¿Tu pregunta de investigación es más adecuada para métodos cuantitativos, cualitativos, o mixtos? ¿Por qué? ¿Qué tipo de datos necesitarías? ¿Qué limitaciones enfrentarías al cuantificar los conceptos centrales de tu investigación? Referencias Abbott, Andrew. 1988. “Transcending General Linear Reality.” Sociological Theory 6 (2): 169–86. ———. 2001. “What Do Cases Do?” In Time Matters: On Theory and Method. Chicago, IL: University of Chicago Press. Giddens, Anthony. 1984. The Constitution of Society: Outline of the Theory of Structuration. Cambridge: Polity Press. Goertz, Gary, and James Mahoney. 2012. A Tale of Two Cultures: Qualitative and Quantitative Research in the Social Sciences. Princeton, NJ: Princeton University Press. Gurr, Ted Robert. 1970. Why Men Rebel. Princeton, N.J.: Princeton University Press. King, Gary, Robert O. Keohane, and Sidney Verba. 1994. Designing Social Inquiry: Scientific Inference in Qualitative Research. Princeton, NJ: Princeton University Press. Kuhn, Thomas S. 1962. The Structure of Scientific Revolutions. Chicago: University of Chicago Press. Lazarsfeld, Paul F., and Morris Rosenberg, eds. 1955. The Language of Social Research: A Reader in the Methodology of Social Research. Glencoe, Illinois: Free Press. Mahoney, James, and Gary Goertz. 2006. “A Tale of Two Cultures: Contrasting Quantitative and Qualitative Research.” Political Analysis 14 (3): 227–49. https://doi.org/10.1093/pan/mpj017. Merton, Robert K. 1949. Social Theory and Social Structure. Glencoe, Illinois: The Free Press. Munck, Gerardo L. 2009. Measuring Democracy: A Bridge Between Scholarship and Politics. Baltimore, MD: Johns Hopkins University Press. Popper, Karl R. 1959. The Logic of Scientific Discovery. London: Routledge. Ragin, Charles C. 1987. The Comparative Method: Moving Beyond Qualitative and Quantitative Strategies. Berkeley: University of California Press. EJEMPLO: “El alma humana es inmortal” no es falsable empíricamente (no hay datos observables que puedan refutarla). “Las personas religiosas votan más por candidatos conservadores” SÍ es falsable mediante encuestas. Ambas afirmaciones pueden ser importantes, pero solo la segunda es científica en sentido metodológico.↩︎ EJEMPLO CHILENO: Durante el estallido social de octubre 2019, académicos publicaron estudios sobre tácticas de movilización efectivas. Los movimientos sociales leyeron estos estudios y adaptaron sus estrategias, haciendo que las teorías iniciales quedaran desactualizadas. En física, las partículas no leen teorías sobre partículas y modifican su comportamiento.↩︎ CASO CONCRETO: En 2022, Freedom House clasificó a Chile como “Libre” (score: 94/100), mientras que V-Dem lo ubicó ligeramente por debajo de Costa Rica en su índice de democracia liberal. Estas diferencias no significan que un índice esté “equivocado”; reflejan distintas conceptualizaciones de qué aspectos de la democracia importan más.↩︎ EJEMPLO NEOPOSITIVISTA: “¿Cuánto aumenta la probabilidad de votar si una persona es contactada telefónicamente por una campaña?” Respuesta: experimento aleatorio donde asignamos contacto/no contacto y medimos diferencia en tasas de participación. EJEMPLO MECANÍSMICO: “¿CÓMO el contacto telefónico aumenta la participación?” Respuesta: entrevistas cualitativas revelando que las llamadas funcionan mediante recordatorio de fecha de elección + presión social de compromiso público. Ambas preguntas son legítimas pero requieren métodos diferentes.↩︎ EJEMPLO COMPLETO CON CASO CHILENO: TEORÍA: Los sistemas proporcionales facilitan entrada de nuevos partidos (Duverger). MECANISMO: En distritos grandes, partidos pequeños pueden ganar escaños con pocos votos, haciendo viable su formación. IMPLICACIÓN: Tras cambio de sistema binominal (2013) a proporcional (2015) en Chile, debería aumentar el número de partidos. HIPÓTESIS TESTEABLE: “El número efectivo de partidos en la Cámara de Diputados chilena será mayor en 2018-2022 que en 2010-2014”. RESULTADO OBSERVADO: Pasó de 5.6 a 8.2 partidos efectivos, consistente con la teoría.↩︎ EJEMPLO ENGAÑOSO CLÁSICO: En comunas chilenas, el número de templos evangélicos correlaciona positivamente con tasas de crimen. ¿Los templos CAUSAN crimen? No. Ambos son causados por una tercera variable (tamaño poblacional): comunas grandes tienen más templos Y más crimen. Esta es una variable confusora. Otro ejemplo: consumo de helado correlaciona con ahogamientos en piscinas. ¿Causa? No: ambos aumentan en verano (temperatura es la confusora).↩︎ "],["diseno.html", "Capítulo 2 Diseño de investigación 2.1 Objetivos del capítulo 2.2 Preguntas de investigación 2.3 Hipótesis y teoría 2.4 Causalidad 2.5 Tipos de diseños 2.6 Validez interna y externa 2.7 Casos, unidades y niveles de análisis 2.8 Resumen del capítulo 2.9 Lecturas recomendadas 2.10 Ejercicios", " Capítulo 2 Diseño de investigación 2.1 Objetivos del capítulo Al finalizar este capítulo, serás capaz de: Formular preguntas de investigación empíricamente respondibles Distinguir entre hipótesis descriptivas, relacionales y causales Comprender el marco contrafactual de causalidad Identificar fortalezas y debilidades de diseños experimentales y observacionales Evaluar validez interna y externa de diseños de investigación 2.2 Preguntas de investigación Toda investigación comienza con una pregunta, pero no cualquier pregunta es una pregunta de investigación útil.^[Una pregunta de investigación no es lo mismo que una pregunta de tesis o un objetivo general. La pregunta de investigación debe ser empíricamente respondible mediante datos observables, mientras que las preguntas normativas (“¿Debería Chile tener un sistema parlamentario?”) pertenecen a la filosofía política, no a la investigación empírica. Las buenas preguntas tienen tres características: especificidad (delimitan claramente qué queremos saber; ej: “¿En qué medida la descentralización fiscal incrementa la corrupción municipal en Chile durante 2000-2020?” es mejor que “¿Por qué hay corrupción en América Latina?”), respuesta empírica (deben poder responderse mediante observación sistemática del mundo; preguntas normativas sobre qué debería ser no son preguntas de investigación empírica, aunque pueden motivarla), y relevancia teórica o sustantiva (contribuyen a debates teóricos, llenan vacíos en conocimiento descriptivo, o informan decisiones prácticas (King, Keohane, and Verba 1994)). Las preguntas se clasifican según su propósito: preguntas descriptivas caracterizan fenómenos (“¿Cuál es la tasa de participación electoral en Chile 2021?”), preguntas relacionales identifican asociaciones entre variables (“¿Se relaciona el nivel educativo con la participación electoral?”), y preguntas causales buscan establecer relaciones de causa-efecto (“¿La inscripción automática aumenta la participación electoral?”). La distinción importa porque cada tipo exige estrategias metodológicas distintas: responder preguntas descriptivas requiere medición cuidadosa y muestreo representativo; responder preguntas causales requiere, además, estrategias para descartar explicaciones alternativas. 2.3 Hipótesis y teoría Una vez formulada la pregunta, necesitamos una respuesta tentativa —una hipótesis: afirmación específica, derivada de teoría, sobre relaciones esperadas entre variables que debe ser falsable^[El criterio de falsabilidad de Popper establece que una hipótesis científica debe poder ser refutada mediante evidencia empírica. “Los partidos de izquierda son mejores” NO es falsable (¿mejores en qué sentido?). “Los partidos de izquierda gastan más en políticas sociales” SÍ es falsable mediante datos observables de gasto público. (Popper 1959). Por ejemplo: “A mayor magnitud de distrito electoral, mayor fragmentación partidaria en el parlamento” es específica, falsable, y se deriva de la teoría de Duverger sobre efectos de sistemas electorales. Las hipótesis provienen de teorías sobre cómo funciona el mundo social mediante un proceso deductivo: Teoría → Mecanismo causal → Implicación observable → Hipótesis. Por ejemplo: la teoría de que los sistemas electorales proporcionales reducen barreras de entrada para partidos pequeños (Lijphart 1994) implica que en distritos grandes, partidos pequeños pueden obtener escaños con porcentajes bajos de votos, incentivando su formación, por lo que deberíamos observar más partidos en parlamentos elegidos con distritos grandes, generando la hipótesis testeable “a mayor magnitud promedio de distrito, mayor número efectivo de partidos parlamentarios”. Este encadenamiento lógico es crucial: cuando testeamos hipótesis, estamos evaluando indirectamente la teoría subyacente. En estadística inferencial (Capítulo 9), formalizamos dos tipos de hipótesis: la hipótesis nula (H₀) que afirma ausencia de relación o efecto (“No hay diferencia en participación electoral entre hombres y mujeres”), y la hipótesis alternativa (H₁)^[CONFUSIÓN COMÚN: Los estudiantes piensan que H₀ es “la hipótesis que queremos refutar” y H₁ “la que queremos probar”. INCORRECTO. H₀ es simplemente el escenario de referencia (status quo, no hay efecto). H₁ es lo que los datos nos permiten considerar SI rechazamos H₀. No “probamos” H₁; solo rechazamos o fallamos en rechazar H₀. Esta lógica asimétrica es fundamental para entender tests de hipótesis en el Capítulo 9. que afirma existencia de relación o efecto (“Las mujeres participan más/menos que los hombres”). El procedimiento estadístico evalúa si los datos son suficientemente inconsistentes con H₀ como para rechazarla en favor de H₁. 2.4 Causalidad El objetivo de mucha investigación cuantitativa es establecer relaciones causales. Queremos saber no solo si X e Y covarían, sino si cambios en X producen cambios en Y. 2.4.1 El problema fundamental de inferencia causal Holland (1986) formuló el problema fundamental de inferencia causal: nunca observamos el mismo caso bajo tratamiento y control simultáneamente. Si una persona votó en una elección con inscripción automática, nunca sabremos si habría votado sin inscripción automática. Ese resultado contrafactual es fundamentalmente inobservable.^[EJEMPLO POLÍTICO CHILENO: En octubre 2019, el presidente Piñera declaró estado de emergencia. ¿Redujo o aumentó las protestas? Para saberlo causalmente, necesitaríamos observar QUÉ HABRÍA PASADO en el Chile de octubre 2019 SIN estado de emergencia. Pero ese Chile no existe—es contrafactual. Solo observamos lo que pasó CON estado de emergencia. Toda inferencia causal enfrenta este problema fundamental. Los métodos cuantitativos intentan aproximar el contrafactual mediante comparaciones (grupos control, diferencias-en-diferencias, etc.). Formalizando: Para el caso \\(i\\), definimos: \\(Y_i(1)\\): resultado si recibe tratamiento \\(Y_i(0)\\): resultado si no recibe tratamiento Efecto causal individual: \\(\\tau_i = Y_i(1) - Y_i(0)\\) El problema: observamos \\(Y_i(1)\\) o \\(Y_i(0)\\), nunca ambos. Uno siempre es contrafactual. 2.4.2 Marco de resultados potenciales Rubin (1974) propuso que, aunque no podemos estimar efectos individuales, podemos estimar efectos causales promedio bajo ciertas condiciones. El efecto causal promedio del tratamiento (ATE) es: \\[ATE = E[Y_i(1) - Y_i(0)] = E[Y_i(1)] - E[Y_i(0)]\\] Pero seguimos sin observar ambos resultados potenciales para cada caso. La solución: usar grupos. Comparamos unidades tratadas con unidades no tratadas. La inferencia causal depende de que estos grupos sean comparables en expectativa. 2.4.3 Condiciones para inferencia causal Para que la comparación entre tratados y no tratados nos informe sobre el efecto causal, necesitamos: 1. Independencia condicional El tratamiento debe asignarse independientemente de los resultados potenciales (condicional en covariables observadas). En experimentos aleatorios, esto se cumple por construcción. En estudios observacionales, debemos argumentarlo o modelarlo. 2. Exclusión El tratamiento debe afectar el resultado solo a través del mecanismo teórico propuesto, no por otras vías. 3. SUTVA (Stable Unit Treatment Value Assumption)^[VIOLACIÓN DE SUTVA EN CONTEXTO REAL: Imagina un experimento donde asignamos aleatoriamente a algunas personas recibir mensajes pro-vacunación COVID. Si los tratados convencen a sus familiares (no tratados) de vacunarse, el resultado de los no-tratados DEPENDE del tratamiento de otros. SUTVA se viola. Esto es común en intervenciones sociales con efectos de contagio, difusión o spillover. Violar SUTVA sesga estimaciones de efectos causales, generalmente subestimándolos. El resultado de cada unidad no debe depender del tratamiento de otras unidades. Si mi vecino vota (tratamiento), mi propia probabilidad de votar (resultado) no debería cambiar. Esta suposición se viola frecuentemente —un problema serio en ciencias sociales. Estas condiciones raramente se cumplen perfectamente en datos observacionales. Gran parte de la metodología cuantitativa consiste en estrategias para aproximarse a inferencia causal válida cuando las condiciones ideales no se cumplen. 2.5 Tipos de diseños Los diseños de investigación varían según cuánto control tenemos sobre la asignación del tratamiento y la recolección de datos. 2.5.1 Diseños experimentales En un experimento, el investigador asigna aleatoriamente el tratamiento. Esto garantiza que, en expectativa, grupos tratados y control son idénticos excepto por el tratamiento. Cualquier diferencia sistemática en resultados es atribuible al efecto causal del tratamiento. Ejemplo: Gerber and Green (2008) realizaron experimentos de campo sobre movilización electoral en Estados Unidos. Asignaron aleatoriamente hogares a recibir llamadas telefónicas, visitas puerta a puerta, o ningún contacto (control). Compararon tasas de participación electoral entre grupos. Ventajas: - Identificación causal clara - No requiere supuestos sobre confusores - Alta validez interna Limitaciones: - Muchas preguntas políticas no permiten experimentación (no podemos asignar aleatoriamente tipo de régimen político)^[LÍMITE ÉTICO OBVIO: No podemos experimentalmente asignar a países “democracia” vs “dictadura” para medir efectos sobre desarrollo económico. Tampoco podemos asignar aleatoriamente “corrupción gubernamental” para estudiar efectos sobre confianza ciudadana. Estos límites éticos y prácticos obligan a usar datos observacionales con estrategias cuasi-experimentales o de control estadístico (regresión múltiple, matching, etc.). - Posibles problemas éticos - Efectos pueden ser específicos al contexto experimental (baja validez externa) - En ciencia política, solo ciertas preguntas son experimentables 2.5.2 Diseños cuasi-experimentales Los diseños cuasi-experimentales explotan variación como si fuera aleatoria, aunque no provenga de asignación experimental. Regresión discontinua (RD) Cuando el tratamiento se asigna según un umbral en una variable continua, podemos comparar casos justo arriba y debajo del umbral —que son casi idénticos excepto en recepción del tratamiento. Ejemplo: Eggers et al. (2015) estudian efectos de ganar una elección sobre riqueza personal de candidatos en UK. Comparan candidatos que ganaron por margen muy estrecho con quienes perdieron por margen muy estrecho. El supuesto: ganar vs. perder por 0.1% de votos es prácticamente aleatorio. Diferencias-en-diferencias (DiD) Compara cambios antes/después de un tratamiento entre grupo tratado y grupo control. Requiere supuesto de tendencias paralelas: sin tratamiento, ambos grupos habrían evolucionado de forma similar. Ejemplo: Meléndez and Rovira Kaltwasser (2019) estudian efecto de una reforma tributaria en Colombia comparando municipios afectados vs. no afectados, antes y después de la reforma. Variables instrumentales (IV) Usa una variable (instrumento) que afecta el tratamiento pero no el resultado directamente. Permite estimar efecto causal incluso cuando tratamiento está confundido. Ejemplo: Acemoglu, Johnson, and Robinson (2001) usan mortalidad de colonos europeos en colonias históricas como instrumento para instituciones actuales, argumentando que afecta instituciones pero no desarrollo económico contemporáneo directamente. 2.5.3 Diseños observacionales La mayoría de investigación en ciencias políticas usa datos observacionales —datos donde el investigador no controla la asignación del tratamiento. Aquí, inferencia causal es más problemática. Estudios de corte transversal Observan muchos casos en un punto temporal. Útiles para descripción y exploración de asociaciones, pero problemáticos para causalidad por confusores no observados. Ejemplo: Analizar si democracias tienen menor desigualdad que autocracias usando datos de 150 países en 2020. El problema: democracia no es aleatoria —correlaciona con desarrollo económico, historia colonial, estructura social, etc. Series de tiempo Observan un caso (o pocos casos) en múltiples momentos. Permiten explotar variación temporal, pero requieren supuestos sobre qué cambió y qué permaneció constante. Ejemplo: Estudiar efecto de una reforma electoral en Chile analizando fragmentación partidaria antes y después. El problema: otros factores también cambiaron simultáneamente. Panel (longitudinal) Combinan ventajas de corte transversal (muchos casos) y series de tiempo (variación temporal). Permiten controlar características fijas no observadas de unidades usando efectos fijos. Ejemplo: Flores and Nooruddin (2016) usan datos de panel de municipios mexicanos para estudiar efecto de presencia militar sobre violencia del crimen organizado, controlando características permanentes de municipios. Estrategias para fortalecer inferencia causal en diseños observacionales: Controles estadísticos: Incluir covariables que eliminan confusión. Problema: solo funciona para confusores observados. Matching: Emparejar casos tratados con controles similares. Aproxima balance experimental, pero depende de calidad del emparejamiento. Diseño de investigación robusto: Múltiples tests de robustez, placebo tests, análisis de sensibilidad. Triangulación: Combinar múltiples fuentes de evidencia (cuantitativa + cualitativa). 2.6 Validez interna y externa Todo diseño de investigación enfrenta tensiones entre dos tipos de validez (Campbell and Stanley 1963). Validez interna es el grado en que podemos confiar que el efecto estimado es genuinamente causal, no espurio (¿X realmente causa Y, o la asociación se debe a confusores?). Las amenazas incluyen variables confusoras (que afectan tanto el tratamiento como el resultado; ej: países con más carreteras son más ricos, pero ¿las carreteras causan riqueza o la riqueza permite construir carreteras?), causalidad inversa (Y puede causar X en vez de X causar Y; ej: Przeworski et al. (2000) argumentan que el desarrollo no causa transiciones democráticas, pero sí hace que las democracias sobrevivan), y sesgo de selección (la asignación al tratamiento no es aleatoria y se relaciona sistemáticamente con el resultado potencial; ej: comparar salarios de quienes asistieron a universidad vs. quienes no ignora que difieren en habilidad, motivación y recursos familiares). Estrategias para mejorar validez interna: aleatorización, diseños cuasi-experimentales rigurosos, controlar estadísticamente confusores observados, análisis de sensibilidad a confusores no observados. Validez externa es el grado en que resultados generalizan más allá del contexto específico estudiado (¿los hallazgos aplican a otras poblaciones, contextos o tiempos?). Las amenazas incluyen muestras no representativas (estudiar estudiantes universitarios no permite generalizar a la población general), especificidad contextual (efectos varían sistemáticamente según contexto; un experimento de movilización electoral en Estados Unidos puede no tener el mismo efecto en Chile), efectos de Hawthorne (sujetos modifican comportamiento porque saben que están siendo estudiados), y dependencia temporal (relaciones causales cambian con el tiempo; teorías sobre comportamiento electoral en los 1960s pueden no aplicar en 2020). Existe tensión fundamental: los diseños con mejor validez interna (experimentos de laboratorio) a menudo tienen peor validez externa; los diseños con muestras más representativas (encuestas nacionales) tienen peor validez interna. Shadish, Cook, and Campbell (2002) argumentan que el objetivo no es maximizar una validez a costa de la otra, sino encontrar equilibrios apropiados según la pregunta de investigación: preguntas sobre mecanismos causales priorizan validez interna; preguntas sobre magnitud de efectos en poblaciones priorizan validez externa. 2.7 Casos, unidades y niveles de análisis Una decisión crucial en diseño de investigación es qué constituye un “caso” —la unidad de análisis: individuos (votantes, legisladores, activistas), agregados subnacionales (municipios, provincias, circunscripciones electorales), países (estados nacionales), eventos (elecciones, protestas, golpes de estado), legislación (leyes, políticas públicas), u organizaciones (partidos políticos, grupos de interés). La unidad de análisis determina qué variación podemos explotar y qué afirmaciones podemos hacer. Debemos evitar dos falacias. Falacia ecológica (Robinson 1950): inferir relaciones a nivel individual desde asociaciones a nivel agregado (si comunas con más inmigrantes votan más por la derecha, ¿significa que inmigrantes votan derecha? No necesariamente; puede ser que nativos en comunas con inmigración voten derecha reactivamente, mientras inmigrantes votan izquierda). Falacia atómica (o “individualista”): inferir relaciones a nivel agregado desde patrones individuales (si individuos religiosos son más conservadores, ¿países más religiosos son más conservadores? No necesariamente; puede haber efectos contextuales que cambian relaciones). La inferencia estadística requiere suficientes observaciones relativas al número de parámetros estimados. King, Keohane, and Verba (1994) enfatizan el problema de “muchas variables, pocas observaciones” (MVPO): si estudio 20 países con 15 variables explicativas, casi cualquier patrón puede ser ajustado sin suficientes grados de libertad para distinguir patrones genuinos de ruido. Soluciones: aumentar observaciones (datos de panel con múltiples países × múltiples años), reducir parámetros (selección teórica de variables, análisis factorial), o combinar enfoques (análisis cuantitativo de patrones generales + estudios de caso que elucidan mecanismos). 2.8 Resumen del capítulo El diseño de investigación es el plan para responder preguntas de investigación. Buenas preguntas son específicas, empíricamente respondibles, y relevantes teórica o prácticamente. Pueden ser descriptivas, relacionales o causales. Las hipótesis son afirmaciones falsables derivadas de teoría sobre relaciones esperadas entre variables. Conectan teoría abstracta con implicaciones observables. La inferencia causal enfrenta el problema fundamental: nunca observamos resultados contrafactuales. El marco de resultados potenciales formaliza este problema. Para inferir causalidad, necesitamos que grupos tratados y control sean comparables. Los diseños experimentales garantizan comparabilidad mediante aleatorización, logrando alta validez interna. Los diseños cuasi-experimentales explotan situaciones “naturalmente” aleatorias. Los diseños observacionales dependen de supuestos más fuertes y técnicas estadísticas para aproximar inferencia causal. Toda investigación enfrenta tensión entre validez interna (¿el efecto es causal?) y validez externa (¿generaliza?). No hay diseño perfecto; cada diseño implica compromisos. La unidad de análisis determina qué variación explotamos y qué afirmaciones justificamos. Inferir relaciones en un nivel desde datos de otro nivel (falacias ecológicas/atómicas) es problemático. 2.9 Lecturas recomendadas Fundamentos de diseño de investigación: Shadish, W. R., Cook, T. D., &amp; Campbell, D. T. (2002). Experimental and Quasi-Experimental Designs for Generalized Causal Inference. Houghton Mifflin. → Tratamiento comprehensivo de validez y diseños experimentales/cuasi-experimentales. Marco contrafactual de causalidad: Morgan, S. L., &amp; Winship, C. (2015). Counterfactuals and Causal Inference: Methods and Principles for Social Research (2nd ed.). Cambridge University Press. → Introducción accesible al marco de resultados potenciales y métodos de inferencia causal. Diseños observacionales en ciencia política: Angrist, J. D., &amp; Pischke, J.-S. (2009). Mostly Harmless Econometrics: An Empiricist’s Companion. Princeton University Press. → Enfoque práctico sobre identificación causal en datos observacionales. Sobre validez de medición: Adcock, R., &amp; Collier, D. (2001). Measurement validity: A shared standard for qualitative and quantitative research. American Political Science Review, 95(3), 529-546. → Discusión conceptual sobre operacionalización y validez. Experimentos de campo en ciencia política: Gerber, A. S., &amp; Green, D. P. (2012). Field Experiments: Design, Analysis, and Interpretation. W.W. Norton. → Guía práctica para diseñar y analizar experimentos de campo. 2.10 Ejercicios 1. Evaluar preguntas de investigación Para cada pregunta, identifica: (a) ¿Es específica? (b) ¿Es empíricamente respondible? (c) ¿Es descriptiva, relacional o causal? (d) ¿Cómo la mejorarías? “¿Por qué hay desigualdad?” “¿Los jóvenes participan menos en política?” “¿Debería Chile tener voto obligatorio?” “¿El voto obligatorio aumenta la participación electoral?” 2. De teoría a hipótesis Teoría: Los sistemas presidenciales son más propensos a crisis democráticas que los parlamentarios porque generan competencia de suma cero entre ejecutivo y legislativo (Linz and Stepan 1996). Identifica el mecanismo causal propuesto Deriva dos hipótesis testeables ¿Qué evidencia falsificaría cada hipótesis? 3. Identificar amenazas a validez interna Un estudio encuentra que municipios que implementaron presupuesto participativo tienen menor corrupción. El estudio compara municipios con presupuesto participativo vs. sin él, controlando por población, PIB per cápita y nivel educativo. ¿Qué confusores no observados podrían explicar la asociación? ¿Podría haber causalidad inversa? ¿Cómo? Propón un diseño alternativo con mejor validez interna 4. Evaluar validez externa Un experimento en Suecia muestra que recibir información sobre uso de impuestos aumenta disposición a pagar impuestos. Los investigadores quieren saber si el resultado aplica a América Latina. ¿Qué diferencias contextuales podrían hacer que el efecto varíe? ¿Cómo evaluarías si el resultado generaliza? ¿Qué diseño permitiría estudiar variación contextual del efecto? 5. Problema de investigación propio Selecciona un fenómeno político que te interese: Formula una pregunta causal específica Propón una teoría que la responda y deriva hipótesis Describe un diseño observacional para testearla Identifica las principales amenazas a validez interna ¿Qué diseño cuasi-experimental podría mejorar la identificación causal? 6. Análisis de artículo Lee un artículo cuantitativo de una revista de ciencia política. Identifica: La pregunta de investigación y su tipo El diseño de investigación usado La unidad de análisis Dos fortalezas del diseño para validez interna Dos limitaciones para validez externa Una estrategia alternativa que los autores podrían haber usado Referencias Acemoglu, Daron, Simon Johnson, and James A. Robinson. 2001. “The Colonial Origins of Comparative Development: An Empirical Investigation.” American Economic Review 91 (5): 1369–1401. https://doi.org/10.1257/aer.91.5.1369. Campbell, Donald T., and Julian C. Stanley. 1963. Experimental and Quasi-Experimental Designs for Research. Chicago: Rand McNally &amp; Company. Eggers, Andrew C., Anthony Fowler, Jens Hainmueller, Andrew B. Hall, and James M. Snyder. 2015. “On the Validity of the Regression Discontinuity Design for Estimating Electoral Effects: New Evidence from over 40,000 Close Races.” American Journal of Political Science 59 (1): 259–74. Flores, Thomas Edward, and Irfan Nooruddin. 2016. Experimentation in the Social Sciences. Cambridge: Cambridge University Press. Gerber, Alan S., and Donald P. Green. 2008. Get Out the Vote: How to Increase Voter Turnout. 2nd ed. Washington, DC: Brookings Institution Press. Holland, Paul W. 1986. “Statistics and Causal Inference.” Journal of the American Statistical Association 81 (396): 945–60. King, Gary, Robert O. Keohane, and Sidney Verba. 1994. Designing Social Inquiry: Scientific Inference in Qualitative Research. Princeton, NJ: Princeton University Press. Lijphart, Arend. 1994. Electoral Systems and Party Systems: A Study of Twenty-Seven Democracies, 1945-1990. Oxford: Oxford University Press. Linz, Juan J., and Alfred Stepan. 1996. Problems of Democratic Transition and Consolidation: Southern Europe, South America, and Post-Communist Europe. Baltimore, MD: Johns Hopkins University Press. Meléndez, Carlos, and Cristóbal Rovira Kaltwasser. 2019. The Collapse of the Venezuelan Party System: Institutionalization, Economic Crisis, and Mass Behavior. Cambridge: Cambridge University Press. Popper, Karl R. 1959. The Logic of Scientific Discovery. London: Routledge. Przeworski, Adam, Michael E. Alvarez, Jose Antonio Cheibub, and Fernando Limongi. 2000. Democracy and Development: Political Institutions and Well-Being in the World, 1950-1990. Cambridge: Cambridge University Press. Robinson, William S. 1950. “Ecological Correlations and the Behavior of Individuals.” American Sociological Review 15 (3): 351–57. Rubin, Donald B. 1974. “Estimating Causal Effects of Treatments in Randomized and Nonrandomized Studies.” Journal of Educational Psychology 66 (5): 688–701. Shadish, William R, Thomas D Cook, and Donald T Campbell. 2002. Experimental and Quasi-Experimental Designs for Generalized Causal Inference. Boston, MA: Houghton Mifflin. "],["medicion.html", "Capítulo 3 Medición: de conceptos a variables 3.1 Objetivos del capítulo 3.2 El problema de la medición 3.3 Conceptos y definiciones operacionales 3.4 Niveles de medición 3.5 Validez y confiabilidad 3.6 Índices y escalas 3.7 Problemas comunes de medición 3.8 Medición de conceptos específicos en ciencias políticas 3.9 Resumen del capítulo 3.10 Lecturas recomendadas 3.11 Ejercicios", " Capítulo 3 Medición: de conceptos a variables 3.1 Objetivos del capítulo Al finalizar este capítulo, serás capaz de: Distinguir entre conceptos teóricos y definiciones operacionales Identificar niveles de medición y sus implicaciones para análisis Evaluar validez y confiabilidad de mediciones Comprender estrategias para construir índices y escalas Reconocer problemas comunes de medición en ciencias políticas 3.2 El problema de la medición Los conceptos centrales de la ciencia política —democracia, legitimidad, participación, corrupción— no son directamente observables. Son abstracciones teóricas que requieren traducción a indicadores empíricos. Esta traducción es el problema de la medición. Adcock and Collier (2001) distinguen cuatro niveles en el proceso de medición: Concepto de fondo: La idea abstracta en su totalidad teórica (ej: “democracia”) Concepto sistematizado: Definición precisa del concepto para propósitos analíticos (ej: “régimen político donde gobernantes son seleccionados mediante elecciones competitivas”) Indicadores: Observables específicos relacionados con el concepto (ej: alternancia en el poder, competitividad electoral, libertades civiles) Puntajes: Valores numéricos asignados a casos en los indicadores (ej: Chile = 8.5 en escala de democracia) Cada transición entre niveles implica decisiones. No hay una única forma “correcta” de medir democracia, capital social, o polarización. Las mediciones son construcciones que reflejan decisiones conceptuales y pragmáticas.^[IMPLICACIÓN PRÁCTICA: Cuando lees “Chile tiene un puntaje de democracia de 8.5”, pregúntate: ¿Qué definición de democracia usa ese índice? ¿Incluye solo elecciones o también estado de derecho, libertades civiles, rendición de cuentas? ¿Cómo ponderan estos componentes? Índices diferentes = puntajes diferentes. No hay una medición “verdadera” de democracia, solo mediciones más o menos útiles para propósitos específicos. 3.3 Conceptos y definiciones operacionales La conceptualización especifica qué entendemos por un término; sin ella, la medición carece de fundamento. Sartori (1970) advirtió sobre el “estiramiento conceptual”: usar un concepto en contextos donde no aplica, diluyendo su utilidad analítica. Por ejemplo, ¿qué es “participación política”? Una conceptualización minimalista^[EJEMPLO DE CONSECUENCIAS: Si usas definición minimalista (solo votar), Chile tendría participación “baja” (45-50% en elecciones recientes). Si usas definición expansiva (votar + protestar + activismo comunitario + participar en cabildos), Chile podría tener participación “alta” (recordar que en octubre 2019, millones participaron en protestas, y en 2021-2022 hubo amplia participación en proceso constituyente). ¿Cuál es “correcta”? Depende de tu pregunta de investigación: ¿te interesa legitimidad electoral o movilización social amplia? (acciones dirigidas a influir en la selección de gobernantes como votar y hacer campaña) exige solo datos electorales, mientras una expansiva (cualquier acción dirigida a influir en decisiones colectivas, incluyendo protesta y activismo comunitario) requiere información sobre múltiples formas de acción. La operacionalización traduce el concepto en procedimientos específicos de medición, siendo el puente entre teoría y datos. Adcock and Collier (2001) identifican tres criterios para buena operacionalización: validez de fondo (los indicadores capturan el significado teórico del concepto; si conceptualizamos democracia como “gobierno del pueblo”, un indicador basado solo en elecciones es insuficiente), convergencia (múltiples indicadores del mismo concepto deberían correlacionar positivamente; si medimos “confianza institucional” con preguntas sobre Congreso, Poder Judicial y policía, estas medidas deberían correlacionar aunque imperfectamente), y discriminación (el indicador debe distinguir entre casos que difieren conceptualmente; una medida de democracia que asigna puntajes similares a Noruega y Venezuela tiene poca validez discriminante). 3.3.1 El dilema minimalista-maximalista Collier and Levitsky (2006) analizan la tensión entre definiciones minimalistas (pocas dimensiones, alta precisión) y maximalistas (múltiples dimensiones, más comprehensivas pero menos precisas). Definiciones minimalistas: - Ventaja: Mayor acuerdo intersubjetivo sobre casos que califican - Desventaja: Pueden omitir aspectos teóricamente importantes Definiciones maximalistas: - Ventaja: Capturan complejidad conceptual - Desventaja: Dificultan acuerdo sobre clasificaciones; aumentan requisitos de datos No hay solución única. La elección depende del propósito teórico. Para estudiar consecuencias de la democracia, definiciones minimalistas (ej: “elecciones competitivas”) permiten muestras grandes. Para estudiar calidad democrática, definiciones maximalistas (incluyendo rendición de cuentas, estado de derecho, etc.) son necesarias. 3.4 Niveles de medición Las variables se clasifican según su nivel de medición, que determina qué operaciones matemáticas y estadísticas son apropiadas. Las variables nominales clasifican casos en categorías mutuamente excluyentes sin ordenamiento (ej: religión, región geográfica, tipo de sistema electoral); las únicas operaciones válidas son contar frecuencias y comparar igualdad/diferencia. Las variables ordinales ordenan casos sin especificar distancias entre categorías (ej: nivel educativo primaria/secundaria/universitaria, acuerdo en escala Likert); podemos ordenar, pero no sabemos si la distancia entre “primaria” y “secundaria” es igual a la entre “secundaria” y “universitaria”^[DEBATE METODOLÓGICO: Estrictamente, si preguntas “¿Cuán satisfecho está con la democracia? 1=Muy insatisfecho, 5=Muy satisfecho”, no sabemos si la distancia entre 1 y 2 es igual a la entre 4 y 5. Entonces calcular “satisfacción promedio = 3.2” es técnicamente inapropiado. PERO: en práctica, TODOS los estudios de opinión pública lo hacen, asumiendo que las categorías son aproximadamente equidistantes. Es una violación “aceptada” por conveniencia. Si te preocupa, usa medianas y tests no-paramétricos. (técnicamente, calcular promedios con datos ordinales es problemático, aunque en práctica se hace frecuentemente con escalas Likert). Las variables de intervalo tienen distancias constantes entre valores pero carecen de cero absoluto (ej: temperatura en Celsius donde la diferencia entre 10°C y 20°C es igual a la entre 20°C y 30°C, pero 0°C no significa “ausencia de temperatura”); en ciencias sociales son raras, y la mayoría de escalas (puntajes de democracia, índices de ideología) deberían tratarse como ordinales aunque frecuentemente las tratamos “como si” fueran de intervalo. Las variables de razón tienen distancias constantes y cero absoluto (ej: ingresos, población, porcentaje de votos, edad); aquí podemos decir que alguien con $2 millones gana el doble que alguien con $1 millón, y todas las operaciones matemáticas son válidas. El nivel de medición determina qué estadísticos son apropiados: nominal (moda, frecuencias, chi-cuadrado), ordinal (mediana, rangos, correlación de Spearman), intervalo/razón (media, desviación estándar, correlación de Pearson, regresión). Usar estadísticos inapropiados produce resultados sin sentido: calcular “ingreso promedio” tiene sentido; calcular “religión promedio” no.^[EJEMPLO ABSURDO para ilustrar: Si codificas religión como Católico=1, Evangélico=2, Ateo=3, Otra=4, y calculas “promedio = 2.3”, ¿qué significa? Nada. No existe “religión 2.3”. Los números son solo etiquetas. En cambio, “ingreso promedio = $650,000” SÍ tiene sentido porque los números representan cantidades reales. La lección: antes de calcular cualquier estadístico, pregúntate si tiene sentido interpretativo dado el nivel de medición. 3.5 Validez y confiabilidad Una buena medición debe ser válida (¿la medida captura el concepto que pretende medir?) y confiable (¿la medición es consistente?). Adcock and Collier (2001) distinguen varios tipos de validez: validez de contenido (los indicadores cubren el dominio del concepto; si conceptualizamos “calidad democrática” incluyendo libertades civiles, procedimientos electorales y rendición de cuentas, una medida basada solo en elecciones tiene baja validez de contenido), validez de constructo (la medida se relaciona como esperado con otras variables; si teorizamos que confianza institucional reduce protesta pero nuestra medida predice más protesta, hay un problema de validez) 3. Validez convergente: Diferentes mediciones del mismo concepto deberían correlacionar. Índices de democracia de Polity, Freedom House y V-Dem miden el mismo concepto; deberían correlacionar fuertemente (y lo hacen, aunque imperfectamente). 4. Validez discriminante: La medida no debería correlacionar fuertemente con conceptos distintos. Una medida de “participación política” que correlaciona 0.95 con “ingreso” probablemente está midiendo ingreso, no participación. 3.5.1 Confiabilidad La confiabilidad pregunta: ¿la medición es consistente? Una medida confiable produce resultados similares cuando se aplica repetidamente al mismo fenómeno. Tipos de confiabilidad: 1. Test-retest: Aplicar la misma medición en dos momentos cercanos. Si puntajes cambian dramáticamente sin razón sustantiva, la medición es poco confiable. 2. Confiabilidad inter-codificadores: Cuando codificadores humanos clasifican datos (ej: codificar manifiestos partidarios), ¿acuerdan? El coeficiente kappa de Cohen mide esto. 3. Consistencia interna: Para escalas multi-ítem (ver siguiente sección), ¿los ítems correlacionan entre sí? El alfa de Cronbach mide consistencia interna. 3.5.2 Relación entre validez y confiabilidad Es posible tener alta confiabilidad pero baja validez. Si medimos “democracia” solo con PIB per cápita, la medida será confiable (el PIB se mide consistentemente) pero inválida (el PIB no es democracia).^[ANALOGÍA ÚTIL: Imagina una balanza que consistentemente marca 5kg más de lo real. Es CONFIABLE (siempre da el mismo error), pero INVÁLIDA (no mide el peso verdadero). En ciencias sociales: si medimos “calidad democrática” solo con “número de partidos en el Congreso”, podríamos medir eso de forma confiable, pero ¿es válido? Un país con 50 partidos fragmentados puede tener peor calidad democrática que uno con 3 partidos funcionales. La medida es confiable pero conceptualmente inválida. También es posible tener alta validez conceptual pero baja confiabilidad. Mediciones de conceptos complejos mediante juicio experto pueden ser válidas pero inconsistentes si expertos desacuerdan. Idealmente, queremos ambas. Pero si debemos priorizar, King, Keohane, and Verba (1994) argumentan que validez importa más: una medición inválida es inútil sin importar cuán confiable sea. 3.6 Índices y escalas Muchos conceptos políticos son latentes—no directamente observables—y multidimensionales. Para medirlos, construimos índices o escalas agregando múltiples indicadores. 3.6.1 Índices aditivos simples El método más simple es sumar (o promediar) múltiples indicadores. Ejemplo: índice de participación política sumando si la persona (1) votó, (2) contactó oficial, (3) asistió a protesta, (4) trabajó en campaña. Rango: 0-4. Ventaja: Simplicidad, transparencia. Desventaja: Asume que todos los indicadores tienen igual peso. ¿Votar importa igual que protestar? 3.6.2 Escalas ponderadas Para reflejar importancia diferencial, podemos ponderar indicadores. Ejemplo: índice de democracia que pondera elecciones competitivas (peso 0.4), libertades civiles (0.3), rendición de cuentas (0.3). Ventaja: Refleja teoría sobre importancia relativa. Desventaja: La elección de pesos es subjetiva y afecta resultados. 3.6.3 Análisis factorial El análisis factorial identifica dimensiones latentes subyacentes a múltiples indicadores observados. Si preguntamos a ciudadanos sobre confianza en Congreso, Ejecutivo, Judicial y policía, el análisis factorial puede revelar una dimensión latente de “confianza institucional general”. Ventaja: Los pesos son determinados empíricamente por la estructura de covariación en los datos. Desventaja: Es ateórico—descubre dimensiones en los datos sin garantizar que correspondan a conceptos teóricos. Además, requiere supuestos fuertes sobre estructura de los datos. 3.6.4 Escalas Likert Las escalas Likert son ubicuas en encuestas. Presentan afirmaciones y solicitan grado de acuerdo (ej: 1=muy en desacuerdo, 5=muy de acuerdo). Consideraciones al construir escalas Likert: 1. Número de opciones: Escalas impares (5, 7 puntos) permiten respuesta neutral; escalas pares (4, 6) fuerzan elección. No hay consenso sobre qué es mejor. 2. Direccionalidad: ¿Todas las preguntas van en la misma dirección o algunas están invertidas? Invertir algunas previene “aquiescencia” (tendencia a estar de acuerdo), pero puede confundir a respondentes. 3. Agregación: Promediar múltiples ítems Likert crea un índice. Pero ítems deben medir el mismo constructo latente—verificable con alfa de Cronbach. 3.6.5 Índices disponibles en ciencias políticas Muchos conceptos tienen índices estandarizados: Democracia: Polity IV, Freedom House, V-Dem, BTI Corrupción: Transparency International CPI, Banco Mundial Control of Corruption Capacidad estatal: Fragile States Index, ICRG Polarización afectiva: Termómetros de sentimiento Ideología: Manifesto Project, DW-NOMINATE (para legisladores) Usar índices establecidos tiene ventajas (comparabilidad entre estudios) y desventajas (conceptualizaciones impuestas, decisiones de medición opacas). La decisión de usar índices existentes versus crear propios depende del propósito de investigación. 3.7 Problemas comunes de medición La medición en ciencias sociales enfrenta problemas sistemáticos que amenazan validez e inferencia. 3.7.1 Sesgo de deseabilidad social Los encuestados pueden responder lo que perciben como socialmente aceptable en lugar de sus verdaderas actitudes. Esto es particularmente problemático para temas sensibles: racismo, corrupción personal, comportamiento antisocial. Estrategias de mitigación: Técnicas de lista: Preguntar por comportamiento de otros, no del respondente Preguntas indirectas: Inferir actitudes de respuestas a escenarios hipotéticos Endorsement experiments: Evaluar apoyo a políticas variando quién las propone 3.7.2 Sesgo de aquiescencia Tendencia a estar de acuerdo con afirmaciones independientemente de su contenido. Particularmente problemático en culturas donde contradecir es descortés. Mitigación: Incluir ítems con dirección invertida. 3.7.3 No-respuesta diferencial Cuando quienes no responden difieren sistemáticamente de quienes responden, las estimaciones se sesgan. Si en una encuesta sobre confianza institucional, los más desconfiados no responden, sobrestimamos confianza. Mitigación: Ponderadores de no-respuesta, análisis de sensibilidad. 3.7.4 Efecto del modo de encuesta Las respuestas pueden variar según cómo se administra la encuesta (cara a cara, telefónica, internet, autoaplicada). Holbrook, Green, and Krosnick (2003) muestran que encuestas cara a cara generan más deseabilidad social que encuestas por internet. 3.7.5 Errores de medición aleatorios vs. sistemáticos Los errores aleatorios reducen confiabilidad pero no sesgan estimaciones (en promedio se cancelan). Los errores sistemáticos sesgan estimaciones consistentemente en una dirección, amenazando validez. Ejemplo: Si los termómetros para medir temperatura están mal calibrados y todos miden 2°C por encima del valor real, tenemos error sistemático. Si algunos miden ligeramente arriba y otros ligeramente abajo aleatoriamente, tenemos error aleatorio. Treier and Jackman (2008) muestran que índices de democracia contienen error de medición sustancial. Ignorar este error produce inferencias sesgadas sobre efectos de la democracia. 3.8 Medición de conceptos específicos en ciencias políticas 3.8.1 Medir ideología La ideología es multidimensional (económica, social, etc.) y contextual. Estrategias: 1. Autoubicación: Preguntar a personas dónde se ubican en escala izquierda-derecha. Simple pero problemático: el significado de “izquierda” varía entre países y períodos. 2. Baterías de ítems: Preguntas sobre posiciones en políticas específicas, agregadas en escala. Más válido pero requiere múltiples preguntas. 3. Scaling de legisladores: Inferir ideología de comportamiento de voto. DW-NOMINATE usa votaciones nominales para ubicar legisladores en espacio ideológico. 3.8.2 Medir polarización Polarización tiene múltiples dimensiones: ideológica, afectiva, por élites vs. masas. Iyengar, Sood, and Lelkes (2012) distinguen polarización ideológica (distancia en posiciones políticas) de polarización afectiva (sentimientos negativos hacia out-group partidario). Mediciones comunes: Distancia media entre posiciones ideológicas de grupos Termómetros de sentimiento hacia partidos opuestos Dispersión de opiniones en la población Diferencia entre posiciones de líderes partidarios La elección depende del concepto teórico específico de polarización que se investiga. 3.8.3 Medir participación política Verba, Schlozman, and Brady (1995) distinguen modos de participación: electoral, activismo de campaña, contacto con oficiales, protesta, activismo comunitario. Problema: Estos modos no correlacionan fuertemente. Quien vota no necesariamente protesta. ¿Son expresiones de un constructo latente de “participación” o fenómenos distintos? La respuesta afecta cómo medimos. Solución pragmática: Medir modos por separado cuando las teorías predicen efectos diferenciados. 3.9 Resumen del capítulo La medición traduce conceptos abstractos en indicadores empíricos. Este proceso involucra conceptualización (definir el concepto) y operacionalización (especificar procedimientos de medición). Cada paso implica decisiones que afectan qué capturamos. Las variables tienen niveles de medición (nominal, ordinal, intervalo, razón) que determinan qué operaciones estadísticas son apropiadas. Confundir niveles produce resultados sin sentido. Buenas mediciones son válidas (capturan el concepto teórico) y confiables (consistentes). Es posible tener una sin la otra, pero idealmente queremos ambas. Los conceptos latentes y multidimensionales requieren índices o escalas. Estos pueden construirse mediante agregación simple, ponderación, o análisis factorial. Los índices existentes en ciencias políticas ofrecen comparabilidad pero imponen conceptualizaciones. La medición enfrenta problemas sistemáticos: sesgos de deseabilidad social y aquiescencia, no-respuesta diferencial, efectos de modo de encuesta, y errores de medición aleatorios o sistemáticos. Reconocer y, cuando es posible, mitigar estos problemas es responsabilidad del investigador. 3.10 Lecturas recomendadas Fundamentos conceptuales de medición: Adcock, R., &amp; Collier, D. (2001). Measurement validity: A shared standard for qualitative and quantitative research. American Political Science Review, 95(3), 529-546. → Artículo seminal sobre niveles de medición y validez. Construcción de escalas e índices: DeVellis, R. F. (2017). Scale Development: Theory and Applications (4th ed.). SAGE. → Guía práctica para desarrollar escalas de medición confiables y válidas. Medición en encuestas: Groves, R. M., et al. (2009). Survey Methodology (2nd ed.). Wiley. → Tratamiento comprehensivo de todos los aspectos de medición mediante encuestas. Problemas de medición en ciencias políticas: Treier, S., &amp; Jackman, S. (2008). Democracy as a latent variable. American Journal of Political Science, 52(1), 201-217. → Análisis del error de medición en índices de democracia y sus consecuencias. Sobre conceptualización: Goertz, G. (2006). Social Science Concepts: A User’s Guide. Princeton University Press. → Discusión profunda sobre formación y uso de conceptos en ciencias sociales. 3.11 Ejercicios 1. Conceptualización y operacionalización Selecciona un concepto abstracto (ej: “legitimidad política”, “clientelismo”, “movilización social”): Propón una definición conceptual clara Identifica al menos tres indicadores empíricos Para cada indicador, especifica el procedimiento de medición Evalúa la validez de contenido de tu operacionalización 2. Niveles de medición Clasifica las siguientes variables según nivel de medición y justifica: Región de residencia (Norte/Centro/Sur) Satisfacción con la democracia (escala 1-10) Ingreso mensual en pesos Religión (Católica/Protestante/Sin religión/Otra) Nivel educativo (Primaria/Secundaria/Universitaria) Temperatura de termómetro de sentimiento hacia partidos políticos (0-100) 3. Evaluar validez Un investigador mide “capital social” preguntando: “¿Cuántas organizaciones sociales existen en su comuna?” ¿Qué dimensión de capital social captura esta medida? ¿Qué dimensiones omite? Propón indicadores adicionales para mejorar validez de contenido ¿Cómo evaluarías la validez convergente de estas medidas? 4. Construir un índice Tienes datos de encuesta con estas preguntas sobre confianza institucional (escala 1-5): ¿Cuánto confía en el Congreso? ¿Cuánto confía en el Presidente? ¿Cuánto confía en la Corte Suprema? ¿Cuánto confía en la policía? Construye un índice aditivo simple de “confianza institucional” ¿Tiene sentido incluir los cuatro ítems en un solo índice? ¿Por qué? ¿Cómo evaluarías la consistencia interna del índice? ¿Qué ponderación alternativa podrías justificar teóricamente? 5. Problemas de medición Imagina que encuestas sobre actitudes hacia la inmigración en Santiago, Chile: ¿Qué sesgo de deseabilidad social podrías esperar? ¿En qué dirección? Propón una estrategia para mitigar ese sesgo Si administras la encuesta por teléfono, ¿qué diferencias esperarías vs. encuesta autoaplicada por internet? ¿Qué grupos podrían tener tasas más altas de no-respuesta? ¿Cómo afectaría tus estimaciones? 6. Análisis crítico de índice existente Revisa la metodología de uno de estos índices (disponibles en línea): Polity IV (democracia) Transparency International CPI (corrupción percibida) V-Dem (variedades de democracia) ¿Cómo conceptualiza el fenómeno? ¿Qué indicadores usa? ¿Cómo agrega los indicadores? Identifica una fortaleza y una debilidad de la medición ¿Para qué preguntas de investigación sería apropiado usar este índice? ¿Para cuáles no? Referencias Adcock, Robert, and David Collier. 2001. “Measurement Validity: A Shared Standard for Qualitative and Quantitative Research.” American Political Science Review 95 (3): 529–46. Collier, David, and Steven Levitsky. 2006. “Democracy with Adjectives: Conceptual Innovation in Comparative Research.” In Regimes and Democracy in Latin America: Theories and Methods, edited by Gerardo L. Munck. Oxford: Oxford University Press. Holbrook, Allyson L., Melanie C. Green, and Jon A. Krosnick. 2003. “Telephone Versus Face-to-Face Interviewing of National Probability Samples with Long Questionnaires: Comparisons of Respondent Satisficing and Social Desirability Response Bias.” Public Opinion Quarterly 67 (1): 79–125. Iyengar, Shanto, Gaurav Sood, and Yphtach Lelkes. 2012. “Affect, Not Ideology: A Social Identity Perspective on Polarization.” Public Opinion Quarterly 76 (3): 405–31. King, Gary, Robert O. Keohane, and Sidney Verba. 1994. Designing Social Inquiry: Scientific Inference in Qualitative Research. Princeton, NJ: Princeton University Press. Sartori, Giovanni. 1970. “Concept Misformation in Comparative Politics.” American Political Science Review 64 (4): 1033–53. Treier, Shawn, and Simon Jackman. 2008. “Democracy as a Latent Variable.” American Journal of Political Science 52 (1): 201–17. Verba, Sidney, Kay Lehman Schlozman, and Henry E. Brady. 1995. Voice and Equality: Civic Voluntarism in American Politics. Cambridge, MA: Harvard University Press. "],["datos.html", "Capítulo 4 Trabajando con datos 4.1 Objetivos del capítulo 4.2 Tipos de datos 4.3 Fuentes de datos para ciencias políticas 4.4 Calidad de datos 4.5 Introducción a R y RStudio 4.6 Importar datos 4.7 Manipulación básica de datos 4.8 Exportar datos 4.9 Flujo de trabajo reproducible 4.10 Resumen del capítulo 4.11 Lecturas recomendadas 4.12 Ejercicios", " Capítulo 4 Trabajando con datos 4.1 Objetivos del capítulo Al finalizar este capítulo, serás capaz de: Distinguir entre tipos de datos según estructura y fuente Evaluar calidad de datos y detectar problemas comunes Navegar el entorno de R y RStudio Importar datos desde múltiples formatos Realizar operaciones básicas de manipulación de datos en R Exportar resultados para análisis posterior o publicación 4.2 Tipos de datos Los datos que usamos en ciencias políticas varían en estructura, granularidad y fuente. Entender estas diferencias es crucial para seleccionar estrategias analíticas apropiadas. 4.2.1 Según estructura Datos de corte transversal (cross-sectional) Observaciones de múltiples unidades en un solo momento. Ejemplo: encuesta a 1,500 votantes en octubre 2024. Cada fila es un individuo; columnas son variables (edad, educación, intención de voto). Ventaja: Simplicidad analítica. Limitación: No observamos cambio temporal. No podemos distinguir efectos de período de efectos de cohorte. Datos de series temporales (time series) Observaciones de una unidad a través del tiempo. Ejemplo: tasa de desempleo mensual en Chile 2000-2024. Cada fila es un mes; columnas son variables económicas. Ventaja: Captura dinámica temporal. Limitación: Una sola unidad limita generalización. Difícil controlar confusores que varían en el tiempo. Datos de panel (longitudinal) Observaciones de múltiples unidades a través del tiempo. Ejemplo: datos electorales de 346 comunas chilenas en 8 elecciones presidenciales. Cada fila es comuna-año; columnas son variables. Ventaja: Controla diferencias persistentes entre unidades (efectos fijos). Observa cambios. Limitación: Complejidad analítica. Requiere supuestos sobre errores correlacionados. Datos jerárquicos (nested/multilevel) Observaciones anidadas en estructuras de múltiples niveles. Ejemplo: estudiantes (nivel 1) dentro de escuelas (nivel 2) dentro de comunas (nivel 3). Ventaja: Modela variación en múltiples niveles simultáneamente. Limitación: Requiere técnicas multinivel (más allá del alcance de este libro introductorio). 4.2.2 Según granularidad Datos micro (individuales) La unidad de observación es el individuo: persona, votante, legislador, manifestante. Estos datos permiten analizar comportamiento individual y heterogeneidad. Datos meso (organizacionales/locales) La unidad es un agregado intermedio: municipios, distritos electorales, partidos políticos, organizaciones. Balance entre detalle y manejo de volumen. Datos macro (nacionales/internacionales) La unidad es el país o la región. Permiten comparación internacional pero pierden variación subnacional. Además, típicamente N es pequeño (196 países en el mundo). La elección de granularidad no es neutral. King (1997) advierten sobre la falacia ecológica: inferir comportamiento individual desde patrones agregados puede ser erróneo si composición de agregados varía. 4.2.3 Según fuente Datos primarios Recolectados por el investigador para el proyecto específico. Encuestas propias, experimentos, observación directa, entrevistas codificadas. Ventaja: Control total sobre qué se mide y cómo. Limitación: Costoso en tiempo y recursos. Datos secundarios Recolectados por otros, usados por el investigador. Censos, estadísticas oficiales, encuestas de opinión pública, datos administrativos. Ventaja: Eficiencia. Acceso a muestras grandes y representativas. Limitación: No se diseñaron para nuestras preguntas específicas. Debemos aceptar decisiones de medición ajenas. Datos administrativos Generados por procesos burocráticos: registros de votantes, datos tributarios, registros judiciales, historiales legislativos. Ventaja: Cobertura completa (no muestral), alta confiabilidad. Limitación: Reflejan categorías burocráticas, no conceptos teóricos. Problemas de acceso y privacidad. Datos digitales Generados por actividad en línea: tweets, posts de Facebook, búsquedas en Google, patrones de navegación. Creciente uso en ciencias sociales computacionales. Ventaja: Volumen masivo, observación de comportamiento real (no reportado). Limitación: Representatividad problemática (no todos están en línea). Inferir actitudes desde comportamiento digital es complicado. 4.3 Fuentes de datos para ciencias políticas 4.3.1 Encuestas de opinión pública Internacionales: - World Values Survey: Actitudes y valores en ~100 países - Latinobarómetro: Opinión pública en 18 países latinoamericanos anualmente - AmericasBarometer (LAPOP): Actitudes políticas en las Américas Chile: - Encuesta CEP: Trimestral desde 1987, serie temporal más larga en Chile - CASEN: Caracterización socioeconómica nacional (bienal) - Encuesta Bicentenario UC-Adimark 4.3.2 Datos electorales Servicio Electoral de Chile (SERVEL): Resultados electorales desagregados International IDEA: Datos electorales comparados internacionalmente Database of Political Institutions (DPI): Instituciones y resultados electorales 4.3.3 Datos económicos y sociales Banco Mundial: Indicadores de desarrollo mundial CEPAL: Estadísticas económicas y sociales de América Latina INE Chile: Estadísticas oficiales nacionales OECD: Datos comparados de países desarrollados 4.3.4 Datos sobre instituciones políticas Polity V: Características de regímenes políticos V-Dem: Variedades de democracia, múltiples dimensiones Database of Political Institutions (DPI): Sistemas electorales, estructuras gubernamentales Comparative Constitutions Project: Contenido de constituciones 4.3.5 Datos legislativos VoteView: Votaciones nominales del Congreso de EE.UU. Manifesto Project: Contenido de manifiestos partidarios Cámara de Diputados de Chile: Votaciones nominales (requiere scraping) 4.4 Calidad de datos No todos los datos son igualmente útiles. Evaluar calidad es responsabilidad del investigador. 4.4.1 Dimensiones de calidad 1. Validez ¿Los datos miden lo que pretenden medir? Vimos validez de medición en Capítulo 3. Aquí, evaluar si las categorías y procedimientos de recolección capturan conceptos teóricos relevantes. 2. Confiabilidad ¿Los datos son consistentes? ¿Diferentes aplicaciones del mismo procedimiento producen resultados similares? En encuestas, verificar si preguntas se formulan igual en diferentes olas. 3. Cobertura ¿Qué población representan los datos? Si una encuesta solo contacta teléfonos fijos, subrepresenta jóvenes. Si datos administrativos solo cubren sector formal, omiten informalidad. 4. Precisión ¿Cuán exactas son las mediciones? Encuestas con muestras pequeñas tienen márgenes de error grandes. Datos administrativos pueden tener errores de digitación o categorización. 5. Actualidad (timeliness) ¿Cuán recientes son los datos? Para fenómenos que cambian rápido, datos de hace 5 años pueden ser obsoletos. 6. Accesibilidad ¿Los datos están disponibles? ¿En qué formato? ¿Con qué restricciones? Algunos datos excelentes son inaccesibles por razones legales o políticas. 4.4.2 Problemas comunes Datos faltantes (missing data) Los valores faltantes son ubicuos. Pueden ser: Completamente aleatorios (MCAR): La probabilidad de faltar no depende de nada. Raro en práctica. Aleatorios condicional (MAR): La probabilidad depende de variables observadas. Manejable estadísticamente. No aleatorios (MNAR): La probabilidad depende del valor no observado. Problemático. Estrategias: eliminación listwise (perder casos), imputación, modelar explícitamente los datos faltantes. Errores de medición Discrepancias entre valor real y valor registrado. Pueden ser aleatorios (ruido) o sistemáticos (sesgo). Errores sistemáticos son más graves porque sesgan estimaciones. Codificación inconsistente Variables categóricas pueden codificarse de forma diferente en distintas partes del dataset. Ejemplo: género como “Masculino/Femenino”, “M/F”, “1/2”, “Hombre/Mujer” en diferentes variables. Esto complica análisis. Valores atípicos (outliers) Observaciones extremas. Pueden ser errores de digitación o casos genuinos inusuales. Antes de eliminarlos, investigar. Duplicados Observaciones repetidas erróneamente. Común cuando múltiples fuentes se fusionan sin cuidado. 4.5 Introducción a R y RStudio R es un lenguaje de programación estadística y entorno para análisis de datos. RStudio es un entorno de desarrollo integrado (IDE) que hace más amigable trabajar con R. 4.5.1 ¿Por qué R? Ventajas: - Gratuito y de código abierto: Sin costos de licencia - Reproducible: Scripts documentan exactamente qué se hizo - Extensible: Miles de paquetes para técnicas especializadas - Comunidad activa: Foros, tutoriales, ayuda abundante - Estándar en ciencias sociales cuantitativas: Facilita colaboración y replicación Desventajas: - Curva de aprendizaje: Programar requiere práctica - Múltiples formas de hacer lo mismo: Puede ser confuso para principiantes 4.5.2 Instalación Descargar R: https://cran.r-project.org/ Descargar RStudio: https://posit.co/download/rstudio-desktop/ Instalar ambos (primero R, luego RStudio) 4.5.3 Anatomía de RStudio RStudio tiene cuatro paneles principales: Editor de scripts (arriba izquierda): Donde escribes código para guardar y ejecutar Consola (abajo izquierda): Donde se ejecuta el código y aparecen resultados Environment (arriba derecha): Muestra objetos en memoria (datasets, variables) Files/Plots/Packages/Help (abajo derecha): Navegación de archivos, gráficos, ayuda 4.5.4 Paquetes R base es poderoso, pero paquetes extienden funcionalidad. Instalación (una vez): install.packages(&quot;tidyverse&quot;) # Suite de paquetes para manipulación de datos install.packages(&quot;haven&quot;) # Leer archivos SPSS, Stata, SAS install.packages(&quot;readxl&quot;) # Leer archivos Excel install.packages(&quot;foreign&quot;) # Leer múltiples formatos Cargar paquetes (cada sesión): library(tidyverse) library(haven) 4.5.5 Objetos básicos en R Vectores: Secuencias de elementos del mismo tipo edades &lt;- c(23, 45, 67, 34, 29) partidos &lt;- c(&quot;PS&quot;, &quot;UDI&quot;, &quot;RN&quot;, &quot;PC&quot;, &quot;PPD&quot;) Data frames: Tablas con filas (observaciones) y columnas (variables) datos &lt;- data.frame( id = 1:5, edad = c(23, 45, 67, 34, 29), partido = c(&quot;PS&quot;, &quot;UDI&quot;, &quot;RN&quot;, &quot;PC&quot;, &quot;PPD&quot;), voto = c(&quot;Apruebo&quot;, &quot;Rechazo&quot;, &quot;Rechazo&quot;, &quot;Apruebo&quot;, &quot;Apruebo&quot;) ) Funciones: Operaciones que transforman inputs en outputs mean(edades) # Promedio ## [1] 39.6 sd(edades) # Desviación estándar ## [1] 17.31473 table(datos$voto) # Tabla de frecuencias ## ## Apruebo Rechazo ## 3 2 4.5.6 Directorios de trabajo R busca y guarda archivos en el “directorio de trabajo”. Verificar: getwd() # ¿Dónde estoy? Cambiar (ajustar ruta según tu computador): setwd(&quot;~/Documentos/Investigacion/datos&quot;) Mejor práctica: usar proyectos de RStudio (.Rproj). Esto establece automáticamente el directorio de trabajo en la carpeta del proyecto. 4.6 Importar datos Los datos pueden venir en múltiples formatos. R puede leer la mayoría. 4.6.1 Archivos de texto: CSV Los archivos CSV (comma-separated values) son universales. Formato simple: id,edad,partido 1,23,PS 2,45,UDI 3,67,RN Importar con R base: datos &lt;- read.csv(&quot;encuesta.csv&quot;) Importar con readr (parte de tidyverse, más rápido): library(readr) datos &lt;- read_csv(&quot;encuesta.csv&quot;) Parámetros comunes: - sep: Separador (, por defecto, ; en algunos países) - header: ¿Primera fila son nombres de variables? (TRUE por defecto) - na.strings: Cómo se codifican valores faltantes (“NA”, “.”, ““) Ejemplo: datos &lt;- read_csv(&quot;encuesta.csv&quot;, na = c(&quot;&quot;, &quot;NA&quot;, &quot;No sabe&quot;), col_types = cols(edad = col_integer(), partido = col_character())) 4.6.2 Archivos de Excel Excel es ubicuo en administración pública. Paquete readxl: library(readxl) datos &lt;- read_excel(&quot;resultados_electorales.xlsx&quot;, sheet = &quot;Presidenciales_2021&quot;) Especificar rango: datos &lt;- read_excel(&quot;archivo.xlsx&quot;, sheet = 2, range = &quot;A1:F100&quot;) 4.6.3 Archivos de software estadístico Stata (.dta): library(haven) datos &lt;- read_dta(&quot;encuesta_casen.dta&quot;) SPSS (.sav): datos &lt;- read_sav(&quot;estudio_cep.sav&quot;) SAS: datos &lt;- read_sas(&quot;datos.sas7bdat&quot;) El paquete haven preserva etiquetas de valores, muy común en encuestas. Ejemplo: datos &lt;- read_dta(&quot;encuesta.dta&quot;) # Variable &quot;educ&quot; tiene valores 1,2,3 con etiquetas &quot;Primaria&quot;,&quot;Secundaria&quot;,&quot;Universitaria&quot; attributes(datos$educ)$labels 4.6.4 Datos en línea Muchos datos están en URLs. Importar directamente: url &lt;- &quot;https://ejemplo.com/datos.csv&quot; datos &lt;- read_csv(url) Para datos de APIs, usar paquetes especializados: - WDI: Banco Mundial - quantmod: Datos financieros - rtweet: API de Twitter (ahora X) 4.6.5 Datos desde bases de datos Para bases SQL, usar DBI: library(DBI) con &lt;- dbConnect(RSQLite::SQLite(), &quot;mi_base.db&quot;) datos &lt;- dbGetQuery(con, &quot;SELECT * FROM votaciones WHERE year = 2021&quot;) dbDisconnect(con) 4.7 Manipulación básica de datos Una vez importados, los datos rara vez están listos para análisis. Necesitan limpieza y transformación. 4.7.1 Inspeccionar datos Primeros y últimos casos: head(datos) # Primeros 6 casos tail(datos, 10) # Últimos 10 casos Estructura: str(datos) # Tipo de cada variable summary(datos) # Resumen estadístico glimpse(datos) # Vista compacta (tidyverse) Nombres de variables: names(datos) colnames(datos) Dimensiones: dim(datos) # Filas y columnas nrow(datos) # Número de filas ncol(datos) # Número de columnas 4.7.2 Seleccionar variables R base: datos_reducido &lt;- datos[, c(&quot;id&quot;, &quot;edad&quot;, &quot;partido&quot;)] Tidyverse (dplyr): library(dplyr) datos_reducido &lt;- select(datos, id, edad, partido) Seleccionar por criterio: # Todas las variables que empiezan con &quot;voto_&quot; datos_reducido &lt;- select(datos, starts_with(&quot;voto_&quot;)) # Todas las variables numéricas datos_reducido &lt;- select(datos, where(is.numeric)) 4.7.3 Filtrar casos R base: jovenes &lt;- datos[datos$edad &lt; 30, ] Tidyverse: jovenes &lt;- filter(datos, edad &lt; 30) jovenes_izquierda &lt;- filter(datos, edad &lt; 30 &amp; partido %in% c(&quot;PS&quot;, &quot;PC&quot;, &quot;FA&quot;)) 4.7.4 Crear y transformar variables R base: datos$edad_decadas &lt;- datos$edad / 10 datos$mayor_edad &lt;- ifelse(datos$edad &gt;= 18, &quot;Sí&quot;, &quot;No&quot;) Tidyverse: datos &lt;- mutate(datos, edad_decadas = edad / 10, mayor_edad = if_else(edad &gt;= 18, &quot;Sí&quot;, &quot;No&quot;), edad_cat = case_when( edad &lt; 30 ~ &quot;Joven&quot;, edad &lt; 60 ~ &quot;Adulto&quot;, TRUE ~ &quot;Mayor&quot; )) 4.7.5 Recodificar variables Cambiar categorías: datos &lt;- mutate(datos, partido_bloques = case_when( partido %in% c(&quot;PS&quot;, &quot;PC&quot;, &quot;PPD&quot;, &quot;FA&quot;) ~ &quot;Izquierda&quot;, partido %in% c(&quot;UDI&quot;, &quot;RN&quot;, &quot;EVOPOLI&quot;) ~ &quot;Derecha&quot;, TRUE ~ &quot;Centro/Otros&quot; )) 4.7.6 Renombrar variables R base: names(datos)[names(datos) == &quot;p1&quot;] &lt;- &quot;confianza_congreso&quot; Tidyverse: datos &lt;- rename(datos, confianza_congreso = p1, confianza_gobierno = p2) 4.7.7 Ordenar datos Por edad (ascendente): datos_ordenado &lt;- arrange(datos, edad) Por edad (descendente): datos_ordenado &lt;- arrange(datos, desc(edad)) Por múltiples variables: datos_ordenado &lt;- arrange(datos, partido, edad) 4.7.8 Agregar datos Resumir por grupos: library(dplyr) resumen_partido &lt;- datos %&gt;% group_by(partido) %&gt;% summarise( n = n(), edad_promedio = mean(edad, na.rm = TRUE), edad_sd = sd(edad, na.rm = TRUE) ) El operador %&gt;% (pipe) pasa el resultado de una función a la siguiente. El código anterior dice: “toma datos, agrúpalo por partido, calcula estadísticos”. 4.7.9 Unir datasets Left join: Mantener todos los casos del dataset izquierdo datos_completo &lt;- left_join(encuesta, resultados_electorales, by = &quot;comuna_id&quot;) Inner join: Mantener solo casos presentes en ambos datasets datos_completo &lt;- inner_join(encuesta, resultados_electorales, by = &quot;comuna_id&quot;) 4.8 Exportar datos Después de limpiar y transformar datos, es útil guardarlos. 4.8.1 CSV write_csv(datos_limpios, &quot;datos_procesados.csv&quot;) 4.8.2 Formato de R Guardar como .RDS (R Data Serialization) preserva estructura completa: saveRDS(datos_limpios, &quot;datos_procesados.rds&quot;) Leer después: datos &lt;- readRDS(&quot;datos_procesados.rds&quot;) 4.8.3 Stata library(haven) write_dta(datos_limpios, &quot;datos_procesados.dta&quot;) 4.8.4 Excel library(writexl) write_xlsx(datos_limpios, &quot;datos_procesados.xlsx&quot;) 4.9 Flujo de trabajo reproducible La reproducibilidad es esencial en ciencia. Otros (y tu yo futuro) deben poder replicar exactamente lo que hiciste. 4.9.1 Principios 1. Usa scripts, no clics Todo debe estar en código. No hacer transformaciones manualmente en Excel que no queden documentadas. 2. Nunca modifiques datos originales Lee los datos crudos, transfórmalos en R, guarda la versión procesada. Mantén los originales intactos. 3. Documenta tu código Comentarios explican por qué hiciste algo: # Recodifico educación en tres categorías para simplificar análisis # La categoría &quot;técnica&quot; es pequeña y la combino con &quot;secundaria&quot; datos &lt;- mutate(datos, educ_cat = case_when( educ &lt;= 2 ~ &quot;Básica&quot;, educ %in% c(3,4) ~ &quot;Media&quot;, educ &gt;= 5 ~ &quot;Superior&quot; )) 4. Organiza tu proyecto Estructura de carpetas clara: proyecto/ datos/ crudos/ procesados/ scripts/ 01_limpieza.R 02_analisis.R resultados/ tablas/ graficos/ documento/ 5. Usa control de versiones Git y GitHub permiten rastrear cambios y colaborar. No es obligatorio para principiantes, pero altamente recomendable a medida que proyectos crecen. 4.9.2 R Markdown R Markdown integra código, resultados y texto en un solo documento. Permite generar reportes reproducibles en HTML, PDF o Word. Ejemplo básico (analisis.Rmd): --- title: &quot;Análisis de participación electoral&quot; author: &quot;Tu Nombre&quot; date: &quot;2025-11-17&quot; output: html_document --- ## Introducción Este análisis examina factores asociados a participación electoral. ## Resultados La participación promedio fue XX%. Al compilar (“Knit”), R ejecuta el código e inserta resultados en el documento final. Si los datos cambian, el documento se actualiza automáticamente. 4.10 Resumen del capítulo Los datos de ciencias políticas varían en estructura (corte transversal, series temporales, panel, jerárquicos), granularidad (micro, meso, macro) y fuente (primarios, secundarios, administrativos, digitales). Cada tipo tiene ventajas y limitaciones. Evaluar calidad de datos es crucial: validez, confiabilidad, cobertura, precisión, actualidad, accesibilidad. Problemas comunes incluyen datos faltantes, errores de medición, codificación inconsistente, outliers y duplicados. R y RStudio proveen un entorno poderoso y reproducible para análisis cuantitativo. Los datos pueden importarse desde múltiples formatos (CSV, Excel, Stata, SPSS, bases de datos, URLs). Los paquetes readr, haven, readxl y foreign facilitan importación. La manipulación de datos involucra inspeccionar, seleccionar variables, filtrar casos, crear nuevas variables, recodificar, ordenar, agregar y unir datasets. El paquete dplyr (parte de tidyverse) provee funciones intuitivas para estas operaciones. Exportar datos procesados en formatos apropiados preserva trabajo y facilita colaboración. El flujo de trabajo reproducible —usando scripts, documentando código, manteniendo organización clara, nunca modificando datos originales— es esencial para investigación rigurosa. 4.11 Lecturas recomendadas Manipulación de datos en R: Wickham, H., &amp; Grolemund, G. (2017). R for Data Science. O’Reilly. [Disponible gratis en https://r4ds.had.co.nz/] → Guía comprehensiva y accesible sobre tidyverse. Reproducibilidad: Gandrud, C. (2015). Reproducible Research with R and RStudio (2nd ed.). CRC Press. → Prácticas y herramientas para investigación reproducible. Calidad de datos: Karr, A. F., Sanil, A. P., &amp; Banks, D. L. (2006). Data quality: A statistical perspective. Statistical Methodology, 3(2), 137-173. → Perspectiva estadística sobre dimensiones de calidad de datos. Datos faltantes: Little, R. J., &amp; Rubin, D. B. (2019). Statistical Analysis with Missing Data (3rd ed.). Wiley. → Tratado técnico sobre manejo de datos faltantes. Recursos en línea: Documentación de tidyverse: https://www.tidyverse.org/ RStudio cheatsheets: https://posit.co/resources/cheatsheets/ Stack Overflow (para preguntas específicas): https://stackoverflow.com/questions/tagged/r 4.12 Ejercicios 1. Evaluación de calidad Descarga datos del CEP (https://www.cepchile.cl/opinion-publica/encuesta-cep/) o Latinobarómetro (https://www.latinobarometro.org/). ¿Qué población representa la muestra? ¿Cuál es el tamaño muestral y margen de error? Identifica tres variables. Para cada una, evalúa: ¿Es válida para medir el concepto que pretende? ¿Qué problemas de medición podrían existir? ¿Qué información sobre calidad de datos provee la documentación? 2. Importar y explorar Importa un dataset de tu elección en R: # Tu código aquí ¿Cuántos casos y variables tiene? ¿Qué tipos de variables contiene (numéricas, categóricas)? ¿Cuántos valores faltantes hay en cada variable? Identifica y describe un valor atípico 3. Limpieza de datos Con el dataset del ejercicio 2: Selecciona 5-10 variables relevantes para una pregunta de investigación que formules Filtra casos para incluir solo observaciones completas (sin valores faltantes en variables clave) Crea al menos dos variables nuevas mediante transformación o recodificación Genera un resumen estadístico de tus variables 4. Datos faltantes # Crea un dataset con valores faltantes set.seed(123) datos &lt;- data.frame( id = 1:100, edad = sample(18:80, 100, replace = TRUE), ingreso = rnorm(100, 500000, 150000) ) # Introduce valores faltantes no aleatorios: # Personas mayores de 60 tienen 50% probabilidad de no reportar ingreso datos$ingreso[datos$edad &gt; 60 &amp; runif(100) &lt; 0.5] &lt;- NA ¿Cuántos valores faltantes hay en ingreso? Calcula ingreso promedio: (1) eliminando casos con valores faltantes, (2) solo entre quienes reportaron. ¿Difieren las estimaciones? ¿Por qué? ¿Qué tipo de datos faltantes son estos (MCAR, MAR, MNAR)? ¿Cómo afecta esto las inferencias sobre ingreso promedio en la población? 5. Combinar datasets Tienes dos datasets: # Resultados electorales por comuna resultados &lt;- data.frame( comuna_id = 1:5, comuna = c(&quot;Santiago&quot;, &quot;Valparaíso&quot;, &quot;Concepción&quot;, &quot;La Serena&quot;, &quot;Temuco&quot;), votos_derecha = c(45, 38, 42, 50, 35), votos_izquierda = c(40, 48, 43, 35, 50) ) # Características socioeconómicas socioeconomico &lt;- data.frame( comuna_id = c(1, 2, 3, 6), ingreso_promedio = c(800000, 650000, 700000, 600000), desigualdad_gini = c(0.48, 0.45, 0.47, 0.50) ) Combina los datasets manteniendo todas las comunas de resultados ¿Qué problema de datos observas después de combinar? ¿Cómo manejarías ese problema para análisis posterior? 6. Proyecto propio Identifica un dataset relevante para tu tesis o interés de investigación: Descríbelo: fuente, estructura (corte transversal/panel/etc), unidad de análisis, N Importa a R y documenta el proceso Realiza una limpieza básica: seleccionar variables relevantes, verificar valores faltantes y outliers, crear variables derivadas si es necesario Genera un reporte en R Markdown que documente: tu pregunta de investigación, descripción de los datos, proceso de limpieza, y estadísticas descriptivas básicas Exporta la versión limpia de los datos Referencias King, Gary. 1997. “A Solution to the Ecological Inference Problem: Reconstructing Individual Behavior from Aggregate Data.” American Journal of Political Science 41 (4): 1027–53. "],["descriptiva.html", "Capítulo 5 Estadística descriptiva 5.1 Objetivos del capítulo 5.2 Distribuciones de frecuencia 5.3 Medidas de tendencia central 5.4 Medidas de dispersión 5.5 Percentiles y cuartiles 5.6 Forma de la distribución 5.7 Gráficos exploratorios 5.8 Detección de valores atípicos 5.9 Estadística descriptiva multivariada 5.10 Estadística descriptiva por grupos 5.11 Resumen del capítulo 5.12 Lecturas recomendadas 5.13 Ejercicios", " Capítulo 5 Estadística descriptiva 5.1 Objetivos del capítulo Al finalizar este capítulo, serás capaz de: Calcular e interpretar medidas de tendencia central Calcular e interpretar medidas de dispersión Describir la forma de distribuciones Identificar cuándo usar cada medida descriptiva Generar gráficos exploratorios en R Detectar valores atípicos mediante métodos gráficos y numéricos 5.2 Distribuciones de frecuencia Antes de calcular estadísticos, conviene visualizar cómo se distribuyen los datos. Una distribución de frecuencia muestra cuántas observaciones caen en cada valor o rango. 5.2.1 Tablas de frecuencia Para variables categóricas, contamos casos en cada categoría: # Simulamos orientación política en encuesta set.seed(123) encuesta &lt;- data.frame( orientacion = sample(c(&quot;Izquierda&quot;, &quot;Centro&quot;, &quot;Derecha&quot;, &quot;Ninguna&quot;), 800, replace = TRUE, prob = c(0.30, 0.25, 0.28, 0.17)) ) # Frecuencias absolutas table(encuesta$orientacion) ## ## Centro Derecha Izquierda Ninguna ## 199 230 238 133 # Frecuencias relativas (proporciones) prop.table(table(encuesta$orientacion)) ## ## Centro Derecha Izquierda Ninguna ## 0.24875 0.28750 0.29750 0.16625 # Porcentajes prop.table(table(encuesta$orientacion)) * 100 ## ## Centro Derecha Izquierda Ninguna ## 24.875 28.750 29.750 16.625 Con tidyverse: encuesta %&gt;% count(orientacion) %&gt;% mutate(porcentaje = n / sum(n) * 100) ## orientacion n porcentaje ## 1 Centro 199 24.875 ## 2 Derecha 230 28.750 ## 3 Izquierda 238 29.750 ## 4 Ninguna 133 16.625 5.2.2 Histogramas Para variables continuas, agrupamos en intervalos (bins): ggplot(comunas, aes(x = participacion)) + geom_histogram(bins = 30, fill = &quot;steelblue&quot;, color = &quot;white&quot;) + labs(x = &quot;Participación electoral (%)&quot;, y = &quot;Número de comunas&quot;, title = &quot;Distribución de participación electoral&quot;) + theme_minimal() Figura 5.1: Distribución de participación electoral en comunas El número de bins afecta la visualización: p1 &lt;- ggplot(comunas, aes(x = participacion)) + geom_histogram(bins = 10, fill = &quot;steelblue&quot;, alpha = 0.7) + labs(title = &quot;10 bins&quot;) + theme_minimal() p2 &lt;- ggplot(comunas, aes(x = participacion)) + geom_histogram(bins = 50, fill = &quot;steelblue&quot;, alpha = 0.7) + labs(title = &quot;50 bins&quot;) + theme_minimal() library(patchwork) p1 | p2 Figura 5.2: Histogramas con diferentes números de bins Muy pocos bins ocultan detalles; demasiados bins generan ruido. La regla de Sturges sugiere \\(k = 1 + 3.322 \\log(n)\\) bins. 5.3 Medidas de tendencia central Las medidas de tendencia central resumen la ubicación “típica” de los datos. La media (\\(\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i\\)) es el promedio que usa toda la información pero es sensible a valores extremos (outliers)^[EJEMPLO DE DESIGUALDAD: En 2022, el ingreso PROMEDIO en Chile era ~$650,000, pero la MEDIANA era ~$420,000. ¿Por qué la diferencia? Porque la distribución de ingresos es asimétrica: pocos súper-ricos jalan la media hacia arriba, pero la mediana (ingreso de la persona en el medio de la distribución ordenada) es más representativa de la “persona típica”. Por eso reportes de desigualdad SIEMPRE usan mediana, no media. La media puede ser engañosa cuando hay outliers o asimetría. y apropiada para distribuciones simétricas. La mediana es el valor que divide la distribución en dos mitades iguales (50% por debajo, 50% por encima), es robusta a outliers, apropiada para distribuciones asimétricas, y tiene interpretación intuitiva. La moda es el valor más frecuente; para variables continuas tiene sentido solo con categorías o bins, siendo poco informativa sin agrupar pero útil para identificar multimodalidad. mean(comunas$participacion) ## [1] 46.75662 median(comunas$participacion) ## [1] 46.79276 # Ejemplo de sensibilidad a outliers ingresos &lt;- c(500, 550, 600, 650, 700, 750, 800, 5000) mean(ingresos) # La media se dispara por el valor extremo ## [1] 1193.75 # Moda en variable categórica tabla &lt;- table(encuesta$orientacion) names(tabla)[which.max(tabla)] ## [1] &quot;Izquierda&quot; # Simulamos distribución bimodal (dos grupos distintos) set.seed(456) bimodal &lt;- c(rnorm(200, mean = 30, sd = 5), rnorm(200, mean = 55, sd = 5)) ggplot(data.frame(x = bimodal), aes(x = x)) + geom_histogram(bins = 40, fill = &quot;coral&quot;, alpha = 0.7) + labs(title = &quot;Distribución bimodal&quot;) + theme_minimal() Figura 5.3: Distribución bimodal Regla general para elegir: distribuciones simétricas (media, usa toda la información), distribuciones asimétricas^[¿CÓMO SABER SI TU DISTRIBUCIÓN ES ASIMÉTRICA? (1) Haz un histograma: si tiene “cola” larga a un lado, es asimétrica. (2) Compara media y mediana: si media &gt;&gt; mediana, asimetría a la derecha (ej: ingresos); si media &lt;&lt; mediana, asimetría a la izquierda (raro en ciencias sociales). (3) Variables que NO pueden ser negativas (ingresos, edad, votos) frecuentemente son asimétricas a la derecha. DEFAULT SEGURO: reporta AMBAS (media Y mediana) siempre. (mediana, robusta a extremos), variables ordinales (mediana, la media no tiene sentido para categorías ordenadas), variables nominales (moda, única medida con sentido) # Distribución asimétrica a la derecha set.seed(789) asimetrica &lt;- rgamma(1000, shape = 2, rate = 0.5) media &lt;- mean(asimetrica) mediana &lt;- median(asimetrica) ggplot(data.frame(x = asimetrica), aes(x = x)) + geom_histogram(bins = 40, fill = &quot;lightblue&quot;, alpha = 0.7) + geom_vline(aes(xintercept = media, color = &quot;Media&quot;), linewidth = 1, linetype = &quot;dashed&quot;) + geom_vline(aes(xintercept = mediana, color = &quot;Mediana&quot;), linewidth = 1, linetype = &quot;dashed&quot;) + scale_color_manual(values = c(&quot;Media&quot; = &quot;red&quot;, &quot;Mediana&quot; = &quot;blue&quot;)) + labs(title = &quot;Distribución asimétrica: media &gt; mediana&quot;, color = &quot;&quot;) + theme_minimal() Figura 5.4: Media vs. mediana en distribución asimétrica En distribuciones asimétricas a la derecha, la media excede la mediana (arrastrada por valores altos). En asimétricas a la izquierda, la media es menor que la mediana. 5.4 Medidas de dispersión Las medidas de tendencia central resumen “dónde” están los datos. Las medidas de dispersión resumen cuánto varían. 5.4.1 Rango El rango es la diferencia entre el máximo y el mínimo: range(comunas$participacion) ## [1] 23.05528 68.61513 diff(range(comunas$participacion)) ## [1] 45.55985 Simple pero sensible a outliers. Un solo valor extremo determina el rango. 5.4.2 Rango intercuartílico (IQR) El IQR es la diferencia entre el tercer cuartil (Q3) y el primer cuartil (Q1). Captura el 50% central de los datos. quantile(comunas$participacion, probs = c(0.25, 0.75)) ## 25% 75% ## 41.68235 51.96510 IQR(comunas$participacion) ## [1] 10.28275 Interpretación: El 50% central de comunas tiene participación entre 41.7% y 52%. IQR es robusto a outliers—solo usa el 50% central. 5.4.3 Varianza La varianza (\\(s^2\\)) mide la dispersión promedio al cuadrado respecto a la media: \\[s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n}(x_i - \\bar{x})^2\\] var(comunas$participacion) ## [1] 58.69646 ¿Por qué \\(n-1\\) y no \\(n\\)? La corrección de Bessel ajusta por usar la media muestral en lugar de la media poblacional. Esto hace que la varianza muestral sea un estimador insesgado de la varianza poblacional. Problema: La varianza está en unidades al cuadrado (% al cuadrado), difícil de interpretar. 5.4.4 Desviación estándar La desviación estándar (\\(s\\)) es la raíz cuadrada de la varianza: \\[s = \\sqrt{s^2}\\] sd(comunas$participacion) ## [1] 7.661361 Interpretación: En promedio, las comunas se desvían 7.7 puntos porcentuales de la participación media. La desviación estándar está en las mismas unidades que los datos originales, facilitando interpretación. 5.4.5 Coeficiente de variación El coeficiente de variación (CV) es la desviación estándar relativa a la media: \\[CV = \\frac{s}{\\bar{x}} \\times 100\\%\\] cv &lt;- (sd(comunas$participacion) / mean(comunas$participacion)) * 100 cv ## [1] 16.38562 CV permite comparar variabilidad entre variables con diferentes escalas. Participación electoral (%) y años de educación tienen unidades incomparables, pero sus CVs son comparables. # Comparar variabilidad de dos variables cv_participacion &lt;- sd(comunas$participacion) / mean(comunas$participacion) cv_educacion &lt;- sd(comunas$educ_superior) / mean(comunas$educ_superior) data.frame( Variable = c(&quot;Participación&quot;, &quot;Educación superior&quot;), CV = c(cv_participacion, cv_educacion) ) %&gt;% kable(digits = 3) Variable CV Participación 0.164 Educación superior 0.417 5.4.6 Comparación de medidas de dispersión # Resumen de dispersión data.frame( Medida = c(&quot;Rango&quot;, &quot;IQR&quot;, &quot;Varianza&quot;, &quot;Desv. Estándar&quot;, &quot;CV (%)&quot;), Valor = c( diff(range(comunas$participacion)), IQR(comunas$participacion), var(comunas$participacion), sd(comunas$participacion), cv ) ) %&gt;% kable(digits = 2) Medida Valor Rango 45.56 IQR 10.28 Varianza 58.70 Desv. Estándar 7.66 CV (%) 16.39 5.5 Percentiles y cuartiles Los percentiles dividen la distribución en 100 partes iguales. El percentil \\(p\\) es el valor por debajo del cual cae el \\(p\\)% de observaciones. # Percentiles importantes quantile(comunas$participacion, probs = c(0.05, 0.25, 0.50, 0.75, 0.95)) ## 5% 25% 50% 75% 95% ## 34.70348 41.68235 46.79276 51.96510 58.54432 Cuartiles son percentiles específicos: Q1 (primer cuartil): Percentil 25 Q2 (segundo cuartil): Mediana (percentil 50) Q3 (tercer cuartil): Percentil 75 Interpretación: El 25% de comunas tiene participación ≤ 41.7%. El 75% tiene participación ≤ 52%. 5.5.1 Resumen de cinco números El resumen de cinco números (five-number summary) incluye: Mínimo Q1 Mediana Q3 Máximo summary(comunas$participacion) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 23.06 41.68 46.79 46.76 51.97 68.62 Este resumen captura ubicación, dispersión y extremos. Es la base del boxplot. 5.6 Forma de la distribución 5.6.1 Asimetría (skewness) La asimetría mide si la distribución se inclina hacia un lado: Asimetría positiva (derecha): Cola larga hacia la derecha. Media &gt; Mediana. Asimetría negativa (izquierda): Cola larga hacia la izquierda. Media &lt; Mediana. Simétrica: Colas balanceadas. Media ≈ Mediana. Coeficiente de asimetría: # Coeficiente de asimetría (requiere paquete moments o e1071) library(e1071) skewness(comunas$participacion) ## [1] -0.03970368 \\(\\text{Skewness} \\approx 0\\): Simétrica \\(\\text{Skewness} &gt; 0\\): Asimétrica a la derecha \\(\\text{Skewness} &lt; 0\\): Asimétrica a la izquierda set.seed(111) # Asimétrica derecha der &lt;- rgamma(1000, shape = 2, rate = 1) # Simétrica sim &lt;- rnorm(1000, mean = 5, sd = 2) # Asimétrica izquierda izq &lt;- 10 - rgamma(1000, shape = 2, rate = 1) datos_asimetria &lt;- data.frame( valor = c(der, sim, izq), tipo = rep(c(&quot;Asimétrica derecha&quot;, &quot;Simétrica&quot;, &quot;Asimétrica izquierda&quot;), each = 1000) ) ggplot(datos_asimetria, aes(x = valor, fill = tipo)) + geom_density(alpha = 0.6) + facet_wrap(~tipo, scales = &quot;free&quot;) + theme_minimal() + theme(legend.position = &quot;none&quot;) Figura 5.5: Distribuciones con diferente asimetría 5.6.2 Curtosis (kurtosis) La curtosis mide si la distribución tiene colas pesadas o ligeras respecto a la normal: kurtosis(comunas$participacion) ## [1] 0.04203359 Leptocúrtica (curtosis &gt; 3): Colas pesadas, más outliers Mesocúrtica (curtosis ≈ 3): Similar a distribución normal Platicúrtica (curtosis &lt; 3): Colas ligeras, pocos outliers En práctica, la asimetría importa más que la curtosis para análisis aplicado. 5.7 Gráficos exploratorios 5.7.1 Boxplot (diagrama de caja) El boxplot visualiza el resumen de cinco números: ggplot(comunas, aes(y = participacion)) + geom_boxplot(fill = &quot;lightblue&quot;, width = 0.5) + labs(y = &quot;Participación electoral (%)&quot;, title = &quot;Distribución de participación electoral&quot;) + theme_minimal() + theme(axis.text.x = element_blank()) Figura 5.6: Boxplot de participación electoral Componentes: Caja: IQR (Q1 a Q3) Línea dentro de caja: Mediana Bigotes (whiskers): Extienden hasta 1.5×IQR desde Q1/Q3 Puntos: Outliers (valores más allá de bigotes) Comparar distribuciones entre grupos: # Crear categorías de pobreza comunas &lt;- comunas %&gt;% mutate(pobreza_cat = cut(pobreza, breaks = quantile(pobreza, probs = c(0, 1/3, 2/3, 1)), labels = c(&quot;Baja&quot;, &quot;Media&quot;, &quot;Alta&quot;), include.lowest = TRUE)) ggplot(comunas, aes(x = pobreza_cat, y = participacion, fill = pobreza_cat)) + geom_boxplot(alpha = 0.7) + labs(x = &quot;Nivel de pobreza&quot;, y = &quot;Participación electoral (%)&quot;, title = &quot;Participación electoral según nivel de pobreza&quot;) + theme_minimal() + theme(legend.position = &quot;none&quot;) Figura 5.7: Participación electoral por nivel de pobreza (terciles) 5.7.2 Violin plot Combina boxplot con densidad: ggplot(comunas, aes(x = pobreza_cat, y = participacion, fill = pobreza_cat)) + geom_violin(alpha = 0.7) + geom_boxplot(width = 0.2, fill = &quot;white&quot;, alpha = 0.8) + labs(x = &quot;Nivel de pobreza&quot;, y = &quot;Participación electoral (%)&quot;) + theme_minimal() + theme(legend.position = &quot;none&quot;) Figura 5.8: Violin plot de participación por pobreza 5.7.3 Gráfico de densidad Alternativa suave al histograma: ggplot(comunas, aes(x = participacion)) + geom_density(fill = &quot;steelblue&quot;, alpha = 0.5) + geom_vline(aes(xintercept = mean(participacion)), color = &quot;red&quot;, linetype = &quot;dashed&quot;, linewidth = 1) + geom_vline(aes(xintercept = median(participacion)), color = &quot;blue&quot;, linetype = &quot;dashed&quot;, linewidth = 1) + annotate(&quot;text&quot;, x = mean(comunas$participacion) + 2, y = 0.045, label = &quot;Media&quot;, color = &quot;red&quot;) + annotate(&quot;text&quot;, x = median(comunas$participacion) - 2, y = 0.045, label = &quot;Mediana&quot;, color = &quot;blue&quot;) + labs(x = &quot;Participación electoral (%)&quot;, y = &quot;Densidad&quot;) + theme_minimal() Figura 5.9: Densidad de participación electoral 5.8 Detección de valores atípicos Los outliers son observaciones inusualmente extremas. Pueden ser errores de medición o casos genuinamente inusuales. 5.8.1 Método IQR Criterio estándar: outliers están más allá de \\(Q1 - 1.5 \\times IQR\\) o \\(Q3 + 1.5 \\times IQR\\): Q1 &lt;- quantile(comunas$participacion, 0.25) Q3 &lt;- quantile(comunas$participacion, 0.75) IQR_val &lt;- IQR(comunas$participacion) limite_inferior &lt;- Q1 - 1.5 * IQR_val limite_superior &lt;- Q3 + 1.5 * IQR_val # Identificar outliers outliers &lt;- comunas %&gt;% filter(participacion &lt; limite_inferior | participacion &gt; limite_superior) nrow(outliers) ## [1] 4 Hay 4 comunas con participación atípica. # Ver outliers outliers %&gt;% select(comuna, participacion) %&gt;% arrange(participacion) %&gt;% head(10) %&gt;% kable(digits = 1) comuna participacion Comuna 59 23.1 Comuna 269 25.4 Comuna 18 25.7 Comuna 118 68.6 5.8.2 Método de puntuaciones z Un z-score mide cuántas desviaciones estándar se aleja una observación de la media: \\[z_i = \\frac{x_i - \\bar{x}}{s}\\] comunas &lt;- comunas %&gt;% mutate(z_participacion = (participacion - mean(participacion)) / sd(participacion)) # Outliers: |z| &gt; 3 (criterio común) outliers_z &lt;- comunas %&gt;% filter(abs(z_participacion) &gt; 3) nrow(outliers_z) ## [1] 1 Con criterio \\(|z| &gt; 3\\), identificamos 1 outliers. 5.8.3 Visualización de outliers ggplot(comunas, aes(x = &quot;&quot;, y = participacion)) + geom_boxplot(outlier.color = &quot;red&quot;, outlier.size = 3) + geom_hline(yintercept = c(limite_inferior, limite_superior), linetype = &quot;dashed&quot;, color = &quot;red&quot;, alpha = 0.5) + labs(y = &quot;Participación electoral (%)&quot;, title = &quot;Outliers en participación electoral&quot;) + theme_minimal() + theme(axis.text.x = element_blank(), axis.title.x = element_blank()) Figura 5.10: Identificación visual de outliers ¿Qué hacer con outliers? Investigar: ¿Es error de datos o caso real extremo? Nunca eliminar automáticamente: Outliers pueden ser teóricamente importantes Análisis de sensibilidad: Repetir análisis con y sin outliers Transformaciones: Log, raíz cuadrada pueden reducir influencia de extremos Métodos robustos: Usar mediana en lugar de media, regresión robusta 5.9 Estadística descriptiva multivariada Frecuentemente queremos describir relaciones entre variables. 5.9.1 Tablas de contingencia Para dos variables categóricas: # Simulamos datos set.seed(222) encuesta &lt;- encuesta %&gt;% mutate(voto = sample(c(&quot;Apruebo&quot;, &quot;Rechazo&quot;), nrow(encuesta), replace = TRUE, prob = c(0.52, 0.48))) # Tabla de contingencia tabla &lt;- table(encuesta$orientacion, encuesta$voto) tabla ## ## Apruebo Rechazo ## Centro 108 91 ## Derecha 114 116 ## Izquierda 112 126 ## Ninguna 74 59 Con proporciones: # Proporciones por fila prop.table(tabla, margin = 1) ## ## Apruebo Rechazo ## Centro 0.5427136 0.4572864 ## Derecha 0.4956522 0.5043478 ## Izquierda 0.4705882 0.5294118 ## Ninguna 0.5563910 0.4436090 # Proporciones por columna prop.table(tabla, margin = 2) ## ## Apruebo Rechazo ## Centro 0.2647059 0.2321429 ## Derecha 0.2794118 0.2959184 ## Izquierda 0.2745098 0.3214286 ## Ninguna 0.1813725 0.1505102 5.9.2 Covarianza La covarianza mide cómo dos variables varían conjuntamente: \\[\\text{Cov}(X, Y) = \\frac{1}{n-1}\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})\\] cov(comunas$participacion, comunas$educ_superior) ## [1] -4.409441 Covarianza positiva: Variables tienden a moverse juntas Covarianza negativa: Variables tienden a moverse en direcciones opuestas Covarianza ≈ 0: No hay relación lineal Problema: La magnitud depende de las escalas. Difícil interpretar. 5.9.3 Correlación La correlación de Pearson (\\(r\\)) es la covarianza estandarizada: \\[r = \\frac{\\text{Cov}(X, Y)}{s_X s_Y}\\] cor(comunas$participacion, comunas$educ_superior) ## [1] -0.05572996 Propiedades: Rango: \\(-1 \\leq r \\leq 1\\) \\(r = 1\\): Correlación positiva perfecta \\(r = -1\\): Correlación negativa perfecta \\(r = 0\\): No hay correlación lineal No depende de escalas ggplot(comunas, aes(x = educ_superior, y = participacion)) + geom_point(alpha = 0.5) + geom_smooth(method = &quot;lm&quot;, se = FALSE, color = &quot;red&quot;) + labs(x = &quot;Población con educación superior (%)&quot;, y = &quot;Participación electoral (%)&quot;, title = paste0(&quot;Correlación: r = &quot;, round(cor(comunas$educ_superior, comunas$participacion), 2))) + theme_minimal() Figura 5.11: Correlación entre participación y educación superior Importante: Correlación mide asociación lineal, no causalidad. Alta correlación no implica que X causa Y. 5.9.4 Matriz de correlaciones Para múltiples variables: # Seleccionar variables numéricas vars_numericas &lt;- comunas %&gt;% select(participacion, pobreza, educ_superior) # Matriz de correlación cor_matrix &lt;- cor(vars_numericas) cor_matrix %&gt;% kable(digits = 2) participacion pobreza educ_superior participacion 1.00 0.00 -0.06 pobreza 0.00 1.00 0.08 educ_superior -0.06 0.08 1.00 Visualización: library(corrplot) corrplot(cor_matrix, method = &quot;color&quot;, type = &quot;upper&quot;, addCoef.col = &quot;black&quot;, number.cex = 0.8, tl.col = &quot;black&quot;, tl.srt = 45) Figura 5.12: Matriz de correlaciones 5.10 Estadística descriptiva por grupos Comparar estadísticos entre grupos: comunas %&gt;% group_by(pobreza_cat) %&gt;% summarise( n = n(), participacion_media = mean(participacion), participacion_mediana = median(participacion), participacion_sd = sd(participacion), educ_media = mean(educ_superior) ) %&gt;% kable(digits = 1) pobreza_cat n participacion_media participacion_mediana participacion_sd educ_media Baja 116 47.0 46.6 8.1 24.0 Media 115 46.7 46.9 7.9 24.8 Alta 115 46.5 46.8 7.0 25.6 Visualización de múltiples estadísticos: resumen &lt;- comunas %&gt;% group_by(pobreza_cat) %&gt;% summarise( Media = mean(participacion), Mediana = median(participacion) ) %&gt;% pivot_longer(cols = c(Media, Mediana), names_to = &quot;Estadistico&quot;, values_to = &quot;Valor&quot;) ggplot(resumen, aes(x = pobreza_cat, y = Valor, fill = Estadistico)) + geom_col(position = &quot;dodge&quot;) + labs(x = &quot;Nivel de pobreza&quot;, y = &quot;Participación electoral (%)&quot;, fill = &quot;Estadístico&quot;) + theme_minimal() Figura 5.13: Comparación de grupos 5.11 Resumen del capítulo La estadística descriptiva resume datos mediante medidas numéricas y gráficos. Las medidas de tendencia central (media, mediana, moda) capturan la ubicación típica. Para distribuciones simétricas, usar la media; para asimétricas, la mediana es más robusta. Las medidas de dispersión (rango, IQR, varianza, desviación estándar) cuantifican variabilidad. La desviación estándar es la más usada por estar en unidades originales. El coeficiente de variación permite comparar dispersión entre variables con diferentes escalas. Los percentiles y cuartiles dividen la distribución en partes iguales. El resumen de cinco números (mínimo, Q1, mediana, Q3, máximo) captura ubicación y dispersión, visualizado en boxplots. La forma de la distribución se caracteriza por asimetría (skewness) y curtosis. Distribuciones asimétricas tienen colas desbalanceadas; la curtosis mide peso de las colas. Los gráficos exploratorios (histogramas, boxplots, densidades, violin plots) revelan patrones que los estadísticos numéricos pueden ocultar. Los outliers requieren investigación—nunca eliminarlos automáticamente. Para relaciones bivariadas, la covarianza mide asociación conjunta pero depende de escalas. La correlación de Pearson estandariza la covarianza y varía entre -1 y 1, midiendo asociación lineal. La estadística descriptiva es exploratoria. Revela patrones, sugiere hipótesis, detecta problemas de datos. Pero no prueba nada—eso requiere inferencia estadística (Capítulos siguientes). 5.12 Lecturas recomendadas Fundamentos de estadística descriptiva: Agresti, A., &amp; Finlay, B. (2018). Statistical Methods for the Social Sciences (5th ed.). Pearson. → Capítulos 2-4 cubren estadística descriptiva con ejemplos de ciencias sociales. Visualización de datos: Healy, K. (2018). Data Visualization: A Practical Introduction. Princeton University Press. → Principios de visualización efectiva con énfasis en ggplot2. Estadística exploratoria: Tukey, J. W. (1977). Exploratory Data Analysis. Addison-Wesley. → Clásico sobre análisis exploratorio y visualización. Para profundizar en R: Wickham, H., &amp; Grolemund, G. (2017). R for Data Science. O’Reilly. [https://r4ds.had.co.nz/] → Capítulos 5 y 7 sobre transformación y análisis exploratorio. 5.13 Ejercicios 1. Cálculo manual Con estos datos de participación electoral en 10 comunas: 45, 52, 48, 51, 39, 55, 47, 50, 44, 49 Calcula media, mediana y moda manualmente Calcula rango, varianza y desviación estándar manualmente ¿La distribución es simétrica o asimétrica? ¿Cómo lo sabes? Verifica tus cálculos en R 2. Análisis exploratorio con datos reales Descarga datos de CEP o CASEN. Selecciona una variable continua de interés: # Tu código aquí Calcula media, mediana, desviación estándar e IQR Crea un histograma y un boxplot Identifica outliers (si los hay) usando el método IQR ¿La distribución es simétrica o asimétrica? Calcula el coeficiente de asimetría Escribe un párrafo interpretando los resultados 3. Comparación de grupos Con el dataset comunas del capítulo: # Datos disponibles comunas Compara participación electoral entre comunas con alta vs. baja educación superior (define umbral apropiado) Calcula media, mediana y desviación estándar para cada grupo Crea boxplots comparando ambos grupos ¿Qué grupo tiene mayor variabilidad? ¿Por qué? 4. Relaciones bivariadas # Usa datos de comunas Calcula la correlación entre participación y pobreza Calcula la correlación entre participación y educación superior Crea scatterplots para ambas relaciones Interpreta: ¿Las correlaciones son consistentes con tus expectativas teóricas? ¿Por qué? 5. Detectar problemas de datos # Dataset con problemas set.seed(999) problemas &lt;- data.frame( id = 1:100, edad = c(sample(18:80, 95, replace = TRUE), 150, 12, -5, 200, NA), ingreso = c(rnorm(95, 500000, 150000), 50000000, NA, NA, -100000, 0) ) Identifica valores imposibles o improbables en cada variable Identifica valores faltantes Calcula media y mediana de ingreso con y sin outliers. ¿Cómo afecta la media? Propón una estrategia para limpiar estos datos justificando cada decisión 6. Estadística descriptiva comprehensiva Elige un dataset de tu proyecto de tesis o interés: Identifica 3-5 variables clave Para cada variable, genera: Tabla de estadísticos descriptivos Gráfico apropiado (histograma, boxplot, o barras según tipo) Interpretación de 2-3 oraciones Calcula correlaciones entre variables numéricas Escribe un reporte de una página resumiendo patrones principales en tus datos Identifica al menos un hallazgo inesperado que requiera investigación adicional "],["visualizacion.html", "Capítulo 6 Visualización de datos 6.1 Objetivos del capítulo 6.2 Principios de visualización efectiva 6.3 Grammar of Graphics y ggplot2 6.4 Gráficos univariados 6.5 Gráficos bivariados 6.6 Series temporales 6.7 Facetas (paneles múltiples) 6.8 Personalización avanzada 6.9 Combinando gráficos 6.10 Anotaciones 6.11 Exportar gráficos 6.12 Visualizaciones problemáticas y cómo mejorarlas 6.13 Resumen del capítulo 6.14 Lecturas recomendadas 6.15 Ejercicios", " Capítulo 6 Visualización de datos 6.1 Objetivos del capítulo Al finalizar este capítulo, serás capaz de: Aplicar principios de diseño gráfico efectivo Usar la gramática de gráficos (grammar of graphics) con ggplot2 Crear y personalizar múltiples tipos de gráficos Identificar visualizaciones problemáticas y mejorarlas Combinar múltiples gráficos en una figura Exportar gráficos para publicación 6.2 Principios de visualización efectiva Tufte (1983) estableció principios fundamentales de diseño gráfico que permanecen vigentes: 6.2.1 1. Maximizar el ratio datos-tinta Eliminar elementos innecesarios. Cada elemento gráfico debe comunicar información. Mal ejemplo (chartjunk): # Gráfico sobrecargado ggplot(comunas %&gt;% slice(1:10), aes(x = reorder(region, -izquierda_2021), y = izquierda_2021)) + geom_bar(stat = &quot;identity&quot;, fill = &quot;red&quot;, color = &quot;gold&quot;, linewidth = 2) + geom_text(aes(label = round(izquierda_2021, 0)), vjust = -0.5, size = 6, color = &quot;blue&quot;) + labs(title = &quot;!!!VOTO DE IZQUIERDA POR REGIÓN!!!&quot;, x = &quot;REGIÓN&quot;, y = &quot;PORCENTAJE (%)&quot;) + theme_dark() + theme( plot.background = element_rect(fill = &quot;yellow&quot;), panel.grid.major = element_line(color = &quot;purple&quot;, linewidth = 2), axis.text = element_text(size = 14, face = &quot;bold&quot;, color = &quot;red&quot;) ) Figura 6.1: Gráfico con elementos innecesarios Buen ejemplo (limpio): comunas %&gt;% group_by(region) %&gt;% summarise(izquierda_media = mean(izquierda_2021)) %&gt;% ggplot(aes(x = reorder(region, izquierda_media), y = izquierda_media)) + geom_col(fill = &quot;steelblue&quot;, width = 0.7) + coord_flip() + labs(x = NULL, y = &quot;Voto izquierda (%)&quot;, title = &quot;Promedio de voto izquierda por región, 2021&quot;) + theme_minimal() Figura 6.2: Gráfico limpio y efectivo 6.2.2 2. Usar el canal visual apropiado La percepción humana procesa algunos atributos visuales mejor que otros: Jerarquía de canales visuales (de más a menos preciso): 1. Posición en eje común 2. Longitud 3. Ángulo/pendiente 4. Área 5. Volumen 6. Color (saturación) 7. Color (tono) Esto explica por qué gráficos de barras son más precisos que gráficos de torta. datos_partidos &lt;- data.frame( partido = c(&quot;PS&quot;, &quot;DC&quot;, &quot;RN&quot;, &quot;UDI&quot;, &quot;Otros&quot;), votos = c(23, 18, 22, 19, 18) ) p1 &lt;- ggplot(datos_partidos, aes(x = reorder(partido, votos), y = votos)) + geom_col(fill = &quot;steelblue&quot;) + coord_flip() + labs(x = NULL, y = &quot;Votos (%)&quot;, title = &quot;Gráfico de barras&quot;) + theme_minimal() p2 &lt;- ggplot(datos_partidos, aes(x = &quot;&quot;, y = votos, fill = partido)) + geom_bar(stat = &quot;identity&quot;, width = 1) + coord_polar(&quot;y&quot;) + labs(title = &quot;Gráfico de torta&quot;) + theme_void() + theme(legend.position = &quot;right&quot;) p1 | p2 Figura 6.3: Comparación: barras vs. torta El gráfico de barras permite comparaciones precisas. El gráfico de torta dificulta distinguir diferencias pequeñas. 6.2.3 3. Mostrar comparaciones Los datos adquieren significado mediante comparación. Comparar contra: - Otros grupos - Otros momentos - Un estándar o objetivo comunas_muestra &lt;- comunas %&gt;% slice_sample(n = 20) ggplot(comunas_muestra, aes(x = izquierda_2017, xend = izquierda_2021, y = reorder(comuna_id, izquierda_2021))) + geom_segment(aes(yend = comuna_id), color = &quot;gray70&quot;, linewidth = 1) + geom_point(aes(x = izquierda_2017, color = &quot;2017&quot;), size = 3) + geom_point(aes(x = izquierda_2021, color = &quot;2021&quot;), size = 3) + scale_color_manual(values = c(&quot;2017&quot; = &quot;coral&quot;, &quot;2021&quot; = &quot;steelblue&quot;)) + labs(x = &quot;Voto izquierda (%)&quot;, y = &quot;Comuna (ID)&quot;, title = &quot;Cambio en voto de izquierda entre elecciones&quot;, color = &quot;Año&quot;) + theme_minimal() Figura 6.4: Comparación de cambio electoral 2017-2021 6.2.4 4. Mostrar causalidad y explicación Los gráficos deben sugerir explicaciones, no solo describir. ggplot(comunas, aes(x = urbano, y = cambio_izquierda, fill = urbano)) + geom_violin(alpha = 0.7, show.legend = FALSE) + geom_boxplot(width = 0.2, fill = &quot;white&quot;, alpha = 0.8, show.legend = FALSE) + scale_x_discrete(labels = c(&quot;FALSE&quot; = &quot;Rural&quot;, &quot;TRUE&quot; = &quot;Urbana&quot;)) + labs(x = &quot;Tipo de comuna&quot;, y = &quot;Cambio en voto izquierda (puntos porcentuales)&quot;, title = &quot;Cambio electoral según urbanización&quot;, subtitle = &quot;Las comunas urbanas experimentaron mayor crecimiento del voto de izquierda&quot;) + theme_minimal() Figura 6.5: Relación entre urbanización y cambio electoral 6.2.5 5. Integrar evidencia Combinar palabras, números y gráficos para una narrativa coherente. 6.3 Grammar of Graphics y ggplot2 Wilkinson (2005) propuso que los gráficos estadísticos tienen una gramática—componentes sistemáticos que se combinan para producir visualizaciones. 6.3.1 Componentes de ggplot2 Datos: El dataset Aesthetics (aes): Mapeo de variables a propiedades visuales (x, y, color, tamaño) Geometrías (geom): Representación visual (puntos, líneas, barras) Escalas (scales): Cómo se traducen valores de datos a valores visuales Facetas (facets): Paneles múltiples Temas (themes): Elementos no relacionados con datos (títulos, fondos) 6.3.2 Estructura básica ggplot(data = &lt;DATOS&gt;, aes(x = &lt;VAR_X&gt;, y = &lt;VAR_Y&gt;)) + geom_&lt;TIPO&gt;() + scale_&lt;...&gt;() + facet_&lt;...&gt;() + labs(...) + theme_&lt;...&gt;() 6.3.3 Ejemplo paso a paso # Paso 1: Solo datos y aesthetics (nada se dibuja) p1 &lt;- ggplot(comunas, aes(x = izquierda_2017, y = izquierda_2021)) # Paso 2: Agregar geometría p2 &lt;- p1 + geom_point(alpha = 0.5) # Paso 3: Agregar línea de referencia p3 &lt;- p2 + geom_abline(slope = 1, intercept = 0, linetype = &quot;dashed&quot;, color = &quot;red&quot;) # Paso 4: Mejorar etiquetas p4 &lt;- p3 + labs(x = &quot;Voto izquierda 2017 (%)&quot;, y = &quot;Voto izquierda 2021 (%)&quot;, title = &quot;Cambio electoral entre elecciones&quot;) # Combinar para mostrar progresión (p1 + ggtitle(&quot;Paso 1: Solo aesthetics&quot;)) / (p2 + ggtitle(&quot;Paso 2: + geometría&quot;)) / (p3 + ggtitle(&quot;Paso 3: + línea de referencia&quot;)) / (p4 + ggtitle(&quot;Paso 4: + etiquetas&quot;)) Figura 6.6: Construcción progresiva de un gráfico 6.4 Gráficos univariados 6.4.1 Variables continuas Histograma con densidad superpuesta: ggplot(comunas, aes(x = cambio_izquierda)) + geom_histogram(aes(y = after_stat(density)), bins = 30, fill = &quot;lightblue&quot;, color = &quot;white&quot;) + geom_density(color = &quot;darkblue&quot;, linewidth = 1) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;red&quot;, linewidth = 1) + labs(x = &quot;Cambio en voto izquierda (puntos porcentuales)&quot;, y = &quot;Densidad&quot;, title = &quot;Distribución del cambio electoral 2017-2021&quot;, subtitle = &quot;La mayoría de comunas experimentó crecimiento del voto de izquierda&quot;) + theme_minimal() Figura 6.7: Distribución del cambio electoral Ridgeline plot (montañas): library(ggridges) ggplot(comunas, aes(x = cambio_izquierda, y = region, fill = region)) + geom_density_ridges(alpha = 0.7, show.legend = FALSE) + labs(x = &quot;Cambio en voto izquierda (puntos porcentuales)&quot;, y = NULL, title = &quot;Cambio electoral por región&quot;) + theme_minimal() Figura 6.8: Distribuciones por región 6.4.2 Variables categóricas Gráfico de barras ordenado: comunas %&gt;% count(region) %&gt;% ggplot(aes(x = reorder(region, n), y = n)) + geom_col(fill = &quot;steelblue&quot;) + geom_text(aes(label = n), hjust = -0.2, size = 3.5) + coord_flip() + labs(x = NULL, y = &quot;Número de comunas&quot;, title = &quot;Comunas por región en la muestra&quot;) + theme_minimal() Figura 6.9: Frecuencias ordenadas Dot plot (preferible cuando muchas categorías): comunas %&gt;% count(region) %&gt;% ggplot(aes(x = n, y = reorder(region, n))) + geom_point(size = 4, color = &quot;steelblue&quot;) + geom_segment(aes(x = 0, xend = n, yend = region), color = &quot;gray70&quot;) + labs(x = &quot;Número de comunas&quot;, y = NULL, title = &quot;Comunas por región&quot;) + theme_minimal() Figura 6.10: Dot plot como alternativa 6.5 Gráficos bivariados 6.5.1 Dos variables continuas: scatter plots Básico con línea de tendencia: ggplot(comunas, aes(x = izquierda_2017, y = izquierda_2021)) + geom_point(alpha = 0.4) + geom_smooth(method = &quot;lm&quot;, se = TRUE, color = &quot;red&quot;) + geom_abline(slope = 1, intercept = 0, linetype = &quot;dashed&quot;, color = &quot;blue&quot;) + labs(x = &quot;Voto izquierda 2017 (%)&quot;, y = &quot;Voto izquierda 2021 (%)&quot;, title = &quot;Relación entre apoyo de izquierda en dos elecciones&quot;, subtitle = &quot;Línea roja: regresión | Línea azul: sin cambio&quot;) + theme_minimal() Figura 6.11: Relación entre voto 2017 y 2021 Con tercera variable (color/tamaño): ggplot(comunas, aes(x = izquierda_2017, y = izquierda_2021)) + geom_point(aes(color = region, size = poblacion), alpha = 0.6) + scale_size_continuous(labels = comma, range = c(1, 8)) + labs(x = &quot;Voto izquierda 2017 (%)&quot;, y = &quot;Voto izquierda 2021 (%)&quot;, size = &quot;Población&quot;, color = &quot;Región&quot;, title = &quot;Cambio electoral según región y tamaño&quot;) + theme_minimal() Figura 6.12: Scatter plot con tercera variable Etiquetado selectivo con ggrepel: # Identificar casos extremos para etiquetar extremos &lt;- comunas %&gt;% filter(abs(cambio_izquierda) &gt; 15) %&gt;% mutate(label = paste0(&quot;Comuna &quot;, comuna_id)) ggplot(comunas, aes(x = izquierda_2017, y = cambio_izquierda)) + geom_point(alpha = 0.3) + geom_point(data = extremos, color = &quot;red&quot;, size = 3) + geom_text_repel(data = extremos, aes(label = label), size = 3, max.overlaps = 15) + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;, color = &quot;blue&quot;) + labs(x = &quot;Voto izquierda 2017 (%)&quot;, y = &quot;Cambio 2017-2021 (puntos porcentuales)&quot;, title = &quot;Cambio electoral desde baseline 2017&quot;, subtitle = &quot;Comunas con cambios extremos etiquetadas en rojo&quot;) + theme_minimal() Figura 6.13: Scatter plot con etiquetas 6.5.2 Variable continua vs. categórica Boxplots comparativos: ggplot(comunas, aes(x = region, y = cambio_izquierda, fill = region)) + geom_boxplot(alpha = 0.7, show.legend = FALSE) + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;, color = &quot;red&quot;) + labs(x = NULL, y = &quot;Cambio en voto izquierda (puntos porcentuales)&quot;, title = &quot;Cambio electoral por región&quot;) + theme_minimal() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) Figura 6.14: Distribuciones por grupo Violin plots con puntos: ggplot(comunas, aes(x = region, y = cambio_izquierda, fill = region)) + geom_violin(alpha = 0.5, show.legend = FALSE) + geom_jitter(width = 0.2, alpha = 0.2, size = 0.8, show.legend = FALSE) + stat_summary(fun = median, geom = &quot;point&quot;, size = 3, color = &quot;red&quot;) + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;, color = &quot;blue&quot;) + labs(x = NULL, y = &quot;Cambio en voto izquierda (p.p.)&quot;, title = &quot;Distribución del cambio electoral por región&quot;, subtitle = &quot;Punto rojo: mediana&quot;) + theme_minimal() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) Figura 6.15: Violin plot con datos individuales 6.5.3 Dos variables categóricas Heatmap de tabla de contingencia: # Crear categorías comunas_cat &lt;- comunas %&gt;% mutate( cambio_cat = cut(cambio_izquierda, breaks = c(-Inf, -5, 5, Inf), labels = c(&quot;Bajó&quot;, &quot;Estable&quot;, &quot;Subió&quot;)), urbano_lab = ifelse(urbano, &quot;Urbana&quot;, &quot;Rural&quot;) ) tabla_cont &lt;- table(comunas_cat$urbano_lab, comunas_cat$cambio_cat) # Convertir a data frame para ggplot tabla_df &lt;- as.data.frame(tabla_cont) names(tabla_df) &lt;- c(&quot;Urbano&quot;, &quot;Cambio&quot;, &quot;Freq&quot;) ggplot(tabla_df, aes(x = Cambio, y = Urbano, fill = Freq)) + geom_tile(color = &quot;white&quot;) + geom_text(aes(label = Freq), color = &quot;white&quot;, size = 5) + scale_fill_gradient(low = &quot;lightblue&quot;, high = &quot;darkblue&quot;) + labs(x = &quot;Cambio electoral&quot;, y = &quot;Tipo de comuna&quot;, fill = &quot;Frecuencia&quot;, title = &quot;Cambio electoral según urbanización&quot;) + theme_minimal() Figura 6.16: Heatmap de frecuencias 6.6 Series temporales Gráfico de líneas simple: ggplot(aprobacion, aes(x = mes, y = aprobacion)) + geom_line(color = &quot;steelblue&quot;, linewidth = 1) + geom_point(color = &quot;steelblue&quot;, size = 2) + scale_x_date(date_labels = &quot;%b %Y&quot;, date_breaks = &quot;3 months&quot;) + scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, 20)) + labs(x = NULL, y = &quot;Aprobación (%)&quot;, title = &quot;Evolución de aprobación presidencial&quot;, subtitle = &quot;Marzo 2022 - Febrero 2024&quot;) + theme_minimal() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) Figura 6.17: Serie temporal de aprobación presidencial Múltiples series: # Convertir a formato largo aprobacion_long &lt;- aprobacion %&gt;% pivot_longer(cols = c(aprobacion, desaprobacion, indeciso), names_to = &quot;categoria&quot;, values_to = &quot;porcentaje&quot;) ggplot(aprobacion_long, aes(x = mes, y = porcentaje, color = categoria)) + geom_line(linewidth = 1) + geom_point(size = 1.5) + scale_color_manual(values = c(&quot;aprobacion&quot; = &quot;darkgreen&quot;, &quot;desaprobacion&quot; = &quot;darkred&quot;, &quot;indeciso&quot; = &quot;gray60&quot;), labels = c(&quot;Aprueba&quot;, &quot;Desaprueba&quot;, &quot;Indeciso&quot;)) + scale_x_date(date_labels = &quot;%b %Y&quot;, date_breaks = &quot;3 months&quot;) + scale_y_continuous(limits = c(0, 100)) + labs(x = NULL, y = &quot;Porcentaje (%)&quot;, color = NULL, title = &quot;Evaluación presidencial a lo largo del tiempo&quot;) + theme_minimal() + theme(legend.position = &quot;bottom&quot;, axis.text.x = element_text(angle = 45, hjust = 1)) Figura 6.18: Múltiples series temporales Área apilada: ggplot(aprobacion_long, aes(x = mes, y = porcentaje, fill = categoria)) + geom_area(alpha = 0.8) + scale_fill_manual(values = c(&quot;aprobacion&quot; = &quot;darkgreen&quot;, &quot;desaprobacion&quot; = &quot;darkred&quot;, &quot;indeciso&quot; = &quot;gray60&quot;), labels = c(&quot;Aprueba&quot;, &quot;Desaprueba&quot;, &quot;Indeciso&quot;)) + scale_x_date(date_labels = &quot;%b %Y&quot;, date_breaks = &quot;3 months&quot;) + scale_y_continuous(limits = c(0, 100), expand = c(0, 0)) + labs(x = NULL, y = &quot;Porcentaje (%)&quot;, fill = NULL, title = &quot;Composición de evaluación presidencial&quot;) + theme_minimal() + theme(legend.position = &quot;bottom&quot;, axis.text.x = element_text(angle = 45, hjust = 1)) Figura 6.19: Gráfico de área apilada 6.7 Facetas (paneles múltiples) Dividir gráficos en paneles según una variable categórica. 6.7.1 facet_wrap ggplot(comunas, aes(x = izquierda_2017, y = izquierda_2021)) + geom_point(alpha = 0.5) + geom_smooth(method = &quot;lm&quot;, se = FALSE, color = &quot;red&quot;) + geom_abline(slope = 1, intercept = 0, linetype = &quot;dashed&quot;, color = &quot;blue&quot;) + facet_wrap(~region, ncol = 2) + labs(x = &quot;Voto izquierda 2017 (%)&quot;, y = &quot;Voto izquierda 2021 (%)&quot;, title = &quot;Cambio electoral por región&quot;) + theme_minimal() Figura 6.20: Facet wrap por región 6.7.2 facet_grid comunas_cat &lt;- comunas %&gt;% mutate( urbano_lab = ifelse(urbano, &quot;Urbana&quot;, &quot;Rural&quot;), cambio_cat = cut(cambio_izquierda, breaks = quantile(cambio_izquierda, c(0, 0.5, 1)), labels = c(&quot;Bajo crecimiento&quot;, &quot;Alto crecimiento&quot;), include.lowest = TRUE) ) ggplot(comunas_cat, aes(x = izquierda_2017, y = izquierda_2021)) + geom_point(alpha = 0.4) + geom_smooth(method = &quot;lm&quot;, se = FALSE, color = &quot;red&quot;) + facet_grid(urbano_lab ~ cambio_cat) + labs(x = &quot;Voto izquierda 2017 (%)&quot;, y = &quot;Voto izquierda 2021 (%)&quot;, title = &quot;Patrones electorales según urbanización y magnitud de cambio&quot;) + theme_minimal() Figura 6.21: Facet grid con dos variables 6.8 Personalización avanzada 6.8.1 Temas predefinidos p_base &lt;- ggplot(comunas %&gt;% slice_sample(n = 100), aes(x = izquierda_2017, y = izquierda_2021)) + geom_point() + labs(title = &quot;Tema: &quot;) (p_base + theme_minimal() + ggtitle(&quot;theme_minimal&quot;)) | (p_base + theme_bw() + ggtitle(&quot;theme_bw&quot;)) / (p_base + theme_classic() + ggtitle(&quot;theme_classic&quot;)) | (p_base + theme_light() + ggtitle(&quot;theme_light&quot;)) Figura 6.22: Comparación de temas 6.8.2 Personalización de elementos ggplot(comunas %&gt;% group_by(region) %&gt;% summarise(cambio_promedio = mean(cambio_izquierda)), aes(x = reorder(region, cambio_promedio), y = cambio_promedio)) + geom_col(aes(fill = cambio_promedio &gt; 0), width = 0.7, show.legend = FALSE) + scale_fill_manual(values = c(&quot;TRUE&quot; = &quot;darkgreen&quot;, &quot;FALSE&quot; = &quot;darkred&quot;)) + geom_hline(yintercept = 0, linewidth = 0.8) + coord_flip() + labs( x = NULL, y = &quot;Cambio promedio en voto izquierda (puntos porcentuales)&quot;, title = &quot;Cambio electoral promedio por región&quot;, subtitle = &quot;Comparación 2021 vs. 2017&quot;, caption = &quot;Fuente: Datos simulados para fines pedagógicos&quot; ) + theme_minimal() + theme( plot.title = element_text(size = 14, face = &quot;bold&quot;), plot.subtitle = element_text(size = 11, color = &quot;gray30&quot;), plot.caption = element_text(size = 8, color = &quot;gray50&quot;, hjust = 0), axis.title.x = element_text(size = 10), axis.text = element_text(size = 9), panel.grid.minor = element_blank(), panel.grid.major.y = element_blank() ) Figura 6.23: Gráfico altamente personalizado 6.8.3 Paletas de colores p_color &lt;- ggplot(comunas, aes(x = region, fill = region)) + geom_bar() + theme_minimal() + theme(legend.position = &quot;none&quot;, axis.text.x = element_text(angle = 45, hjust = 1)) p1 &lt;- p_color + scale_fill_brewer(palette = &quot;Set2&quot;) + ggtitle(&quot;Brewer: Set2&quot;) p2 &lt;- p_color + scale_fill_viridis_d() + ggtitle(&quot;Viridis (accesible)&quot;) p3 &lt;- p_color + scale_fill_manual(values = c(&quot;#E41A1C&quot;, &quot;#377EB8&quot;, &quot;#4DAF4A&quot;, &quot;#984EA3&quot;)) + ggtitle(&quot;Manual&quot;) p1 / p2 / p3 Figura 6.24: Diferentes paletas de colores 6.9 Combinando gráficos El paquete patchwork permite combinar gráficos fácilmente. # Crear gráficos individuales p1 &lt;- ggplot(comunas, aes(x = cambio_izquierda)) + geom_histogram(bins = 30, fill = &quot;steelblue&quot;, color = &quot;white&quot;) + labs(x = &quot;Cambio electoral&quot;, y = &quot;Frecuencia&quot;, title = &quot;A) Distribución&quot;) + theme_minimal() p2 &lt;- ggplot(comunas, aes(x = izquierda_2017, y = izquierda_2021)) + geom_point(alpha = 0.4) + geom_smooth(method = &quot;lm&quot;, color = &quot;red&quot;) + labs(x = &quot;2017&quot;, y = &quot;2021&quot;, title = &quot;B) Relación temporal&quot;) + theme_minimal() p3 &lt;- ggplot(comunas, aes(x = region, y = cambio_izquierda, fill = region)) + geom_boxplot(show.legend = FALSE) + labs(x = NULL, y = &quot;Cambio electoral&quot;, title = &quot;C) Por región&quot;) + theme_minimal() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) p4 &lt;- ggplot(comunas, aes(x = urbano, y = cambio_izquierda, fill = urbano)) + geom_violin(show.legend = FALSE, alpha = 0.7) + scale_x_discrete(labels = c(&quot;FALSE&quot; = &quot;Rural&quot;, &quot;TRUE&quot; = &quot;Urbano&quot;)) + labs(x = NULL, y = &quot;Cambio electoral&quot;, title = &quot;D) Por tipo&quot;) + theme_minimal() # Combinar con layout específico (p1 | p2) / (p3 | p4) Figura 6.25: Combinación compleja de gráficos 6.10 Anotaciones Agregar texto, flechas y formas para destacar patrones. ggplot(aprobacion, aes(x = mes, y = aprobacion)) + geom_line(color = &quot;steelblue&quot;, linewidth = 1) + geom_point(color = &quot;steelblue&quot;, size = 2) + # Anotar punto específico annotate(&quot;point&quot;, x = as.Date(&quot;2023-06-01&quot;), y = 65, color = &quot;red&quot;, size = 4) + annotate(&quot;text&quot;, x = as.Date(&quot;2023-06-01&quot;), y = 68, label = &quot;Pico máximo\\n(Junio 2023)&quot;, size = 3.5, color = &quot;red&quot;) + annotate(&quot;segment&quot;, x = as.Date(&quot;2023-06-01&quot;), xend = as.Date(&quot;2023-06-01&quot;), y = 66.5, yend = 65.5, arrow = arrow(length = unit(0.2, &quot;cm&quot;)), color = &quot;red&quot;) + # Área de interés annotate(&quot;rect&quot;, xmin = as.Date(&quot;2023-03-01&quot;), xmax = as.Date(&quot;2023-09-01&quot;), ymin = -Inf, ymax = Inf, alpha = 0.1, fill = &quot;yellow&quot;) + scale_x_date(date_labels = &quot;%b %Y&quot;, date_breaks = &quot;3 months&quot;) + labs(x = NULL, y = &quot;Aprobación (%)&quot;, title = &quot;Aprobación presidencial con anotaciones&quot;, subtitle = &quot;Período destacado: marzo-septiembre 2023&quot;) + theme_minimal() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) Figura 6.26: Gráfico con anotaciones 6.11 Exportar gráficos Guardar gráficos para publicación. # Crear gráfico p &lt;- ggplot(comunas, aes(x = izquierda_2017, y = izquierda_2021)) + geom_point() + theme_minimal() # Guardar en diferentes formatos ggsave(&quot;grafico.png&quot;, p, width = 8, height = 6, dpi = 300) ggsave(&quot;grafico.pdf&quot;, p, width = 8, height = 6) ggsave(&quot;grafico.svg&quot;, p, width = 8, height = 6) # Especificar unidades ggsave(&quot;grafico_cm.png&quot;, p, width = 20, height = 15, units = &quot;cm&quot;, dpi = 300) Recomendaciones: PNG: Para web y presentaciones (300 dpi para calidad) PDF: Para publicaciones académicas (vectorial, escalable) SVG: Para edición posterior en Illustrator/Inkscape Dimensiones: Verificar requisitos de revista (ej: ancho máximo 180mm) 6.12 Visualizaciones problemáticas y cómo mejorarlas 6.12.1 Problema 1: Eje Y truncado datos_ejemplo &lt;- data.frame( año = 2019:2023, valor = c(50, 52, 51, 53, 54) ) p_malo &lt;- ggplot(datos_ejemplo, aes(x = año, y = valor)) + geom_col(fill = &quot;steelblue&quot;) + coord_cartesian(ylim = c(48, 55)) + labs(title = &quot;Problemático: Eje truncado exagera diferencias&quot;) + theme_minimal() p_bueno &lt;- ggplot(datos_ejemplo, aes(x = año, y = valor)) + geom_col(fill = &quot;steelblue&quot;) + coord_cartesian(ylim = c(0, 60)) + labs(title = &quot;Mejor: Eje desde cero muestra escala real&quot;) + theme_minimal() p_malo | p_bueno Figura 6.27: Eje truncado vs. completo 6.12.2 Problema 2: Demasiadas categorías # Simular datos con muchas categorías set.seed(456) muchas_cat &lt;- data.frame( partido = paste(&quot;Partido&quot;, 1:15), votos = runif(15, 2, 12) ) p_malo &lt;- ggplot(muchas_cat, aes(x = partido, y = votos)) + geom_col(fill = &quot;steelblue&quot;) + labs(title = &quot;Problemático: Demasiadas categorías&quot;) + theme_minimal() + theme(axis.text.x = element_text(angle = 90, size = 6)) # Agrupar categorías menores muchas_cat_agrup &lt;- muchas_cat %&gt;% mutate( partido_agrup = ifelse(votos &lt; 5, &quot;Otros (menor 5%)&quot;, partido) ) %&gt;% group_by(partido_agrup) %&gt;% summarise(votos = sum(votos)) %&gt;% arrange(desc(votos)) p_bueno &lt;- ggplot(muchas_cat_agrup, aes(x = reorder(partido_agrup, votos), y = votos)) + geom_col(fill = &quot;steelblue&quot;) + coord_flip() + labs(title = &quot;Mejor: Categorías agrupadas&quot;, x = NULL) + theme_minimal() p_malo | p_bueno Figura 6.28: Reducción de categorías 6.12.3 Problema 3: Dobles ejes Y Los dobles ejes Y pueden ser engañosos—la escala de cada eje puede manipularse para sugerir relaciones inexistentes. Mejor práctica: Usar facetas o gráficos separados. 6.13 Resumen del capítulo La visualización efectiva comunica patrones de datos clara y honestamente. Los principios de Tufte—maximizar ratio datos-tinta, usar canales visuales apropiados, mostrar comparaciones, sugerir causalidad—guían el diseño. La gramática de gráficos (implementada en ggplot2) descompone visualizaciones en componentes sistemáticos: datos, aesthetics, geometrías, escalas, facetas, temas. Esta estructura permite crear gráficos complejos mediante combinación de capas. Para variables continuas, histogramas y densidades muestran distribución; boxplots comparan grupos. Scatter plots revelan relaciones bivariadas. Series temporales usan gráficos de línea; múltiples series requieren codificación cuidadosa mediante color. Facetas (facet_wrap, facet_grid) dividen datos en paneles, facilitando comparaciones entre grupos. Temas y personalización permiten adaptar estética a contextos (publicación, presentación, web). Combinar gráficos (patchwork) y agregar anotaciones (annotate) crean narrativas visuales comprehensivas. Exportar en formatos apropiados (PNG para web, PDF para publicación) asegura calidad. Evitar visualizaciones problemáticas—ejes truncados, demasiadas categorías, dobles ejes Y engañosos—es responsabilidad del investigador. La visualización no solo describe datos; argumenta e informa decisiones. 6.14 Lecturas recomendadas Fundamentos de visualización: Tufte, E. R. (1983). The Visual Display of Quantitative Information. Graphics Press. → Clásico sobre principios de diseño gráfico efectivo. Aplicación práctica con ggplot2: Healy, K. (2018). Data Visualization: A Practical Introduction. Princeton University Press. → Guía accesible con énfasis en ciencias sociales. Referencia técnica de ggplot2: Wickham, H. (2016). ggplot2: Elegant Graphics for Data Analysis (2nd ed.). Springer. → Documentación comprehensiva del creador de ggplot2. Visualización crítica: Cairo, A. (2016). The Truthful Art: Data, Charts, and Maps for Communication. New Riders. → Énfasis en honestidad y ética en visualización. Recursos en línea: R Graph Gallery: https://www.r-graph-gallery.com/ ggplot2 documentation: https://ggplot2.tidyverse.org/ ColorBrewer (paletas): https://colorbrewer2.org/ 6.15 Ejercicios 1. Replicar y mejorar Este gráfico problemático: ggplot(comunas, aes(x = region, y = cambio_izquierda)) + geom_bar(stat = &quot;identity&quot;, fill = rainbow(4)) + labs(title = &quot;CAMBIO!!!&quot;) Identifica al menos 4 problemas Crea una versión mejorada aplicando principios del capítulo Justifica cada decisión de diseño 2. Exploración visual de datos propios Con un dataset de tu proyecto: Crea histograma/densidad de variable continua clave Crea boxplot comparando grupos relevantes Crea scatter plot de dos variables con línea de tendencia Combina los tres gráficos en una figura con patchwork Exporta en formato apropiado (300 dpi PNG) 3. Series temporales Descarga datos de aprobación presidencial real (ej: CEP, Cadem). Crea gráfico de línea con aprobación y desaprobación Agrega anotaciones para eventos importantes (ej: estallido social, pandemia) Usa facetas para comparar períodos presidenciales 4. Visualización multivariada # Usa datos de comunas Crea scatter plot con tres variables (x, y, color o tamaño) Agrega facetas por una cuarta variable categórica Personaliza completamente (tema, colores, etiquetas) Escribe interpretación de 100 palabras de patrones observados 5. Del mal al buen gráfico Busca un gráfico problemático en medios (Twitter, periódicos, reportes). Captura/descarga el gráfico original Lista todos los problemas que identificas Si tienes acceso a los datos, recréalo correctamente en ggplot2 Si no, crea un gráfico similar con datos simulados que demuestre la mejora Escribe explicación de 150 palabras sobre qué cambió y por qué 6. Proyecto de visualización completo Crea un “dashboard” de una página con 4-6 gráficos que cuenten una historia sobre tu tema de tesis: Diseña layout con patchwork Incluye diferentes tipos de gráficos (univariados, bivariados, temporal si aplica) Usa un tema coherente en todos los gráficos Agrega título general y caption con fuente Exporta en alta resolución Presenta a colegas y solicita feedback sobre claridad Referencias Tufte, Edward R. 1983. The Visual Display of Quantitative Information. Cheshire, Connecticut: Graphics Press. Wilkinson, Leland. 2005. The Grammar of Graphics. 2nd ed. New York: Springer-Verlag. "],["probabilidad.html", "Capítulo 7 Introducción a probabilidad 7.1 Objetivos del capítulo 7.2 ¿Por qué probabilidad en ciencias sociales? 7.3 Conceptos básicos de probabilidad 7.4 Variables aleatorias 7.5 Distribuciones de probabilidad comunes 7.6 Teorema del Límite Central 7.7 Resumen del capítulo 7.8 Lecturas recomendadas 7.9 Ejercicios", " Capítulo 7 Introducción a probabilidad 7.1 Objetivos del capítulo Al finalizar este capítulo, deberías ser capaz de: Comprender el concepto de probabilidad y su relación con la incertidumbre Distinguir entre interpretaciones frecuentista y bayesiana de probabilidad Calcular probabilidades básicas y aplicar reglas fundamentales Identificar y trabajar con variables aleatorias discretas y continuas Reconocer distribuciones de probabilidad comunes en ciencias sociales Comprender el Teorema del Límite Central y su importancia para la inferencia 7.2 ¿Por qué probabilidad en ciencias sociales? La investigación social cuantitativa enfrenta invariablemente la incertidumbre. Cuando encuestamos 1,500 votantes chilenos para estimar apoyo a un candidato presidencial, no conocemos las preferencias de los millones que no fueron encuestados. Cuando comparamos tasas de homicidio entre países con y sin pena de muerte, no podemos asegurar que la diferencia observada no sea producto del azar. La teoría de probabilidad nos proporciona un lenguaje matemático riguroso para cuantificar esta incertidumbre. No elimina la incertidumbre (esto es imposible cuando trabajamos con muestras), pero nos permite hacer afirmaciones precisas sobre qué tan confiables son nuestras conclusiones.7 7.3 Conceptos básicos de probabilidad 7.3.1 Definición y notación Una probabilidad es un número entre 0 y 1 que cuantifica qué tan probable es que ocurra un evento: \\(P(A) = 0\\) significa que el evento \\(A\\) es imposible \\(P(A) = 1\\) significa que el evento \\(A\\) es seguro \\(P(A) = 0.5\\) significa que \\(A\\) tiene la misma probabilidad de ocurrir que de no ocurrir Por ejemplo, si en una encuesta con 1,200 entrevistados, 360 declaran que votarán por candidatos del Frente Amplio en elecciones legislativas chilenas, podemos estimar: \\(P(\\text{Voto FA}) = \\frac{360}{1200} = 0.30\\). Esto NO significa que exactamente 30% de los votantes votará por el FA el día de la elección. Significa que, basándonos en nuestra muestra, estimamos esa probabilidad con cierto nivel de incertidumbre (que cuantificaremos en el próximo capítulo con intervalos de confianza). 7.3.2 Interpretaciones de probabilidad Existen dos interpretaciones fundamentales de qué significa “probabilidad”: 1. Interpretación frecuentista8 La probabilidad es el límite de la frecuencia relativa cuando un experimento se repite infinitas veces. Por ejemplo, \\(P(\\text{Cara}) = 0.5\\) al lanzar una moneda significa que, si lanzamos la moneda millones de veces, aproximadamente 50% serán caras. 2. Interpretación bayesiana La probabilidad cuantifica grado de creencia o certeza subjetiva sobre un evento. Permite asignar probabilidades a eventos únicos (como “¿cuál es la probabilidad de que Chile tenga una nueva Constitución en 2026?”). Figura 7.1: Comparación de interpretaciones de probabilidad 7.3.3 Reglas fundamentales de probabilidad Regla de la suma (eventos mutuamente excluyentes) Si \\(A\\) y \\(B\\) no pueden ocurrir simultáneamente: \\[P(A \\text{ o } B) = P(A) + P(B)\\] Por ejemplo, en las elecciones municipales 2024 en Santiago, si un votante puede elegir solo un candidato: \\(P(\\text{Izquierda o Derecha}) = P(\\text{Izquierda}) + P(\\text{Derecha})\\). Regla del complemento \\[P(\\text{no } A) = 1 - P(A)\\] Por ejemplo, si \\(P(\\text{Voto})=0.52\\) en elecciones legislativas chilenas: \\(P(\\text{Abstención}) = 1 - 0.52 = 0.48\\). Regla del producto (eventos independientes) Si \\(A\\) y \\(B\\) son independientes (la ocurrencia de uno no afecta la probabilidad del otro): \\[P(A \\text{ y } B) = P(A) \\times P(B)\\] Por ejemplo, si encuestamos a dos votantes al azar y queremos saber la probabilidad de que ambos voten por la izquierda, asumiendo independencia y \\(P(\\text{Izquierda})=0.30\\): \\(P(\\text{ambos izquierda}) = 0.30 \\times 0.30 = 0.09\\). Probabilidad condicional La probabilidad de \\(A\\) dado que ya sabemos que \\(B\\) ocurrió: \\[P(A|B) = \\frac{P(A \\text{ y } B)}{P(B)}\\] Por ejemplo, consideremos voto por género en una encuesta chilena. Supongamos que en una encuesta: 30% vota Apruebo, 60% son mujeres, y 20% del total son mujeres que votan Apruebo. Entonces \\(P(\\text{Apruebo}|\\text{Mujer}) = \\frac{P(\\text{Apruebo y Mujer})}{P(\\text{Mujer})} = \\frac{0.20}{0.60} = 0.33\\). Es decir, entre las mujeres, 33% vota Apruebo (mientras que en la población general es 30%). 7.4 Variables aleatorias Una variable aleatoria es una función que asigna un valor numérico a cada resultado posible de un fenómeno aleatorio. Son la conexión entre probabilidad y estadística. 7.4.1 Variables aleatorias discretas Toman valores específicos y contables (generalmente enteros).9 Función de masa de probabilidad (PMF) Para una variable aleatoria discreta \\(X\\), la PMF especifica la probabilidad de cada valor: \\[P(X = x)\\] # Simulación: Número de protestas por mes en una ciudad # (Distribución Poisson con promedio = 2.5) set.seed(456) protestas &lt;- rpois(1000, lambda = 2.5) # Tabla de frecuencias table(protestas) / 1000 ## protestas ## 0 1 2 3 4 5 6 7 8 ## 0.074 0.194 0.242 0.217 0.154 0.074 0.030 0.013 0.002 Figura 7.2: Distribución de variable aleatoria discreta: Número de protestas 7.4.2 Variables aleatorias continuas Pueden tomar cualquier valor en un intervalo (infinitos valores posibles).10 Función de densidad de probabilidad (PDF) Para variables continuas, \\(P(X = x) = 0\\) (la probabilidad de un valor exacto es cero). En su lugar, trabajamos con intervalos: \\[P(a &lt; X &lt; b) = \\int_a^b f(x)dx\\] donde \\(f(x)\\) es la función de densidad. # Simulación: Porcentaje de votos para alcalde # (Distribución aproximadamente Normal) set.seed(789) votos &lt;- rnorm(1000, mean = 35, sd = 5) # Probabilidad de obtener entre 30% y 40% mean(votos &gt;= 30 &amp; votos &lt;= 40) ## [1] 0.686 Figura 7.3: Distribución de variable aleatoria continua: Porcentaje de votos 7.4.3 Valor esperado y varianza Valor esperado (media poblacional): \\(E(X) = \\mu\\) Para variable discreta: \\(E(X) = \\sum x \\cdot P(X=x)\\) Para variable continua: \\(E(X) = \\int x \\cdot f(x)dx\\) Varianza: \\(\\text{Var}(X) = \\sigma^2 = E[(X - \\mu)^2]\\) Desviación estándar: \\(\\sigma = \\sqrt{\\text{Var}(X)}\\) Es importante distinguir que estos son parámetros poblacionales (generalmente desconocidos). Los estimamos a partir de muestras usando \\(\\bar{x}\\) y \\(s^2\\). 7.5 Distribuciones de probabilidad comunes 7.5.1 Distribución Normal (Gaussiana) La distribución más importante en estadística inferencial. Una variable \\(X\\) sigue una distribución Normal con media \\(\\mu\\) y varianza \\(\\sigma^2\\): \\[X \\sim N(\\mu, \\sigma^2)\\] Propiedades: Simétrica alrededor de \\(\\mu\\) Forma de campana 68% de observaciones dentro de \\(\\mu \\pm 1\\sigma\\) 95% dentro de \\(\\mu \\pm 1.96\\sigma\\) 99.7% dentro de \\(\\mu \\pm 3\\sigma\\) Figura 7.4: Distribución Normal estándar con regla 68-95-99.7 Las alturas de hombres adultos chilenos se distribuyen aproximadamente \\(N(170, 7^2)\\) cm. Podemos usar esta distribución para responder preguntas como: ¿Qué proporción de hombres mide más de 180 cm? o ¿Qué proporción mide entre 165 y 175 cm? # ¿Qué proporción de hombres mide más de 180 cm? 1 - pnorm(180, mean = 170, sd = 7) ## [1] 0.07656373 # ¿Qué proporción mide entre 165 y 175 cm? pnorm(175, mean = 170, sd = 7) - pnorm(165, mean = 170, sd = 7) ## [1] 0.5249495 7.5.2 Distribución Binomial Modela el número de “éxitos” en \\(n\\) ensayos independientes, cada uno con probabilidad \\(p\\) de éxito: \\[X \\sim \\text{Binomial}(n, p)\\] \\(E(X) = np\\) \\(\\text{Var}(X) = np(1-p)\\) Por ejemplo, si encuestamos \\(n=1000\\) votantes y la verdadera proporción que apoya un candidato es \\(p=0.40\\), el número de encuestados que declaran apoyo sigue \\(X \\sim \\text{Binomial}(1000, 0.40)\\): # Probabilidad de observar exactamente 400 apoyos dbinom(400, size = 1000, prob = 0.40) ## [1] 0.02574482 # Probabilidad de observar entre 380 y 420 apoyos sum(dbinom(380:420, size = 1000, prob = 0.40)) ## [1] 0.814288 # Valor esperado y desviación estándar n &lt;- 1000; p &lt;- 0.40 c(media = n*p, sd = sqrt(n*p*(1-p))) ## media sd ## 400.00000 15.49193 Figura 7.5: Distribución Binomial: Número de votantes que apoyan candidato (n=1000, p=0.40) 7.5.3 Distribución de Poisson Modela el número de eventos en un intervalo fijo de tiempo o espacio, cuando estos eventos ocurren a una tasa promedio constante \\(\\lambda\\): \\[X \\sim \\text{Poisson}(\\lambda)\\] \\(E(X) = \\lambda\\) \\(\\text{Var}(X) = \\lambda\\) Por ejemplo, si históricamente ocurren en promedio \\(\\lambda = 3.2\\) protestas por mes en una ciudad, podemos calcular probabilidades sobre el número de protestas en el próximo mes: # Probabilidad de exactamente 5 protestas este mes dpois(5, lambda = 3.2) ## [1] 0.1139794 # Probabilidad de 0 protestas dpois(0, lambda = 3.2) ## [1] 0.0407622 # Probabilidad de más de 6 protestas 1 - ppois(6, lambda = 3.2) ## [1] 0.0446191 7.6 Teorema del Límite Central El Teorema del Límite Central (TLC) es posiblemente el resultado más importante de la estadística. Fundamenta toda la inferencia estadística basada en muestras. El teorema establece que si tomamos muestras aleatorias de tamaño \\(n\\) de cualquier población con media \\(\\mu\\) y varianza finita \\(\\sigma^2\\), entonces conforme \\(n\\) aumenta, la distribución de la media muestral \\(\\bar{X}\\) se aproxima a una distribución Normal: \\(\\bar{X} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)\\). Esto ocurre independientemente de la forma de la distribución original, siempre que \\(n\\) sea suficientemente grande (típicamente \\(n \\geq 30\\)). 7.6.1 Implicaciones para ciencias sociales Podemos usar la distribución Normal para hacer inferencias sobre medias muestrales, incluso si la variable original no es Normal La varianza de \\(\\bar{X}\\) disminuye con \\(n\\): Muestras más grandes producen estimaciones más precisas Justifica el uso de pruebas t y intervalos de confianza (próximos capítulos) 7.6.2 Simulación del TLC Demostremos el TLC con un ejemplo de ciencias políticas: # Población NO normal: Participación en protestas (variable muy asimétrica) # Mayoría no participa (0), algunos participan ocasionalmente set.seed(2024) poblacion &lt;- c(rep(0, 7000), rep(1, 2000), rep(2, 700), rep(3, 200), rep(4, 80), rep(5, 20)) # Media y SD poblacionales mu_poblacion &lt;- mean(poblacion) sigma_poblacion &lt;- sd(poblacion) cat(&quot;Distribución poblacional:\\n&quot;) ## Distribución poblacional: cat(&quot;Media:&quot;, mu_poblacion, &quot;\\n&quot;) ## Media: 0.442 cat(&quot;SD:&quot;, sigma_poblacion, &quot;\\n\\n&quot;) ## SD: 0.8016859 # Tomamos 5000 muestras de diferentes tamaños y calculamos sus medias simular_medias &lt;- function(n, n_muestras = 5000) { replicate(n_muestras, mean(sample(poblacion, n, replace = TRUE))) } medias_n10 &lt;- simular_medias(10) medias_n30 &lt;- simular_medias(30) medias_n100 &lt;- simular_medias(100) # Comparación resultados &lt;- data.frame( tamaño = c(&quot;n=10&quot;, &quot;n=30&quot;, &quot;n=100&quot;), media = c(mean(medias_n10), mean(medias_n30), mean(medias_n100)), sd_observada = c(sd(medias_n10), sd(medias_n30), sd(medias_n100)), sd_teorica = sigma_poblacion / sqrt(c(10, 30, 100)) ) print(resultados) ## tamaño media sd_observada sd_teorica ## 1 n=10 0.4436600 0.25167533 0.25351534 ## 2 n=30 0.4415867 0.14769120 0.14636715 ## 3 n=100 0.4427280 0.08018356 0.08016859 Figura 7.6: Convergencia a la Normal según el Teorema del Límite Central Aunque la población original es extremadamente asimétrica (la mayoría tiene valor 0), las medias muestrales se distribuyen cada vez más normalmente conforme aumenta \\(n\\). Con \\(n=100\\), la distribución de \\(\\bar{X}\\) es prácticamente Normal. 7.7 Resumen del capítulo Conceptos clave: Probabilidad cuantifica incertidumbre; permite hacer inferencias rigurosas desde muestras Variables aleatorias (discretas y continuas) conectan probabilidad con datos observables Distribuciones importantes: Normal (continua, base de la inferencia), Binomial (conteos de éxitos), Poisson (eventos raros) Teorema del Límite Central: Las medias muestrales se distribuyen normalmente, independientemente de la distribución original TLC justifica el uso de métodos basados en la Normal para inferencia (intervalos de confianza, pruebas de hipótesis) Conexión con próximos capítulos: Cap. 8 usará el TLC para construir intervalos de confianza Cap. 9 aplicará distribuciones de probabilidad para pruebas de hipótesis Caps. 10-11 usarán la distribución Normal para comparar medias y hacer regresión 7.8 Lecturas recomendadas Agresti, A. &amp; Finlay, B. (2009). Statistical Methods for the Social Sciences. Capítulo 4: Probability Distributions. Llaudet, E. &amp; Imai, K. (2022). Data Analysis for Social Science. Capítulo 6: Probability. Diez, D., Barr, C. &amp; Çetinkaya-Rundel, M. (2019). OpenIntro Statistics. Capítulo 3: Distributions of random variables. Acceso libre 7.9 Ejercicios Conceptuales: Explica con tus propias palabras por qué es imposible que la probabilidad de un evento sea negativa o mayor que 1. ¿Cuál es la diferencia entre \\(P(A|B)\\) y \\(P(B|A)\\)? Proporciona un ejemplo de ciencias políticas donde estas dos probabilidades sean distintas. Un investigador afirma: “La probabilidad de que Chile tenga una nueva Constitución en 2026 es 0.40”. ¿Qué interpretación de probabilidad está usando: frecuentista o bayesiana? Justifica. Explica por qué la distribución Normal es tan importante en estadística, incluso cuando muchas variables en ciencias sociales no son normales. Aplicados: En una encuesta, 45% declara intención de votar. Si encuestamos 800 personas: ¿Cuál es la probabilidad de que exactamente 360 declaren intención de votar? ¿Cuál es la probabilidad de que entre 340 y 380 lo hagan? ¿Cuál sería el número esperado y la desviación estándar? Históricamente, ocurren en promedio 2.8 huelgas por mes en un sector industrial. Asumiendo distribución Poisson: ¿Probabilidad de 0 huelgas este mes? ¿Probabilidad de más de 4 huelgas? ¿Cuál es la varianza del número de huelgas? Simulación del TLC: Replica la simulación del Teorema del Límite Central usando una distribución poblacional diferente (por ejemplo, uniforme o exponencial). Compara la convergencia a la Normal para \\(n = 5, 30, 100\\). El índice de democracia V-Dem para países latinoamericanos tiene media 0.52 y SD 0.18. Si tomamos muestras aleatorias de 40 países con reemplazo: ¿Cuál es la distribución esperada de \\(\\bar{X}\\)? ¿Probabilidad de que \\(\\bar{X} &gt; 0.55\\)? ¿Probabilidad de que \\(\\bar{X}\\) esté entre 0.50 y 0.54? CONCEPTO CLAVE: La probabilidad no predice el futuro ni elimina la incertidumbre. Nos permite cuantificarla y tomar decisiones informadas bajo condiciones de información imperfecta.↩︎ PERSPECTIVA DOMINANTE: En ciencias sociales cuantitativas, la interpretación frecuentista es el estándar. Cuando un artículo reporta “p &lt; 0.05”, está usando lógica frecuentista: si no hubiera efecto real, veríamos un resultado tan extremo menos de 5% de las veces.↩︎ EJEMPLOS EN CIENCIAS SOCIALES: Número de partidos en el Congreso (1, 2, 3, …), número de protestas en un mes (0, 1, 2, 3, …), respuesta en escala Likert (1, 2, 3, 4, 5), número de votantes en una mesa (0, 1, 2, …, 300).↩︎ EJEMPLOS EN CIENCIAS SOCIALES: Porcentaje de votos obtenido (0% a 100%, cualquier valor decimal), ingreso mensual (cualquier valor positivo), índice de democracia (escala continua de 0 a 10), tiempo hasta próxima protesta (cualquier valor positivo).↩︎ "],["inferencia.html", "Capítulo 8 Inferencia estadística 8.1 Objetivos del capítulo 8.2 El problema fundamental de la inferencia 8.3 Muestras y poblaciones 8.4 Distribuciones muestrales 8.5 Error estándar 8.6 Intervalos de confianza 8.7 Determinación del tamaño muestral 8.8 Simulación: Interpretación de ICs 8.9 Resumen del capítulo 8.10 Lecturas recomendadas 8.11 Ejercicios", " Capítulo 8 Inferencia estadística 8.1 Objetivos del capítulo Al finalizar este capítulo, deberías ser capaz de: Comprender la lógica de la inferencia estadística: generalizar desde muestras a poblaciones Distinguir entre parámetros poblacionales y estadísticos muestrales Entender el concepto de distribución muestral y su relación con el Teorema del Límite Central Calcular e interpretar el error estándar Construir e interpretar intervalos de confianza para medias y proporciones Evaluar el tamaño muestral necesario para cierto nivel de precisión 8.2 El problema fundamental de la inferencia En ciencias sociales raramente tenemos acceso a poblaciones completas. Queremos saber: ¿Cuál es el apoyo real a la reforma de pensiones entre todos los chilenos? ¿Cuál es el ingreso promedio de hogares en América Latina? ¿Qué proporción de electores cambia su voto entre elecciones? Pero solo podemos encuestar una muestra de cientos o miles de personas, no los millones que componen la población. La inferencia estadística es el proceso de usar datos de una muestra para hacer afirmaciones sobre una población, cuantificando la incertidumbre asociada. 8.2.1 Ejemplo motivador: Encuestas electorales en Chile Antes de las elecciones presidenciales 2021 (segunda vuelta), múltiples encuestadoras reportaron: Preguntas clave: ¿Por qué las encuestas difieren si todas miden “lo mismo”? ¿Cuán confiables son estos números? ¿Qué tan grande debe ser la muestra? La inferencia estadística nos da herramientas para responder estas preguntas. 8.3 Muestras y poblaciones 8.3.1 Definiciones fundamentales Población: Conjunto completo de unidades de interés. Tiene parámetros (valores fijos, generalmente desconocidos): - Media poblacional: \\(\\mu\\) - Proporción poblacional: \\(p\\) - Varianza poblacional: \\(\\sigma^2\\) Muestra: Subconjunto de la población que observamos. Tiene estadísticos (valores calculados a partir de los datos): - Media muestral: \\(\\bar{x}\\) - Proporción muestral: \\(\\hat{p}\\) - Varianza muestral: \\(s^2\\) Es fundamental distinguir que los parámetros \\((\\mu, p, \\sigma^2)\\) son valores fijos (pero desconocidos) de la población, mientras que los estadísticos \\((\\bar{x}, \\hat{p}, s^2)\\) son calculados a partir de la muestra y varían entre muestras. Usamos estadísticos para estimar parámetros. Por ejemplo, consideremos el apoyo a una reforma tributaria. La población son 15 millones de votantes chilenos, y el parámetro de interés es \\(p\\) = proporción que apoya la reforma (desconocida). Si tomamos una muestra de 1,200 votantes encuestados y observamos el estadístico \\(\\hat{p} = 0.42\\) (42% de la muestra apoya), la pregunta inferencial es: ¿Qué podemos decir sobre \\(p\\) (desconocido) a partir de \\(\\hat{p} = 0.42\\) (conocido)? 8.3.2 Muestreo aleatorio simple Para que la inferencia sea válida, necesitamos muestras probabilísticas. El diseño más simple: Muestreo Aleatorio Simple (MAS): Cada unidad de la población tiene la misma probabilidad de ser seleccionada. # Simulación de población y muestra set.seed(2024) # Población de 10,000 votantes (40% apoya reforma) poblacion &lt;- c(rep(1, 4000), rep(0, 6000)) # 1 = apoya, 0 = no apoya p_verdadero &lt;- mean(poblacion) cat(&quot;Parámetro poblacional verdadero: p =&quot;, p_verdadero, &quot;\\n\\n&quot;) ## Parámetro poblacional verdadero: p = 0.4 # Tomamos una muestra aleatoria de n=1000 muestra &lt;- sample(poblacion, size = 1000, replace = FALSE) p_hat &lt;- mean(muestra) cat(&quot;Estadístico muestral: p̂ =&quot;, p_hat, &quot;\\n&quot;) ## Estadístico muestral: p̂ = 0.418 cat(&quot;Error de estimación: p̂ - p =&quot;, p_hat - p_verdadero, &quot;\\n&quot;) ## Error de estimación: p̂ - p = 0.018 Propiedades del MAS: Insesgado: En promedio, \\(E(\\hat{p}) = p\\) y \\(E(\\bar{x}) = \\mu\\) Variable: Diferentes muestras producen diferentes estimaciones Más preciso con muestras grandes: El error disminuye con \\(n\\) 8.4 Distribuciones muestrales La clave para entender la inferencia es reconocer que los estadísticos son variables aleatorias. 8.4.1 Distribución muestral de la media Si tomamos muchas muestras de tamaño \\(n\\) y calculamos \\(\\bar{x}\\) para cada una, la distribución de todos esos \\(\\bar{x}\\) es la distribución muestral de la media. Propiedades (del Teorema del Límite Central, visto en Cap. 7): \\[\\bar{X} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)\\] Media: \\(E(\\bar{X}) = \\mu\\) (insesgado) Varianza: \\(\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\) (disminuye con \\(n\\)) Forma: Aproximadamente Normal para \\(n \\geq 30\\) # Población: Ingresos mensuales (en miles de pesos) # Distribución asimétrica (lognormal) set.seed(123) poblacion_ingresos &lt;- rlnorm(100000, meanlog = log(500), sdlog = 0.6) mu_real &lt;- mean(poblacion_ingresos) sigma_real &lt;- sd(poblacion_ingresos) cat(&quot;Población:\\n&quot;) ## Población: cat(&quot;Media (μ) =&quot;, round(mu_real, 1), &quot;mil pesos\\n&quot;) ## Media (μ) = 598.8 mil pesos cat(&quot;SD (σ) =&quot;, round(sigma_real, 1), &quot;mil pesos\\n\\n&quot;) ## SD (σ) = 393.1 mil pesos # Tomamos 5000 muestras de n=100 y calculamos sus medias n_muestra &lt;- 100 medias_muestrales &lt;- replicate(5000, mean(sample(poblacion_ingresos, n_muestra))) cat(&quot;Distribución muestral de X̄ (n=100):\\n&quot;) ## Distribución muestral de X̄ (n=100): cat(&quot;Media =&quot;, round(mean(medias_muestrales), 1), &quot; (muy cerca de μ =&quot;, round(mu_real, 1), &quot;)\\n&quot;) ## Media = 598.9 (muy cerca de μ = 598.8 ) cat(&quot;SD observada =&quot;, round(sd(medias_muestrales), 1), &quot;\\n&quot;) ## SD observada = 39.3 cat(&quot;SD teórica (σ/√n) =&quot;, round(sigma_real/sqrt(n_muestra), 1), &quot;\\n&quot;) ## SD teórica (σ/√n) = 39.3 Figura 8.1: Distribución poblacional vs distribución muestral Aunque la población de ingresos es altamente asimétrica, la distribución de \\(\\bar{X}\\) es aproximadamente Normal. Esto es el Teorema del Límite Central en acción. 8.4.2 Distribución muestral de la proporción Para proporciones, una lógica similar aplica. Si \\(\\hat{p}\\) es la proporción muestral: \\[\\hat{p} \\sim N\\left(p, \\frac{p(1-p)}{n}\\right)\\] (Aproximación válida cuando \\(np \\geq 10\\) y \\(n(1-p) \\geq 10\\)) Por ejemplo, si en una encuesta electoral el verdadero apoyo es \\(p = 0.45\\) y encuestamos \\(n = 1000\\) personas: p &lt;- 0.45 n &lt;- 1000 # Media y SD de p̂ media_p_hat &lt;- p sd_p_hat &lt;- sqrt(p * (1 - p) / n) cat(&quot;Distribución de p̂:\\n&quot;) ## Distribución de p̂: cat(&quot;Media =&quot;, media_p_hat, &quot;\\n&quot;) ## Media = 0.45 cat(&quot;SD (error estándar) =&quot;, round(sd_p_hat, 4), &quot;\\n\\n&quot;) ## SD (error estándar) = 0.0157 # Probabilidad de que nuestra muestra subestime apoyo en &gt;3% prob_error_grande &lt;- pnorm(0.42, mean = p, sd = sd_p_hat) cat(&quot;P(p̂ &lt; 0.42) =&quot;, round(prob_error_grande, 3)) ## P(p̂ &lt; 0.42) = 0.028 8.5 Error estándar El error estándar (SE, standard error) es la desviación estándar de la distribución muestral de un estadístico. 8.5.1 Error estándar de la media \\[\\text{SE}(\\bar{x}) = \\frac{\\sigma}{\\sqrt{n}}\\] Pero \\(\\sigma\\) (SD poblacional) es generalmente desconocido. Lo estimamos con \\(s\\) (SD muestral): \\[\\widehat{\\text{SE}}(\\bar{x}) = \\frac{s}{\\sqrt{n}}\\] Es importante distinguir entre error estándar y desviación estándar. La desviación estándar (\\(s\\)) mide variabilidad en los datos, mientras que el error estándar (\\(\\text{SE}\\)) mide variabilidad del estadístico (precisión de la estimación). El \\(\\text{SE}\\) disminuye con \\(n\\); \\(s\\) NO (permanece constante en promedio).11 Por ejemplo, consideremos datos de ingreso familiar en una encuesta tipo CASEN: # Datos simulados de ingresos (en miles de $) set.seed(456) ingresos &lt;- rlnorm(500, meanlog = log(600), sdlog = 0.7) n &lt;- length(ingresos) media &lt;- mean(ingresos) s &lt;- sd(ingresos) se &lt;- s / sqrt(n) cat(&quot;Muestra de n =&quot;, n, &quot;hogares\\n&quot;) ## Muestra de n = 500 hogares cat(&quot;Media muestral: $&quot;, round(media, 0), &quot; mil\\n&quot;, sep = &quot;&quot;) ## Media muestral: $810 mil cat(&quot;SD de ingresos (s): $&quot;, round(s, 0), &quot; mil\\n&quot;, sep = &quot;&quot;) ## SD de ingresos (s): $606 mil cat(&quot;SE de la media: $&quot;, round(se, 0), &quot; mil\\n\\n&quot;, sep = &quot;&quot;) ## SE de la media: $27 mil cat(&quot;Interpretación:\\n&quot;) ## Interpretación: cat(&quot;- Los ingresos individuales varían típicamente ±$&quot;, round(s, 0), &quot; mil alrededor de la media\\n&quot;, sep = &quot;&quot;) ## - Los ingresos individuales varían típicamente ±$606 mil alrededor de la media cat(&quot;- Nuestra estimación de la media tiene error típico de ±$&quot;, round(se, 0), &quot; mil\\n&quot;, sep = &quot;&quot;) ## - Nuestra estimación de la media tiene error típico de ±$27 mil 8.5.2 Error estándar de la proporción \\[\\text{SE}(\\hat{p}) = \\sqrt{\\frac{p(1-p)}{n}}\\] Como \\(p\\) es desconocido, lo estimamos con \\(\\hat{p}\\): \\[\\widehat{\\text{SE}}(\\hat{p}) = \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\] # Encuesta: proporción que apoya política X n &lt;- 1200 apoyos &lt;- 510 p_hat &lt;- apoyos / n se_p &lt;- sqrt(p_hat * (1 - p_hat) / n) cat(&quot;n =&quot;, n, &quot;encuestados\\n&quot;) ## n = 1200 encuestados cat(&quot;Apoyan =&quot;, apoyos, &quot;(&quot;, round(p_hat * 100, 1), &quot;%)\\n&quot;, sep = &quot;&quot;) ## Apoyan =510(42.5%) cat(&quot;SE(p̂) =&quot;, round(se_p, 4), &quot;o&quot;, round(se_p * 100, 2), &quot;puntos porcentuales\\n&quot;) ## SE(p̂) = 0.0143 o 1.43 puntos porcentuales 8.5.3 El error estándar disminuye con \\(\\sqrt{n}\\) Una implicación crucial: para reducir el SE a la mitad, necesitas cuadruplicar el tamaño muestral. Figura 8.2: Relación entre tamaño muestral y error estándar 8.6 Intervalos de confianza Un intervalo de confianza (IC) es un rango de valores plausibles para el parámetro poblacional, construido de tal manera que, si repitiéramos el muestreo infinitas veces, el IC contendría el valor verdadero en (por ejemplo) 95% de las muestras. 8.6.1 Intervalo de confianza para la media Fórmula general: \\[\\text{IC}_{95\\%} = \\bar{x} \\pm t_{n-1, 0.975} \\cdot \\frac{s}{\\sqrt{n}}\\] donde \\(t_{n-1, 0.975}\\) es el valor crítico de la distribución \\(t\\) con \\(n-1\\) grados de libertad. Cuando \\(n\\) es grande (\\(n \\geq 30\\)), \\(t \\approx 1.96\\), así que: \\[\\text{IC}_{95\\%} \\approx \\bar{x} \\pm 1.96 \\cdot \\text{SE}(\\bar{x})\\] La interpretación correcta de un IC 95% es: “Si repitiéramos este proceso de muestreo muchas veces, aproximadamente 95% de los intervalos construidos contendrían el verdadero valor de \\(\\mu\\).” NO significa “Hay 95% de probabilidad de que \\(\\mu\\) esté en este intervalo específico.” (La diferencia es sutil pero importante: \\(\\mu\\) es fijo; el intervalo es lo que varía entre muestras.) Por ejemplo, consideremos el cálculo de un intervalo de confianza para el ingreso promedio: # Datos de ingresos (retomando ejemplo anterior) set.seed(789) ingresos &lt;- rlnorm(200, meanlog = log(550), sdlog = 0.65) n &lt;- length(ingresos) media &lt;- mean(ingresos) s &lt;- sd(ingresos) se &lt;- s / sqrt(n) # Valor crítico t para 95% de confianza t_crit &lt;- qt(0.975, df = n - 1) # Intervalo de confianza ic_inferior &lt;- media - t_crit * se ic_superior &lt;- media + t_crit * se cat(&quot;Ingreso promedio mensual (n =&quot;, n, &quot;hogares):\\n&quot;) ## Ingreso promedio mensual (n = 200 hogares): cat(&quot;Media muestral: $&quot;, round(media, 0), &quot; mil\\n&quot;, sep = &quot;&quot;) ## Media muestral: $653 mil cat(&quot;IC 95%: [$&quot;, round(ic_inferior, 0), &quot;, $&quot;, round(ic_superior, 0), &quot;] mil\\n\\n&quot;, sep = &quot;&quot;) ## IC 95%: [$588, $719] mil cat(&quot;Interpretación: Estamos 95% confiados de que el ingreso promedio\\n&quot;) ## Interpretación: Estamos 95% confiados de que el ingreso promedio cat(&quot;poblacional está entre $&quot;, round(ic_inferior, 0), &quot; y $&quot;, round(ic_superior, 0), &quot; mil.\\n&quot;, sep = &quot;&quot;) ## poblacional está entre $588 y $719 mil. 8.6.2 Intervalo de confianza para la proporción \\[\\text{IC}_{95\\%} = \\hat{p} \\pm 1.96 \\cdot \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\] (Válido cuando \\(n\\hat{p} \\geq 10\\) y \\(n(1-\\hat{p}) \\geq 10\\)) Por ejemplo, para una encuesta de intención de voto: # Encuesta: ¿Votará en próximas elecciones? n &lt;- 1500 votaran &lt;- 780 p_hat &lt;- votaran / n se_p &lt;- sqrt(p_hat * (1 - p_hat) / n) # IC 95% ic_inf &lt;- p_hat - 1.96 * se_p ic_sup &lt;- p_hat + 1.96 * se_p cat(&quot;Encuesta (n =&quot;, n, &quot;):\\n&quot;) ## Encuesta (n = 1500 ): cat(&quot;Declaran que votarán:&quot;, votaran, &quot;personas (&quot;, round(p_hat * 100, 1), &quot;%)\\n&quot;, sep = &quot;&quot;) ## Declaran que votarán:780personas (52%) cat(&quot;IC 95%: [&quot;, round(ic_inf * 100, 1), &quot;%, &quot;, round(ic_sup * 100, 1), &quot;%]\\n\\n&quot;, sep = &quot;&quot;) ## IC 95%: [49.5%, 54.5%] cat(&quot;Interpretación: El verdadero porcentaje de personas que votarán\\n&quot;) ## Interpretación: El verdadero porcentaje de personas que votarán cat(&quot;está probablemente entre&quot;, round(ic_inf * 100, 1), &quot;% y&quot;, round(ic_sup * 100, 1), &quot;%.\\n&quot;) ## está probablemente entre 49.5 % y 54.5 %. 8.6.3 Niveles de confianza alternativos No estamos limitados a 95%. Podemos construir ICs con cualquier nivel de confianza: Nivel de Confianza Valor Crítico \\(z\\) Intervalo 90% 1.645 \\(\\bar{x} \\pm 1.645 \\cdot \\text{SE}\\) 95% 1.960 \\(\\bar{x} \\pm 1.960 \\cdot \\text{SE}\\) 99% 2.576 \\(\\bar{x} \\pm 2.576 \\cdot \\text{SE}\\) Relación inversa: Mayor confianza → Intervalo más ancho # Ejemplo con ingreso promedio media &lt;- 550 se &lt;- 35 niveles &lt;- c(0.90, 0.95, 0.99) z_valores &lt;- qnorm(1 - (1 - niveles)/2) resultados &lt;- data.frame( nivel = paste0(niveles * 100, &quot;%&quot;), z = round(z_valores, 3), inferior = round(media - z_valores * se, 0), superior = round(media + z_valores * se, 0) ) resultados$ancho &lt;- resultados$superior - resultados$inferior print(resultados) ## nivel z inferior superior ancho ## 1 90% 1.645 492 608 116 ## 2 95% 1.960 481 619 138 ## 3 99% 2.576 460 640 180 Figura 8.3: Visualización de ICs con diferentes niveles de confianza 8.7 Determinación del tamaño muestral Una pregunta práctica crucial: ¿Qué tan grande debe ser mi muestra? 8.7.1 Para estimar una media Queremos que el IC tenga ancho máximo \\(2E\\) (es decir, margen de error \\(E\\)): \\[n = \\left(\\frac{z_{\\alpha/2} \\cdot \\sigma}{E}\\right)^2\\] Por ejemplo, si queremos estimar el ingreso promedio con precisión de ±$20 mil: # Deseamos IC 95% con margen de error E = 20 mil # Estimamos σ ≈ 300 mil (de estudios previos) E &lt;- 20 sigma &lt;- 300 z &lt;- 1.96 n_necesario &lt;- ceiling((z * sigma / E)^2) cat(&quot;Para estimar ingreso promedio con:\\n&quot;) ## Para estimar ingreso promedio con: cat(&quot;- Nivel de confianza: 95%\\n&quot;) ## - Nivel de confianza: 95% cat(&quot;- Margen de error: ±$&quot;, E, &quot; mil\\n&quot;, sep = &quot;&quot;) ## - Margen de error: ±$20 mil cat(&quot;- σ estimado: $&quot;, sigma, &quot; mil\\n&quot;, sep = &quot;&quot;) ## - σ estimado: $300 mil cat(&quot;\\nTamaño muestral necesario: n =&quot;, n_necesario, &quot;hogares\\n&quot;) ## ## Tamaño muestral necesario: n = 865 hogares ::: 8.7.2 Para estimar una proporción \\[n = \\left(\\frac{z_{\\alpha/2}}{E}\\right)^2 \\cdot p(1-p)\\] Si no conocemos \\(p\\), usamos \\(p = 0.5\\) (el escenario más conservador): \\[n = \\left(\\frac{z_{\\alpha/2}}{E}\\right)^2 \\cdot 0.25\\] Tamaño muestral para encuesta electoral ¿Cuántos encuestados necesito para estimar intención de voto con margen de error de ±3% (95% de confianza)? E &lt;- 0.03 # 3 puntos porcentuales z &lt;- 1.96 p &lt;- 0.5 # Peor caso n_necesario &lt;- ceiling((z / E)^2 * p * (1 - p)) cat(&quot;Para estimar proporción con:\\n&quot;) ## Para estimar proporción con: cat(&quot;- Nivel de confianza: 95%\\n&quot;) ## - Nivel de confianza: 95% cat(&quot;- Margen de error: ±&quot;, E * 100, &quot;%\\n&quot;, sep = &quot;&quot;) ## - Margen de error: ±3% cat(&quot;\\nTamaño muestral necesario: n =&quot;, n_necesario, &quot;\\n&quot;) ## ## Tamaño muestral necesario: n = 1068 Por eso las encuestas electorales típicamente tienen ~1,000-1,500 entrevistados. 8.7.3 Tabla de referencia: Tamaño muestral para proporciones Tabla 8.1: Tamaño muestral necesario para estimar proporción (p=0.5) Margen error 90% 95% 99% ±1% 6764 9604 16588 ±2% 1691 2401 4147 ±3% 752 1068 1844 ±4% 423 601 1037 ±5% 271 385 664 ±10% 68 97 166 8.8 Simulación: Interpretación de ICs Demostremos con simulación qué significa “95% de confianza”: # Parámetros poblacionales conocidos (para la simulación) mu_real &lt;- 500 sigma_real &lt;- 120 n &lt;- 50 # Tomamos 100 muestras y calculamos IC para cada una set.seed(2025) n_simulaciones &lt;- 100 resultados_sim &lt;- data.frame( muestra = 1:n_simulaciones, media = numeric(n_simulaciones), ic_inf = numeric(n_simulaciones), ic_sup = numeric(n_simulaciones) ) for (i in 1:n_simulaciones) { muestra &lt;- rnorm(n, mean = mu_real, sd = sigma_real) media &lt;- mean(muestra) se &lt;- sd(muestra) / sqrt(n) t_crit &lt;- qt(0.975, df = n - 1) resultados_sim$media[i] &lt;- media resultados_sim$ic_inf[i] &lt;- media - t_crit * se resultados_sim$ic_sup[i] &lt;- media + t_crit * se } # ¿Cuántos ICs contienen μ? resultados_sim$contiene_mu &lt;- (resultados_sim$ic_inf &lt;= mu_real &amp; resultados_sim$ic_sup &gt;= mu_real) prop_contiene &lt;- mean(resultados_sim$contiene_mu) cat(&quot;De&quot;, n_simulaciones, &quot;intervalos de confianza al 95%:\\n&quot;) ## De 100 intervalos de confianza al 95%: cat(sum(resultados_sim$contiene_mu), &quot;contienen el verdadero valor μ =&quot;, mu_real, &quot;\\n&quot;) ## 93 contienen el verdadero valor μ = 500 cat(&quot;Proporción:&quot;, round(prop_contiene, 3), &quot;\\n&quot;) ## Proporción: 0.93 cat(&quot;(Esperábamos ~0.95)\\n&quot;) ## (Esperábamos ~0.95) Figura 8.4: 100 intervalos de confianza: los verdes contienen μ, los rojos no Mensaje clave: El “95%” NO se refiere a una muestra individual, sino al procedimiento. Si lo repitiéramos infinitas veces, 95% de los intervalos contendrían \\(\\mu\\). Para cualquier muestra específica, o contiene \\(\\mu\\) o no (pero no sabemos cuál). 8.9 Resumen del capítulo Conceptos clave: Inferencia estadística: Usar muestras para hacer afirmaciones sobre poblaciones Parámetros vs estadísticos: \\(\\mu, p\\) (poblacionales, fijos, desconocidos) vs \\(\\bar{x}, \\hat{p}\\) (muestrales, variables, observables) Distribución muestral: Distribución de un estadístico a través de todas las muestras posibles Error estándar: SD de la distribución muestral; mide precisión de la estimación; \\(\\text{SE} = s/\\sqrt{n}\\) Intervalos de confianza: Rango plausible para el parámetro; nivel de confianza se refiere al procedimiento, no a un intervalo específico Tamaño muestral: Determinar \\(n\\) necesario para lograr margen de error deseado Fórmulas esenciales: Concepto Media Proporción Error estándar \\(\\text{SE} = s/\\sqrt{n}\\) \\(\\text{SE} = \\sqrt{\\hat{p}(1-\\hat{p})/n}\\) IC 95% \\(\\bar{x} \\pm 1.96 \\cdot \\text{SE}\\) \\(\\hat{p} \\pm 1.96 \\cdot \\text{SE}\\) Tamaño muestral \\(n = (z\\sigma/E)^2\\) \\(n = (z/E)^2 \\cdot 0.25\\) Conexión con próximos capítulos: Cap. 9 extenderá la lógica de inferencia a pruebas de hipótesis Caps. 10-11 aplicarán ICs y pruebas para comparar grupos y analizar relaciones 8.10 Lecturas recomendadas Agresti, A. &amp; Finlay, B. (2009). Statistical Methods for the Social Sciences. Capítulo 5: Statistical Inference: Estimation. Llaudet, E. &amp; Imai, K. (2022). Data Analysis for Social Science. Capítulo 7: Uncertainty. Diez, D. et al. (2019). OpenIntro Statistics. Capítulo 4: Foundations for inference. Acceso libre 8.11 Ejercicios Conceptuales: Explica la diferencia entre error estándar y desviación estándar. ¿Por qué el error estándar disminuye con \\(n\\) pero la desviación estándar no? Un estudiante afirma: “Calculé un IC 95% de [45%, 51%] para la intención de voto. Esto significa que hay 95% de probabilidad de que el verdadero porcentaje esté en ese rango.” ¿Es correcta esta interpretación? Corrige si es necesario. ¿Por qué un IC 99% es más ancho que un IC 95% para los mismos datos? ¿Cuál es el trade-off? Si duplicas el tamaño de tu muestra, ¿en cuánto se reduce el error estándar? Aplicados: Una encuesta con \\(n=800\\) encuentra que 55% apoya una reforma constitucional. Calcula el error estándar de \\(\\hat{p}\\) Construye un IC 95% para la proporción poblacional ¿Es razonable concluir que la mayoría de la población apoya la reforma? El ingreso promedio en una muestra de \\(n=150\\) hogares es \\(\\bar{x} = 680\\) mil pesos, con \\(s = 210\\) mil. Calcula el error estándar de \\(\\bar{x}\\) Construye un IC 95% para el ingreso promedio poblacional Construye un IC 99% y compara el ancho Planificación de encuesta: Quieres estimar el porcentaje de estudiantes que aprueban un curso con margen de error de ±5% (IC 95%). ¿Cuántos estudiantes debes encuestar? Simulación: Replica la simulación de 100 ICs del capítulo, pero usando un IC 90% en lugar de 95%. ¿Aproximadamente cuántos intervalos esperarías que NO contengan \\(\\mu\\)? Verifica con código. Una encuestadora reporta: “Candidato A: 48% ± 3%”. Interpreta este resultado en términos de IC ¿Aproximadamente cuál fue el tamaño muestral? ¿Podemos concluir que el candidato perdería (&lt; 50%)? CONFUSIÓN COMÚN: El error estándar (\\(\\text{SE}\\)) mide qué tan precisa es nuestra estimación de la media. La desviación estándar (\\(s\\)) mide qué tan dispersos están los datos individuales. Son conceptos diferentes: \\(\\text{SE} = s/\\sqrt{n}\\) siempre es menor que \\(s\\) (excepto cuando \\(n=1\\)).↩︎ "],["hipotesis.html", "Capítulo 9 Pruebas de hipótesis 9.1 Objetivos del capítulo 9.2 Lógica de las pruebas de hipótesis 9.3 Hipótesis nula y alternativa 9.4 Valores p y significancia estadística 9.5 Errores tipo I y tipo II 9.6 Resumen del capítulo 9.7 Lecturas recomendadas 9.8 Ejercicios", " Capítulo 9 Pruebas de hipótesis 9.1 Objetivos del capítulo Al finalizar este capítulo, deberías ser capaz de: Comprender la lógica de las pruebas de hipótesis estadísticas Formular correctamente hipótesis nula (\\(H_0\\)) y alternativa (\\(H_1\\)) Interpretar valores p y niveles de significancia Distinguir entre significancia estadística y sustantiva Reconocer y evitar errores tipo I y tipo II Realizar pruebas de hipótesis para medias y proporciones Entender las limitaciones y mal usos comunes de las pruebas de hipótesis 9.2 Lógica de las pruebas de hipótesis Las pruebas de hipótesis responden a una pregunta fundamental en investigación: ¿Este patrón que observo en mis datos es real, o podría ser producto del azar? Consideremos un caso concreto: en una encuesta antes de una campaña publicitaria, 42% de 800 encuestados apoyaba al Candidato A. Después de la campaña, en otra muestra de 800 personas, 47% lo apoya. La pregunta relevante es: ¿la campaña fue efectiva, o esta diferencia de 5 puntos porcentuales podría deberse simplemente a error muestral? 9.2.1 La lógica de prueba por contradicción Las pruebas de hipótesis usan un argumento de reducción al absurdo: Asumimos que NO hay efecto (hipótesis nula: \\(H_0\\)) Preguntamos: ¿Qué tan probable es observar nuestros datos si \\(H_0\\) fuera cierta? Si esa probabilidad es muy baja, rechazamos \\(H_0\\) como implausible Si la probabilidad no es tan baja, no rechazamos \\(H_0\\) (no tenemos evidencia suficiente contra ella) Es crucial entender la asimetría fundamental de este razonamiento: nunca “aceptamos” o “probamos” \\(H_0\\). Solo podemos rechazar \\(H_0\\) (cuando hay evidencia contra ella) o no rechazar \\(H_0\\) (cuando no hay evidencia suficiente contra ella). Esto es análogo a un juicio judicial: no “probamos inocencia”, solo establecemos que “no hay evidencia suficiente de culpabilidad”. 9.3 Hipótesis nula y alternativa 9.3.1 Formulación de hipótesis Hipótesis nula (\\(H_0\\)): Afirmación de “no efecto” o “no diferencia”. Es lo que asumimos como cierto inicialmente. Hipótesis alternativa (\\(H_1\\)): Lo que esperamos encontrar si rechazamos \\(H_0\\). Puede ser: - Bilateral (dos colas): \\(H_1: \\mu \\neq \\mu_0\\) (hay diferencia, en cualquier dirección) - Unilateral (una cola): \\(H_1: \\mu &gt; \\mu_0\\) o \\(H_1: \\mu &lt; \\mu_0\\) (dirección específica) Consideremos algunos casos concretos en ciencias sociales. Si evaluamos el efecto de una política pública sobre desempleo, podríamos plantear \\(H_0: \\mu = 8\\%\\) (el desempleo se mantiene en 8%) versus \\(H_1: \\mu &lt; 8\\%\\) (la política redujo el desempleo), usando una prueba unilateral. Para comparar participación electoral entre géneros, formularíamos \\(H_0: p_{\\text{hombres}} = p_{\\text{mujeres}}\\) (no hay diferencia) contra \\(H_1: p_{\\text{hombres}} \\neq p_{\\text{mujeres}}\\) (hay diferencia), usando una prueba bilateral. Finalmente, al comparar el ingreso promedio de una región con el nacional, plantearíamos \\(H_0: \\mu_{\\text{región}} = 550\\) mil pesos (igual al promedio nacional) versus \\(H_1: \\mu_{\\text{región}} \\neq 550\\) mil (diferente al nacional).12 9.4 Valores p y significancia estadística 9.4.1 ¿Qué es un valor p? El valor p (p-value) es la probabilidad de observar datos tan extremos como los nuestros (o más), asumiendo que \\(H_0\\) es cierta. \\[\\text{valor } p = P(\\text{datos tan extremos} \\mid H_0 \\text{ es cierta})\\] La interpretación correcta del valor p es fundamental para evitar errores comunes.13 Cuando observamos \\(p = 0.03\\), debemos interpretar: “Si no hubiera efecto real, veríamos resultados tan extremos solo 3% de las veces.” Un valor \\(p = 0.001\\) indica: “Si \\(H_0\\) fuera cierta, estos datos serían extremadamente raros (1 en 1000).” Por el contrario, \\(p = 0.45\\) significa: “Estos datos son muy compatibles con \\(H_0\\); no hay evidencia contra ella.” El valor p NO representa la probabilidad de que \\(H_0\\) sea cierta. 9.5 Errores tipo I y tipo II En pruebas de hipótesis, existen dos tipos de error posibles: Error Tipo I: Rechazar \\(H_0\\) cuando es cierta (falso positivo) - Probabilidad: \\(\\alpha\\) (nivel de significancia) Error Tipo II: No rechazar \\(H_0\\) cuando es falsa (falso negativo) - Probabilidad: \\(\\beta\\) Poder estadístico: \\(1 - \\beta\\) (probabilidad de detectar un efecto real) 9.6 Resumen del capítulo Conceptos clave: Pruebas de hipótesis usan lógica de reducción al absurdo Valor p: Probabilidad de datos tan extremos bajo \\(H_0\\) Errores: Tipo I (falso positivo), Tipo II (falso negativo) Significancia estadística vs sustantiva Nunca “aceptamos” \\(H_0\\): Solo podemos rechazarla o no rechazarla 9.7 Lecturas recomendadas Agresti, A. &amp; Finlay, B. (2009). Statistical Methods for the Social Sciences. Capítulo 6: Statistical Inference: Significance Tests. Llaudet, E. &amp; Imai, K. (2022). Data Analysis for Social Science. Capítulo 7.5: Hypothesis Testing. 9.8 Ejercicios Explica la diferencia entre “no rechazar \\(H_0\\)” y “aceptar \\(H_0\\)”. Un investigador reporta: “El valor p fue 0.08, por lo tanto no hay efecto.” ¿Qué está mal? ¿Qué es más grave: Error Tipo I o Error Tipo II? Discute según el contexto. EJEMPLOS ADICIONALES EN CIENCIAS POLÍTICAS: Evaluar si una reforma electoral aumentó la participación (\\(H_0: p_{\\text{antes}} = p_{\\text{después}}\\) vs \\(H_1: p_{\\text{después}} &gt; p_{\\text{antes}}\\)); comparar aprobación presidencial entre regiones urbanas y rurales (\\(H_0: \\mu_{\\text{urbana}} = \\mu_{\\text{rural}}\\) vs \\(H_1: \\mu_{\\text{urbana}} \\neq \\mu_{\\text{rural}}\\)).↩︎ INTERPRETACIÓN ERRÓNEA COMÚN: “p = 0.03 significa que hay 3% de probabilidad de que \\(H_0\\) sea cierta”. FALSO. El valor p NO es \\(P(H_0 | \\text{datos})\\). Es \\(P(\\text{datos} | H_0)\\). La hipótesis nula es una afirmación fija, no una variable aleatoria con probabilidad asociada. Esta confusión entre probabilidades condicionales es uno de los errores más frecuentes en la interpretación de resultados estadísticos.↩︎ "],["comparacion.html", "Capítulo 10 Comparación de medias 10.1 Objetivos del capítulo 10.2 Prueba t para una muestra 10.3 Prueba t para dos muestras 10.4 ANOVA 10.5 Supuestos y alternativas no paramétricas 10.6 Resumen del capítulo 10.7 Lecturas recomendadas 10.8 Ejercicios", " Capítulo 10 Comparación de medias 10.1 Objetivos del capítulo Al finalizar este capítulo, deberías ser capaz de: Realizar pruebas t para comparar medias entre dos grupos Distinguir entre pruebas t para muestras independientes y pareadas Comprender los supuestos de las pruebas paramétricas Usar ANOVA para comparar medias de más de dos grupos Identificar cuándo usar alternativas no paramétricas 10.2 Prueba t para una muestra La prueba t para una muestra compara la media de una muestra con un valor teórico o poblacional. Hipótesis: - \\(H_0: \\mu = \\mu_0\\) - \\(H_1: \\mu \\neq \\mu_0\\) Estadístico t: \\[t = \\frac{\\bar{x} - \\mu_0}{s / \\sqrt{n}}\\] 10.3 Prueba t para dos muestras 10.3.1 Muestras independientes Comparamos las medias de dos grupos independientes. Hipótesis: - \\(H_0: \\mu_1 = \\mu_2\\) - \\(H_1: \\mu_1 \\neq \\mu_2\\) Estadístico t: \\[t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\\] Consideremos un caso concreto para ilustrar esta prueba: la comparación de ingresos promedio entre hombres y mujeres en Chile. # Datos simulados: Diferencia salarial por género set.seed(2024) ingresos_hombres &lt;- rlnorm(150, meanlog = log(750), sdlog = 0.6) ingresos_mujeres &lt;- rlnorm(150, meanlog = log(650), sdlog = 0.6) # Prueba t para dos muestras independientes resultado &lt;- t.test(ingresos_hombres, ingresos_mujeres) print(resultado) ## ## Welch Two Sample t-test ## ## data: ingresos_hombres and ingresos_mujeres ## t = 0.7294, df = 297.17, p-value = 0.4663 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -71.76787 156.29638 ## sample estimates: ## mean of x mean of y ## 865.2076 822.9434 10.3.2 Muestras pareadas Para datos pareados (mismo sujeto medido dos veces, o pares emparejados) se requiere una prueba t específica que reconoce la dependencia entre observaciones. Consideremos el caso de evaluación de una intervención policial sobre percepción de seguridad, donde medimos a los mismos individuos antes y después de la intervención: # Datos: Percepción de seguridad antes y después de intervención policial set.seed(123) antes &lt;- rnorm(50, mean = 4.2, sd = 1.5) despues &lt;- antes + rnorm(50, mean = 0.8, sd = 1.0) # Mejora promedio # Prueba t pareada resultado &lt;- t.test(despues, antes, paired = TRUE) print(resultado) ## ## Paired t-test ## ## data: despues and antes ## t = 7.391, df = 49, p-value = 1.649e-09 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## 0.689083 1.203734 ## sample estimates: ## mean difference ## 0.9464083 10.4 ANOVA Análisis de Varianza (ANOVA) compara medias de más de dos grupos. Hipótesis: - \\(H_0: \\mu_1 = \\mu_2 = \\mu_3 = \\ldots = \\mu_k\\) - \\(H_1\\): Al menos una media es diferente Ilustremos el uso de ANOVA con un caso frecuente en ciencias sociales: la comparación de ingresos según nivel educacional. Queremos determinar si existen diferencias significativas entre los ingresos promedio de personas con educación básica, media y superior. # Datos simulados: Ingresos por nivel educacional set.seed(456) datos &lt;- data.frame( ingreso = c( rnorm(100, mean = 500, sd = 120), # Básica rnorm(100, mean = 650, sd = 150), # Media rnorm(100, mean = 900, sd = 200) # Superior ), educacion = factor(rep(c(&quot;Básica&quot;, &quot;Media&quot;, &quot;Superior&quot;), each = 100)) ) # ANOVA modelo &lt;- aov(ingreso ~ educacion, data = datos) summary(modelo) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## educacion 2 8688775 4344388 180.4 &lt;2e-16 *** ## Residuals 297 7151203 24078 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # Comparaciones post-hoc (para identificar qué grupos difieren) TukeyHSD(modelo) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = ingreso ~ educacion, data = datos) ## ## $educacion ## diff lwr upr p adj ## Media-Básica 118.0247 66.33382 169.7156 5e-07 ## Superior-Básica 405.2554 353.56452 456.9463 0e+00 ## Superior-Media 287.2307 235.53980 338.9216 0e+00 10.5 Supuestos y alternativas no paramétricas 10.5.1 Supuestos de pruebas t y ANOVA Normalidad: Los datos siguen distribución normal Homogeneidad de varianzas: Las varianzas son iguales entre grupos Independencia: Las observaciones son independientes 10.5.2 Alternativas no paramétricas Cuando los supuestos no se cumplen: Mann-Whitney U (en lugar de t para dos muestras independientes) Wilcoxon signed-rank (en lugar de t pareada) Kruskal-Wallis (en lugar de ANOVA) 10.6 Resumen del capítulo Conceptos clave: Prueba t: Compara medias entre grupos Muestras independientes vs pareadas: Requieren diferentes pruebas ANOVA: Compara más de dos grupos simultáneamente Supuestos: Normalidad, homogeneidad, independencia Alternativas no paramétricas: Para cuando no se cumplen supuestos 10.7 Lecturas recomendadas Agresti, A. &amp; Finlay, B. (2009). Statistical Methods for the Social Sciences. Capítulo 7: Comparison of Two Groups. Llaudet, E. &amp; Imai, K. (2022). Data Analysis for Social Science. Capítulo 3: Causality. 10.8 Ejercicios Compara los ingresos promedio entre dos regiones de Chile usando una prueba t. Realiza un ANOVA para comparar niveles de participación electoral entre 4 países latinoamericanos. Verifica los supuestos de normalidad y homogeneidad de varianzas para tus datos. "],["regresion-bivariada.html", "Capítulo 11 Regresión bivariada 11.1 Objetivos del capítulo 11.2 Correlación 11.3 El modelo de regresión lineal simple 11.4 Mínimos cuadrados ordinarios 11.5 Interpretación de coeficientes 11.6 Bondad de ajuste 11.7 Resumen del capítulo 11.8 Lecturas recomendadas 11.9 Ejercicios", " Capítulo 11 Regresión bivariada 11.1 Objetivos del capítulo Al finalizar este capítulo, deberías ser capaz de: Calcular e interpretar coeficientes de correlación Comprender la diferencia entre correlación y causalidad Estimar modelos de regresión lineal simple usando mínimos cuadrados ordinarios Interpretar coeficientes de regresión e intercepto Evaluar la bondad de ajuste usando \\(R^2\\) Realizar pruebas de hipótesis sobre coeficientes de regresión 11.2 Correlación La correlación mide la fuerza y dirección de la relación lineal entre dos variables. Coeficiente de correlación de Pearson: \\[r = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum (x_i - \\bar{x})^2} \\sqrt{\\sum (y_i - \\bar{y})^2}}\\] \\(-1 \\leq r \\leq 1\\) \\(r = 1\\): Correlación positiva perfecta \\(r = 0\\): Sin correlación lineal \\(r = -1\\): Correlación negativa perfecta Para ilustrar el uso de la correlación, consideremos la relación entre desarrollo económico y democracia, un tema clásico en ciencia política. Analizamos datos de PIB per cápita y nivel de democracia en una muestra de países: # Datos simulados: PIB per cápita y nivel de democracia set.seed(2024) n &lt;- 50 pib &lt;- rnorm(n, mean = 15000, sd = 8000) democracia &lt;- 3 + 0.0003 * pib + rnorm(n, mean = 0, sd = 1.5) # Correlación de Pearson cor_pearson &lt;- cor(pib, democracia) cat(&quot;Correlación de Pearson:&quot;, round(cor_pearson, 3), &quot;\\n&quot;) ## Correlación de Pearson: 0.865 # Test de significancia cor.test(pib, democracia) ## ## Pearson&#39;s product-moment correlation ## ## data: pib and democracia ## t = 11.931, df = 48, p-value = 5.76e-16 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.7723183 0.9213409 ## sample estimates: ## cor ## 0.8647649 Es fundamental recordar que una correlación fuerte NO implica que una variable cause la otra. Pueden existir variables confusoras, causalidad inversa, o relaciones espurias.14 11.3 El modelo de regresión lineal simple La regresión lineal modela la relación entre una variable dependiente \\(Y\\) y una variable independiente \\(X\\): \\[Y_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i\\] donde: - \\(\\beta_0\\) = intercepto (valor de \\(Y\\) cuando \\(X = 0\\)) - \\(\\beta_1\\) = pendiente (cambio en \\(Y\\) por unidad de cambio en \\(X\\)) - \\(\\epsilon_i\\) = error (variación no explicada por el modelo) 11.4 Mínimos cuadrados ordinarios El método de mínimos cuadrados ordinarios (OLS, Ordinary Least Squares) estima \\(\\beta_0\\) y \\(\\beta_1\\) minimizando la suma de errores al cuadrado: \\[\\min_{\\beta_0, \\beta_1} \\sum_{i=1}^n (Y_i - \\hat{Y}_i)^2\\] Fórmulas OLS: \\[\\hat{\\beta}_1 = \\frac{\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum (X_i - \\bar{X})^2} = r \\cdot \\frac{s_Y}{s_X}\\] \\[\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1 \\bar{X}\\] Ilustremos la estimación OLS con un ejemplo de economía política: la relación entre gasto público y crecimiento económico. # Datos simulados: Gasto público y crecimiento económico set.seed(456) gasto_publico &lt;- runif(40, min = 15, max = 40) # % del PIB crecimiento &lt;- 5 - 0.15 * gasto_publico + rnorm(40, mean = 0, sd = 1.2) # Modelo de regresión lineal simple modelo &lt;- lm(crecimiento ~ gasto_publico) summary(modelo) ## ## Call: ## lm(formula = crecimiento ~ gasto_publico) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.60682 -0.55133 -0.02959 0.53668 2.21695 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.07893 0.69853 5.839 9.46e-07 *** ## gasto_publico -0.11667 0.02305 -5.061 1.10e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.063 on 38 degrees of freedom ## Multiple R-squared: 0.4027, Adjusted R-squared: 0.3869 ## F-statistic: 25.62 on 1 and 38 DF, p-value: 1.097e-05 Figura 11.1: Regresión lineal: Gasto público y crecimiento 11.5 Interpretación de coeficientes Intercepto (\\(\\hat{\\beta}_0\\)): Valor predicho de \\(Y\\) cuando \\(X = 0\\) Pendiente (\\(\\hat{\\beta}_1\\)): Cambio promedio en \\(Y\\) asociado con un incremento de una unidad en \\(X\\) En el modelo anterior, si obtuviéramos \\(\\hat{\\beta}_1 = -0.15\\), interpretaríamos: “Por cada punto porcentual adicional de gasto público, el crecimiento económico disminuye en promedio 0.15 puntos porcentuales.”15 11.6 Bondad de ajuste 11.6.1 R cuadrado (\\(R^2\\)) El coeficiente de determinación mide qué proporción de la variabilidad en \\(Y\\) es explicada por \\(X\\): \\[R^2 = 1 - \\frac{\\sum (Y_i - \\hat{Y}_i)^2}{\\sum (Y_i - \\bar{Y})^2}\\] \\(0 \\leq R^2 \\leq 1\\) \\(R^2 = 0\\): El modelo no explica nada \\(R^2 = 1\\): El modelo explica perfectamente Por ejemplo, si \\(R^2 = 0.42\\), interpretamos: “El 42% de la variabilidad en el crecimiento económico es explicada por el gasto público. El 58% restante se debe a otros factores.” Es crucial entender que un \\(R^2\\) alto NO implica relación causal. Puede haber variables omitidas importantes, relaciones espurias, o causalidad inversa.16 11.7 Resumen del capítulo Conceptos clave: Correlación: Mide fuerza y dirección de relación lineal (no implica causalidad) Regresión lineal: Modela \\(Y\\) como función lineal de \\(X\\) OLS: Método para estimar coeficientes minimizando errores al cuadrado Interpretación: \\(\\beta_0\\) = intercepto, \\(\\beta_1\\) = pendiente \\(R^2\\): Proporción de variabilidad explicada por el modelo Fórmulas clave: Correlación: \\(r = \\frac{\\text{Cov}(X,Y)}{s_X s_Y}\\) Pendiente: \\(\\hat{\\beta}_1 = r \\cdot \\frac{s_Y}{s_X}\\) Intercepto: \\(\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1 \\bar{X}\\) Bondad de ajuste: \\(R^2 = 1 - \\frac{\\text{SSR}}{\\text{SST}}\\) 11.8 Lecturas recomendadas Agresti, A. &amp; Finlay, B. (2009). Statistical Methods for the Social Sciences. Capítulo 9: Linear Regression and Correlation. Llaudet, E. &amp; Imai, K. (2022). Data Analysis for Social Science. Capítulo 4: Prediction. 11.9 Ejercicios Calcula la correlación entre años de educación e ingreso. Interpreta el resultado. Estima un modelo de regresión para predecir participación electoral a partir de nivel educacional promedio por comuna. Interpreta los coeficientes y el \\(R^2\\) del modelo estimado en el ejercicio 2. Discute por qué una correlación alta entre helado y ahogamientos NO implica causalidad. ADVERTENCIA CRUCIAL: La distinción entre correlación y causalidad es uno de los conceptos más importantes en metodología cuantitativa. Que dos variables estén correlacionadas no significa que una cause la otra. Por ejemplo, existe correlación entre ventas de helado y ahogamientos en playas, pero ninguna causa la otra; ambas son causadas por una tercera variable (temperatura/verano). En ciencias sociales, establecer causalidad requiere teoría sólida, diseños de investigación apropiados (experimentos, diseños quasi-experimentales), y control de variables confusoras.↩︎ INTERPRETACIÓN DE COEFICIENTES: Es crucial ser preciso en la interpretación. El coeficiente indica asociación, no necesariamente causalidad. Además, la unidad de medida importa: si \\(X\\) está en miles y \\(Y\\) en porcentajes, debemos ajustar nuestra interpretación en consecuencia. Siempre especifica las unidades y evita lenguaje causal a menos que el diseño lo justifique.↩︎ ADVERTENCIA SOBRE \\(R^2\\): Un modelo puede tener \\(R^2\\) alto y aún así ser inválido para inferencia causal. Por ejemplo, si omitimos una variable confusora importante (como nivel educacional al estudiar la relación entre edad e ingreso), el \\(R^2\\) puede ser alto pero los coeficientes estarán sesgados. Además, en ciencias sociales, valores bajos de \\(R^2\\) (0.10-0.30) son frecuentes y no necesariamente indican un modelo “malo” - simplemente reflejan que el comportamiento humano y social es multifactorial y difícil de predecir completamente.↩︎ "],["regresion-multiple.html", "Capítulo 12 Regresión múltiple 12.1 Objetivos del capítulo 12.2 El modelo de regresión múltiple 12.3 Interpretación de coeficientes 12.4 Variables de control 12.5 Multicolinealidad 12.6 Variables categóricas 12.7 Interacciones 12.8 Resumen del capítulo 12.9 Lecturas recomendadas 12.10 Ejercicios", " Capítulo 12 Regresión múltiple 12.1 Objetivos del capítulo 12.2 El modelo de regresión múltiple 12.3 Interpretación de coeficientes 12.4 Variables de control 12.5 Multicolinealidad 12.6 Variables categóricas 12.7 Interacciones 12.8 Resumen del capítulo 12.9 Lecturas recomendadas 12.10 Ejercicios "],["supuestos.html", "Capítulo 13 Supuestos de OLS y diagnósticos 13.1 Objetivos del capítulo 13.2 Los supuestos de Gauss-Markov 13.3 Diagnóstico de regresión 13.4 Heterocedasticidad 13.5 Autocorrelación 13.6 Valores atípicos e influyentes 13.7 Resumen del capítulo 13.8 Lecturas recomendadas 13.9 Ejercicios", " Capítulo 13 Supuestos de OLS y diagnósticos 13.1 Objetivos del capítulo 13.2 Los supuestos de Gauss-Markov 13.3 Diagnóstico de regresión 13.4 Heterocedasticidad 13.5 Autocorrelación 13.6 Valores atípicos e influyentes 13.7 Resumen del capítulo 13.8 Lecturas recomendadas 13.9 Ejercicios "],["glm.html", "Capítulo 14 Introducción a modelos lineales generalizados 14.1 Objetivos del capítulo 14.2 Limitaciones de OLS 14.3 La familia de GLM 14.4 Regresión logística 14.5 Regresión de Poisson 14.6 Resumen del capítulo 14.7 Lecturas recomendadas 14.8 Ejercicios", " Capítulo 14 Introducción a modelos lineales generalizados 14.1 Objetivos del capítulo 14.2 Limitaciones de OLS 14.3 La familia de GLM 14.4 Regresión logística 14.5 Regresión de Poisson 14.6 Resumen del capítulo 14.7 Lecturas recomendadas 14.8 Ejercicios "],["referencias.html", "Referencias", " Referencias Abbott, Andrew. 1988. “Transcending General Linear Reality.” Sociological Theory 6 (2): 169–86. ———. 2001. “What Do Cases Do?” In Time Matters: On Theory and Method. Chicago, IL: University of Chicago Press. Acemoglu, Daron, Simon Johnson, and James A. Robinson. 2001. “The Colonial Origins of Comparative Development: An Empirical Investigation.” American Economic Review 91 (5): 1369–1401. https://doi.org/10.1257/aer.91.5.1369. Adcock, Robert, and David Collier. 2001. “Measurement Validity: A Shared Standard for Qualitative and Quantitative Research.” American Political Science Review 95 (3): 529–46. Campbell, Donald T., and Julian C. Stanley. 1963. Experimental and Quasi-Experimental Designs for Research. Chicago: Rand McNally &amp; Company. Collier, David, and Steven Levitsky. 2006. “Democracy with Adjectives: Conceptual Innovation in Comparative Research.” In Regimes and Democracy in Latin America: Theories and Methods, edited by Gerardo L. Munck. Oxford: Oxford University Press. Eggers, Andrew C., Anthony Fowler, Jens Hainmueller, Andrew B. Hall, and James M. Snyder. 2015. “On the Validity of the Regression Discontinuity Design for Estimating Electoral Effects: New Evidence from over 40,000 Close Races.” American Journal of Political Science 59 (1): 259–74. Flores, Thomas Edward, and Irfan Nooruddin. 2016. Experimentation in the Social Sciences. Cambridge: Cambridge University Press. Gerber, Alan S., and Donald P. Green. 2008. Get Out the Vote: How to Increase Voter Turnout. 2nd ed. Washington, DC: Brookings Institution Press. Giddens, Anthony. 1984. The Constitution of Society: Outline of the Theory of Structuration. Cambridge: Polity Press. Goertz, Gary, and James Mahoney. 2012. A Tale of Two Cultures: Qualitative and Quantitative Research in the Social Sciences. Princeton, NJ: Princeton University Press. Gurr, Ted Robert. 1970. Why Men Rebel. Princeton, N.J.: Princeton University Press. Holbrook, Allyson L., Melanie C. Green, and Jon A. Krosnick. 2003. “Telephone Versus Face-to-Face Interviewing of National Probability Samples with Long Questionnaires: Comparisons of Respondent Satisficing and Social Desirability Response Bias.” Public Opinion Quarterly 67 (1): 79–125. Holland, Paul W. 1986. “Statistics and Causal Inference.” Journal of the American Statistical Association 81 (396): 945–60. Iyengar, Shanto, Gaurav Sood, and Yphtach Lelkes. 2012. “Affect, Not Ideology: A Social Identity Perspective on Polarization.” Public Opinion Quarterly 76 (3): 405–31. King, Gary. 1997. “A Solution to the Ecological Inference Problem: Reconstructing Individual Behavior from Aggregate Data.” American Journal of Political Science 41 (4): 1027–53. King, Gary, Robert O. Keohane, and Sidney Verba. 1994. Designing Social Inquiry: Scientific Inference in Qualitative Research. Princeton, NJ: Princeton University Press. Kuhn, Thomas S. 1962. The Structure of Scientific Revolutions. Chicago: University of Chicago Press. Lazarsfeld, Paul F., and Morris Rosenberg, eds. 1955. The Language of Social Research: A Reader in the Methodology of Social Research. Glencoe, Illinois: Free Press. Lijphart, Arend. 1994. Electoral Systems and Party Systems: A Study of Twenty-Seven Democracies, 1945-1990. Oxford: Oxford University Press. Linz, Juan J., and Alfred Stepan. 1996. Problems of Democratic Transition and Consolidation: Southern Europe, South America, and Post-Communist Europe. Baltimore, MD: Johns Hopkins University Press. Mahoney, James, and Gary Goertz. 2006. “A Tale of Two Cultures: Contrasting Quantitative and Qualitative Research.” Political Analysis 14 (3): 227–49. https://doi.org/10.1093/pan/mpj017. Meléndez, Carlos, and Cristóbal Rovira Kaltwasser. 2019. The Collapse of the Venezuelan Party System: Institutionalization, Economic Crisis, and Mass Behavior. Cambridge: Cambridge University Press. Merton, Robert K. 1949. Social Theory and Social Structure. Glencoe, Illinois: The Free Press. Munck, Gerardo L. 2009. Measuring Democracy: A Bridge Between Scholarship and Politics. Baltimore, MD: Johns Hopkins University Press. Popper, Karl R. 1959. The Logic of Scientific Discovery. London: Routledge. Przeworski, Adam, Michael E. Alvarez, Jose Antonio Cheibub, and Fernando Limongi. 2000. Democracy and Development: Political Institutions and Well-Being in the World, 1950-1990. Cambridge: Cambridge University Press. Ragin, Charles C. 1987. The Comparative Method: Moving Beyond Qualitative and Quantitative Strategies. Berkeley: University of California Press. Robinson, William S. 1950. “Ecological Correlations and the Behavior of Individuals.” American Sociological Review 15 (3): 351–57. Rubin, Donald B. 1974. “Estimating Causal Effects of Treatments in Randomized and Nonrandomized Studies.” Journal of Educational Psychology 66 (5): 688–701. Sartori, Giovanni. 1970. “Concept Misformation in Comparative Politics.” American Political Science Review 64 (4): 1033–53. Shadish, William R, Thomas D Cook, and Donald T Campbell. 2002. Experimental and Quasi-Experimental Designs for Generalized Causal Inference. Boston, MA: Houghton Mifflin. Treier, Shawn, and Simon Jackman. 2008. “Democracy as a Latent Variable.” American Journal of Political Science 52 (1): 201–17. Tufte, Edward R. 1983. The Visual Display of Quantitative Information. Cheshire, Connecticut: Graphics Press. Verba, Sidney, Kay Lehman Schlozman, and Henry E. Brady. 1995. Voice and Equality: Civic Voluntarism in American Politics. Cambridge, MA: Harvard University Press. Wilkinson, Leland. 2005. The Grammar of Graphics. 2nd ed. New York: Springer-Verlag. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
