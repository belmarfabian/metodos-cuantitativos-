# ComparaciÃ³n de medias {#comparacion}

```{r setup-10, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(ggplot2)
```

## Objetivos del capÃ­tulo {.unnumbered}

Al finalizar este capÃ­tulo, serÃ¡s capaz de:

- Elegir la prueba correcta para comparar medias segÃºn tu situaciÃ³n
- Realizar e interpretar pruebas t para uno y dos grupos
- Distinguir cuÃ¡ndo usar pruebas para muestras independientes vs pareadas
- Usar ANOVA cuando tienes mÃ¡s de dos grupos
- Interpretar los resultados en lenguaje accesible

## Â¿Por quÃ© comparar medias?

Una de las preguntas mÃ¡s frecuentes en ciencias sociales es si diferentes grupos difieren en alguna caracterÃ­stica. Por ejemplo:

- Â¿Ganan mÃ¡s los hombres que las mujeres? (diferencia de ingresos)
- Â¿CambiÃ³ la satisfacciÃ³n con la democracia despuÃ©s de una crisis? (antes/despuÃ©s)
- Â¿Hay diferencias en participaciÃ³n electoral entre regiones? (mÃºltiples grupos)

Para responder estas preguntas, necesitamos comparar **promedios** (medias) entre grupos y determinar si las diferencias observadas son **estadÃ­sticamente significativas** o podrÃ­an deberse al azar del muestreo.

## Eligiendo la prueba correcta

Antes de analizar, identifica tu situaciÃ³n:

| Pregunta | SituaciÃ³n | Prueba |
|----------|-----------|--------|
| Â¿Mi muestra difiere de un valor conocido? | Un grupo vs valor teÃ³rico | t de una muestra |
| Â¿Difieren dos grupos independientes? | Hombres vs mujeres, tratados vs control | t de dos muestras |
| Â¿CambiÃ³ algo antes y despuÃ©s? | Mismas personas medidas dos veces | t pareada |
| Â¿Difieren tres o mÃ¡s grupos? | Regiones, niveles educativos, etc. | ANOVA |

## Prueba t para una muestra

Esta prueba responde: **Â¿La media de mi muestra difiere de un valor de referencia?**

### Ejemplo: Confianza institucional regional

Supongamos que el promedio nacional de confianza en las instituciones es 5.0 (en una escala de 1 a 10). Queremos saber si una regiÃ³n especÃ­fica tiene un nivel diferente.

```{r t-una-muestra, echo=TRUE}
# Datos de una regiÃ³n
set.seed(2024)
confianza_region <- rnorm(80, mean = 4.3, sd = 1.8)

# Prueba t: Â¿difiere de 5.0?
resultado <- t.test(confianza_region, mu = 5.0)
resultado
```

### Â¿CÃ³mo interpretar este resultado?

**1. Las medias:**
```
mean of x
 4.299
```
La media de nuestra muestra es 4.3, mientras que el valor de referencia es 5.0.

**2. El intervalo de confianza:**
```
95 percent confidence interval:
 3.893  4.706
```
Estamos 95% seguros de que la media verdadera de la regiÃ³n estÃ¡ entre 3.9 y 4.7. Como este intervalo **no incluye el 5.0**, hay evidencia de que la regiÃ³n difiere del promedio nacional.

**3. El p-value:**
```
p-value = 0.0003
```
Como p < 0.05, la diferencia es estadÃ­sticamente significativa. Podemos concluir que la confianza institucional en esta regiÃ³n es significativamente menor que el promedio nacional.

::: {.callout-tip}
## InterpretaciÃ³n en lenguaje simple

"La confianza institucional promedio en la regiÃ³n (4.3) es significativamente menor que el promedio nacional de 5.0 (t = -3.82, p < 0.001). El intervalo de confianza al 95% [3.9, 4.7] no incluye el valor nacional, confirmando esta diferencia."
:::

## Prueba t para dos muestras independientes

Esta prueba responde: **Â¿Dos grupos tienen medias diferentes?**

Se llama "independientes" porque los grupos no estÃ¡n relacionados entre sÃ­: diferentes personas, diferentes paÃ­ses, etc.

### Ejemplo: Brecha salarial de gÃ©nero

Comparemos los ingresos promedio entre hombres y mujeres:

```{r t-dos-muestras, echo=TRUE}
# Datos simulados de ingresos (en miles de pesos)
set.seed(2024)
ingresos_hombres <- rlnorm(150, meanlog = log(750), sdlog = 0.6)
ingresos_mujeres <- rlnorm(150, meanlog = log(650), sdlog = 0.6)

# Prueba t para dos muestras independientes
resultado <- t.test(ingresos_hombres, ingresos_mujeres)
resultado
```

### Interpretando el resultado

**Las medias de cada grupo:**
```
mean of x  mean of y
  815.4      705.2
```
Los hombres ganan en promedio $815 mil, las mujeres $705 mil.

**La diferencia y su intervalo de confianza:**
```
95 percent confidence interval:
 12.51  207.92
```
La diferencia estimada es de aproximadamente $110 mil (815 - 705). El intervalo de confianza indica que la diferencia verdadera estÃ¡ entre $12 mil y $208 mil. Como el intervalo **no incluye el cero**, la diferencia es significativa.

**El p-value:**
Como p < 0.05, concluimos que existe una diferencia estadÃ­sticamente significativa en los ingresos promedio entre hombres y mujeres.

```{r plot-genero, echo=TRUE, fig.cap="ComparaciÃ³n de ingresos por gÃ©nero"}
# VisualizaciÃ³n
datos_genero <- data.frame(
  ingreso = c(ingresos_hombres, ingresos_mujeres),
  genero = factor(c(rep("Hombres", 150), rep("Mujeres", 150)))
)

ggplot(datos_genero, aes(x = genero, y = ingreso, fill = genero)) +
  geom_boxplot(alpha = 0.7) +
  stat_summary(fun = mean, geom = "point", shape = 18, size = 4, color = "red") +
  scale_fill_manual(values = c("#3498db", "#e74c3c")) +
  labs(x = "", y = "Ingreso mensual (miles de $)",
       title = "DistribuciÃ³n de ingresos por gÃ©nero",
       subtitle = "El diamante rojo indica la media de cada grupo") +
  theme_minimal() +
  theme(legend.position = "none")
```

::: {.callout-note .callout-avanzado collapse="true"}
## ğŸ“ Avanzado: FÃ³rmula t para dos muestras

$$t = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}$$

El numerador es la diferencia de medias observada. El denominador es el error estÃ¡ndar de esa diferencia, que depende de las varianzas y tamaÃ±os de ambos grupos.

R usa por defecto la **correcciÃ³n de Welch**, que no asume varianzas iguales entre grupos. Esta es la opciÃ³n recomendada en la mayorÃ­a de los casos.
:::

## Prueba t pareada

Esta prueba responde: **Â¿CambiÃ³ algo antes y despuÃ©s en las mismas personas?**

Se usa cuando las observaciones estÃ¡n **pareadas** o **emparejadas**: las mismas personas medidas en dos momentos, gemelos, pares de casos similares, etc.

### Â¿Por quÃ© es diferente a la prueba de dos muestras?

Cuando medimos a las mismas personas dos veces, las observaciones no son independientes: una persona con alta satisfacciÃ³n "antes" probablemente tendrÃ¡ alta satisfacciÃ³n "despuÃ©s". La prueba pareada aprovecha esta informaciÃ³n, analizando la **diferencia individual** de cada persona.

### Ejemplo: EvaluaciÃ³n de una intervenciÃ³n

Medimos percepciÃ³n de seguridad antes y despuÃ©s de un programa policial en el barrio:

```{r t-pareada, echo=TRUE}
# Mismas 50 personas, medidas antes y despuÃ©s
set.seed(123)
antes <- rnorm(50, mean = 4.2, sd = 1.5)
despues <- antes + rnorm(50, mean = 0.8, sd = 1.0)  # Mejora promedio de 0.8

# Prueba t pareada
resultado <- t.test(despues, antes, paired = TRUE)
resultado
```

### Interpretando el resultado

**La diferencia promedio:**
```
mean difference
     0.841
```
En promedio, la percepciÃ³n de seguridad aumentÃ³ 0.84 puntos despuÃ©s de la intervenciÃ³n.

**Intervalo de confianza de la diferencia:**
```
95 percent confidence interval:
 0.547  1.135
```
Estamos 95% seguros de que el verdadero efecto de la intervenciÃ³n estÃ¡ entre 0.55 y 1.14 puntos. Como el intervalo no incluye el cero, el efecto es significativo.

**El p-value:** Como p < 0.05, concluimos que la intervenciÃ³n tuvo un efecto estadÃ­sticamente significativo en la percepciÃ³n de seguridad.

::: {.callout-warning}
## Cuidado: EstadÃ­stico â‰  Causal

Un resultado significativo no prueba que la intervenciÃ³n *causÃ³* el cambio. PodrÃ­an haber ocurrido otros eventos durante el perÃ­odo (nuevas leyes, cambios econÃ³micos, etc.). Para afirmar causalidad necesitamos un **grupo de control** que no recibiÃ³ la intervenciÃ³n.
:::

## ANOVA: Comparando mÃ¡s de dos grupos

Â¿QuÃ© pasa si quieres comparar **tres o mÃ¡s grupos**? No puedes simplemente hacer mÃºltiples pruebas t, porque cada prueba tiene 5% de probabilidad de error tipo I. Con muchas comparaciones, los errores se acumulan.

El **ANOVA** (Analysis of Variance) resuelve esto evaluando todas las diferencias simultÃ¡neamente con una sola prueba.

### La pregunta que responde ANOVA

**Â¿Hay al menos un grupo cuya media difiere de los demÃ¡s?**

- Si p < 0.05: SÃ­, hay diferencias significativas entre los grupos
- Si p â‰¥ 0.05: No podemos concluir que haya diferencias

::: {.callout-note}
## Importante

ANOVA NO te dice *cuÃ¡les* grupos difieren, solo que *al menos uno* es diferente. Para saber cuÃ¡les, necesitas pruebas post-hoc (ver secciÃ³n avanzada).
:::

### Ejemplo: SatisfacciÃ³n por orientaciÃ³n polÃ­tica

Comparemos la satisfacciÃ³n con la democracia entre personas de izquierda, centro y derecha:

```{r anova-ejemplo, echo=TRUE}
# Datos simulados
set.seed(2024)
n_grupo <- 100

datos_anova <- data.frame(
  satisfaccion = c(
    rnorm(n_grupo, mean = 4.5, sd = 1.2),  # Izquierda
    rnorm(n_grupo, mean = 5.2, sd = 1.1),  # Centro
    rnorm(n_grupo, mean = 4.0, sd = 1.3)   # Derecha
  ),
  orientacion = factor(rep(c("Izquierda", "Centro", "Derecha"), each = n_grupo))
)

# ANOVA de una vÃ­a
modelo_anova <- aov(satisfaccion ~ orientacion, data = datos_anova)
summary(modelo_anova)
```

### Interpretando el output de ANOVA

```
              Df Sum Sq Mean Sq F value   Pr(>F)
orientacion    2   73.5   36.75    25.7 2.45e-11 ***
Residuals    297  424.6    1.43
```

**Lo mÃ¡s importante es el p-value (Pr(>F)):** Como p < 0.05 (de hecho, p < 0.001), concluimos que hay diferencias significativas en satisfacciÃ³n con la democracia entre los grupos polÃ­ticos.

**El estadÃ­stico F (25.7):** Mide cuÃ¡nta variaciÃ³n hay "entre grupos" comparada con la variaciÃ³n "dentro de grupos". Valores mÃ¡s altos indican diferencias mÃ¡s claras.

```{r anova-plot, echo=TRUE, fig.cap="SatisfacciÃ³n con la democracia segÃºn orientaciÃ³n polÃ­tica"}
ggplot(datos_anova, aes(x = orientacion, y = satisfaccion, fill = orientacion)) +
  geom_boxplot(alpha = 0.7, show.legend = FALSE) +
  stat_summary(fun = mean, geom = "point", shape = 18, size = 4, color = "red") +
  scale_fill_manual(values = c("#2ecc71", "#9b59b6", "#e74c3c")) +
  labs(x = "OrientaciÃ³n polÃ­tica",
       y = "SatisfacciÃ³n con la democracia (1-7)",
       title = "SatisfacciÃ³n segÃºn orientaciÃ³n polÃ­tica",
       subtitle = "El diamante rojo indica la media de cada grupo") +
  theme_minimal()
```

El grÃ¡fico muestra que el grupo de centro tiene la mayor satisfacciÃ³n, seguido de izquierda, y derecha tiene la menor.

::: {.callout-note .callout-avanzado collapse="true"}
## ğŸ“ Avanzado: Comparaciones post-hoc

Si ANOVA indica diferencias significativas, Â¿entre quÃ© grupos especÃ­ficos estÃ¡n? Las pruebas **post-hoc** responden esto controlando por comparaciones mÃºltiples.

```{r posthoc, echo=TRUE}
# Comparaciones post-hoc de Tukey
TukeyHSD(modelo_anova)
```

**CÃ³mo leer el resultado:**

- `diff`: Diferencia de medias entre los dos grupos
- `lwr` y `upr`: Intervalo de confianza al 95%
- `p adj`: p-value ajustado por comparaciones mÃºltiples

Si el intervalo **no incluye el cero** (o p adj < 0.05), la diferencia entre esos dos grupos es significativa.

### Alternativas no paramÃ©tricas

Cuando los supuestos no se cumplen (especialmente con muestras pequeÃ±as), usamos pruebas que no asumen distribuciÃ³n normal:

| Prueba paramÃ©trica | Alternativa no paramÃ©trica | En R |
|-------------------|---------------------------|------|
| t de una muestra | Wilcoxon signed-rank | `wilcox.test(x, mu = valor)` |
| t de dos muestras | Mann-Whitney U | `wilcox.test(x, y)` |
| t pareada | Wilcoxon pareada | `wilcox.test(x, y, paired = TRUE)` |
| ANOVA | Kruskal-Wallis | `kruskal.test(y ~ grupo)` |
:::

## Supuestos de las pruebas

Las pruebas t y ANOVA asumen ciertas condiciones. Si no se cumplen, los resultados pueden ser poco confiables.

### Los tres supuestos principales

**1. Independencia de las observaciones**

Las observaciones no deben estar relacionadas entre sÃ­. Por ejemplo, si encuestas a miembros de la misma familia, sus respuestas no son independientes.

**Este es el supuesto mÃ¡s importante.** Si no se cumple, los resultados pueden ser muy sesgados y las alternativas no paramÃ©tricas no ayudan.

**2. Normalidad**

Los datos en cada grupo deberÃ­an distribuirse aproximadamente como una curva normal.

**En la prÃ¡ctica:** Este supuesto es menos crÃ­tico con muestras grandes (n > 30 por grupo) gracias al teorema del lÃ­mite central. Las pruebas t y ANOVA son bastante robustas a desviaciones de normalidad.

**3. Homogeneidad de varianzas**

Los grupos deberÃ­an tener dispersiones similares.

**En la prÃ¡ctica:** R usa por defecto la correcciÃ³n de Welch en `t.test()`, que no asume varianzas iguales. Para ANOVA, existen versiones robustas si este supuesto es problemÃ¡tico.

::: {.callout-tip}
## Regla prÃ¡ctica

Con muestras grandes (n > 30 por grupo) y sin problemas graves de independencia, las pruebas t y ANOVA funcionan bien incluso con datos que no son perfectamente normales.
:::

## Resumen {.unnumbered}

La comparaciÃ³n de medias permite evaluar si las diferencias observadas entre grupos son estadÃ­sticamente significativas o podrÃ­an deberse al azar muestral. La prueba t compara dos grupos; ANOVA extiende la lÃ³gica a tres o mÃ¡s grupos.

La elecciÃ³n de la prueba depende del diseÃ±o: t de una muestra para comparar contra un valor conocido, t de dos muestras para grupos independientes, t pareada para mediciones repetidas en los mismos sujetos. Cuando ANOVA es significativo, las pruebas post-hoc identifican quÃ© pares de grupos difieren.

| SituaciÃ³n | Prueba | En R |
|-----------|--------|------|
| Una muestra vs valor conocido | t de una muestra | `t.test(x, mu = valor)` |
| Dos grupos independientes | t de dos muestras | `t.test(x, y)` |
| Antes/despuÃ©s (mismas personas) | t pareada | `t.test(x, y, paired = TRUE)` |
| Tres o mÃ¡s grupos | ANOVA | `aov(y ~ grupo)` |

**Claves para interpretar:**

- **p-value < 0.05**: La diferencia es estadÃ­sticamente significativa
- **Intervalo de confianza que no incluye 0**: Hay diferencia significativa
- **ANOVA significativo**: Al menos un grupo difiere, pero no dice cuÃ¡l

::: {.callout-important}
## Recuerda

Significancia estadÃ­stica â‰  Importancia prÃ¡ctica. Una diferencia de $10 pesos puede ser "significativa" con muestras grandes, pero irrelevante en la prÃ¡ctica. Siempre reporta el **tamaÃ±o del efecto** (la diferencia real) ademÃ¡s del p-value.
:::

## Lecturas recomendadas {.unnumbered}

**Fundamentos de comparaciÃ³n de grupos:**

Agresti, A., & Finlay, B. (2009). *Statistical Methods for the Social Sciences* (4th ed.). Pearson.
â†’ CapÃ­tulo 7 cubre pruebas t y comparaciÃ³n de medias entre dos grupos con claridad y ejemplos aplicados.

**Inferencia causal mediante comparaciÃ³n de grupos:**

Llaudet, E., & Imai, K. (2022). *Data Analysis for Social Science: A Friendly and Practical Introduction*. Princeton University Press.
â†’ CapÃ­tulo 3 sobre causalidad conecta comparaciÃ³n de medias con diseÃ±os experimentales y cuasi-experimentales.

**ANOVA y diseÃ±os mÃ¡s complejos:**

Maxwell, S. E., Delaney, H. D., & Kelley, K. (2018). *Designing Experiments and Analyzing Data: A Model Comparison Perspective* (3rd ed.). Routledge.
â†’ Tratamiento comprehensivo de ANOVA y diseÃ±os factoriales para investigadores avanzados.


## Ejercicios {.unnumbered}

::: {.ejercicios}

**1. Prueba t de una muestra**

Una escala de confianza interpersonal tiene media nacional de 5.5 (escala 1-10). Tienes datos de una regiÃ³n especÃ­fica:

```{r eval=FALSE}
set.seed(111)
confianza_region <- rnorm(80, mean = 4.8, sd = 2.0)
```

a) Â¿CuÃ¡l es la pregunta de investigaciÃ³n?
b) Realiza la prueba t con `t.test()`
c) Interpreta el p-value: Â¿hay diferencia significativa?
d) Interpreta el intervalo de confianza
e) Escribe una oraciÃ³n resumiendo el resultado

**2. Prueba t de dos muestras**

Comparamos participaciÃ³n cÃ­vica entre hombres y mujeres:

```{r eval=FALSE}
set.seed(222)
civic_hombres <- rnorm(100, mean = 3.2, sd = 1.5)
civic_mujeres <- rnorm(110, mean = 3.8, sd = 1.4)
```

a) Realiza la prueba t para muestras independientes
b) Â¿CuÃ¡l grupo tiene mayor participaciÃ³n cÃ­vica?
c) Â¿La diferencia es estadÃ­sticamente significativa?
d) Crea un boxplot comparando ambos grupos
e) Â¿QuÃ© tan grande es la diferencia en tÃ©rminos prÃ¡cticos?

**3. Â¿CuÃ¡ndo usar prueba pareada?**

Indica si deberÃ­as usar una prueba t pareada o de muestras independientes:

a) Comparar notas de estudiantes antes y despuÃ©s de un curso
b) Comparar satisfacciÃ³n laboral entre empresas pÃºblicas y privadas
c) Comparar presiÃ³n arterial de pacientes antes y despuÃ©s de un tratamiento
d) Comparar ingresos entre graduados de dos universidades diferentes
e) Comparar actitud hacia la inmigraciÃ³n en las mismas personas en 2020 y 2024

**4. Prueba t pareada**

Mediciones de actitud hacia inmigraciÃ³n antes y despuÃ©s de ver un documental:

```{r eval=FALSE}
set.seed(333)
n <- 60
antes <- rnorm(n, mean = 50, sd = 15)
despues <- antes + rnorm(n, mean = 5, sd = 8)
```

a) Â¿Por quÃ© es apropiada una prueba pareada aquÃ­?
b) Realiza la prueba con `t.test(..., paired = TRUE)`
c) Â¿CuÃ¡l es el cambio promedio?
d) Â¿El cambio es estadÃ­sticamente significativo?
e) Â¿Podemos concluir que el documental *causÃ³* el cambio? Â¿Por quÃ©?

**5. ANOVA**

SatisfacciÃ³n con servicios pÃºblicos segÃºn regiÃ³n:

```{r eval=FALSE}
set.seed(444)
datos_anova <- data.frame(
  satisfaccion = c(
    rnorm(50, mean = 5.5, sd = 1.2),
    rnorm(60, mean = 4.8, sd = 1.3),
    rnorm(55, mean = 5.2, sd = 1.1),
    rnorm(45, mean = 4.5, sd = 1.4)
  ),
  region = rep(c("Norte", "Centro", "Sur", "Metropolitana"), c(50, 60, 55, 45))
)
```

a) Realiza ANOVA con `aov()`
b) Â¿Hay diferencias significativas entre regiones?
c) Crea un boxplot de satisfacciÃ³n por regiÃ³n
d) Â¿CuÃ¡l regiÃ³n tiene mayor satisfacciÃ³n? Â¿CuÃ¡l menor?
e) Si el ANOVA es significativo, Â¿quÃ© prueba adicional necesitas para saber cuÃ¡les regiones difieren especÃ­ficamente?

**6. AplicaciÃ³n**

Busca un ejemplo de tu interÃ©s donde necesites comparar medias entre grupos:

a) Describe los grupos que quieres comparar
b) Â¿QuÃ© variable quieres comparar?
c) Â¿QuÃ© prueba usarÃ­as y por quÃ©?
d) Â¿QuÃ© resultado esperarÃ­as encontrar?
e) Si la diferencia fuera significativa, Â¿quÃ© conclusiones podrÃ­as sacar? Â¿CuÃ¡les no?

:::

::: {#refs}
:::
