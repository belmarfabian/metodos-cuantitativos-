# Introducci√≥n a probabilidad {#probabilidad}

## Objetivos del cap√≠tulo {.unnumbered}

Al finalizar este cap√≠tulo, ser√°s capaz de:

- Comprender qu√© es la probabilidad y para qu√© sirve en investigaci√≥n social
- Calcular probabilidades b√°sicas y aplicar reglas fundamentales
- Distinguir entre variables aleatorias discretas y continuas
- Usar la distribuci√≥n Normal para responder preguntas sobre poblaciones
- Entender el Teorema del L√≠mite Central y por qu√© es tan importante

## ¬øPara qu√© necesitamos probabilidad?

La investigaci√≥n social enfrenta constantemente la **incertidumbre**. Cuando encuestamos a 1,500 votantes para estimar el apoyo a un candidato, no conocemos las preferencias de los millones que no fueron encuestados. Cuando comparamos dos pol√≠ticas p√∫blicas, no podemos estar 100% seguros de que la diferencia observada sea real.

La **probabilidad** nos da un lenguaje para cuantificar esta incertidumbre. No la elimina (eso es imposible), pero nos permite hacer afirmaciones precisas sobre qu√© tan confiables son nuestras conclusiones.

## Conceptos b√°sicos de probabilidad

### ¬øQu√© es una probabilidad?

Una **probabilidad** es un n√∫mero entre 0 y 1 que cuantifica qu√© tan probable es que ocurra algo:

| Probabilidad | Significado |
|--------------|-------------|
| 0 | Imposible |
| 0.25 | Poco probable |
| 0.50 | Igual de probable que improbable |
| 0.75 | Bastante probable |
| 1 | Seguro |

### Ejemplo: Interpretando probabilidades

Si en una encuesta de 1,200 personas, 360 declaran que votar√°n por un partido:

```{r probabilidad-basica}
# Calculamos la probabilidad (proporci√≥n) de votar por ese partido
apoyos <- 360
total <- 1200
probabilidad <- apoyos / total

cat("Probabilidad estimada de votar por el partido:", probabilidad, "\n")
cat("Esto equivale al", probabilidad * 100, "%")
```

Importante: Esto **NO** significa que exactamente 30% de la poblaci√≥n votar√° por el partido. Es nuestra mejor estimaci√≥n basada en la muestra, con cierto nivel de incertidumbre.

### ¬øC√≥mo se interpretan las probabilidades?

**Interpretaci√≥n frecuentista** (la m√°s com√∫n): La probabilidad es la proporci√≥n de veces que algo ocurrir√≠a si repiti√©ramos el experimento muchas veces.

Por ejemplo, decir que la probabilidad de "cara" al lanzar una moneda es 0.5 significa que, si lanz√°ramos la moneda millones de veces, aproximadamente la mitad ser√≠an caras.

```{r probabilidad-frecuentista, echo=FALSE, fig.cap="La proporci√≥n converge a 0.5 conforme aumentan los lanzamientos"}
library(ggplot2)
library(dplyr)

set.seed(123)
n_lanzamientos <- 1000
lanzamientos <- data.frame(
  n = 1:n_lanzamientos,
  resultado = sample(c("Cara", "Sello"), n_lanzamientos, replace = TRUE)
)

lanzamientos <- lanzamientos %>%
  mutate(
    es_cara = ifelse(resultado == "Cara", 1, 0),
    prop_acumulada = cumsum(es_cara) / n
  )

ggplot(lanzamientos, aes(x = n, y = prop_acumulada)) +
  geom_line(color = "#3498db", linewidth = 1) +
  geom_hline(yintercept = 0.5, linetype = "dashed", color = "#e74c3c", linewidth = 1) +
  labs(
    title = "Convergencia a la probabilidad real",
    subtitle = "La proporci√≥n de 'Cara' se acerca a 0.5 conforme lanzamos m√°s veces",
    x = "N√∫mero de lanzamientos",
    y = "Proporci√≥n acumulada de Cara"
  ) +
  theme_minimal()
```

## Reglas b√°sicas de probabilidad

### Regla del complemento: Lo que NO ocurre

Si la probabilidad de que algo ocurra es p, entonces la probabilidad de que NO ocurra es 1 - p.

```{r regla-complemento}
# Si la probabilidad de votar es 52%
p_vota <- 0.52

# Entonces la probabilidad de abstenerse es:
p_abstiene <- 1 - p_vota

cat("P(abstenci√≥n) =", p_abstiene, "o", p_abstiene * 100, "%")
```

### Regla de la suma: Una cosa U otra

Si dos eventos no pueden ocurrir al mismo tiempo (son "mutuamente excluyentes"), la probabilidad de que ocurra uno u otro es la suma de sus probabilidades.

```{r regla-suma}
# Un votante puede elegir izquierda, centro, o derecha (solo una opci√≥n)
p_izquierda <- 0.30
p_centro <- 0.25
p_derecha <- 0.45

# Probabilidad de votar izquierda O centro
p_izq_o_centro <- p_izquierda + p_centro

cat("P(izquierda O centro) =", p_izq_o_centro)
```

### Regla del producto: Una cosa Y otra

Si dos eventos son independientes (uno no afecta al otro), la probabilidad de que ocurran ambos es el producto de sus probabilidades.

```{r regla-producto}
# Si encuestamos a dos personas al azar
# P(ambos votan izquierda) = P(primero izq) √ó P(segundo izq)
p_izquierda <- 0.30

p_ambos_izq <- p_izquierda * p_izquierda

cat("P(ambos votan izquierda) =", p_ambos_izq)
```

### Probabilidad condicional: Dado que ya s√© algo

A veces queremos saber la probabilidad de algo **dado** que ya sabemos otra cosa.

::: {.callout-tip}
## Ejemplo: Voto por g√©nero

En una encuesta de 500 personas:

|             | Aprueba | Rechaza | Total |
|-------------|:-------:|:-------:|:-----:|
| Hombres     |   80    |   120   |  200  |
| Mujeres     |  150    |   150   |  300  |
| **Total**   |  230    |   270   |  500  |

**Pregunta:** Entre las mujeres, ¬øqu√© proporci√≥n aprueba?

```{r probabilidad-condicional}
# P(Aprueba | Mujer) = Mujeres que aprueban / Total de mujeres
p_aprueba_dado_mujer <- 150 / 300

cat("P(Aprueba | Mujer) =", p_aprueba_dado_mujer, "\n")
cat("Es decir, el", p_aprueba_dado_mujer * 100, "% de las mujeres aprueba")
```

Compara con la poblaci√≥n general:

```{r}
# P(Aprueba) = Total que aprueba / Total
p_aprueba <- 230 / 500

cat("P(Aprueba) en general =", p_aprueba, "\n")
cat("Es decir, el", p_aprueba * 100, "% de la poblaci√≥n aprueba")
```

Las mujeres aprueban m√°s que la poblaci√≥n general (50% vs 46%).
:::

::: {.callout-warning}
## Error com√∫n: No confundas P(A|B) con P(B|A)

Estas dos probabilidades son diferentes:

- **P(Aprueba | Mujer) = 0.50** ‚Üí "De las mujeres, ¬øqu√© proporci√≥n aprueba?"
- **P(Mujer | Aprueba) = 150/230 = 0.65** ‚Üí "De quienes aprueban, ¬øqu√© proporci√≥n son mujeres?"

Este error es muy com√∫n. Siempre preg√∫ntate: "¬øCu√°l es mi grupo de referencia?"
:::

::: {.callout-note .callout-avanzado collapse="true"}
## üéì M√©todos Cuantitativos Avanzados

### F√≥rmulas de probabilidad

**Regla del complemento:**
$$P(\text{no } A) = 1 - P(A)$$

**Regla de la suma (eventos mutuamente excluyentes):**
$$P(A \text{ o } B) = P(A) + P(B)$$

**Regla de la suma (eventos no excluyentes):**
$$P(A \text{ o } B) = P(A) + P(B) - P(A \text{ y } B)$$

**Regla del producto (eventos independientes):**
$$P(A \text{ y } B) = P(A) \times P(B)$$

**Probabilidad condicional:**
$$P(A|B) = \frac{P(A \text{ y } B)}{P(B)}$$
:::

## Variables aleatorias

Una **variable aleatoria** es algo que toma diferentes valores con diferentes probabilidades. Son la conexi√≥n entre probabilidad y datos reales.

### Variables discretas vs continuas

| Tipo | Qu√© son | Ejemplos |
|------|---------|----------|
| **Discretas** | Toman valores espec√≠ficos y contables | N√∫mero de protestas en un mes, respuesta en escala Likert (1-5), votos obtenidos |
| **Continuas** | Pueden tomar cualquier valor en un rango | Porcentaje de apoyo, ingreso mensual, tiempo hasta un evento |

### Ejemplo de variable discreta

```{r variable-discreta, fig.cap="Distribuci√≥n del n√∫mero de protestas por mes"}
# Simulamos: n√∫mero de protestas por mes en una ciudad
set.seed(456)
protestas <- rpois(1000, lambda = 2.5)  # Promedio de 2.5 protestas/mes

# Tabla de frecuencias
tabla <- table(protestas)
cat("Frecuencias observadas:\n")
print(tabla)

cat("\nProbabilidades:\n")
print(round(tabla / sum(tabla), 3))
```

```{r plot-discreta, echo=FALSE}
library(ggplot2)
data.frame(protestas = protestas) %>%
  ggplot(aes(x = protestas)) +
  geom_bar(aes(y = after_stat(count)/sum(after_stat(count))),
           fill = "#3498db", color = "white") +
  labs(
    title = "Distribuci√≥n del n√∫mero de protestas por mes",
    x = "N√∫mero de protestas",
    y = "Probabilidad"
  ) +
  scale_x_continuous(breaks = 0:10) +
  theme_minimal()
```

### Ejemplo de variable continua

```{r variable-continua, fig.cap="Distribuci√≥n de porcentaje de votos para alcalde"}
# Simulamos: porcentaje de votos para un candidato a alcalde
set.seed(789)
votos <- rnorm(1000, mean = 35, sd = 5)

# ¬øQu√© proporci√≥n obtiene entre 30% y 40% de los votos?
prop_30_40 <- mean(votos >= 30 & votos <= 40)

cat("Proporci√≥n de candidatos con 30-40% de votos:", round(prop_30_40, 2))
```

```{r plot-continua, echo=FALSE}
data.frame(votos = votos) %>%
  ggplot(aes(x = votos)) +
  geom_histogram(aes(y = after_stat(density)), bins = 30,
                 fill = "#3498db", color = "white", alpha = 0.7) +
  geom_density(color = "#e74c3c", linewidth = 1.2) +
  labs(
    title = "Distribuci√≥n del porcentaje de votos",
    x = "Porcentaje de votos (%)",
    y = "Densidad"
  ) +
  theme_minimal()
```

## La distribuci√≥n Normal

La **distribuci√≥n Normal** (o "campana de Gauss") es la m√°s importante en estad√≠stica. Muchos fen√≥menos naturales y sociales siguen aproximadamente esta distribuci√≥n.

### Caracter√≠sticas de la Normal

La distribuci√≥n Normal tiene forma de campana sim√©trica:

- La mayor√≠a de los valores est√°n cerca del centro (la media)
- Los valores extremos son menos frecuentes
- Es sim√©trica: igual de probable estar por arriba que por debajo de la media

```{r normal-regla, echo=FALSE, fig.cap="Distribuci√≥n Normal: La regla 68-95-99.7"}
library(ggplot2)

x <- seq(-4, 4, length.out = 1000)
y <- dnorm(x)
df <- data.frame(x = x, y = y)

ggplot(df, aes(x = x, y = y)) +
  geom_line(linewidth = 1.2, color = "#2c3e50") +
  geom_area(data = subset(df, x >= -1 & x <= 1),
            fill = "#3498db", alpha = 0.3) +
  geom_area(data = subset(df, x >= -1.96 & x <= 1.96),
            fill = "#3498db", alpha = 0.2) +
  geom_vline(xintercept = c(-1, 1), linetype = "dashed", color = "#e74c3c") +
  geom_vline(xintercept = c(-1.96, 1.96), linetype = "dashed", color = "#e67e22") +
  annotate("text", x = 0, y = 0.2, label = "68%", size = 5, fontface = "bold") +
  annotate("text", x = 0, y = 0.1, label = "95%", size = 5, fontface = "bold") +
  labs(
    title = "Distribuci√≥n Normal: La regla 68-95-99.7",
    subtitle = "68% de los datos est√° dentro de ¬±1 SD, 95% dentro de ¬±2 SD",
    x = "Desviaciones est√°ndar desde la media",
    y = "Densidad"
  ) +
  theme_minimal()
```

### La regla 68-95-99.7

En una distribuci√≥n Normal:

| Rango | Porcentaje de datos |
|-------|---------------------|
| Media ¬± 1 desviaci√≥n est√°ndar | 68% |
| Media ¬± 2 desviaciones est√°ndar | 95% |
| Media ¬± 3 desviaciones est√°ndar | 99.7% |

### Ejemplo: Alturas de personas

Las alturas de hombres adultos chilenos se distribuyen aproximadamente Normal con media 170 cm y desviaci√≥n est√°ndar 7 cm.

```{r ejemplo-alturas}
# ¬øQu√© proporci√≥n de hombres mide m√°s de 180 cm?
prop_mayor_180 <- 1 - pnorm(180, mean = 170, sd = 7)

cat("Proporci√≥n que mide m√°s de 180 cm:", round(prop_mayor_180, 3), "\n")
cat("Es decir, aproximadamente el", round(prop_mayor_180 * 100, 1), "%")
```

```{r ejemplo-alturas-2}
# ¬øQu√© proporci√≥n mide entre 165 y 175 cm?
prop_165_175 <- pnorm(175, mean = 170, sd = 7) - pnorm(165, mean = 170, sd = 7)

cat("Proporci√≥n que mide entre 165 y 175 cm:", round(prop_165_175, 3), "\n")
cat("Es decir, aproximadamente el", round(prop_165_175 * 100, 1), "%")
```

### Funciones de R para la distribuci√≥n Normal

R tiene cuatro funciones para trabajar con la Normal:

| Funci√≥n | Qu√© hace | Ejemplo |
|---------|----------|---------|
| `pnorm(x)` | Probabilidad de estar por debajo de x | `pnorm(180, mean=170, sd=7)` = 0.92 |
| `qnorm(p)` | ¬øQu√© valor tiene p% de datos por debajo? | `qnorm(0.90, mean=170, sd=7)` = 179 |
| `dnorm(x)` | Altura de la curva en x | Para graficar |
| `rnorm(n)` | Genera n valores aleatorios | `rnorm(100, mean=170, sd=7)` |

```{r funciones-normal}
# ¬øCu√°l es el percentil 90 de alturas?
# Es decir, ¬øqu√© altura es mayor que el 90% de los hombres?
percentil_90 <- qnorm(0.90, mean = 170, sd = 7)

cat("El percentil 90 de alturas es", round(percentil_90, 1), "cm\n")
cat("Es decir, el 90% de los hombres mide menos de", round(percentil_90, 1), "cm")
```

## El Teorema del L√≠mite Central

Este es probablemente el resultado m√°s importante de toda la estad√≠stica. Fundamenta toda la inferencia que veremos en los pr√≥ximos cap√≠tulos.

### ¬øQu√© dice el teorema?

Si tomamos muchas muestras de cualquier poblaci√≥n y calculamos la media de cada una:

1. **Las medias se distribuyen de forma Normal** (aunque la poblaci√≥n original no lo sea)
2. **Est√°n centradas en la media verdadera de la poblaci√≥n**
3. **Su dispersi√≥n disminuye con muestras m√°s grandes**

Esto funciona siempre que la muestra sea suficientemente grande (t√≠picamente n ‚â• 30).

### ¬øPor qu√© es tan importante?

Porque nos permite usar la distribuci√≥n Normal para hacer inferencia, sin importar c√≥mo se vean los datos originales.

### Demostraci√≥n con simulaci√≥n

Veamos el teorema en acci√≥n con un ejemplo extremo: participaci√≥n en protestas.

```{r tlc-demo, fig.height=6}
# Poblaci√≥n muy asim√©trica: mayor√≠a no participa (0), pocos participan
set.seed(2024)
poblacion <- c(rep(0, 7000), rep(1, 2000), rep(2, 700),
               rep(3, 200), rep(4, 80), rep(5, 20))

mu_poblacion <- mean(poblacion)
cat("Media poblacional:", round(mu_poblacion, 2), "\n")
cat("La distribuci√≥n es MUY asim√©trica (mayor√≠a son ceros)\n")

# Visualizamos la poblaci√≥n
hist(poblacion, main = "Distribuci√≥n poblacional (muy asim√©trica)",
     xlab = "N√∫mero de protestas", col = "#3498db", border = "white")
```

Ahora tomamos muchas muestras y calculamos sus medias:

```{r tlc-muestras}
# Tomamos 5000 muestras de n=100 y calculamos la media de cada una
set.seed(2024)
medias_muestrales <- replicate(5000, mean(sample(poblacion, 100, replace = TRUE)))

# Las medias S√ç se distribuyen Normal
hist(medias_muestrales, breaks = 40,
     main = "Distribuci√≥n de medias muestrales (n=100)",
     xlab = "Media muestral", col = "#2ecc71", border = "white")
abline(v = mu_poblacion, col = "red", lwd = 2, lty = 2)

cat("Media de las medias muestrales:", round(mean(medias_muestrales), 3), "\n")
cat("(Muy cerca de la media poblacional:", round(mu_poblacion, 3), ")")
```

Aunque la poblaci√≥n original es extremadamente asim√©trica, las **medias muestrales se distribuyen de forma Normal**.

### Efecto del tama√±o de muestra

Muestras m√°s grandes producen distribuciones de medias m√°s "apretadas":

```{r tlc-tama√±os, fig.height=8, echo=FALSE}
simular_medias <- function(n, n_muestras = 5000) {
  replicate(n_muestras, mean(sample(poblacion, n, replace = TRUE)))
}

set.seed(2024)
medias_n10 <- simular_medias(10)
medias_n30 <- simular_medias(30)
medias_n100 <- simular_medias(100)

par(mfrow = c(3, 1))
hist(medias_n10, breaks = 40, main = "n = 10",
     xlab = "Media muestral", col = "#3498db", border = "white", xlim = c(0, 1))
abline(v = mu_poblacion, col = "red", lwd = 2)

hist(medias_n30, breaks = 40, main = "n = 30",
     xlab = "Media muestral", col = "#3498db", border = "white", xlim = c(0, 1))
abline(v = mu_poblacion, col = "red", lwd = 2)

hist(medias_n100, breaks = 40, main = "n = 100",
     xlab = "Media muestral", col = "#3498db", border = "white", xlim = c(0, 1))
abline(v = mu_poblacion, col = "red", lwd = 2)
par(mfrow = c(1, 1))
```

```{r comparacion-sd}
cat("Desviaci√≥n est√°ndar de las medias muestrales:\n")
cat("n = 10: ", round(sd(medias_n10), 4), "\n")
cat("n = 30: ", round(sd(medias_n30), 4), "\n")
cat("n = 100:", round(sd(medias_n100), 4), "\n")
cat("\nMuestras m√°s grandes ‚Üí Estimaciones m√°s precisas")
```

::: {.callout-note .callout-avanzado collapse="true"}
## üéì M√©todos Cuantitativos Avanzados

### Distribuci√≥n Binomial

La distribuci√≥n binomial modela el n√∫mero de "√©xitos" en n ensayos independientes, cada uno con probabilidad p de √©xito.

Por ejemplo, si encuestamos a 1000 personas y la probabilidad real de apoyo es 0.40:

```{r binomial}
n <- 1000
p <- 0.40

# Valor esperado
media <- n * p

# Desviaci√≥n est√°ndar
sd <- sqrt(n * p * (1 - p))

cat("Valor esperado:", media, "personas apoyar√°n\n")
cat("Desviaci√≥n est√°ndar:", round(sd, 1), "\n")

# Probabilidad de observar exactamente 400 apoyos
dbinom(400, size = 1000, prob = 0.40)

# Probabilidad de observar entre 380 y 420 apoyos
sum(dbinom(380:420, size = 1000, prob = 0.40))
```

### Formalizaci√≥n del Teorema del L√≠mite Central

Si X‚ÇÅ, X‚ÇÇ, ..., X‚Çô son variables aleatorias independientes de una poblaci√≥n con media Œº y varianza œÉ¬≤, entonces la media muestral:

$$\bar{X} \sim N\left(\mu, \frac{\sigma^2}{n}\right)$$

para n suficientemente grande.

El "error est√°ndar" de la media es:

$$SE(\bar{X}) = \frac{\sigma}{\sqrt{n}}$$

Esto explica por qu√© la dispersi√≥n disminuye con ‚àön.
:::

## Resumen: Conceptos clave {.unnumbered}

### Vocabulario esencial

| Concepto | Significado |
|----------|-------------|
| Probabilidad | N√∫mero entre 0 y 1 que cuantifica qu√© tan probable es algo |
| Variable aleatoria | Algo que toma diferentes valores con diferentes probabilidades |
| Distribuci√≥n Normal | Distribuci√≥n en forma de campana, base de la inferencia |
| Teorema del L√≠mite Central | Las medias muestrales siempre se distribuyen Normal |

### Ideas principales

1. **La probabilidad cuantifica incertidumbre:** Nos permite hacer afirmaciones precisas sobre qu√© tan seguros estamos
2. **La distribuci√≥n Normal es fundamental:** La regla 68-95-99.7 aplica a muchos fen√≥menos
3. **El TLC es la base de la inferencia:** Justifica usar la Normal para analizar muestras

### Funciones de R

| Funci√≥n | Uso |
|---------|-----|
| `pnorm(x, mean, sd)` | Probabilidad de estar por debajo de x |
| `qnorm(p, mean, sd)` | Valor correspondiente al percentil p |
| `rnorm(n, mean, sd)` | Genera n valores aleatorios de una Normal |

## Lecturas recomendadas {.unnumbered}

**Fundamentos de teor√≠a de probabilidad:**

Agresti, A., & Finlay, B. (2009). *Statistical Methods for the Social Sciences* (4th ed.). Pearson.
‚Üí Cap√≠tulo 4 ofrece introducci√≥n accesible a distribuciones de probabilidad.

**Aplicaciones en ciencias sociales:**

Llaudet, E., & Imai, K. (2022). *Data Analysis for Social Science: A Friendly and Practical Introduction*. Princeton University Press.
‚Üí Cap√≠tulo 6 conecta teor√≠a de probabilidad con aplicaciones pr√°cticas.

**Recurso complementario de acceso libre:**

Diez, D., Barr, C., & √áetinkaya-Rundel, M. (2019). *OpenIntro Statistics* (4th ed.). [Disponible gratis en https://www.openintro.org/book/os/]
‚Üí Cap√≠tulo 3 sobre distribuciones de variables aleatorias.

## Ejercicios {.unnumbered}

::: {.ejercicios}

**1. Probabilidades b√°sicas**

En una encuesta, 45% apoya la pol√≠tica A, 30% apoya la pol√≠tica B, y 15% apoya ambas.

a) ¬øCu√°l es la probabilidad de apoyar A o B (o ambas)?
b) Si alguien apoya B, ¬øcu√°l es la probabilidad de que tambi√©n apoye A?
c) ¬øSon A y B independientes? ¬øPor qu√©?

**2. Distribuci√≥n Normal**

Los puntajes de confianza institucional se distribuyen Normal con media 50 y desviaci√≥n est√°ndar 12.

a) ¬øQu√© proporci√≥n de personas tiene puntaje mayor a 60?
b) ¬øQu√© proporci√≥n tiene puntaje entre 40 y 65?
c) ¬øCu√°l es el puntaje correspondiente al percentil 90?
d) Si seleccionas 100 personas al azar, ¬øcu√°ntas esperar√≠as con puntaje menor a 35?

**3. Teorema del L√≠mite Central**

Tienes una poblaci√≥n con distribuci√≥n muy asim√©trica (ingresos).

```{r eval=FALSE}
set.seed(123)
poblacion <- rlnorm(100000, meanlog = 12, sdlog = 1)
```

a) Calcula media y desviaci√≥n est√°ndar de la poblaci√≥n
b) Toma 1,000 muestras de n=30 y calcula la media de cada una
c) Grafica la distribuci√≥n de esas medias
d) ¬øSe ve aproximadamente Normal? ¬øEst√° centrada en la media poblacional?

**4. Simulaci√≥n de encuestas**

Una poblaci√≥n tiene 52% de intenci√≥n de voto por el candidato A.

```{r eval=FALSE}
set.seed(123)
# Simula 1000 encuestas de n=1000
encuestas <- replicate(1000, mean(rbinom(1000, 1, 0.52)))
```

a) Grafica la distribuci√≥n de resultados
b) ¬øCu√°ntas encuestas hubieran predicho victoria del oponente (resultado < 0.50)?
c) ¬øC√≥mo cambia si el tama√±o de muestra es n=500?

:::
