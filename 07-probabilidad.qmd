# Introducción a probabilidad {#probabilidad}

## Objetivos del capítulo {.unnumbered}

Al finalizar este capítulo, serás capaz de:

- Comprender el concepto de probabilidad y su relación con la incertidumbre
- Distinguir entre interpretaciones frecuentista y bayesiana de probabilidad
- Calcular probabilidades básicas y aplicar reglas fundamentales
- Identificar y trabajar con variables aleatorias discretas y continuas
- Reconocer distribuciones de probabilidad comunes en ciencias sociales
- Comprender el Teorema del Límite Central y su importancia para la inferencia

## Fundamentos de probabilidad

La investigación social cuantitativa enfrenta invariablemente la **incertidumbre**. Cuando encuestamos 1,500 votantes chilenos para estimar apoyo a un candidato presidencial, no conocemos las preferencias de los millones que no fueron encuestados. Cuando comparamos tasas de homicidio entre países con y sin pena de muerte, no podemos asegurar que la diferencia observada no sea producto del azar.

La **teoría de probabilidad** nos proporciona un lenguaje matemático riguroso para cuantificar esta incertidumbre. No elimina la incertidumbre (esto es imposible cuando trabajamos con muestras), pero nos permite hacer afirmaciones precisas sobre qué tan confiables son nuestras conclusiones.[^prob-concepto]

[^prob-concepto]: La probabilidad no predice el futuro ni elimina la incertidumbre. Nos permite cuantificarla y tomar decisiones informadas bajo condiciones de información imperfecta.

#### Conceptos básicos

#### Definición y notación

Una **probabilidad** es un número entre 0 y 1 que cuantifica qué tan probable es que ocurra un evento:

- $P(A) = 0$ significa que el evento $A$ es imposible
- $P(A) = 1$ significa que el evento $A$ es seguro
- $P(A) = 0.5$ significa que $A$ tiene la misma probabilidad de ocurrir que de no ocurrir

Por ejemplo, si en una encuesta con 1,200 entrevistados, 360 declaran que votarán por candidatos del Frente Amplio en elecciones legislativas chilenas, podemos estimar: $P(\text{Voto FA}) = \frac{360}{1200} = 0.30$. Esto NO significa que exactamente 30% de los votantes votará por el FA el día de la elección. Significa que, basándonos en nuestra muestra, estimamos esa probabilidad con cierto nivel de incertidumbre (que cuantificaremos en el próximo capítulo con intervalos de confianza).

#### Interpretaciones de probabilidad

Existen dos interpretaciones fundamentales de qué significa "probabilidad":

**Interpretación frecuentista**:[^frecuentista] La probabilidad es el **límite de la frecuencia relativa** cuando un experimento se repite infinitas veces. Por ejemplo, $P(\text{Cara}) = 0.5$ al lanzar una moneda significa que, si lanzamos la moneda millones de veces, aproximadamente 50% serán caras. Esta es la interpretación estándar en ciencias sociales cuantitativas.

[^frecuentista]: Cuando un artículo reporta "p < 0.05", está usando lógica frecuentista: si no hubiera efecto real, veríamos un resultado tan extremo menos de 5% de las veces.

::: {.nivel data-nivel="avanzado"}
**Interpretación bayesiana**: La probabilidad cuantifica **grado de creencia** o certeza subjetiva sobre un evento. Permite asignar probabilidades a eventos únicos (como "¿cuál es la probabilidad de que Chile tenga una nueva Constitución en 2026?"). La estadística bayesiana actualiza creencias previas (prior) con nueva evidencia usando el teorema de Bayes. Es cada vez más usada en ciencias sociales, pero requiere fundamentos matemáticos adicionales.
:::

```{r probabilidad-interpretaciones, echo=FALSE, fig.cap="Comparación de interpretaciones de probabilidad"}
library(ggplot2)
library(dplyr)

# Simulación lanzamiento de moneda (frecuentista)
set.seed(123)
n_lanzamientos <- 1000
lanzamientos <- data.frame(
  n = 1:n_lanzamientos,
  resultado = sample(c("Cara", "Sello"), n_lanzamientos, replace = TRUE)
)

lanzamientos <- lanzamientos %>%
  mutate(
    es_cara = ifelse(resultado == "Cara", 1, 0),
    prop_acumulada = cumsum(es_cara) / n
  )

ggplot(lanzamientos, aes(x = n, y = prop_acumulada)) +
  geom_line(color = "#3498db", size = 1) +
  geom_hline(yintercept = 0.5, linetype = "dashed", color = "#e74c3c", size = 1) +
  labs(
    title = "Interpretación Frecuentista: Convergencia a la probabilidad real",
    subtitle = "Proporción de 'Cara' converge a 0.5 conforme aumentan los lanzamientos",
    x = "Número de lanzamientos",
    y = "Proporción acumulada de Cara"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"))
```

#### Reglas fundamentales de probabilidad

**Regla de la suma** (eventos mutuamente excluyentes)

Si $A$ y $B$ no pueden ocurrir simultáneamente:
$$P(A \text{ o } B) = P(A) + P(B)$$

Por ejemplo, en las elecciones municipales 2024 en Santiago, si un votante puede elegir solo un candidato: $P(\text{Izquierda o Derecha}) = P(\text{Izquierda}) + P(\text{Derecha})$.

**Regla del complemento**

$$P(\text{no } A) = 1 - P(A)$$

Por ejemplo, si $P(\text{Voto})=0.52$ en elecciones legislativas chilenas: $P(\text{Abstención}) = 1 - 0.52 = 0.48$.

**Regla del producto** (eventos independientes)

Si $A$ y $B$ son independientes (la ocurrencia de uno no afecta la probabilidad del otro):
$$P(A \text{ y } B) = P(A) \times P(B)$$

Por ejemplo, si encuestamos a dos votantes al azar y queremos saber la probabilidad de que ambos voten por la izquierda, asumiendo independencia y $P(\text{Izquierda})=0.30$: $P(\text{ambos izquierda}) = 0.30 \times 0.30 = 0.09$.

**Probabilidad condicional**

La probabilidad de $A$ dado que ya sabemos que $B$ ocurrió:
$$P(A|B) = \frac{P(A \text{ y } B)}{P(B)}$$

Por ejemplo, consideremos voto por género en una encuesta chilena. Supongamos que en una encuesta: 30% vota Apruebo, 60% son mujeres, y 20% del total son mujeres que votan Apruebo. Entonces $P(\text{Apruebo}|\text{Mujer}) = \frac{P(\text{Apruebo y Mujer})}{P(\text{Mujer})} = \frac{0.20}{0.60} = 0.33$. Es decir, entre las mujeres, 33% vota Apruebo (mientras que en la población general es 30%).

::: {.callout-tip}
## Ejemplo paso a paso: Calculando probabilidades

Una encuesta de 500 personas recopiló información sobre género y preferencia de voto:

|             | Aprueba | Rechaza | Total |
|-------------|:-------:|:-------:|:-----:|
| Hombres     |   80    |   120   |  200  |
| Mujeres     |  150    |   150   |  300  |
| **Total**   |  230    |   270   |  500  |

Calculemos algunas probabilidades:

```{r}
# Definir los datos
total <- 500
hombres <- 200
mujeres <- 300
aprueba <- 230
rechaza <- 270
hombres_aprueba <- 80
mujeres_aprueba <- 150

# P(Aprueba) - probabilidad marginal
P_aprueba <- aprueba / total
cat("P(Aprueba) =", P_aprueba, "\n")

# P(Mujer) - probabilidad marginal
P_mujer <- mujeres / total
cat("P(Mujer) =", P_mujer, "\n")

# P(Mujer Y Aprueba) - probabilidad conjunta
P_mujer_y_aprueba <- mujeres_aprueba / total
cat("P(Mujer Y Aprueba) =", P_mujer_y_aprueba, "\n")

# P(Aprueba | Mujer) - probabilidad condicional
P_aprueba_dado_mujer <- P_mujer_y_aprueba / P_mujer
cat("P(Aprueba | Mujer) =", P_aprueba_dado_mujer, "\n")

# Verificación directa
cat("Verificación: 150/300 =", 150/300, "\n")
```
:::

::: {.callout-warning}
## Error común: Confundir P(A|B) con P(B|A)

$P(\text{Aprueba}|\text{Mujer}) \neq P(\text{Mujer}|\text{Aprueba})$

- $P(\text{Aprueba}|\text{Mujer}) = 150/300 = 0.50$ → "De las mujeres, ¿qué proporción aprueba?"
- $P(\text{Mujer}|\text{Aprueba}) = 150/230 = 0.65$ → "De quienes aprueban, ¿qué proporción son mujeres?"

Este error es muy común y puede llevar a conclusiones incorrectas. Siempre pregúntate: "¿Cuál es mi población de referencia?"
:::

## Variables aleatorias y distribuciones

Una **variable aleatoria** es una función que asigna un valor numérico a cada resultado posible de un fenómeno aleatorio. Son la conexión entre probabilidad y estadística.

#### Variables aleatorias discretas

Toman valores específicos y contables (generalmente enteros).[^var-discretas]

[^var-discretas]: Ejemplos en ciencias sociales: número de partidos en el Congreso, número de protestas en un mes, respuesta en escala Likert, número de votantes en una mesa.

**Función de masa de probabilidad (PMF)**

Para una variable aleatoria discreta $X$, la PMF especifica la probabilidad de cada valor:
$$P(X = x)$$

```{r ejemplo-discreta, echo=TRUE}
# Simulación: Número de protestas por mes en una ciudad
# (Distribución Poisson con promedio = 2.5)
set.seed(456)
protestas <- rpois(1000, lambda = 2.5)

# Tabla de frecuencias
table(protestas) / 1000
```

```{r plot-discreta, echo=FALSE, fig.cap="Distribución de variable aleatoria discreta: Número de protestas"}
library(ggplot2)
data.frame(protestas = protestas) %>%
  ggplot(aes(x = protestas)) +
  geom_bar(aes(y = after_stat(count)/sum(after_stat(count))),
           fill = "#3498db", color = "white") +
  labs(
    title = "Distribución del número de protestas por mes",
    x = "Número de protestas",
    y = "Probabilidad"
  ) +
  scale_x_continuous(breaks = 0:10) +
  theme_minimal()
```

#### Variables aleatorias continuas

Pueden tomar cualquier valor en un intervalo (infinitos valores posibles).[^var-continuas]

[^var-continuas]: Ejemplos en ciencias sociales: porcentaje de votos obtenido, ingreso mensual, índice de democracia, tiempo hasta próxima protesta.

**Función de densidad de probabilidad (PDF)**

Para variables continuas, $P(X = x) = 0$ (la probabilidad de un valor exacto es cero). En su lugar, trabajamos con **intervalos**:

$$P(a < X < b) = \int_a^b f(x)dx$$

donde $f(x)$ es la función de densidad.

```{r ejemplo-continua, echo=TRUE}
# Simulación: Porcentaje de votos para alcalde
# (Distribución aproximadamente Normal)
set.seed(789)
votos <- rnorm(1000, mean = 35, sd = 5)

# Probabilidad de obtener entre 30% y 40%
mean(votos >= 30 & votos <= 40)
```

```{r plot-continua, echo=FALSE, fig.cap="Distribución de variable aleatoria continua: Porcentaje de votos"}
data.frame(votos = votos) %>%
  ggplot(aes(x = votos)) +
  geom_histogram(aes(y = after_stat(density)), bins = 30,
                 fill = "#3498db", color = "white", alpha = 0.7) +
  geom_density(color = "#e74c3c", size = 1.2) +
  labs(
    title = "Distribución del porcentaje de votos",
    x = "Porcentaje de votos (%)",
    y = "Densidad"
  ) +
  theme_minimal()
```

#### Valor esperado y varianza

**Valor esperado** (media poblacional): $E(X) = \mu$

El valor esperado es el promedio "teórico" de una variable aleatoria si pudiéramos observarla infinitas veces. Para variables discretas, se calcula sumando cada valor multiplicado por su probabilidad.

**Varianza**: $\text{Var}(X) = \sigma^2$ mide la dispersión alrededor del valor esperado.

**Desviación estándar**: $\sigma = \sqrt{\text{Var}(X)}$

Es importante distinguir que estos son parámetros **poblacionales** (generalmente desconocidos). Los estimamos a partir de muestras usando $\bar{x}$ y $s^2$.

::: {.nivel data-nivel="avanzado"}
**Fórmulas matemáticas del valor esperado:**

- Para variable discreta: $E(X) = \sum x \cdot P(X=x)$
- Para variable continua: $E(X) = \int x \cdot f(x)dx$
- Varianza: $\text{Var}(X) = E[(X - \mu)^2] = E(X^2) - [E(X)]^2$
:::

#### Distribuciones comunes

#### Distribución Normal (Gaussiana)

La distribución más importante en estadística inferencial. Una variable $X$ sigue una distribución Normal con media $\mu$ y varianza $\sigma^2$:

$$X \sim N(\mu, \sigma^2)$$

| Propiedad | Descripción |
|-----------|-------------|
| Forma | Simétrica, campana |
| 68% | Dentro de $\mu \pm 1\sigma$ |
| 95% | Dentro de $\mu \pm 1.96\sigma$ |
| 99.7% | Dentro de $\mu \pm 3\sigma$ |

```{r normal-distribution, echo=FALSE, fig.cap="Distribución Normal estándar con regla 68-95-99.7"}
library(ggplot2)

x <- seq(-4, 4, length.out = 1000)
y <- dnorm(x)

df <- data.frame(x = x, y = y)

ggplot(df, aes(x = x, y = y)) +
  geom_line(size = 1.2, color = "#2c3e50") +
  # Área 68%
  geom_area(data = subset(df, x >= -1 & x <= 1),
            fill = "#3498db", alpha = 0.3) +
  # Área 95%
  geom_area(data = subset(df, x >= -1.96 & x <= 1.96),
            fill = "#3498db", alpha = 0.2) +
  # Líneas verticales
  geom_vline(xintercept = c(-1, 1), linetype = "dashed", color = "#e74c3c") +
  geom_vline(xintercept = c(-1.96, 1.96), linetype = "dashed", color = "#e67e22") +
  annotate("text", x = 0, y = 0.2, label = "68%", size = 5, fontface = "bold") +
  annotate("text", x = 0, y = 0.1, label = "95%", size = 5, fontface = "bold") +
  labs(
    title = "Distribución Normal: Regla 68-95-99.7",
    x = "Desviaciones estándar desde la media",
    y = "Densidad"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold", size = 14))
```

Las alturas de hombres adultos chilenos se distribuyen aproximadamente $N(170, 7^2)$ cm. Podemos usar esta distribución para responder preguntas como: ¿Qué proporción de hombres mide más de 180 cm? o ¿Qué proporción mide entre 165 y 175 cm?

```{r ejemplo-normal, echo=TRUE}
# ¿Qué proporción de hombres mide más de 180 cm?
1 - pnorm(180, mean = 170, sd = 7)

# ¿Qué proporción mide entre 165 y 175 cm?
pnorm(175, mean = 170, sd = 7) - pnorm(165, mean = 170, sd = 7)
```

::: {.callout-note}
## Funciones de R para distribución Normal

R tiene cuatro funciones para trabajar con la distribución Normal:

| Función | Qué hace | Ejemplo |
|---------|----------|---------|
| `dnorm(x)` | Densidad en el punto x | `dnorm(0)` = 0.399 (altura de la curva en x=0) |
| `pnorm(x)` | Probabilidad acumulada P(X ≤ x) | `pnorm(0)` = 0.5 (50% está por debajo de la media) |
| `qnorm(p)` | Cuantil: ¿qué valor tiene probabilidad p por debajo? | `qnorm(0.975)` = 1.96 |
| `rnorm(n)` | Genera n valores aleatorios | `rnorm(100)` genera 100 valores |

```{r}
# Ejemplo práctico: ¿Cuál es el percentil 90 de alturas?
# Es decir, ¿qué altura es mayor que el 90% de los hombres?
qnorm(0.90, mean = 170, sd = 7)
```
:::

#### Distribución Binomial

Modela el número de "éxitos" en $n$ ensayos independientes, cada uno con probabilidad $p$ de éxito:

$$X \sim \text{Binomial}(n, p)$$

- $E(X) = np$
- $\text{Var}(X) = np(1-p)$

Por ejemplo, si encuestamos $n=1000$ votantes y la verdadera proporción que apoya un candidato es $p=0.40$, el número de encuestados que declaran apoyo sigue $X \sim \text{Binomial}(1000, 0.40)$:

```{r binomial-ejemplo, echo=TRUE}
# Probabilidad de observar exactamente 400 apoyos
dbinom(400, size = 1000, prob = 0.40)

# Probabilidad de observar entre 380 y 420 apoyos
sum(dbinom(380:420, size = 1000, prob = 0.40))

# Valor esperado y desviación estándar
n <- 1000; p <- 0.40
c(media = n*p, sd = sqrt(n*p*(1-p)))
```

```{r binomial-plot, echo=FALSE, fig.cap="Distribución Binomial: Número de votantes que apoyan candidato (n=1000, p=0.40)"}
x <- 350:450
probs <- dbinom(x, size = 1000, prob = 0.40)

data.frame(x = x, probabilidad = probs) %>%
  ggplot(aes(x = x, y = probabilidad)) +
  geom_col(fill = "#3498db", color = "white") +
  geom_vline(xintercept = 400, linetype = "dashed", color = "#e74c3c", size = 1) +
  annotate("text", x = 410, y = max(probs)*0.9,
           label = "Media = 400", color = "#e74c3c", size = 4) +
  labs(
    title = "Distribución del número de encuestados que apoyan candidato",
    subtitle = "n = 1000 encuestados, p = 0.40 probabilidad real de apoyo",
    x = "Número de encuestados que declaran apoyo",
    y = "Probabilidad"
  ) +
  theme_minimal()
```


## Teorema del Límite Central

El **Teorema del Límite Central (TLC)** es posiblemente el resultado más importante de la estadística. Fundamenta toda la inferencia estadística basada en muestras. El teorema establece que si tomamos muestras aleatorias de tamaño $n$ de **cualquier** población con media $\mu$ y varianza finita $\sigma^2$, entonces conforme $n$ aumenta, la distribución de la media muestral $\bar{X}$ se aproxima a una distribución Normal: $\bar{X} \sim N\left(\mu, \frac{\sigma^2}{n}\right)$. Esto ocurre **independientemente de la forma de la distribución original**, siempre que $n$ sea suficientemente grande (típicamente $n \geq 30$).

#### Implicaciones para ciencias sociales

1. **Podemos usar la distribución Normal** para hacer inferencias sobre medias muestrales, incluso si la variable original no es Normal

2. **La varianza de $\bar{X}$ disminuye con $n$**: Muestras más grandes producen estimaciones más precisas

3. **Justifica el uso de pruebas t y intervalos de confianza** (próximos capítulos)

#### Simulación del TLC

Demostremos el TLC con un ejemplo de ciencias políticas:

```{r tlc-simulacion, echo=TRUE, fig.cap="Teorema del Límite Central: Simulación"}
# Población NO normal: Participación en protestas (variable muy asimétrica)
# Mayoría no participa (0), algunos participan ocasionalmente
set.seed(2024)
poblacion <- c(rep(0, 7000), rep(1, 2000), rep(2, 700),
               rep(3, 200), rep(4, 80), rep(5, 20))

# Media y SD poblacionales
mu_poblacion <- mean(poblacion)
sigma_poblacion <- sd(poblacion)

cat("Distribución poblacional:\n")
cat("Media:", mu_poblacion, "\n")
cat("SD:", sigma_poblacion, "\n\n")

# Tomamos 5000 muestras de diferentes tamaños y calculamos sus medias
simular_medias <- function(n, n_muestras = 5000) {
  replicate(n_muestras, mean(sample(poblacion, n, replace = TRUE)))
}

medias_n10 <- simular_medias(10)
medias_n30 <- simular_medias(30)
medias_n100 <- simular_medias(100)

# Comparación
resultados <- data.frame(
  tamaño = c("n=10", "n=30", "n=100"),
  media = c(mean(medias_n10), mean(medias_n30), mean(medias_n100)),
  sd_observada = c(sd(medias_n10), sd(medias_n30), sd(medias_n100)),
  sd_teorica = sigma_poblacion / sqrt(c(10, 30, 100))
)

print(resultados)
```

```{r tlc-plot, echo=FALSE, fig.height=8, fig.cap="Convergencia a la Normal según el Teorema del Límite Central"}
library(tidyr)
library(ggplot2)

df_medias <- data.frame(
  n10 = medias_n10,
  n30 = medias_n30,
  n100 = medias_n100
) %>%
  pivot_longer(everything(), names_to = "tamaño", values_to = "media")

df_medias$tamaño <- factor(df_medias$tamaño,
                            levels = c("n10", "n30", "n100"),
                            labels = c("n = 10", "n = 30", "n = 100"))

ggplot(df_medias, aes(x = media)) +
  geom_histogram(aes(y = after_stat(density)), bins = 40,
                 fill = "#3498db", color = "white", alpha = 0.7) +
  geom_density(color = "#e74c3c", size = 1.2) +
  facet_wrap(~ tamaño, ncol = 1, scales = "free_y") +
  geom_vline(xintercept = mu_poblacion, linetype = "dashed",
             color = "#2ecc71", size = 1) +
  labs(
    title = "Teorema del Límite Central en acción",
    subtitle = "Distribución de medias muestrales para diferentes tamaños de muestra",
    x = "Media muestral de participación en protestas",
    y = "Densidad",
    caption = "Población original altamente asimétrica (mayoría ceros). \nLínea verde = media poblacional verdadera"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    strip.text = element_text(face = "bold", size = 12)
  )
```

Aunque la población original es extremadamente asimétrica (la mayoría tiene valor 0), las medias muestrales **se distribuyen cada vez más normalmente** conforme aumenta $n$. Con $n=100$, la distribución de $\bar{X}$ es prácticamente Normal.

## Resumen {.unnumbered}

| Concepto | Descripción |
|----------|-------------|
| **Probabilidad** | Cuantifica incertidumbre (0 a 1) |
| **Variables aleatorias** | Discretas (conteos) o continuas (intervalos) |
| **Normal** | Base de inferencia; regla 68-95-99.7 |
| **Binomial** | Conteo de éxitos en n ensayos |
| **TLC** | Medias muestrales → Normal (si n ≥ 30) |

El Teorema del Límite Central justifica el uso de la distribución Normal para inferencia (intervalos de confianza, pruebas de hipótesis).

## Lecturas recomendadas {.unnumbered}

**Fundamentos de teoría de probabilidad:**

Agresti, A., & Finlay, B. (2009). *Statistical Methods for the Social Sciences* (4th ed.). Pearson.  
→ Capítulo 4 ofrece una introducción accesible a distribuciones de probabilidad con ejemplos de ciencias sociales.

**Aplicaciones en ciencias sociales:**

Llaudet, E., & Imai, K. (2022). *Data Analysis for Social Science: A Friendly and Practical Introduction*. Princeton University Press.  
→ Capítulo 6 conecta teoría de probabilidad con aplicaciones en investigación social y política.

**Recurso complementario de acceso libre:**

Diez, D., Barr, C., & Çetinkaya-Rundel, M. (2019). *OpenIntro Statistics* (4th ed.). [Disponible gratis en https://www.openintro.org/book/os/]  
→ Capítulo 3 sobre distribuciones de variables aleatorias, con ejercicios interactivos.


## Ejercicios {.unnumbered}

Los ejercicios para este capítulo se encuentran en el [Anexo de Ejercicios](#ejercicios-cap7).

::: {#refs}
:::
