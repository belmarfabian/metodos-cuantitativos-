# Introducci√≥n a probabilidad {#probabilidad}

## Objetivos del cap√≠tulo {.unnumbered}

Al finalizar este cap√≠tulo, ser√°s capaz de:

- Comprender el concepto de probabilidad y su relaci√≥n con la incertidumbre
- Distinguir entre interpretaciones frecuentista y bayesiana de probabilidad
- Calcular probabilidades b√°sicas y aplicar reglas fundamentales
- Identificar y trabajar con variables aleatorias discretas y continuas
- Reconocer distribuciones de probabilidad comunes en ciencias sociales
- Comprender el Teorema del L√≠mite Central y su importancia para la inferencia

## Fundamentos de probabilidad

La investigaci√≥n social cuantitativa enfrenta invariablemente la **incertidumbre**. Cuando encuestamos 1,500 votantes chilenos para estimar apoyo a un candidato presidencial, no conocemos las preferencias de los millones que no fueron encuestados. Cuando comparamos tasas de homicidio entre pa√≠ses con y sin pena de muerte, no podemos asegurar que la diferencia observada no sea producto del azar.

La **teor√≠a de probabilidad** nos proporciona un lenguaje matem√°tico riguroso para cuantificar esta incertidumbre. No elimina la incertidumbre (esto es imposible cuando trabajamos con muestras), pero nos permite hacer afirmaciones precisas sobre qu√© tan confiables son nuestras conclusiones.[^prob-concepto]

[^prob-concepto]: La probabilidad no predice el futuro ni elimina la incertidumbre. Nos permite cuantificarla y tomar decisiones informadas bajo condiciones de informaci√≥n imperfecta.

### Conceptos b√°sicos

### Definici√≥n y notaci√≥n

Una **probabilidad** es un n√∫mero entre 0 y 1 que cuantifica qu√© tan probable es que ocurra un evento:

- $P(A) = 0$ significa que el evento $A$ es imposible
- $P(A) = 1$ significa que el evento $A$ es seguro
- $P(A) = 0.5$ significa que $A$ tiene la misma probabilidad de ocurrir que de no ocurrir

Por ejemplo, si en una encuesta con 1,200 entrevistados, 360 declaran que votar√°n por candidatos del Frente Amplio en elecciones legislativas chilenas, podemos estimar: $P(\text{Voto FA}) = \frac{360}{1200} = 0.30$. Esto NO significa que exactamente 30% de los votantes votar√° por el FA el d√≠a de la elecci√≥n. Significa que, bas√°ndonos en nuestra muestra, estimamos esa probabilidad con cierto nivel de incertidumbre (que cuantificaremos en el pr√≥ximo cap√≠tulo con intervalos de confianza).

### Interpretaciones de probabilidad

Existen dos interpretaciones fundamentales de qu√© significa "probabilidad":

**Interpretaci√≥n frecuentista**:[^frecuentista] La probabilidad es el **l√≠mite de la frecuencia relativa** cuando un experimento se repite infinitas veces. Por ejemplo, $P(\text{Cara}) = 0.5$ al lanzar una moneda significa que, si lanzamos la moneda millones de veces, aproximadamente 50% ser√°n caras. Esta es la interpretaci√≥n est√°ndar en ciencias sociales cuantitativas.

[^frecuentista]: Cuando un art√≠culo reporta "p < 0.05", est√° usando l√≥gica frecuentista: si no hubiera efecto real, ver√≠amos un resultado tan extremo menos de 5% de las veces.

::: {.callout-note .callout-avanzado collapse="true"}
## üéì M√©todos Cuantitativos Avanzados

**Interpretaci√≥n bayesiana**: La probabilidad cuantifica **grado de creencia** o certeza subjetiva sobre un evento. Permite asignar probabilidades a eventos √∫nicos (como "¬øcu√°l es la probabilidad de que Chile tenga una nueva Constituci√≥n en 2026?"). La estad√≠stica bayesiana actualiza creencias previas (prior) con nueva evidencia usando el teorema de Bayes. Es cada vez m√°s usada en ciencias sociales, pero requiere fundamentos matem√°ticos adicionales.
:::

```{r probabilidad-interpretaciones, echo=FALSE, fig.cap="Comparaci√≥n de interpretaciones de probabilidad"}
library(ggplot2)
library(dplyr)

# Simulaci√≥n lanzamiento de moneda (frecuentista)
set.seed(123)
n_lanzamientos <- 1000
lanzamientos <- data.frame(
  n = 1:n_lanzamientos,
  resultado = sample(c("Cara", "Sello"), n_lanzamientos, replace = TRUE)
)

lanzamientos <- lanzamientos %>%
  mutate(
    es_cara = ifelse(resultado == "Cara", 1, 0),
    prop_acumulada = cumsum(es_cara) / n
  )

ggplot(lanzamientos, aes(x = n, y = prop_acumulada)) +
  geom_line(color = "#3498db", size = 1) +
  geom_hline(yintercept = 0.5, linetype = "dashed", color = "#e74c3c", size = 1) +
  labs(
    title = "Interpretaci√≥n Frecuentista: Convergencia a la probabilidad real",
    subtitle = "Proporci√≥n de 'Cara' converge a 0.5 conforme aumentan los lanzamientos",
    x = "N√∫mero de lanzamientos",
    y = "Proporci√≥n acumulada de Cara"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold"))
```

### Reglas fundamentales de probabilidad

**Regla de la suma** (eventos mutuamente excluyentes)

Si $A$ y $B$ no pueden ocurrir simult√°neamente:
$$P(A \text{ o } B) = P(A) + P(B)$$

Por ejemplo, en las elecciones municipales 2024 en Santiago, si un votante puede elegir solo un candidato: $P(\text{Izquierda o Derecha}) = P(\text{Izquierda}) + P(\text{Derecha})$.

**Regla del complemento**

$$P(\text{no } A) = 1 - P(A)$$

Por ejemplo, si $P(\text{Voto})=0.52$ en elecciones legislativas chilenas: $P(\text{Abstenci√≥n}) = 1 - 0.52 = 0.48$.

**Regla del producto** (eventos independientes)

Si $A$ y $B$ son independientes (la ocurrencia de uno no afecta la probabilidad del otro):
$$P(A \text{ y } B) = P(A) \times P(B)$$

Por ejemplo, si encuestamos a dos votantes al azar y queremos saber la probabilidad de que ambos voten por la izquierda, asumiendo independencia y $P(\text{Izquierda})=0.30$: $P(\text{ambos izquierda}) = 0.30 \times 0.30 = 0.09$.

**Probabilidad condicional**

La probabilidad de $A$ dado que ya sabemos que $B$ ocurri√≥:
$$P(A|B) = \frac{P(A \text{ y } B)}{P(B)}$$

Por ejemplo, consideremos voto por g√©nero en una encuesta chilena. Supongamos que en una encuesta: 30% vota Apruebo, 60% son mujeres, y 20% del total son mujeres que votan Apruebo. Entonces $P(\text{Apruebo}|\text{Mujer}) = \frac{P(\text{Apruebo y Mujer})}{P(\text{Mujer})} = \frac{0.20}{0.60} = 0.33$. Es decir, entre las mujeres, 33% vota Apruebo (mientras que en la poblaci√≥n general es 30%).

::: {.callout-tip}
## Ejemplo paso a paso: Calculando probabilidades

Una encuesta de 500 personas recopil√≥ informaci√≥n sobre g√©nero y preferencia de voto:

|             | Aprueba | Rechaza | Total |
|-------------|:-------:|:-------:|:-----:|
| Hombres     |   80    |   120   |  200  |
| Mujeres     |  150    |   150   |  300  |
| **Total**   |  230    |   270   |  500  |

Calculemos algunas probabilidades:

```{r}
# Definir los datos
total <- 500
hombres <- 200
mujeres <- 300
aprueba <- 230
rechaza <- 270
hombres_aprueba <- 80
mujeres_aprueba <- 150

# P(Aprueba) - probabilidad marginal
P_aprueba <- aprueba / total
cat("P(Aprueba) =", P_aprueba, "\n")

# P(Mujer) - probabilidad marginal
P_mujer <- mujeres / total
cat("P(Mujer) =", P_mujer, "\n")

# P(Mujer Y Aprueba) - probabilidad conjunta
P_mujer_y_aprueba <- mujeres_aprueba / total
cat("P(Mujer Y Aprueba) =", P_mujer_y_aprueba, "\n")

# P(Aprueba | Mujer) - probabilidad condicional
P_aprueba_dado_mujer <- P_mujer_y_aprueba / P_mujer
cat("P(Aprueba | Mujer) =", P_aprueba_dado_mujer, "\n")

# Verificaci√≥n directa
cat("Verificaci√≥n: 150/300 =", 150/300, "\n")
```
:::

::: {.callout-warning}
## Error com√∫n: Confundir P(A|B) con P(B|A)

$P(\text{Aprueba}|\text{Mujer}) \neq P(\text{Mujer}|\text{Aprueba})$

- $P(\text{Aprueba}|\text{Mujer}) = 150/300 = 0.50$ ‚Üí "De las mujeres, ¬øqu√© proporci√≥n aprueba?"
- $P(\text{Mujer}|\text{Aprueba}) = 150/230 = 0.65$ ‚Üí "De quienes aprueban, ¬øqu√© proporci√≥n son mujeres?"

Este error es muy com√∫n y puede llevar a conclusiones incorrectas. Siempre preg√∫ntate: "¬øCu√°l es mi poblaci√≥n de referencia?"
:::

## Variables aleatorias y distribuciones

Una **variable aleatoria** es una funci√≥n que asigna un valor num√©rico a cada resultado posible de un fen√≥meno aleatorio. Son la conexi√≥n entre probabilidad y estad√≠stica.

### Variables aleatorias discretas

Toman valores espec√≠ficos y contables (generalmente enteros).[^var-discretas]

[^var-discretas]: Ejemplos en ciencias sociales: n√∫mero de partidos en el Congreso, n√∫mero de protestas en un mes, respuesta en escala Likert, n√∫mero de votantes en una mesa.

**Funci√≥n de masa de probabilidad (PMF)**

Para una variable aleatoria discreta $X$, la PMF especifica la probabilidad de cada valor:
$$P(X = x)$$

```{r ejemplo-discreta, echo=TRUE}
# Simulaci√≥n: N√∫mero de protestas por mes en una ciudad
# (Distribuci√≥n Poisson con promedio = 2.5)
set.seed(456)
protestas <- rpois(1000, lambda = 2.5)

# Tabla de frecuencias
table(protestas) / 1000
```

```{r plot-discreta, echo=FALSE, fig.cap="Distribuci√≥n de variable aleatoria discreta: N√∫mero de protestas"}
library(ggplot2)
data.frame(protestas = protestas) %>%
  ggplot(aes(x = protestas)) +
  geom_bar(aes(y = after_stat(count)/sum(after_stat(count))),
           fill = "#3498db", color = "white") +
  labs(
    title = "Distribuci√≥n del n√∫mero de protestas por mes",
    x = "N√∫mero de protestas",
    y = "Probabilidad"
  ) +
  scale_x_continuous(breaks = 0:10) +
  theme_minimal()
```

### Variables aleatorias continuas

Pueden tomar cualquier valor en un intervalo (infinitos valores posibles).[^var-continuas]

[^var-continuas]: Ejemplos en ciencias sociales: porcentaje de votos obtenido, ingreso mensual, √≠ndice de democracia, tiempo hasta pr√≥xima protesta.

**Funci√≥n de densidad de probabilidad (PDF)**

Para variables continuas, $P(X = x) = 0$ (la probabilidad de un valor exacto es cero). En su lugar, trabajamos con **intervalos**:

$$P(a < X < b) = \int_a^b f(x)dx$$

donde $f(x)$ es la funci√≥n de densidad.

```{r ejemplo-continua, echo=TRUE}
# Simulaci√≥n: Porcentaje de votos para alcalde
# (Distribuci√≥n aproximadamente Normal)
set.seed(789)
votos <- rnorm(1000, mean = 35, sd = 5)

# Probabilidad de obtener entre 30% y 40%
mean(votos >= 30 & votos <= 40)
```

```{r plot-continua, echo=FALSE, fig.cap="Distribuci√≥n de variable aleatoria continua: Porcentaje de votos"}
data.frame(votos = votos) %>%
  ggplot(aes(x = votos)) +
  geom_histogram(aes(y = after_stat(density)), bins = 30,
                 fill = "#3498db", color = "white", alpha = 0.7) +
  geom_density(color = "#e74c3c", size = 1.2) +
  labs(
    title = "Distribuci√≥n del porcentaje de votos",
    x = "Porcentaje de votos (%)",
    y = "Densidad"
  ) +
  theme_minimal()
```

### Valor esperado y varianza

**Valor esperado** (media poblacional): $E(X) = \mu$

El valor esperado es el promedio "te√≥rico" de una variable aleatoria si pudi√©ramos observarla infinitas veces. Para variables discretas, se calcula sumando cada valor multiplicado por su probabilidad.

**Varianza**: $\text{Var}(X) = \sigma^2$ mide la dispersi√≥n alrededor del valor esperado.

**Desviaci√≥n est√°ndar**: $\sigma = \sqrt{\text{Var}(X)}$

Es importante distinguir que estos son par√°metros **poblacionales** (generalmente desconocidos). Los estimamos a partir de muestras usando $\bar{x}$ y $s^2$.

::: {.callout-note .callout-avanzado collapse="true"}
## üéì M√©todos Cuantitativos Avanzados

**F√≥rmulas matem√°ticas del valor esperado:**

- Para variable discreta: $E(X) = \sum x \cdot P(X=x)$
- Para variable continua: $E(X) = \int x \cdot f(x)dx$
- Varianza: $\text{Var}(X) = E[(X - \mu)^2] = E(X^2) - [E(X)]^2$
:::

### Distribuciones comunes

### Distribuci√≥n Normal (Gaussiana)

La distribuci√≥n m√°s importante en estad√≠stica inferencial. Una variable $X$ sigue una distribuci√≥n Normal con media $\mu$ y varianza $\sigma^2$:

$$X \sim N(\mu, \sigma^2)$$

| Propiedad | Descripci√≥n |
|-----------|-------------|
| Forma | Sim√©trica, campana |
| 68% | Dentro de $\mu \pm 1\sigma$ |
| 95% | Dentro de $\mu \pm 1.96\sigma$ |
| 99.7% | Dentro de $\mu \pm 3\sigma$ |

```{r normal-distribution, echo=FALSE, fig.cap="Distribuci√≥n Normal est√°ndar con regla 68-95-99.7"}
library(ggplot2)

x <- seq(-4, 4, length.out = 1000)
y <- dnorm(x)

df <- data.frame(x = x, y = y)

ggplot(df, aes(x = x, y = y)) +
  geom_line(size = 1.2, color = "#2c3e50") +
  # √Årea 68%
  geom_area(data = subset(df, x >= -1 & x <= 1),
            fill = "#3498db", alpha = 0.3) +
  # √Årea 95%
  geom_area(data = subset(df, x >= -1.96 & x <= 1.96),
            fill = "#3498db", alpha = 0.2) +
  # L√≠neas verticales
  geom_vline(xintercept = c(-1, 1), linetype = "dashed", color = "#e74c3c") +
  geom_vline(xintercept = c(-1.96, 1.96), linetype = "dashed", color = "#e67e22") +
  annotate("text", x = 0, y = 0.2, label = "68%", size = 5, fontface = "bold") +
  annotate("text", x = 0, y = 0.1, label = "95%", size = 5, fontface = "bold") +
  labs(
    title = "Distribuci√≥n Normal: Regla 68-95-99.7",
    x = "Desviaciones est√°ndar desde la media",
    y = "Densidad"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold", size = 14))
```

Las alturas de hombres adultos chilenos se distribuyen aproximadamente $N(170, 7^2)$ cm. Podemos usar esta distribuci√≥n para responder preguntas como: ¬øQu√© proporci√≥n de hombres mide m√°s de 180 cm? o ¬øQu√© proporci√≥n mide entre 165 y 175 cm?

```{r ejemplo-normal, echo=TRUE}
# ¬øQu√© proporci√≥n de hombres mide m√°s de 180 cm?
1 - pnorm(180, mean = 170, sd = 7)

# ¬øQu√© proporci√≥n mide entre 165 y 175 cm?
pnorm(175, mean = 170, sd = 7) - pnorm(165, mean = 170, sd = 7)
```

::: {.callout-note}
## Funciones de R para distribuci√≥n Normal

R tiene cuatro funciones para trabajar con la distribuci√≥n Normal:

| Funci√≥n | Qu√© hace | Ejemplo |
|---------|----------|---------|
| `dnorm(x)` | Densidad en el punto x | `dnorm(0)` = 0.399 (altura de la curva en x=0) |
| `pnorm(x)` | Probabilidad acumulada P(X ‚â§ x) | `pnorm(0)` = 0.5 (50% est√° por debajo de la media) |
| `qnorm(p)` | Cuantil: ¬øqu√© valor tiene probabilidad p por debajo? | `qnorm(0.975)` = 1.96 |
| `rnorm(n)` | Genera n valores aleatorios | `rnorm(100)` genera 100 valores |

```{r}
# Ejemplo pr√°ctico: ¬øCu√°l es el percentil 90 de alturas?
# Es decir, ¬øqu√© altura es mayor que el 90% de los hombres?
qnorm(0.90, mean = 170, sd = 7)
```
:::

### Distribuci√≥n Binomial

Modela el n√∫mero de "√©xitos" en $n$ ensayos independientes, cada uno con probabilidad $p$ de √©xito:

$$X \sim \text{Binomial}(n, p)$$

- $E(X) = np$
- $\text{Var}(X) = np(1-p)$

Por ejemplo, si encuestamos $n=1000$ votantes y la verdadera proporci√≥n que apoya un candidato es $p=0.40$, el n√∫mero de encuestados que declaran apoyo sigue $X \sim \text{Binomial}(1000, 0.40)$:

```{r binomial-ejemplo, echo=TRUE}
# Probabilidad de observar exactamente 400 apoyos
dbinom(400, size = 1000, prob = 0.40)

# Probabilidad de observar entre 380 y 420 apoyos
sum(dbinom(380:420, size = 1000, prob = 0.40))

# Valor esperado y desviaci√≥n est√°ndar
n <- 1000; p <- 0.40
c(media = n*p, sd = sqrt(n*p*(1-p)))
```

```{r binomial-plot, echo=FALSE, fig.cap="Distribuci√≥n Binomial: N√∫mero de votantes que apoyan candidato (n=1000, p=0.40)"}
x <- 350:450
probs <- dbinom(x, size = 1000, prob = 0.40)

data.frame(x = x, probabilidad = probs) %>%
  ggplot(aes(x = x, y = probabilidad)) +
  geom_col(fill = "#3498db", color = "white") +
  geom_vline(xintercept = 400, linetype = "dashed", color = "#e74c3c", size = 1) +
  annotate("text", x = 410, y = max(probs)*0.9,
           label = "Media = 400", color = "#e74c3c", size = 4) +
  labs(
    title = "Distribuci√≥n del n√∫mero de encuestados que apoyan candidato",
    subtitle = "n = 1000 encuestados, p = 0.40 probabilidad real de apoyo",
    x = "N√∫mero de encuestados que declaran apoyo",
    y = "Probabilidad"
  ) +
  theme_minimal()
```


## Teorema del L√≠mite Central

El **Teorema del L√≠mite Central (TLC)** es posiblemente el resultado m√°s importante de la estad√≠stica. Fundamenta toda la inferencia estad√≠stica basada en muestras. El teorema establece que si tomamos muestras aleatorias de tama√±o $n$ de **cualquier** poblaci√≥n con media $\mu$ y varianza finita $\sigma^2$, entonces conforme $n$ aumenta, la distribuci√≥n de la media muestral $\bar{X}$ se aproxima a una distribuci√≥n Normal: $\bar{X} \sim N\left(\mu, \frac{\sigma^2}{n}\right)$. Esto ocurre **independientemente de la forma de la distribuci√≥n original**, siempre que $n$ sea suficientemente grande (t√≠picamente $n \geq 30$).

### Implicaciones para ciencias sociales

1. **Podemos usar la distribuci√≥n Normal** para hacer inferencias sobre medias muestrales, incluso si la variable original no es Normal

2. **La varianza de $\bar{X}$ disminuye con $n$**: Muestras m√°s grandes producen estimaciones m√°s precisas

3. **Justifica el uso de pruebas t y intervalos de confianza** (pr√≥ximos cap√≠tulos)

### Simulaci√≥n del TLC

Demostremos el TLC con un ejemplo de ciencias pol√≠ticas:

```{r tlc-simulacion, echo=TRUE, fig.cap="Teorema del L√≠mite Central: Simulaci√≥n"}
# Poblaci√≥n NO normal: Participaci√≥n en protestas (variable muy asim√©trica)
# Mayor√≠a no participa (0), algunos participan ocasionalmente
set.seed(2024)
poblacion <- c(rep(0, 7000), rep(1, 2000), rep(2, 700),
               rep(3, 200), rep(4, 80), rep(5, 20))

# Media y SD poblacionales
mu_poblacion <- mean(poblacion)
sigma_poblacion <- sd(poblacion)

cat("Distribuci√≥n poblacional:\n")
cat("Media:", mu_poblacion, "\n")
cat("SD:", sigma_poblacion, "\n\n")

# Tomamos 5000 muestras de diferentes tama√±os y calculamos sus medias
simular_medias <- function(n, n_muestras = 5000) {
  replicate(n_muestras, mean(sample(poblacion, n, replace = TRUE)))
}

medias_n10 <- simular_medias(10)
medias_n30 <- simular_medias(30)
medias_n100 <- simular_medias(100)

# Comparaci√≥n
resultados <- data.frame(
  tama√±o = c("n=10", "n=30", "n=100"),
  media = c(mean(medias_n10), mean(medias_n30), mean(medias_n100)),
  sd_observada = c(sd(medias_n10), sd(medias_n30), sd(medias_n100)),
  sd_teorica = sigma_poblacion / sqrt(c(10, 30, 100))
)

print(resultados)
```

```{r tlc-plot, echo=FALSE, fig.height=8, fig.cap="Convergencia a la Normal seg√∫n el Teorema del L√≠mite Central"}
library(tidyr)
library(ggplot2)

df_medias <- data.frame(
  n10 = medias_n10,
  n30 = medias_n30,
  n100 = medias_n100
) %>%
  pivot_longer(everything(), names_to = "tama√±o", values_to = "media")

df_medias$tama√±o <- factor(df_medias$tama√±o,
                            levels = c("n10", "n30", "n100"),
                            labels = c("n = 10", "n = 30", "n = 100"))

ggplot(df_medias, aes(x = media)) +
  geom_histogram(aes(y = after_stat(density)), bins = 40,
                 fill = "#3498db", color = "white", alpha = 0.7) +
  geom_density(color = "#e74c3c", size = 1.2) +
  facet_wrap(~ tama√±o, ncol = 1, scales = "free_y") +
  geom_vline(xintercept = mu_poblacion, linetype = "dashed",
             color = "#2ecc71", size = 1) +
  labs(
    title = "Teorema del L√≠mite Central en acci√≥n",
    subtitle = "Distribuci√≥n de medias muestrales para diferentes tama√±os de muestra",
    x = "Media muestral de participaci√≥n en protestas",
    y = "Densidad",
    caption = "Poblaci√≥n original altamente asim√©trica (mayor√≠a ceros). \nL√≠nea verde = media poblacional verdadera"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    strip.text = element_text(face = "bold", size = 12)
  )
```

Aunque la poblaci√≥n original es extremadamente asim√©trica (la mayor√≠a tiene valor 0), las medias muestrales **se distribuyen cada vez m√°s normalmente** conforme aumenta $n$. Con $n=100$, la distribuci√≥n de $\bar{X}$ es pr√°cticamente Normal.

## Resumen {.unnumbered}

| Concepto | Descripci√≥n |
|----------|-------------|
| **Probabilidad** | Cuantifica incertidumbre (0 a 1) |
| **Variables aleatorias** | Discretas (conteos) o continuas (intervalos) |
| **Normal** | Base de inferencia; regla 68-95-99.7 |
| **Binomial** | Conteo de √©xitos en n ensayos |
| **TLC** | Medias muestrales ‚Üí Normal (si n ‚â• 30) |

El Teorema del L√≠mite Central justifica el uso de la distribuci√≥n Normal para inferencia (intervalos de confianza, pruebas de hip√≥tesis).

## Lecturas recomendadas {.unnumbered}

**Fundamentos de teor√≠a de probabilidad:**

Agresti, A., & Finlay, B. (2009). *Statistical Methods for the Social Sciences* (4th ed.). Pearson.  
‚Üí Cap√≠tulo 4 ofrece una introducci√≥n accesible a distribuciones de probabilidad con ejemplos de ciencias sociales.

**Aplicaciones en ciencias sociales:**

Llaudet, E., & Imai, K. (2022). *Data Analysis for Social Science: A Friendly and Practical Introduction*. Princeton University Press.  
‚Üí Cap√≠tulo 6 conecta teor√≠a de probabilidad con aplicaciones en investigaci√≥n social y pol√≠tica.

**Recurso complementario de acceso libre:**

Diez, D., Barr, C., & √áetinkaya-Rundel, M. (2019). *OpenIntro Statistics* (4th ed.). [Disponible gratis en https://www.openintro.org/book/os/]  
‚Üí Cap√≠tulo 3 sobre distribuciones de variables aleatorias, con ejercicios interactivos.


## Ejercicios {.unnumbered}

::: {.ejercicios}

**1. Reglas de probabilidad**

En una encuesta, 45% de los encuestados apoya pol√≠tica A, 30% apoya pol√≠tica B, y 15% apoya ambas.

a) ¬øCu√°l es $P(A \text{ o } B)$?
b) ¬øCu√°l es $P(A | B)$?
c) ¬øSon A y B independientes? Demuestra matem√°ticamente
d) ¬øSon A y B mutuamente excluyentes? ¬øPor qu√©?

**2. Distribuci√≥n binomial**

Una encuesta estima que 35% de los chilenos votar√≠a por candidato X. Si encuestas a 500 personas:

a) ¬øCu√°l es el valor esperado del n√∫mero de votantes por X?
b) ¬øCu√°l es la desviaci√≥n est√°ndar?
c) Calcula $P(X \leq 150)$ en R
d) Calcula $P(165 \leq X \leq 185)$
e) ¬øCu√°l es el m√≠nimo de votos que esperar√≠as con 95% de confianza?

**3. Distribuci√≥n Normal**

Scores de confianza institucional se distribuyen Normal con media 50 y SD 12.

a) ¬øQu√© proporci√≥n de personas tiene score > 60?
b) ¬øQu√© proporci√≥n tiene score entre 40 y 65?
c) ¬øCu√°l es el score correspondiente al percentil 90?
d) Si seleccionas aleatoriamente 100 personas, ¬øcu√°ntas esperas tengan score < 35?

**4. Teorema del L√≠mite Central**

Tienes una poblaci√≥n con distribuci√≥n muy asim√©trica (ej: ingresos).

a) Simula una poblaci√≥n de 100,000 ingresos usando `rlnorm(100000, 12, 1)`
b) Calcula y reporta media, mediana y SD poblacionales
c) Toma 1,000 muestras de n=10 y grafica distribuci√≥n de medias muestrales
d) Repite con n=30 y n=100
e) ¬øA partir de qu√© $n$ la distribuci√≥n de medias "parece" Normal?

**5. Simulaci√≥n de encuestas**

Una poblaci√≥n tiene 52% de intenci√≥n de voto por candidato A.

```{r eval=FALSE}
set.seed(123)
# Simula 1000 encuestas de n=1000
encuestas <- replicate(1000, mean(rbinom(1000, 1, 0.52)))
```

a) Ejecuta la simulaci√≥n y grafica distribuci√≥n de resultados
b) ¬øCu√°ntas encuestas hubieran predicho victoria del oponente (es decir, $\hat{p} < 0.50$)?
c) ¬øC√≥mo cambia si $n = 500$? ¬øY si $n = 2000$?
d) Si la diferencia real fuera solo de 1 punto (51-49), ¬øqu√© proporci√≥n de encuestas de n=1000 predecir√≠an mal?

**6. Probabilidad condicional aplicada**

Una prueba de COVID tiene sensibilidad de 95% (detecta correctamente a infectados) y especificidad de 98% (identifica correctamente a no infectados). Si la prevalencia en la poblaci√≥n es 2%:

a) Calcula la probabilidad de estar infectado dado un test positivo
b) ¬øPor qu√© esta probabilidad es sorprendentemente baja?
c) ¬øC√≥mo cambia si la prevalencia sube a 10%?
d) ¬øQu√© implicaciones tiene esto para pol√≠ticas de testeo masivo?

:::

::: {#refs}
:::
