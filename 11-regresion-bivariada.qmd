# Regresi√≥n bivariada {#regresion-bivariada}

```{r setup-11, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(ggplot2)
```

## Objetivos del cap√≠tulo {.unnumbered}

Al finalizar este cap√≠tulo, ser√°s capaz de:

- Calcular e interpretar coeficientes de correlaci√≥n
- Comprender la diferencia entre correlaci√≥n y causalidad
- Estimar modelos de regresi√≥n lineal simple usando m√≠nimos cuadrados ordinarios
- Interpretar coeficientes de regresi√≥n e intercepto
- Evaluar la bondad de ajuste usando $R^2$
- Realizar pruebas de hip√≥tesis sobre coeficientes de regresi√≥n

## Correlaci√≥n y regresi√≥n

La **correlaci√≥n** mide la fuerza y direcci√≥n de la relaci√≥n lineal entre dos variables.

**Coeficiente de correlaci√≥n de Pearson:**
$$r = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum (x_i - \bar{x})^2} \sqrt{\sum (y_i - \bar{y})^2}}$$

- $-1 \leq r \leq 1$
- $r = 1$: Correlaci√≥n positiva perfecta
- $r = 0$: Sin correlaci√≥n lineal
- $r = -1$: Correlaci√≥n negativa perfecta

Para ilustrar el uso de la correlaci√≥n, consideremos la relaci√≥n entre desarrollo econ√≥mico y democracia, un tema cl√°sico en ciencia pol√≠tica. Analizamos datos de PIB per c√°pita y nivel de democracia en una muestra de pa√≠ses:

```{r correlacion-ejemplo, echo=TRUE}
# Datos simulados: PIB per c√°pita y nivel de democracia
set.seed(2024)
n <- 50
pib <- rnorm(n, mean = 15000, sd = 8000)
democracia <- 3 + 0.0003 * pib + rnorm(n, mean = 0, sd = 1.5)

# Correlaci√≥n de Pearson
cor_pearson <- cor(pib, democracia)
cat("Correlaci√≥n de Pearson:", round(cor_pearson, 3), "\n")

# Test de significancia
cor.test(pib, democracia)
```

Es fundamental recordar que una correlaci√≥n fuerte **NO implica que una variable cause la otra**. Pueden existir variables confusoras, causalidad inversa, o relaciones espurias.[^corr-causal]

[^corr-causal]: Correlaci√≥n no implica causalidad. Por ejemplo, ventas de helado y ahogamientos correlacionan, pero ambas son causadas por una tercera variable (temperatura). Establecer causalidad requiere teor√≠a, dise√±os apropiados y control de confusores.

### El modelo de regresi√≥n

La regresi√≥n lineal modela la relaci√≥n entre una variable dependiente $Y$ y una variable independiente $X$:

$$Y_i = \beta_0 + \beta_1 X_i + \epsilon_i$$

donde:
- $\beta_0$ = intercepto (valor de $Y$ cuando $X = 0$)
- $\beta_1$ = pendiente (cambio en $Y$ por unidad de cambio en $X$)
- $\epsilon_i$ = error (variaci√≥n no explicada por el modelo)

### M√≠nimos cuadrados ordinarios

El m√©todo de **m√≠nimos cuadrados ordinarios** (OLS, *Ordinary Least Squares*) estima $\beta_0$ y $\beta_1$ minimizando la suma de errores al cuadrado:

$$\min_{\beta_0, \beta_1} \sum_{i=1}^n (Y_i - \hat{Y}_i)^2$$

::: {.callout-note .callout-avanzado collapse="true"}
## üéì M√©todos Cuantitativos Avanzados

**F√≥rmulas OLS:**

$$\hat{\beta}_1 = \frac{\sum (X_i - \bar{X})(Y_i - \bar{Y})}{\sum (X_i - \bar{X})^2} = r \cdot \frac{s_Y}{s_X}$$

$$\hat{\beta}_0 = \bar{Y} - \hat{\beta}_1 \bar{X}$$
:::

Ilustremos la estimaci√≥n OLS con un ejemplo de econom√≠a pol√≠tica: la relaci√≥n entre gasto p√∫blico y crecimiento econ√≥mico.

```{r regresion-ejemplo, echo=TRUE}
# Datos simulados: Gasto p√∫blico y crecimiento econ√≥mico
set.seed(456)
gasto_publico <- runif(40, min = 15, max = 40)  # % del PIB
crecimiento <- 5 - 0.15 * gasto_publico + rnorm(40, mean = 0, sd = 1.2)

# Modelo de regresi√≥n lineal simple
modelo <- lm(crecimiento ~ gasto_publico)
summary(modelo)
```

```{r plot-regresion, echo=FALSE, fig.cap="Regresi√≥n lineal: Gasto p√∫blico y crecimiento"}
library(ggplot2)

datos <- data.frame(gasto_publico, crecimiento)

ggplot(datos, aes(x = gasto_publico, y = crecimiento)) +
  geom_point(size = 3, alpha = 0.6, color = "#3498db") +
  geom_smooth(method = "lm", se = TRUE, color = "#e74c3c", fill = "#e74c3c", alpha = 0.2) +
  labs(
    title = "Relaci√≥n entre gasto p√∫blico y crecimiento econ√≥mico",
    x = "Gasto p√∫blico (% del PIB)",
    y = "Crecimiento econ√≥mico (%)"
  ) +
  theme_minimal()
```

## Interpretaci√≥n y ajuste

**Intercepto ($\hat{\beta}_0$)**: Valor predicho de $Y$ cuando $X = 0$

**Pendiente ($\hat{\beta}_1$)**: Cambio promedio en $Y$ asociado con un incremento de una unidad en $X$

En el modelo anterior, si obtuvi√©ramos $\hat{\beta}_1 = -0.15$, interpretar√≠amos: "Por cada punto porcentual adicional de gasto p√∫blico, el crecimiento econ√≥mico disminuye en promedio 0.15 puntos porcentuales."[^interp-coef]

[^interp-coef]: El coeficiente indica asociaci√≥n, no necesariamente causalidad. La unidad de medida importa: siempre especifica las unidades y evita lenguaje causal a menos que el dise√±o lo justifique.

### Bondad de ajuste

### R cuadrado ($R^2$)

El **coeficiente de determinaci√≥n** mide qu√© proporci√≥n de la variabilidad en $Y$ es explicada por $X$:

::: {.callout-note .callout-avanzado collapse="true"}
## üéì M√©todos Cuantitativos Avanzados

$$R^2 = 1 - \frac{\sum (Y_i - \hat{Y}_i)^2}{\sum (Y_i - \bar{Y})^2}$$
:::

- $0 \leq R^2 \leq 1$
- $R^2 = 0$: El modelo no explica nada
- $R^2 = 1$: El modelo explica perfectamente

Por ejemplo, si $R^2 = 0.42$, interpretamos: "El 42% de la variabilidad en el crecimiento econ√≥mico es explicada por el gasto p√∫blico. El 58% restante se debe a otros factores."

Es crucial entender que un $R^2$ alto **NO implica relaci√≥n causal**. Puede haber variables omitidas importantes, relaciones espurias, o causalidad inversa.[^r2-advertencia]

[^r2-advertencia]: Un modelo puede tener $R^2$ alto y ser inv√°lido para inferencia causal si omite confusores. En ciencias sociales, valores bajos de $R^2$ (0.10-0.30) son frecuentes y no indican un modelo "malo".

## Resumen {.unnumbered}

| Concepto | Descripci√≥n | Funci√≥n en R |
|----------|-------------|--------------|
| **Correlaci√≥n** | Fuerza y direcci√≥n de relaci√≥n lineal (-1 a 1) | `cor(x, y)` |
| **Regresi√≥n** | Modela $Y = \beta_0 + \beta_1 X + \epsilon$ | `lm(y ~ x)` |
| **Intercepto** ($\beta_0$) | Valor de $Y$ cuando $X = 0$ | `coef(modelo)[1]` |
| **Pendiente** ($\beta_1$) | Cambio en $Y$ por unidad de $X$ | `coef(modelo)[2]` |
| **$R^2$** | Proporci√≥n de variabilidad explicada | `summary(modelo)$r.squared` |

::: {.callout-important}
## Correlaci√≥n ‚â† Causalidad
Un $R^2$ alto NO implica relaci√≥n causal. Siempre pueden existir confusores omitidos.
:::

## Lecturas recomendadas {.unnumbered}

**Fundamentos de regresi√≥n lineal:**

Agresti, A., & Finlay, B. (2009). *Statistical Methods for the Social Sciences* (4th ed.). Pearson.  
‚Üí Cap√≠tulo 9 ofrece introducci√≥n clara y accesible a regresi√≥n lineal y correlaci√≥n con ejemplos de ciencias sociales.

**Predicci√≥n y modelos lineales:**

Llaudet, E., & Imai, K. (2022). *Data Analysis for Social Science: A Friendly and Practical Introduction*. Princeton University Press.  
‚Üí Cap√≠tulo 4 sobre predicci√≥n conecta regresi√≥n con aplicaciones pr√°cticas en an√°lisis de datos sociales.

**Tratamiento m√°s t√©cnico:**

Wooldridge, J. M. (2020). *Introductory Econometrics: A Modern Approach* (7th ed.). Cengage Learning.  
‚Üí Cap√≠tulos 2-3 cubren regresi√≥n simple con mayor rigor t√©cnico y √©nfasis en interpretaci√≥n causal.


## Ejercicios {.unnumbered}

::: {.ejercicios}

**1. Correlaci√≥n**

Con estos datos de desarrollo y democracia:

```{r eval=FALSE}
set.seed(111)
pib_pc <- runif(40, 5000, 40000)
democracia <- 2 + 0.0001 * pib_pc + rnorm(40, 0, 1.5)
```

a) Calcula la correlaci√≥n de Pearson
b) Realiza la prueba de significancia
c) Crea un scatter plot con l√≠nea de tendencia
d) Interpreta: ¬øla relaci√≥n es fuerte, moderada o d√©bil?
e) ¬øQu√© limitaciones tiene la correlaci√≥n para establecer causalidad?

**2. Regresi√≥n simple**

Relaci√≥n entre gasto en campa√±a y votos obtenidos:

```{r eval=FALSE}
set.seed(222)
gasto <- runif(30, 100, 1000)  # miles de d√≥lares
votos <- 10 + 0.05 * gasto + rnorm(30, 0, 5)  # porcentaje
```

a) Estima el modelo de regresi√≥n
b) Interpreta el intercepto y la pendiente
c) ¬øEl coeficiente de gasto es estad√≠sticamente significativo?
d) ¬øQu√© porcentaje de votos predice el modelo para un candidato que gasta $500,000?
e) Calcula e interpreta $R^2$

**3. Interpretaci√≥n de coeficientes**

Un modelo estima: $\text{Participaci√≥n} = 35 + 0.4 \times \text{Educaci√≥n}$, donde Participaci√≥n es el porcentaje de votantes y Educaci√≥n es a√±os promedio de educaci√≥n.

a) Interpreta el intercepto
b) Interpreta la pendiente
c) ¬øTiene sentido el intercepto en este contexto? ¬øPor qu√©?
d) Predice participaci√≥n para una comuna con 12 a√±os de educaci√≥n promedio
e) ¬øQu√© sucede si la comuna tiene 8 a√±os de educaci√≥n promedio?

**4. Diagn√≥stico de modelo**

Con el modelo del ejercicio 2:

a) Calcula y grafica los residuos
b) ¬øLos residuos parecen distribuirse normalmente? (histograma o Q-Q plot)
c) Grafica residuos vs. valores ajustados. ¬øHay patrones preocupantes?
d) Identifica observaciones influyentes (si las hay)

**5. Comparaci√≥n de modelos**

Estima dos modelos para explicar confianza en instituciones:

```{r eval=FALSE}
set.seed(333)
n <- 100
edad <- sample(18:80, n, replace = TRUE)
educacion <- sample(1:20, n, replace = TRUE)
confianza <- 3 + 0.02 * edad + 0.15 * educacion + rnorm(n, 0, 1.5)

modelo1 <- lm(confianza ~ edad)
modelo2 <- lm(confianza ~ educacion)
```

a) Compara los $R^2$ de ambos modelos
b) ¬øCu√°l variable explica m√°s variabilidad?
c) ¬øLos coeficientes son significativos en ambos modelos?
d) Si tuvieras que elegir solo una variable predictora, ¬øcu√°l elegir√≠as?

**6. Proyecto de regresi√≥n**

Con datos de tu inter√©s:

a) Formula una hip√≥tesis sobre la relaci√≥n entre dos variables
b) Estima un modelo de regresi√≥n simple
c) Interpreta todos los componentes del output de `summary()`
d) Verifica supuestos b√°sicos
e) Crea un gr√°fico de dispersi√≥n con la l√≠nea de regresi√≥n
f) Escribe un p√°rrafo reportando los resultados
g) Discute las limitaciones de tu an√°lisis para establecer causalidad

:::

::: {#refs}
:::
