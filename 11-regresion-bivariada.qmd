# Regresi√≥n bivariada {#regresion-bivariada}

```{r setup-11, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(ggplot2)
```

## Objetivos del cap√≠tulo {.unnumbered}

Al finalizar este cap√≠tulo, ser√°s capaz de:

- Comprender qu√© es la correlaci√≥n y c√≥mo interpretarla
- Distinguir claramente entre correlaci√≥n y causalidad
- Estimar e interpretar un modelo de regresi√≥n lineal simple en R
- Leer e interpretar el output de `summary()` de un modelo de regresi√≥n
- Evaluar qu√© tan bien el modelo explica los datos usando $R^2$

## ¬øQu√© es la correlaci√≥n?

Cuando investigamos fen√≥menos sociales, frecuentemente queremos saber si dos variables est√°n relacionadas. Por ejemplo:

- ¬øLos pa√≠ses m√°s ricos tienden a ser m√°s democr√°ticos?
- ¬øLas comunas con mayor educaci√≥n tienen mayor participaci√≥n electoral?
- ¬øExiste relaci√≥n entre desigualdad econ√≥mica y criminalidad?

La **correlaci√≥n** nos permite responder estas preguntas midiendo qu√© tan fuerte es la relaci√≥n lineal entre dos variables. El **coeficiente de correlaci√≥n de Pearson** ($r$) es un n√∫mero que va de -1 a 1:

| Valor de $r$ | Interpretaci√≥n |
|:------------:|----------------|
| $r = 1$ | Correlaci√≥n positiva perfecta: cuando una sube, la otra siempre sube |
| $r = 0.7$ a $0.9$ | Correlaci√≥n positiva fuerte |
| $r = 0.4$ a $0.6$ | Correlaci√≥n positiva moderada |
| $r = 0.1$ a $0.3$ | Correlaci√≥n positiva d√©bil |
| $r = 0$ | Sin correlaci√≥n lineal |
| $r = -0.7$ a $-0.9$ | Correlaci√≥n negativa fuerte |
| $r = -1$ | Correlaci√≥n negativa perfecta |

::: {.callout-note .callout-avanzado collapse="true"}
## üéì M√©todos Cuantitativos Avanzados

**F√≥rmula del coeficiente de correlaci√≥n de Pearson:**

$$r = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum (x_i - \bar{x})^2} \sqrt{\sum (y_i - \bar{y})^2}}$$

Esta f√≥rmula mide la covarianza entre $X$ e $Y$ estandarizada por sus desviaciones est√°ndar, lo que produce un valor siempre entre -1 y 1.
:::

### Ejemplo: Desarrollo econ√≥mico y democracia

Una de las preguntas cl√°sicas en ciencia pol√≠tica es si los pa√≠ses m√°s ricos tienden a ser m√°s democr√°ticos. Analicemos datos de PIB per c√°pita y nivel de democracia en una muestra de pa√≠ses:

```{r correlacion-ejemplo, echo=TRUE}
# Datos simulados: PIB per c√°pita y nivel de democracia
set.seed(2024)
n <- 50
pib <- rnorm(n, mean = 15000, sd = 8000)
democracia <- 3 + 0.0003 * pib + rnorm(n, mean = 0, sd = 1.5)

# Calcular correlaci√≥n
cor(pib, democracia)
```

La correlaci√≥n de `r round(cor(pib, democracia), 2)` indica una relaci√≥n positiva moderada: los pa√≠ses con mayor PIB per c√°pita tienden a tener niveles m√°s altos de democracia, pero la relaci√≥n no es perfecta.

### ¬øEs la correlaci√≥n estad√≠sticamente significativa?

Para saber si la correlaci√≥n observada es "real" o podr√≠a deberse al azar, usamos una prueba de hip√≥tesis con `cor.test()`:

```{r cor-test, echo=TRUE}
cor.test(pib, democracia)
```

**¬øC√≥mo interpretar este resultado?**

1. **cor**: El coeficiente de correlaci√≥n (en este caso, positivo y moderado)
2. **t y df**: El estad√≠stico de prueba y grados de libertad (detalles t√©cnicos)
3. **p-value**: Si es menor a 0.05, la correlaci√≥n es estad√≠sticamente significativa
4. **95 percent confidence interval**: Rango plausible de la correlaci√≥n verdadera

En este ejemplo, como $p < 0.05$, concluimos que existe una correlaci√≥n estad√≠sticamente significativa entre PIB per c√°pita y democracia.

### Correlaci√≥n NO es causalidad

::: {.callout-important}
## El error m√°s com√∫n en investigaci√≥n

Una correlaci√≥n fuerte **NO significa que una variable cause la otra**. Pueden ocurrir tres cosas:

1. **Variable confusora**: Una tercera variable causa ambas. Ejemplo: ventas de helado y ahogamientos correlacionan, pero ambas son causadas por temperatura alta.

2. **Causalidad inversa**: Quiz√°s no es que la riqueza cause democracia, sino que la democracia facilita el desarrollo econ√≥mico.

3. **Relaci√≥n espuria**: La correlaci√≥n es pura coincidencia estad√≠stica.
:::

Para establecer causalidad necesitamos teor√≠a s√≥lida, dise√±os de investigaci√≥n apropiados (experimentos o cuasi-experimentos), y control de variables confusoras.

## ¬øQu√© es la regresi√≥n lineal?

Mientras la correlaci√≥n nos dice *si* existe relaci√≥n entre dos variables, la **regresi√≥n lineal** nos permite:

1. **Predecir** valores de una variable a partir de otra
2. **Cuantificar** cu√°nto cambia $Y$ cuando $X$ aumenta en una unidad
3. **Controlar** por otras variables (en regresi√≥n m√∫ltiple)

### La idea intuitiva

Imagina un gr√°fico de dispersi√≥n (scatter plot) con puntos que representan pa√≠ses: PIB en el eje X, democracia en el eje Y. La regresi√≥n lineal busca la **mejor l√≠nea recta** que pase "lo m√°s cerca posible" de todos los puntos.

Esta l√≠nea tiene la forma:

$$Y = \beta_0 + \beta_1 X$$

Donde:

- **$\beta_0$ (intercepto)**: El valor de $Y$ cuando $X = 0$. Es donde la l√≠nea cruza el eje vertical.
- **$\beta_1$ (pendiente)**: Cu√°nto aumenta (o disminuye) $Y$ por cada unidad que aumenta $X$. Es la "inclinaci√≥n" de la l√≠nea.

::: {.callout-tip}
## Analog√≠a √∫til

Piensa en la pendiente como una "tasa de cambio". Si $\beta_1 = 2$, significa que por cada unidad adicional de $X$, $Y$ aumenta en promedio 2 unidades. Si $\beta_1 = -0.5$, por cada unidad adicional de $X$, $Y$ disminuye en promedio 0.5 unidades.
:::

### Ejemplo: Gasto p√∫blico y crecimiento econ√≥mico

Analicemos la relaci√≥n entre gasto p√∫blico (como % del PIB) y crecimiento econ√≥mico en una muestra de pa√≠ses:

```{r regresion-ejemplo, echo=TRUE}
# Datos simulados
set.seed(456)
gasto_publico <- runif(40, min = 15, max = 40)  # % del PIB
crecimiento <- 5 - 0.15 * gasto_publico + rnorm(40, mean = 0, sd = 1.2)

# Crear data frame
datos <- data.frame(gasto_publico, crecimiento)

# Estimar modelo de regresi√≥n
modelo <- lm(crecimiento ~ gasto_publico, data = datos)
```

El comando `lm()` (linear model) estima la regresi√≥n. La sintaxis `crecimiento ~ gasto_publico` significa "crecimiento explicado por gasto_publico".

```{r plot-regresion, echo=TRUE, fig.cap="Regresi√≥n lineal: Gasto p√∫blico y crecimiento econ√≥mico"}
ggplot(datos, aes(x = gasto_publico, y = crecimiento)) +
  geom_point(size = 3, alpha = 0.6, color = "#3498db") +
  geom_smooth(method = "lm", se = TRUE, color = "#e74c3c", fill = "#e74c3c", alpha = 0.2) +
  labs(
    title = "Relaci√≥n entre gasto p√∫blico y crecimiento econ√≥mico",
    x = "Gasto p√∫blico (% del PIB)",
    y = "Crecimiento econ√≥mico (%)"
  ) +
  theme_minimal()
```

La l√≠nea roja es la **l√≠nea de regresi√≥n** estimada. El √°rea sombreada muestra el intervalo de confianza al 95%.

## C√≥mo leer el output de regresi√≥n en R

Veamos el resultado completo del modelo:

```{r summary-modelo, echo=TRUE}
summary(modelo)
```

Este output puede parecer intimidante, pero contiene toda la informaci√≥n importante. Vamos parte por parte:

### 1. Coeficientes (lo m√°s importante)

```
Coefficients:
              Estimate Std. Error t value Pr(>|t|)
(Intercept)    5.02       0.71     7.07    2e-08 ***
gasto_publico -0.15       0.03    -5.88    8e-07 ***
```

**Intercepto (5.02)**: El valor predicho de crecimiento cuando gasto p√∫blico = 0%. En este contexto no tiene interpretaci√≥n pr√°ctica (ning√∫n pa√≠s tiene 0% de gasto p√∫blico), pero es necesario para la ecuaci√≥n.

**Pendiente (-0.15)**: Por cada punto porcentual adicional de gasto p√∫blico, el crecimiento econ√≥mico disminuye en promedio 0.15 puntos porcentuales.

**Std. Error**: Mide la precisi√≥n de la estimaci√≥n. Valores m√°s peque√±os indican mayor precisi√≥n.

**t value y Pr(>|t|)**: La prueba de hip√≥tesis. Si Pr(>|t|) < 0.05, el coeficiente es estad√≠sticamente significativo (los asteriscos *** indican alta significancia).

### 2. R-cuadrado

```
Multiple R-squared:  0.4769
```

El **$R^2$ (R-cuadrado)** indica qu√© proporci√≥n de la variaci√≥n en $Y$ es explicada por $X$. En este caso, el gasto p√∫blico explica aproximadamente el 48% de la variaci√≥n en crecimiento econ√≥mico.

**¬øEs esto bueno o malo?** Depende del contexto:

| Contexto | $R^2$ t√≠pico |
|----------|--------------|
| Ciencias naturales (experimentos controlados) | 0.80 - 0.99 |
| Ciencias sociales (datos observacionales) | 0.10 - 0.40 |
| Predicci√≥n de comportamiento individual | 0.05 - 0.20 |

En ciencias sociales, un $R^2$ de 0.20 puede ser perfectamente aceptable porque el comportamiento humano es complejo y multicausal.

### 3. Significancia global del modelo

```
F-statistic: 34.55 on 1 and 38 DF,  p-value: 8.416e-07
```

Esta l√≠nea indica si el modelo en su conjunto es estad√≠sticamente significativo. Un p-value < 0.05 significa que el modelo explica m√°s variaci√≥n de la que esperar√≠amos por azar.

## Interpretaci√≥n de coeficientes

La interpretaci√≥n correcta de los coeficientes es crucial. Siempre debemos incluir:

1. **La direcci√≥n** del efecto (positivo o negativo)
2. **La magnitud** del efecto (el valor del coeficiente)
3. **Las unidades** de las variables
4. **La incertidumbre** (significancia estad√≠stica)

::: {.callout-tip}
## Plantilla para interpretar coeficientes

"Por cada [unidad] adicional de [variable X], [variable Y] [aumenta/disminuye] en promedio [coeficiente] [unidades de Y], y este efecto es [significativo/no significativo] estad√≠sticamente (p = [valor])."

**Ejemplo**: "Por cada punto porcentual adicional de gasto p√∫blico, el crecimiento econ√≥mico disminuye en promedio 0.15 puntos porcentuales, y este efecto es estad√≠sticamente significativo (p < 0.001)."
:::

### El intercepto: ¬øcu√°ndo tiene sentido?

El intercepto ($\beta_0$) representa el valor de $Y$ cuando $X = 0$. A veces esto tiene sentido (ej: "satisfacci√≥n cuando ingreso = 0"), pero frecuentemente $X = 0$ est√° fuera del rango de los datos o no tiene sentido (ej: "democracia cuando PIB per c√°pita = 0").

::: {.callout-warning}
## Cuidado con la extrapolaci√≥n

La regresi√≥n es confiable solo dentro del rango de datos observados. Predecir fuera de ese rango (extrapolaci√≥n) puede dar resultados absurdos.
:::

## Predicci√≥n con regresi√≥n

Una vez estimado el modelo, podemos predecir valores de $Y$ para nuevos valores de $X$:

```{r prediccion, echo=TRUE}
# Predecir crecimiento para pa√≠ses con 20%, 30% y 40% de gasto p√∫blico
nuevos_datos <- data.frame(gasto_publico = c(20, 30, 40))
predict(modelo, newdata = nuevos_datos)
```

Interpretaci√≥n: Seg√∫n el modelo, un pa√≠s con 30% de gasto p√∫blico tendr√≠a un crecimiento econ√≥mico predicho de aproximadamente `r round(predict(modelo, newdata = data.frame(gasto_publico = 30)), 1)`%.

::: {.callout-note .callout-avanzado collapse="true"}
## üéì M√©todos Cuantitativos Avanzados

**M√≠nimos cuadrados ordinarios (OLS)**

El m√©todo OLS encuentra la l√≠nea que minimiza la suma de los errores al cuadrado:

$$\min_{\beta_0, \beta_1} \sum_{i=1}^n (Y_i - \hat{Y}_i)^2$$

Las f√≥rmulas cerradas para los estimadores son:

$$\hat{\beta}_1 = \frac{\sum (X_i - \bar{X})(Y_i - \bar{Y})}{\sum (X_i - \bar{X})^2} = r \cdot \frac{s_Y}{s_X}$$

$$\hat{\beta}_0 = \bar{Y} - \hat{\beta}_1 \bar{X}$$

Nota que $\hat{\beta}_1$ est√° directamente relacionado con la correlaci√≥n $r$.

**F√≥rmula del $R^2$:**

$$R^2 = 1 - \frac{\sum (Y_i - \hat{Y}_i)^2}{\sum (Y_i - \bar{Y})^2} = \frac{\text{Variaci√≥n explicada}}{\text{Variaci√≥n total}}$$
:::

## Limitaciones importantes

### Correlaci√≥n sigue sin ser causalidad

Aunque la regresi√≥n nos da coeficientes precisos, sigue siendo un an√°lisis de **asociaci√≥n**. El coeficiente $\beta_1 = -0.15$ NO significa que "aumentar el gasto p√∫blico cause menor crecimiento". Puede haber:

- **Variables omitidas**: Quiz√°s pa√≠ses con problemas econ√≥micos aumentan el gasto (causalidad inversa)
- **Confusores**: Quiz√°s otra variable (ej: calidad institucional) afecta ambas

Para hacer afirmaciones causales, necesitamos dise√±os de investigaci√≥n apropiados (experimentos, diferencias en diferencias, variables instrumentales, etc.).

### Linealidad

La regresi√≥n lineal asume que la relaci√≥n entre $X$ e $Y$ es una l√≠nea recta. Si la relaci√≥n verdadera es curva, el modelo ser√° inadecuado.

### Outliers

Observaciones extremas pueden distorsionar fuertemente la l√≠nea de regresi√≥n. Siempre visualiza tus datos antes de interpretar resultados.

## Resumen {.unnumbered}

| Concepto | Qu√© significa | En R |
|----------|---------------|------|
| **Correlaci√≥n** | Fuerza de relaci√≥n lineal (-1 a 1) | `cor(x, y)` |
| **Regresi√≥n** | Ecuaci√≥n que predice $Y$ a partir de $X$ | `lm(y ~ x)` |
| **Intercepto** | Valor de $Y$ cuando $X = 0$ | `coef(modelo)[1]` |
| **Pendiente** | Cambio en $Y$ por cada unidad de $X$ | `coef(modelo)[2]` |
| **$R^2$** | % de variaci√≥n explicada | `summary(modelo)$r.squared` |
| **p-value** | Significancia del coeficiente | Ver `summary(modelo)` |

::: {.callout-important}
## Mensaje clave del cap√≠tulo

La regresi√≥n es una herramienta poderosa para describir relaciones y hacer predicciones, pero **correlaci√≥n y regresi√≥n no demuestran causalidad**. Para hacer afirmaciones causales necesitas teor√≠a s√≥lida, dise√±o de investigaci√≥n apropiado, y control de confusores.
:::

## Lecturas recomendadas {.unnumbered}

**Fundamentos de regresi√≥n lineal:**

Agresti, A., & Finlay, B. (2009). *Statistical Methods for the Social Sciences* (4th ed.). Pearson.
‚Üí Cap√≠tulo 9 ofrece introducci√≥n clara y accesible a regresi√≥n lineal y correlaci√≥n con ejemplos de ciencias sociales.

**Predicci√≥n y modelos lineales:**

Llaudet, E., & Imai, K. (2022). *Data Analysis for Social Science: A Friendly and Practical Introduction*. Princeton University Press.
‚Üí Cap√≠tulo 4 sobre predicci√≥n conecta regresi√≥n con aplicaciones pr√°cticas en an√°lisis de datos sociales.

**Tratamiento m√°s t√©cnico:**

Wooldridge, J. M. (2020). *Introductory Econometrics: A Modern Approach* (7th ed.). Cengage Learning.
‚Üí Cap√≠tulos 2-3 cubren regresi√≥n simple con mayor rigor t√©cnico y √©nfasis en interpretaci√≥n causal.


## Ejercicios {.unnumbered}

::: {.ejercicios}

**1. Correlaci√≥n e interpretaci√≥n**

Con estos datos de desarrollo y democracia:

```{r eval=FALSE}
set.seed(111)
pib_pc <- runif(40, 5000, 40000)
democracia <- 2 + 0.0001 * pib_pc + rnorm(40, 0, 1.5)
```

a) Calcula la correlaci√≥n de Pearson
b) Realiza la prueba de significancia con `cor.test()`
c) Crea un scatter plot con l√≠nea de tendencia
d) Interpreta: ¬øla relaci√≥n es fuerte, moderada o d√©bil?
e) ¬øPor qu√© no podemos concluir que "el PIB causa democracia" solo con esta correlaci√≥n?

**2. Regresi√≥n e interpretaci√≥n de output**

Relaci√≥n entre gasto en campa√±a y votos obtenidos:

```{r eval=FALSE}
set.seed(222)
gasto <- runif(30, 100, 1000)  # miles de d√≥lares
votos <- 10 + 0.05 * gasto + rnorm(30, 0, 5)  # porcentaje
```

a) Estima el modelo de regresi√≥n con `lm()`
b) Usa `summary()` e identifica: el intercepto, la pendiente, el $R^2$, y el p-value de la pendiente
c) Escribe una oraci√≥n interpretando la pendiente (incluye unidades)
d) ¬øQu√© porcentaje de votos predice el modelo para un candidato que gasta $500,000?
e) ¬øTiene sentido el intercepto en este contexto? ¬øPor qu√©?

**3. Interpretaci√≥n de coeficientes**

Un investigador estima el modelo: Participaci√≥n = 35 + 0.4 √ó Educaci√≥n, donde Participaci√≥n es el porcentaje de votantes y Educaci√≥n es a√±os promedio de educaci√≥n.

a) Interpreta el intercepto: ¬øqu√© significa el valor 35?
b) Interpreta la pendiente: ¬øqu√© significa el valor 0.4?
c) Predice la participaci√≥n para una comuna con 12 a√±os de educaci√≥n promedio
d) ¬øSer√≠a apropiado usar este modelo para predecir participaci√≥n en una comuna con 3 a√±os de educaci√≥n promedio? ¬øPor qu√©?

**4. Visualizaci√≥n y diagn√≥stico**

Con los datos del ejercicio 2:

a) Crea un scatter plot con la l√≠nea de regresi√≥n usando `geom_smooth(method = "lm")`
b) ¬øLos puntos parecen seguir una relaci√≥n lineal?
c) ¬øHay alg√∫n punto que parezca muy alejado de los dem√°s (outlier)?
d) Si hubiera outliers, ¬øc√≥mo afectar√≠an la l√≠nea de regresi√≥n?

**5. Comparaci√≥n de modelos**

Estima dos modelos para explicar confianza en instituciones:

```{r eval=FALSE}
set.seed(333)
n <- 100
edad <- sample(18:80, n, replace = TRUE)
educacion <- sample(1:20, n, replace = TRUE)
confianza <- 3 + 0.02 * edad + 0.15 * educacion + rnorm(n, 0, 1.5)

modelo1 <- lm(confianza ~ edad)
modelo2 <- lm(confianza ~ educacion)
```

a) Compara los $R^2$ de ambos modelos
b) ¬øCu√°l variable explica m√°s variabilidad en la confianza?
c) ¬øLos coeficientes son significativos en ambos modelos?
d) Si tuvieras que elegir solo una variable predictora, ¬øcu√°l elegir√≠as y por qu√©?

**6. Aplicaci√≥n a datos reales**

Busca datos de tu inter√©s (pueden ser de CASEN, CEP, o cualquier fuente) con dos variables num√©ricas:

a) Formula una hip√≥tesis sobre la relaci√≥n entre las dos variables
b) Calcula la correlaci√≥n e interpr√©tala
c) Estima un modelo de regresi√≥n simple
d) Interpreta el coeficiente de la pendiente con unidades
e) ¬øQu√© porcentaje de la variaci√≥n explica el modelo?
f) Escribe un p√°rrafo reportando los resultados como aparecer√≠a en un informe
g) Discute: ¬øpuedes hacer afirmaciones causales? ¬øPor qu√© s√≠ o por qu√© no?

:::

::: {#refs}
:::
