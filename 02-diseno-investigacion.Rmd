# Diseño de investigación {#diseno}

## Objetivos del capítulo

Al finalizar este capítulo, serás capaz de:

- Formular preguntas de investigación empíricamente respondibles
- Distinguir entre hipótesis descriptivas, relacionales y causales
- Comprender el marco contrafactual de causalidad
- Identificar fortalezas y debilidades de diseños experimentales y observacionales
- Evaluar validez interna y externa de diseños de investigación

## Preguntas de investigación

Toda investigación comienza con una pregunta, pero no cualquier pregunta es una **pregunta de investigación** útil.<span class="sidenote">Una pregunta de investigación no es lo mismo que una pregunta de tesis o un objetivo general. La pregunta de investigación debe ser empíricamente respondible mediante datos observables, mientras que las preguntas normativas ("¿Debería Chile tener un sistema parlamentario?") pertenecen a la filosofía política, no a la investigación empírica.</span> Las buenas preguntas tienen tres características: **especificidad** (delimitan claramente qué queremos saber; ej: "¿En qué medida la descentralización fiscal incrementa la corrupción municipal en Chile durante 2000-2020?" es mejor que "¿Por qué hay corrupción en América Latina?"), **respuesta empírica** (deben poder responderse mediante observación sistemática del mundo; preguntas normativas sobre qué *debería ser* no son preguntas de investigación empírica, aunque pueden motivarla), y **relevancia teórica o sustantiva** (contribuyen a debates teóricos, llenan vacíos en conocimiento descriptivo, o informan decisiones prácticas [@king1994]).

Las preguntas se clasifican según su propósito: **preguntas descriptivas** caracterizan fenómenos ("¿Cuál es la tasa de participación electoral en Chile 2021?"), **preguntas relacionales** identifican asociaciones entre variables ("¿Se relaciona el nivel educativo con la participación electoral?"), y **preguntas causales** buscan establecer relaciones de causa-efecto ("¿La inscripción automática aumenta la participación electoral?"). La distinción importa porque cada tipo exige estrategias metodológicas distintas: responder preguntas descriptivas requiere medición cuidadosa y muestreo representativo; responder preguntas causales requiere, además, estrategias para descartar explicaciones alternativas.

## Hipótesis y teoría

Una vez formulada la pregunta, necesitamos una respuesta tentativa —una **hipótesis**: afirmación específica, derivada de teoría, sobre relaciones esperadas entre variables que debe ser **falsable**<span class="sidenote">El criterio de falsabilidad de Popper establece que una hipótesis científica debe poder ser refutada mediante evidencia empírica. "Los partidos de izquierda son mejores" NO es falsable (¿mejores en qué sentido?). "Los partidos de izquierda gastan más en políticas sociales" SÍ es falsable mediante datos observables de gasto público.</span> [@popper1959]. Por ejemplo: "A mayor magnitud de distrito electoral, mayor fragmentación partidaria en el parlamento" es específica, falsable, y se deriva de la teoría de Duverger sobre efectos de sistemas electorales.

Las hipótesis provienen de teorías sobre cómo funciona el mundo social mediante un proceso deductivo: **Teoría** → **Mecanismo causal** → **Implicación observable** → **Hipótesis**. Por ejemplo: la teoría de que los sistemas electorales proporcionales reducen barreras de entrada para partidos pequeños [@lijphart1994] implica que en distritos grandes, partidos pequeños pueden obtener escaños con porcentajes bajos de votos, incentivando su formación, por lo que deberíamos observar más partidos en parlamentos elegidos con distritos grandes, generando la hipótesis testeable "a mayor magnitud promedio de distrito, mayor número efectivo de partidos parlamentarios". Este encadenamiento lógico es crucial: cuando testeamos hipótesis, estamos evaluando indirectamente la teoría subyacente.

En estadística inferencial (Capítulo \@ref(hipotesis)), formalizamos dos tipos de hipótesis: la **hipótesis nula (H₀)** que afirma ausencia de relación o efecto ("No hay diferencia en participación electoral entre hombres y mujeres"), y la **hipótesis alternativa (H₁)**<span class="sidenote">CONFUSIÓN COMÚN: Los estudiantes piensan que H₀ es "la hipótesis que queremos refutar" y H₁ "la que queremos probar". INCORRECTO. H₀ es simplemente el escenario de referencia (status quo, no hay efecto). H₁ es lo que los datos nos permiten considerar SI rechazamos H₀. No "probamos" H₁; solo rechazamos o fallamos en rechazar H₀. Esta lógica asimétrica es fundamental para entender tests de hipótesis en el Capítulo 9.</span> que afirma existencia de relación o efecto ("Las mujeres participan más/menos que los hombres"). El procedimiento estadístico evalúa si los datos son suficientemente inconsistentes con H₀ como para rechazarla en favor de H₁.

## Causalidad

El objetivo de mucha investigación cuantitativa es establecer **relaciones causales**. Queremos saber no solo si X e Y covarían, sino si cambios en X *producen* cambios en Y.

::: {.nivel data-nivel="avanzado"}

### El problema fundamental de inferencia causal

@holland1986 formuló el **problema fundamental de inferencia causal**: nunca observamos el mismo caso bajo tratamiento y control simultáneamente. Si una persona votó en una elección con inscripción automática, nunca sabremos si habría votado sin inscripción automática. Ese **resultado contrafactual** es fundamentalmente inobservable.<span class="sidenote">EJEMPLO POLÍTICO CHILENO: En octubre 2019, el presidente Piñera declaró estado de emergencia. ¿Redujo o aumentó las protestas? Para saberlo causalmente, necesitaríamos observar QUÉ HABRÍA PASADO en el Chile de octubre 2019 SIN estado de emergencia. Pero ese Chile no existe—es contrafactual. Solo observamos lo que pasó CON estado de emergencia. Toda inferencia causal enfrenta este problema fundamental. Los métodos cuantitativos intentan aproximar el contrafactual mediante comparaciones (grupos control, diferencias-en-diferencias, etc.).</span>

Formalizando: Para el caso $i$, definimos:

- $Y_i(1)$: resultado si recibe tratamiento
- $Y_i(0)$: resultado si no recibe tratamiento
- **Efecto causal individual**: $\tau_i = Y_i(1) - Y_i(0)$

El problema: observamos $Y_i(1)$ *o* $Y_i(0)$, nunca ambos. Uno siempre es contrafactual.

### Marco de resultados potenciales

@rubin1974 propuso que, aunque no podemos estimar efectos individuales, podemos estimar **efectos causales promedio** bajo ciertas condiciones. El **efecto causal promedio del tratamiento** (ATE) es:

$$ATE = E[Y_i(1) - Y_i(0)] = E[Y_i(1)] - E[Y_i(0)]$$

Pero seguimos sin observar ambos resultados potenciales para cada caso. La solución: usar *grupos*. Comparamos unidades tratadas con unidades no tratadas. La inferencia causal depende de que estos grupos sean **comparables** en expectativa.

### Condiciones para inferencia causal

Para que la comparación entre tratados y no tratados nos informe sobre el efecto causal, necesitamos:

**1. Independencia condicional**

El tratamiento debe asignarse independientemente de los resultados potenciales (condicional en covariables observadas). En experimentos aleatorios, esto se cumple por construcción. En estudios observacionales, debemos argumentarlo o modelarlo.

**2. Exclusión**

El tratamiento debe afectar el resultado solo a través del mecanismo teórico propuesto, no por otras vías.

**3. SUTVA** (Stable Unit Treatment Value Assumption)<span class="sidenote">VIOLACIÓN DE SUTVA EN CONTEXTO REAL: Imagina un experimento donde asignamos aleatoriamente a algunas personas recibir mensajes pro-vacunación COVID. Si los tratados convencen a sus familiares (no tratados) de vacunarse, el resultado de los no-tratados DEPENDE del tratamiento de otros. SUTVA se viola. Esto es común en intervenciones sociales con efectos de contagio, difusión o spillover. Violar SUTVA sesga estimaciones de efectos causales, generalmente subestimándolos.</span>

El resultado de cada unidad no debe depender del tratamiento de otras unidades. Si mi vecino vota (tratamiento), mi propia probabilidad de votar (resultado) no debería cambiar. Esta suposición se viola frecuentemente —un problema serio en ciencias sociales.

Estas condiciones raramente se cumplen perfectamente en datos observacionales. Gran parte de la metodología cuantitativa consiste en estrategias para aproximarse a inferencia causal válida cuando las condiciones ideales no se cumplen.

:::

## Tipos de diseños

Los diseños de investigación varían según cuánto control tenemos sobre la asignación del tratamiento y la recolección de datos.

### Diseños experimentales

En un **experimento**, el investigador asigna aleatoriamente el tratamiento. Esto garantiza que, en expectativa, grupos tratados y control son idénticos excepto por el tratamiento. Cualquier diferencia sistemática en resultados es atribuible al efecto causal del tratamiento.

**Ejemplo**: @gerber2008 realizaron experimentos de campo sobre movilización electoral en Estados Unidos. Asignaron aleatoriamente hogares a recibir llamadas telefónicas, visitas puerta a puerta, o ningún contacto (control). Compararon tasas de participación electoral entre grupos.

**Ventajas**:
- Identificación causal clara
- No requiere supuestos sobre confusores
- Alta validez interna

**Limitaciones**:
- Muchas preguntas políticas no permiten experimentación (no podemos asignar aleatoriamente tipo de régimen político)<span class="sidenote">LÍMITE ÉTICO OBVIO: No podemos experimentalmente asignar a países "democracia" vs "dictadura" para medir efectos sobre desarrollo económico. Tampoco podemos asignar aleatoriamente "corrupción gubernamental" para estudiar efectos sobre confianza ciudadana. Estos límites éticos y prácticos obligan a usar datos observacionales con estrategias cuasi-experimentales o de control estadístico (regresión múltiple, matching, etc.).</span>
- Posibles problemas éticos
- Efectos pueden ser específicos al contexto experimental (baja validez externa)
- En ciencia política, solo ciertas preguntas son experimentables

::: {.nivel data-nivel="avanzado"}

### Diseños cuasi-experimentales

Los diseños cuasi-experimentales explotan variación *como si* fuera aleatoria, aunque no provenga de asignación experimental.

**Regresión discontinua (RD)**

Cuando el tratamiento se asigna según un umbral en una variable continua, podemos comparar casos justo arriba y debajo del umbral —que son casi idénticos excepto en recepción del tratamiento.

**Ejemplo**: @eggers2015 estudian efectos de ganar una elección sobre riqueza personal de candidatos en UK. Comparan candidatos que ganaron por margen muy estrecho con quienes perdieron por margen muy estrecho. El supuesto: ganar vs. perder por 0.1% de votos es prácticamente aleatorio.

**Diferencias-en-diferencias (DiD)**

Compara cambios antes/después de un tratamiento entre grupo tratado y grupo control. Requiere supuesto de **tendencias paralelas**: sin tratamiento, ambos grupos habrían evolucionado de forma similar.

**Ejemplo**: @melendez2021 estudian efecto de una reforma tributaria en Colombia comparando municipios afectados vs. no afectados, antes y después de la reforma.

**Variables instrumentales (IV)**

Usa una variable (instrumento) que afecta el tratamiento pero no el resultado directamente. Permite estimar efecto causal incluso cuando tratamiento está confundido.

**Ejemplo**: @acemoglu2001 usan mortalidad de colonos europeos en colonias históricas como instrumento para instituciones actuales, argumentando que afecta instituciones pero no desarrollo económico contemporáneo directamente.

:::

### Diseños observacionales

La mayoría de investigación en ciencias políticas usa **datos observacionales** —datos donde el investigador no controla la asignación del tratamiento. Aquí, inferencia causal es más problemática.

**Estudios de corte transversal**

Observan muchos casos en un punto temporal. Útiles para descripción y exploración de asociaciones, pero problemáticos para causalidad por confusores no observados.

**Ejemplo**: Analizar si democracias tienen menor desigualdad que autocracias usando datos de 150 países en 2020. El problema: democracia no es aleatoria —correlaciona con desarrollo económico, historia colonial, estructura social, etc.

**Series de tiempo**

Observan un caso (o pocos casos) en múltiples momentos. Permiten explotar variación temporal, pero requieren supuestos sobre qué cambió y qué permaneció constante.

**Ejemplo**: Estudiar efecto de una reforma electoral en Chile analizando fragmentación partidaria antes y después. El problema: otros factores también cambiaron simultáneamente.

**Panel (longitudinal)**

Combinan ventajas de corte transversal (muchos casos) y series de tiempo (variación temporal). Permiten controlar características fijas no observadas de unidades usando **efectos fijos**.

**Ejemplo**: @flores2019 usan datos de panel de municipios mexicanos para estudiar efecto de presencia militar sobre violencia del crimen organizado, controlando características permanentes de municipios.

**Estrategias para fortalecer inferencia causal en diseños observacionales**:

1. **Controles estadísticos**: Incluir covariables que eliminan confusión. Problema: solo funciona para confusores *observados*.

2. **Matching**: Emparejar casos tratados con controles similares. Aproxima balance experimental, pero depende de calidad del emparejamiento.

3. **Diseño de investigación robusto**: Múltiples tests de robustez, placebo tests, análisis de sensibilidad.

4. **Triangulación**: Combinar múltiples fuentes de evidencia (cuantitativa + cualitativa).

## Validez interna y externa

Todo diseño de investigación enfrenta tensiones entre dos tipos de validez [@campbell1957]. **Validez interna** es el grado en que podemos confiar que el efecto estimado es genuinamente causal, no espurio (¿X realmente causa Y, o la asociación se debe a confusores?). Las amenazas incluyen **variables confusoras** (que afectan tanto el tratamiento como el resultado; ej: países con más carreteras son más ricos, pero ¿las carreteras causan riqueza o la riqueza permite construir carreteras?), **causalidad inversa** (Y puede causar X en vez de X causar Y; ej: @przeworski2000 argumentan que el desarrollo no causa transiciones democráticas, pero sí hace que las democracias sobrevivan), y **sesgo de selección** (la asignación al tratamiento no es aleatoria y se relaciona sistemáticamente con el resultado potencial; ej: comparar salarios de quienes asistieron a universidad vs. quienes no ignora que difieren en habilidad, motivación y recursos familiares). Estrategias para mejorar validez interna: aleatorización, diseños cuasi-experimentales rigurosos, controlar estadísticamente confusores observados, análisis de sensibilidad a confusores no observados.

**Validez externa** es el grado en que resultados generalizan más allá del contexto específico estudiado (¿los hallazgos aplican a otras poblaciones, contextos o tiempos?). Las amenazas incluyen **muestras no representativas** (estudiar estudiantes universitarios no permite generalizar a la población general), **especificidad contextual** (efectos varían sistemáticamente según contexto; un experimento de movilización electoral en Estados Unidos puede no tener el mismo efecto en Chile), **efectos de Hawthorne** (sujetos modifican comportamiento porque saben que están siendo estudiados), y **dependencia temporal** (relaciones causales cambian con el tiempo; teorías sobre comportamiento electoral en los 1960s pueden no aplicar en 2020).

Existe tensión fundamental: los diseños con mejor validez interna (experimentos de laboratorio) a menudo tienen peor validez externa; los diseños con muestras más representativas (encuestas nacionales) tienen peor validez interna. @shadish2002 argumentan que el objetivo no es maximizar una validez a costa de la otra, sino encontrar equilibrios apropiados según la pregunta de investigación: preguntas sobre mecanismos causales priorizan validez interna; preguntas sobre magnitud de efectos en poblaciones priorizan validez externa.

## Casos, unidades y niveles de análisis

Una decisión crucial en diseño de investigación es qué constituye un "caso" —la **unidad de análisis**: individuos (votantes, legisladores, activistas), agregados subnacionales (municipios, provincias, circunscripciones electorales), países (estados nacionales), eventos (elecciones, protestas, golpes de estado), legislación (leyes, políticas públicas), u organizaciones (partidos políticos, grupos de interés). La unidad de análisis determina qué variación podemos explotar y qué afirmaciones podemos hacer.

Debemos evitar dos falacias. **Falacia ecológica** [@robinson1950]: inferir relaciones a nivel individual desde asociaciones a nivel agregado (si comunas con más inmigrantes votan más por la derecha, ¿significa que inmigrantes votan derecha? No necesariamente; puede ser que nativos en comunas con inmigración voten derecha reactivamente, mientras inmigrantes votan izquierda). **Falacia atómica** (o "individualista"): inferir relaciones a nivel agregado desde patrones individuales (si individuos religiosos son más conservadores, ¿países más religiosos son más conservadores? No necesariamente; puede haber efectos contextuales que cambian relaciones).

La inferencia estadística requiere suficientes observaciones relativas al número de parámetros estimados. @king1994 enfatizan el problema de "muchas variables, pocas observaciones" (MVPO): si estudio 20 países con 15 variables explicativas, casi cualquier patrón puede ser ajustado sin suficientes **grados de libertad** para distinguir patrones genuinos de ruido. Soluciones: aumentar observaciones (datos de panel con múltiples países × múltiples años), reducir parámetros (selección teórica de variables, análisis factorial), o combinar enfoques (análisis cuantitativo de patrones generales + estudios de caso que elucidan mecanismos).

## Resumen del capítulo

El diseño de investigación es el plan para responder preguntas de investigación. Buenas preguntas son específicas, empíricamente respondibles, y relevantes teórica o prácticamente. Pueden ser descriptivas, relacionales o causales.

Las hipótesis son afirmaciones falsables derivadas de teoría sobre relaciones esperadas entre variables. Conectan teoría abstracta con implicaciones observables.

La inferencia causal enfrenta el problema fundamental: nunca observamos resultados contrafactuales. El marco de resultados potenciales formaliza este problema. Para inferir causalidad, necesitamos que grupos tratados y control sean comparables.

Los diseños experimentales garantizan comparabilidad mediante aleatorización, logrando alta validez interna. Los diseños cuasi-experimentales explotan situaciones "naturalmente" aleatorias. Los diseños observacionales dependen de supuestos más fuertes y técnicas estadísticas para aproximar inferencia causal.

Toda investigación enfrenta tensión entre validez interna (¿el efecto es causal?) y validez externa (¿generaliza?). No hay diseño perfecto; cada diseño implica compromisos.

La unidad de análisis determina qué variación explotamos y qué afirmaciones justificamos. Inferir relaciones en un nivel desde datos de otro nivel (falacias ecológicas/atómicas) es problemático.

## Lecturas recomendadas

**Fundamentos de diseño de investigación:**

Shadish, W. R., Cook, T. D., & Campbell, D. T. (2002). *Experimental and Quasi-Experimental Designs for Generalized Causal Inference*. Houghton Mifflin.  
→ Tratamiento comprehensivo de validez y diseños experimentales/cuasi-experimentales.

**Marco contrafactual de causalidad:**

Morgan, S. L., & Winship, C. (2015). *Counterfactuals and Causal Inference: Methods and Principles for Social Research* (2nd ed.). Cambridge University Press.  
→ Introducción accesible al marco de resultados potenciales y métodos de inferencia causal.

**Diseños observacionales en ciencia política:**

Angrist, J. D., & Pischke, J.-S. (2009). *Mostly Harmless Econometrics: An Empiricist's Companion*. Princeton University Press.  
→ Enfoque práctico sobre identificación causal en datos observacionales.

**Sobre validez de medición:**

Adcock, R., & Collier, D. (2001). Measurement validity: A shared standard for qualitative and quantitative research. *American Political Science Review*, 95(3), 529-546.  
→ Discusión conceptual sobre operacionalización y validez.

**Experimentos de campo en ciencia política:**

Gerber, A. S., & Green, D. P. (2012). *Field Experiments: Design, Analysis, and Interpretation*. W.W. Norton.  
→ Guía práctica para diseñar y analizar experimentos de campo.

## Ejercicios

**1. Evaluar preguntas de investigación**

Para cada pregunta, identifica: (a) ¿Es específica? (b) ¿Es empíricamente respondible? (c) ¿Es descriptiva, relacional o causal? (d) ¿Cómo la mejorarías?

- "¿Por qué hay desigualdad?"
- "¿Los jóvenes participan menos en política?"
- "¿Debería Chile tener voto obligatorio?"
- "¿El voto obligatorio aumenta la participación electoral?"

**2. De teoría a hipótesis**

Teoría: Los sistemas presidenciales son más propensos a crisis democráticas que los parlamentarios porque generan competencia de suma cero entre ejecutivo y legislativo [@linz1990].

a) Identifica el mecanismo causal propuesto  
b) Deriva dos hipótesis testeables  
c) ¿Qué evidencia falsificaría cada hipótesis?  

**3. Identificar amenazas a validez interna**

Un estudio encuentra que municipios que implementaron presupuesto participativo tienen menor corrupción. El estudio compara municipios con presupuesto participativo vs. sin él, controlando por población, PIB per cápita y nivel educativo.

a) ¿Qué confusores no observados podrían explicar la asociación?  
b) ¿Podría haber causalidad inversa? ¿Cómo?  
c) Propón un diseño alternativo con mejor validez interna  

**4. Evaluar validez externa**

Un experimento en Suecia muestra que recibir información sobre uso de impuestos aumenta disposición a pagar impuestos. Los investigadores quieren saber si el resultado aplica a América Latina.

a) ¿Qué diferencias contextuales podrían hacer que el efecto varíe?  
b) ¿Cómo evaluarías si el resultado generaliza?  
c) ¿Qué diseño permitiría estudiar variación contextual del efecto?  

**5. Problema de investigación propio**

Selecciona un fenómeno político que te interese:

a) Formula una pregunta causal específica  
b) Propón una teoría que la responda y deriva hipótesis  
c) Describe un diseño observacional para testearla  
d) Identifica las principales amenazas a validez interna  
e) ¿Qué diseño cuasi-experimental podría mejorar la identificación causal?

**6. Análisis de artículo**

Lee un artículo cuantitativo de una revista de ciencia política. Identifica:

a) La pregunta de investigación y su tipo  
b) El diseño de investigación usado  
c) La unidad de análisis  
d) Dos fortalezas del diseño para validez interna  
e) Dos limitaciones para validez externa  
f) Una estrategia alternativa que los autores podrían haber usado
