# Trabajando con datos {#datos}

## Objetivos del capítulo {.unnumbered}

Al finalizar este capítulo, serás capaz de:

- Distinguir entre tipos de datos según estructura y fuente
- Evaluar calidad de datos y detectar problemas comunes
- Navegar el entorno de R y RStudio
- Importar datos desde múltiples formatos
- Realizar operaciones básicas de manipulación de datos en R
- Exportar resultados para análisis posterior o publicación

## Tipos y fuentes de datos

Los datos que usamos en ciencias políticas varían en estructura, granularidad y fuente. Entender estas diferencias es crucial para seleccionar estrategias analíticas apropiadas.

### Según estructura

| Tipo | Descripción | Ejemplo | Ventaja | Limitación |
|------|-------------|---------|---------|------------|
| **Corte transversal** | Múltiples unidades, un momento | Encuesta a 1,500 votantes en oct 2024 | Simplicidad analítica | No observa cambio temporal |
| **Series temporales** | Una unidad, múltiples momentos | Desempleo mensual Chile 2000-2024 | Captura dinámica temporal | Una unidad limita generalización |
| **Panel** | Múltiples unidades, múltiples momentos | 346 comunas en 8 elecciones | Controla efectos fijos | Complejidad analítica |
| **Jerárquico** | Unidades anidadas en niveles | Estudiantes en escuelas en comunas | Modela variación multinivel | Requiere técnicas avanzadas |

### Según granularidad

| Nivel | Unidad de observación | Ejemplos | Característica |
|-------|----------------------|----------|----------------|
| **Micro** | Individuo | Votante, legislador, manifestante | Permite analizar heterogeneidad individual |
| **Meso** | Agregado intermedio | Municipio, distrito, partido | Balance entre detalle y volumen |
| **Macro** | País/región | Estados nacionales | Comparación internacional, pero N pequeño |

::: {.callout-warning}
## Cuidado con la falacia ecológica
@king1997 advierten: inferir comportamiento individual desde patrones agregados puede ser erróneo si la composición de agregados varía.
:::

### Según fuente

| Fuente | Descripción | Ejemplos | Ventaja | Limitación |
|--------|-------------|----------|---------|------------|
| **Primarios** | Recolectados por el investigador | Encuestas propias, experimentos | Control total sobre medición | Costoso en tiempo y recursos |
| **Secundarios** | Recolectados por otros | Censos, encuestas públicas | Eficiencia, muestras grandes | No diseñados para tu pregunta |
| **Administrativos** | Generados por procesos burocráticos | Registros de votantes, datos tributarios | Cobertura completa, alta confiabilidad | Reflejan categorías burocráticas |
| **Digitales** | Generados por actividad en línea | Tweets, búsquedas Google | Volumen masivo, comportamiento real | Representatividad problemática |

### Principales fuentes de datos

Para ciencias sociales en Chile y América Latina, las fuentes más utilizadas incluyen:

- **Encuestas**: CEP, CASEN, Latinobarómetro, LAPOP
- **Datos electorales**: SERVEL (Chile), International IDEA
- **Datos económicos**: Banco Mundial, INE, CEPAL
- **Datos de instituciones**: V-Dem, Polity V

::: {.nivel data-nivel="avanzado"}
**Catálogo completo de fuentes de datos:**

**Encuestas de opinión pública internacionales:**
- World Values Survey: Actitudes y valores en ~100 países
- Latinobarómetro: 18 países latinoamericanos
- AmericasBarometer (LAPOP): Actitudes políticas en las Américas

**Datos sobre instituciones políticas:**
- Polity V: Características de regímenes políticos
- V-Dem: Variedades de democracia, múltiples dimensiones
- Database of Political Institutions (DPI): Sistemas electorales
- Comparative Constitutions Project: Contenido de constituciones

**Datos legislativos:**
- VoteView: Votaciones nominales del Congreso de EE.UU.
- Manifesto Project: Contenido de manifiestos partidarios
:::

### Calidad de datos

No todos los datos son igualmente útiles. Evaluar calidad es responsabilidad del investigador.

### Dimensiones de calidad

| Dimensión | Pregunta clave | Ejemplo de problema |
|-----------|----------------|---------------------|
| **Validez** | ¿Miden lo que pretenden? | Categorías no capturan el concepto teórico |
| **Confiabilidad** | ¿Son consistentes? | Preguntas cambian entre olas de encuesta |
| **Cobertura** | ¿Qué población representan? | Solo teléfonos fijos → subrepresenta jóvenes |
| **Precisión** | ¿Cuán exactas son las mediciones? | Muestras pequeñas → márgenes de error grandes |
| **Actualidad** | ¿Cuán recientes son? | Datos de 5 años para fenómenos que cambian rápido |
| **Accesibilidad** | ¿Están disponibles? | Restricciones legales o políticas |

### Problemas comunes

| Problema | Descripción | Estrategia |
|----------|-------------|------------|
| **Datos faltantes** | Valores ausentes (MCAR, MAR, MNAR) | Eliminación listwise, imputación |
| **Errores de medición** | Discrepancias valor real vs registrado | Verificar, corregir sesgos sistemáticos |
| **Codificación inconsistente** | Misma variable con códigos diferentes (ej: "M/F" vs "1/2") | Estandarizar antes de análisis |
| **Valores atípicos** | Observaciones extremas | Investigar antes de eliminar |
| **Duplicados** | Observaciones repetidas | Identificar y eliminar con cuidado |

## Trabajando con R

R es un lenguaje de programación estadística y entorno para análisis de datos. RStudio es un entorno de desarrollo integrado (IDE) que hace más amigable trabajar con R.

### ¿Por qué R?

**Ventajas:**
- **Gratuito y de código abierto**: Sin costos de licencia
- **Reproducible**: Scripts documentan exactamente qué se hizo
- **Extensible**: Miles de paquetes para técnicas especializadas
- **Comunidad activa**: Foros, tutoriales, ayuda abundante
- **Estándar en ciencias sociales cuantitativas**: Facilita colaboración y replicación

**Desventajas:**
- **Curva de aprendizaje**: Programar requiere práctica
- **Múltiples formas de hacer lo mismo**: Puede ser confuso para principiantes

### Instalación

1. Descargar R: https://cran.r-project.org/
2. Descargar RStudio: https://posit.co/download/rstudio-desktop/
3. Instalar ambos (primero R, luego RStudio)

### Anatomía de RStudio

RStudio tiene cuatro paneles principales:

1. **Editor de scripts** (arriba izquierda): Donde escribes código para guardar y ejecutar
2. **Consola** (abajo izquierda): Donde se ejecuta el código y aparecen resultados
3. **Environment** (arriba derecha): Muestra objetos en memoria (datasets, variables)
4. **Files/Plots/Packages/Help** (abajo derecha): Navegación de archivos, gráficos, ayuda

### Paquetes

R base es poderoso, pero paquetes extienden funcionalidad. Instalación (una vez):

```{r eval=FALSE}
install.packages("tidyverse")  # Suite de paquetes para manipulación de datos
install.packages("haven")      # Leer archivos SPSS, Stata, SAS
install.packages("readxl")     # Leer archivos Excel
install.packages("foreign")    # Leer múltiples formatos
```

Cargar paquetes (cada sesión):

```{r eval=FALSE}
library(tidyverse)
library(haven)
```

### Objetos básicos en R

**Vectores**: Secuencias de elementos del mismo tipo

```{r}
edades <- c(23, 45, 67, 34, 29)
partidos <- c("PS", "UDI", "RN", "PC", "PPD")
```

**Data frames**: Tablas con filas (observaciones) y columnas (variables)

```{r}
datos <- data.frame(
  id = 1:5,
  edad = c(23, 45, 67, 34, 29),
  partido = c("PS", "UDI", "RN", "PC", "PPD"),
  voto = c("Apruebo", "Rechazo", "Rechazo", "Apruebo", "Apruebo")
)
```

**Funciones**: Operaciones que transforman inputs en outputs

```{r}
mean(edades)        # Promedio
sd(edades)          # Desviación estándar
table(datos$voto)   # Tabla de frecuencias
```

### Directorios de trabajo

R busca y guarda archivos en el "directorio de trabajo". Verificar:

```{r eval=FALSE}
getwd()  # ¿Dónde estoy?
```

Cambiar (ajustar ruta según tu computador):

```{r eval=FALSE}
setwd("~/Documentos/Investigacion/datos")
```

Mejor práctica: usar **proyectos de RStudio** (`.Rproj`). Esto establece automáticamente el directorio de trabajo en la carpeta del proyecto.

### Importar datos

Los datos pueden venir en múltiples formatos. R puede leer la mayoría.

### Archivos de texto: CSV

Los archivos CSV (comma-separated values) son universales. Formato simple:

```
id,edad,partido
1,23,PS
2,45,UDI
3,67,RN
```

Importar con R base:

```{r eval=FALSE}
datos <- read.csv("encuesta.csv")
```

Importar con `readr` (parte de tidyverse, más rápido):

```{r eval=FALSE}
library(readr)
datos <- read_csv("encuesta.csv")
```

**Parámetros comunes:**
- `sep`: Separador (`,` por defecto, `;` en algunos países)
- `header`: ¿Primera fila son nombres de variables? (TRUE por defecto)
- `na.strings`: Cómo se codifican valores faltantes ("NA", ".", "")

Ejemplo:

```{r eval=FALSE}
datos <- read_csv("encuesta.csv", 
                  na = c("", "NA", "No sabe"),
                  col_types = cols(edad = col_integer(),
                                   partido = col_character()))
```

### Archivos de Excel

Excel es ubicuo en administración pública. Paquete `readxl`:

```{r eval=FALSE}
library(readxl)
datos <- read_excel("resultados_electorales.xlsx", 
                    sheet = "Presidenciales_2021")
```

Especificar rango:

```{r eval=FALSE}
datos <- read_excel("archivo.xlsx", 
                    sheet = 2, 
                    range = "A1:F100")
```

### Archivos de software estadístico

**Stata (.dta):**

```{r eval=FALSE}
library(haven)
datos <- read_dta("encuesta_casen.dta")
```

**SPSS (.sav):**

```{r eval=FALSE}
datos <- read_sav("estudio_cep.sav")
```

**SAS:**

```{r eval=FALSE}
datos <- read_sas("datos.sas7bdat")
```

El paquete `haven` preserva etiquetas de valores, muy común en encuestas. Ejemplo:

```{r eval=FALSE}
datos <- read_dta("encuesta.dta")
# Variable "educ" tiene valores 1,2,3 con etiquetas "Primaria","Secundaria","Universitaria"
attributes(datos$educ)$labels
```

::: {.nivel data-nivel="avanzado"}
### Datos en línea y bases de datos

Muchos datos están en URLs. Importar directamente:

```{r eval=FALSE}
url <- "https://ejemplo.com/datos.csv"
datos <- read_csv(url)
```

Para datos de APIs, usar paquetes especializados: `WDI` (Banco Mundial), `quantmod` (datos financieros).

Para bases SQL, usar `DBI`:

```{r eval=FALSE}
library(DBI)
con <- dbConnect(RSQLite::SQLite(), "mi_base.db")
datos <- dbGetQuery(con, "SELECT * FROM votaciones WHERE year = 2021")
dbDisconnect(con)
```
:::

## Manipulación de datos

Una vez importados, los datos rara vez están listos para análisis. Necesitan limpieza y transformación.

### Inspeccionar datos

Primeros y últimos casos:

```{r eval=FALSE}
head(datos)       # Primeros 6 casos
tail(datos, 10)   # Últimos 10 casos
```

Estructura:

```{r eval=FALSE}
str(datos)        # Tipo de cada variable
summary(datos)    # Resumen estadístico
glimpse(datos)    # Vista compacta (tidyverse)
```

Nombres de variables:

```{r eval=FALSE}
names(datos)
colnames(datos)
```

Dimensiones:

```{r eval=FALSE}
dim(datos)        # Filas y columnas
nrow(datos)       # Número de filas
ncol(datos)       # Número de columnas
```

### Seleccionar variables

R base:

```{r eval=FALSE}
datos_reducido <- datos[, c("id", "edad", "partido")]
```

Tidyverse (`dplyr`):

```{r eval=FALSE}
library(dplyr)
datos_reducido <- select(datos, id, edad, partido)
```

Seleccionar por criterio:

```{r eval=FALSE}
# Todas las variables que empiezan con "voto_"
datos_reducido <- select(datos, starts_with("voto_"))

# Todas las variables numéricas
datos_reducido <- select(datos, where(is.numeric))
```

### Filtrar casos

R base:

```{r eval=FALSE}
jovenes <- datos[datos$edad < 30, ]
```

Tidyverse:

```{r eval=FALSE}
jovenes <- filter(datos, edad < 30)
jovenes_izquierda <- filter(datos, edad < 30 & partido %in% c("PS", "PC", "FA"))
```

### Crear y transformar variables

R base:

```{r eval=FALSE}
datos$edad_decadas <- datos$edad / 10
datos$mayor_edad <- ifelse(datos$edad >= 18, "Sí", "No")
```

Tidyverse:

```{r eval=FALSE}
datos <- mutate(datos, 
                edad_decadas = edad / 10,
                mayor_edad = if_else(edad >= 18, "Sí", "No"),
                edad_cat = case_when(
                  edad < 30 ~ "Joven",
                  edad < 60 ~ "Adulto",
                  TRUE ~ "Mayor"
                ))
```

### Recodificar variables

Cambiar categorías:

```{r eval=FALSE}
datos <- mutate(datos,
                partido_bloques = case_when(
                  partido %in% c("PS", "PC", "PPD", "FA") ~ "Izquierda",
                  partido %in% c("UDI", "RN", "EVOPOLI") ~ "Derecha",
                  TRUE ~ "Centro/Otros"
                ))
```

### Renombrar variables

R base:

```{r eval=FALSE}
names(datos)[names(datos) == "p1"] <- "confianza_congreso"
```

Tidyverse:

```{r eval=FALSE}
datos <- rename(datos, 
                confianza_congreso = p1,
                confianza_gobierno = p2)
```

### Ordenar datos

Por edad (ascendente):

```{r eval=FALSE}
datos_ordenado <- arrange(datos, edad)
```

Por edad (descendente):

```{r eval=FALSE}
datos_ordenado <- arrange(datos, desc(edad))
```

Por múltiples variables:

```{r eval=FALSE}
datos_ordenado <- arrange(datos, partido, edad)
```

::: {.nivel data-nivel="avanzado"}
### Agregar datos por grupos

Resumir por grupos usando el operador pipe (`%>%`):

```{r eval=FALSE}
library(dplyr)
resumen_partido <- datos %>%
  group_by(partido) %>%
  summarise(
    n = n(),
    edad_promedio = mean(edad, na.rm = TRUE),
    edad_sd = sd(edad, na.rm = TRUE)
  )
```

El operador `%>%` pasa el resultado de una función a la siguiente.

### Unir datasets

**Left join**: Mantener todos los casos del dataset izquierdo

```{r eval=FALSE}
datos_completo <- left_join(encuesta, resultados_electorales,
                             by = "comuna_id")
```

**Inner join**: Mantener solo casos presentes en ambos datasets

```{r eval=FALSE}
datos_completo <- inner_join(encuesta, resultados_electorales,
                              by = "comuna_id")
```
:::

## Exportar datos

Después de limpiar y transformar datos, es útil guardarlos.

### CSV

```{r eval=FALSE}
write_csv(datos_limpios, "datos_procesados.csv")
```

### Formato de R

Guardar como `.RDS` (R Data Serialization) preserva estructura completa:

```{r eval=FALSE}
saveRDS(datos_limpios, "datos_procesados.rds")
```

Leer después:

```{r eval=FALSE}
datos <- readRDS("datos_procesados.rds")
```

### Stata

```{r eval=FALSE}
library(haven)
write_dta(datos_limpios, "datos_procesados.dta")
```

### Excel

```{r eval=FALSE}
library(writexl)
write_xlsx(datos_limpios, "datos_procesados.xlsx")
```

### Flujo reproducible

La reproducibilidad es esencial en ciencia. Otros (y tu yo futuro) deben poder replicar exactamente lo que hiciste.

### Principios

1. **Usa scripts, no clics**: Todo debe estar en código. No hacer transformaciones manualmente en Excel que no queden documentadas.
2. **Nunca modifiques datos originales**: Lee los datos crudos, transfórmalos en R, guarda la versión procesada. Mantén los originales intactos.
3. **Documenta tu código**: Comentarios explican *por qué* hiciste algo:

```{r eval=FALSE}
# Recodifico educación en tres categorías para simplificar análisis
# La categoría "técnica" es pequeña y la combino con "secundaria"
datos <- mutate(datos,
                educ_cat = case_when(
                  educ <= 2 ~ "Básica",
                  educ %in% c(3,4) ~ "Media",
                  educ >= 5 ~ "Superior"
                ))
```

4. **Organiza tu proyecto**: Estructura de carpetas clara:

```
proyecto/
  datos/
    crudos/
    procesados/
  scripts/
    01_limpieza.R
    02_analisis.R
  resultados/
    tablas/
    graficos/
  documento/
```

5. **Usa control de versiones**: Git y GitHub permiten rastrear cambios y colaborar. No es obligatorio para principiantes, pero altamente recomendable a medida que proyectos crecen.

::: {.nivel data-nivel="avanzado"}
### R Markdown y Quarto

R Markdown y Quarto integran código, resultados y texto en un solo documento. Permiten generar reportes reproducibles en HTML, PDF o Word.

Un documento típico tiene un encabezado YAML (título, autor, formato de salida), secciones en Markdown, y bloques de código R que se ejecutan al compilar. Al hacer "Knit" o "Render", R ejecuta el código e inserta resultados en el documento final. Si los datos cambian, el documento se actualiza automáticamente.
:::

## Resumen {.unnumbered}

| Concepto | Descripción |
|----------|-------------|
| **Estructuras de datos** | Corte transversal (un momento), series temporales (un caso, varios tiempos), panel (varios casos y tiempos), jerárquicos (anidados) |
| **Granularidad** | Micro (individuos), meso (organizaciones), macro (países/regiones) |
| **Fuentes** | Primarios (propios), secundarios (existentes), administrativos (gobierno), digitales (web/redes) |
| **Calidad de datos** | Validez, confiabilidad, cobertura, precisión, actualidad, accesibilidad |
| **Problemas comunes** | Datos faltantes, errores de medición, codificación inconsistente, outliers, duplicados |

| Operación | Función en R | Paquete |
|-----------|--------------|---------|
| Importar CSV | `read_csv()` | readr |
| Importar Stata/SPSS | `read_dta()`, `read_sav()` | haven |
| Seleccionar variables | `select()` | dplyr |
| Filtrar casos | `filter()` | dplyr |
| Crear variables | `mutate()` | dplyr |
| Agrupar y resumir | `group_by() %>% summarise()` | dplyr |

**Flujo reproducible:** Usar scripts, documentar código, organización clara, nunca modificar datos originales.

## Lecturas recomendadas {.unnumbered}

**Manipulación de datos en R:**

Wickham, H., & Grolemund, G. (2017). *R for Data Science*. O'Reilly. [Disponible gratis en https://r4ds.had.co.nz/]  
→ Guía comprehensiva y accesible sobre tidyverse.

**Reproducibilidad:**

Gandrud, C. (2015). *Reproducible Research with R and RStudio* (2nd ed.). CRC Press.  
→ Prácticas y herramientas para investigación reproducible.

**Calidad de datos:**

Karr, A. F., Sanil, A. P., & Banks, D. L. (2006). Data quality: A statistical perspective. *Statistical Methodology*, 3(2), 137-173.  
→ Perspectiva estadística sobre dimensiones de calidad de datos.

**Datos faltantes:**

Little, R. J., & Rubin, D. B. (2019). *Statistical Analysis with Missing Data* (3rd ed.). Wiley.  
→ Tratado técnico sobre manejo de datos faltantes.

**Recursos en línea:**

- Documentación de tidyverse: https://www.tidyverse.org/
- RStudio cheatsheets: https://posit.co/resources/cheatsheets/
- Stack Overflow (para preguntas específicas): https://stackoverflow.com/questions/tagged/r


## Ejercicios {.unnumbered}

::: {.ejercicios}

**1. Evaluación de calidad**

Descarga datos del CEP (https://www.cepchile.cl/opinion-publica/encuesta-cep/) o Latinobarómetro (https://www.latinobarometro.org/).

a) ¿Qué población representa la muestra?
b) ¿Cuál es el tamaño muestral y margen de error?
c) Identifica tres variables. Para cada una, evalúa: ¿Es válida para medir el concepto que pretende? ¿Qué problemas de medición podrían existir?
d) ¿Qué información sobre calidad de datos provee la documentación?

**2. Importar y explorar**

Importa un dataset de tu elección en R:

```{r eval=FALSE}
# Tu código aquí
```

a) ¿Cuántos casos y variables tiene?
b) ¿Qué tipos de variables contiene (numéricas, categóricas)?
c) ¿Cuántos valores faltantes hay en cada variable?
d) Identifica y describe un valor atípico

**3. Limpieza de datos**

Con el dataset del ejercicio 2:

a) Selecciona 5-10 variables relevantes para una pregunta de investigación que formules
b) Filtra casos para incluir solo observaciones completas (sin valores faltantes en variables clave)
c) Crea al menos dos variables nuevas mediante transformación o recodificación
d) Genera un resumen estadístico de tus variables

**4. Datos faltantes**

```{r eval=FALSE}
# Crea un dataset con valores faltantes
set.seed(123)
datos <- data.frame(
  id = 1:100,
  edad = sample(18:80, 100, replace = TRUE),
  ingreso = rnorm(100, 500000, 150000)
)
# Introduce valores faltantes no aleatorios:
# Personas mayores de 60 tienen 50% probabilidad de no reportar ingreso
datos$ingreso[datos$edad > 60 & runif(100) < 0.5] <- NA
```

a) ¿Cuántos valores faltantes hay en `ingreso`?
b) Calcula ingreso promedio: (1) eliminando casos con valores faltantes, (2) solo entre quienes reportaron. ¿Difieren las estimaciones? ¿Por qué?
c) ¿Qué tipo de datos faltantes son estos (MCAR, MAR, MNAR)?
d) ¿Cómo afecta esto las inferencias sobre ingreso promedio en la población?

**5. Combinar datasets**

Tienes dos datasets:

```{r eval=FALSE}
# Resultados electorales por comuna
resultados <- data.frame(
  comuna_id = 1:5,
  comuna = c("Santiago", "Valparaíso", "Concepción", "La Serena", "Temuco"),
  votos_derecha = c(45, 38, 42, 50, 35),
  votos_izquierda = c(40, 48, 43, 35, 50)
)

# Características socioeconómicas
socioeconomico <- data.frame(
  comuna_id = c(1, 2, 3, 6),
  ingreso_promedio = c(800000, 650000, 700000, 600000),
  desigualdad_gini = c(0.48, 0.45, 0.47, 0.50)
)
```

a) Combina los datasets manteniendo todas las comunas de `resultados`
b) ¿Qué problema de datos observas después de combinar?
c) ¿Cómo manejarías ese problema para análisis posterior?

**6. Proyecto propio**

Identifica un dataset relevante para tu tesis o interés de investigación:

a) Descríbelo: fuente, estructura (corte transversal/panel/etc), unidad de análisis, N
b) Importa a R y documenta el proceso
c) Realiza una limpieza básica: seleccionar variables relevantes, verificar valores faltantes y outliers, crear variables derivadas si es necesario
d) Genera un reporte en R Markdown que documente: tu pregunta de investigación, descripción de los datos, proceso de limpieza, y estadísticas descriptivas básicas
e) Exporta la versión limpia de los datos

:::

::: {#refs}
:::
