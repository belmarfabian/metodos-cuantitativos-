# Pruebas de hipÃ³tesis {#hipotesis}

## Objetivos del capÃ­tulo {.unnumbered}

Al finalizar este capÃ­tulo, serÃ¡s capaz de:

- Comprender la lÃ³gica de las pruebas de hipÃ³tesis estadÃ­sticas
- Formular correctamente hipÃ³tesis nula ($H_0$) y alternativa ($H_1$)
- Interpretar valores p y niveles de significancia
- Distinguir entre significancia estadÃ­stica y sustantiva
- Reconocer y evitar errores tipo I y tipo II
- Realizar pruebas de hipÃ³tesis para medias y proporciones
- Entender las limitaciones y mal usos comunes de las pruebas de hipÃ³tesis

## LÃ³gica de pruebas de hipÃ³tesis

Las pruebas de hipÃ³tesis responden a una pregunta fundamental en investigaciÃ³n: **Â¿Este patrÃ³n que observo en mis datos es real, o podrÃ­a ser producto del azar?** Consideremos un caso concreto: en una encuesta antes de una campaÃ±a publicitaria, 42% de 800 encuestados apoyaba al Candidato A. DespuÃ©s de la campaÃ±a, en otra muestra de 800 personas, 47% lo apoya. La pregunta relevante es: Â¿la campaÃ±a fue efectiva, o esta diferencia de 5 puntos porcentuales podrÃ­a deberse simplemente a error muestral?

### La lÃ³gica de prueba por contradicciÃ³n

Las pruebas de hipÃ³tesis usan un argumento de **reducciÃ³n al absurdo**:

1. Asumimos que **NO hay efecto** (hipÃ³tesis nula: $H_0$)
2. Preguntamos: Â¿QuÃ© tan probable es observar nuestros datos si $H_0$ fuera cierta?
3. Si esa probabilidad es muy baja, **rechazamos** $H_0$ como implausible
4. Si la probabilidad no es tan baja, **no rechazamos** $H_0$ (no tenemos evidencia suficiente contra ella)

Es crucial entender la asimetrÃ­a fundamental de este razonamiento: nunca "aceptamos" o "probamos" $H_0$. Solo podemos **rechazar** $H_0$ (cuando hay evidencia contra ella) o **no rechazar** $H_0$ (cuando no hay evidencia suficiente contra ella). Esto es anÃ¡logo a un juicio judicial: no "probamos inocencia", solo establecemos que "no hay evidencia suficiente de culpabilidad".

### HipÃ³tesis nula y alternativa

### FormulaciÃ³n de hipÃ³tesis

**HipÃ³tesis nula ($H_0$)**: AfirmaciÃ³n de "no efecto" o "no diferencia". Es lo que asumimos como cierto inicialmente.

**HipÃ³tesis alternativa ($H_1$)**: Lo que esperamos encontrar si rechazamos $H_0$. Puede ser:
- **Bilateral** (dos colas): $H_1: \mu \neq \mu_0$ (hay diferencia, en cualquier direcciÃ³n)
- **Unilateral** (una cola): $H_1: \mu > \mu_0$ o $H_1: \mu < \mu_0$ (direcciÃ³n especÃ­fica)

**Ejemplos en ciencias sociales:**

| Pregunta | $H_0$ | $H_1$ | Tipo |
|----------|-------|-------|------|
| Â¿PolÃ­tica redujo desempleo? | $\mu = 8\%$ | $\mu < 8\%$ | Unilateral |
| Â¿ParticipaciÃ³n difiere por gÃ©nero? | $p_H = p_M$ | $p_H \neq p_M$ | Bilateral |
| Â¿Ingreso regional â‰  nacional? | $\mu = 550$ | $\mu \neq 550$ | Bilateral |

Otros ejemplos: evaluar si una reforma electoral aumentÃ³ la participaciÃ³n, o comparar aprobaciÃ³n presidencial entre regiones.

## Valores p y errores

### Â¿QuÃ© es un valor p?

El **valor p** (*p-value*) es la probabilidad de observar datos tan extremos como los nuestros (o mÃ¡s), **asumiendo que $H_0$ es cierta**.

$$\text{valor } p = P(\text{datos tan extremos} \mid H_0 \text{ es cierta})$$

La interpretaciÃ³n correcta del valor p es fundamental para evitar errores comunes.[^error-valor-p] Cuando observamos $p = 0.03$, debemos interpretar: "Si no hubiera efecto real, verÃ­amos resultados tan extremos solo 3% de las veces."

[^error-valor-p]: Error comÃºn: "p = 0.03 significa 3% de probabilidad de que $H_0$ sea cierta". Falso. El valor p es $P(\text{datos} | H_0)$, no $P(H_0 | \text{datos})$. La hipÃ³tesis nula no es una variable aleatoria.

Un valor $p = 0.001$ indica: "Si $H_0$ fuera cierta, estos datos serÃ­an extremadamente raros (1 en 1000)." Por el contrario, $p = 0.45$ significa: "Estos datos son muy compatibles con $H_0$; no hay evidencia contra ella." El valor p **NO** representa la probabilidad de que $H_0$ sea cierta.

### Nivel de significancia ($\alpha$)

El **nivel de significancia** $\alpha$ es el umbral que elegimos *antes* de analizar los datos para decidir cuÃ¡ndo rechazar $H_0$. Convencionalmente se usa $\alpha = 0.05$, pero esta elecciÃ³n es arbitraria.[^alpha-arbitrario]

[^alpha-arbitrario]: Â¿Por quÃ© 0.05? R.A. Fisher lo propuso como "conveniente" en los aÃ±os 1920. No hay nada mÃ¡gico en este nÃºmero. En fÃ­sica de partÃ­culas usan $\alpha = 0.0000003$ (5 sigmas). En estudios exploratorios, algunos usan $\alpha = 0.10$. La elecciÃ³n deberÃ­a depender del costo relativo de los errores tipo I y II.

La regla de decisiÃ³n es:

- Si $p < \alpha$: Rechazamos $H_0$ (resultado "estadÃ­sticamente significativo")
- Si $p \geq \alpha$: No rechazamos $H_0$ (no hay evidencia suficiente)

::: {.callout-warning}
## Cuidado con el tÃ©rmino "significativo"

"EstadÃ­sticamente significativo" NO significa "importante" o "relevante". Solo significa que el resultado es improbable bajo $H_0$. Un efecto puede ser estadÃ­sticamente significativo pero prÃ¡cticamente irrelevante (especialmente con muestras grandes), o puede ser sustantivamente importante pero no alcanzar significancia estadÃ­stica (con muestras pequeÃ±as).
:::

### Errores tipo I y tipo II

En pruebas de hipÃ³tesis, existen dos tipos de error posibles:

|                        | $H_0$ es verdadera | $H_0$ es falsa |
|------------------------|:------------------:|:--------------:|
| **Rechazar $H_0$**     | Error Tipo I ($\alpha$) | DecisiÃ³n correcta (Poder) |
| **No rechazar $H_0$**  | DecisiÃ³n correcta | Error Tipo II ($\beta$) |

**Error Tipo I** (falso positivo): Rechazar $H_0$ cuando es cierta. Es como condenar a un inocente. La probabilidad de cometerlo es $\alpha$, que nosotros controlamos al elegir el nivel de significancia.

**Error Tipo II** (falso negativo): No rechazar $H_0$ cuando es falsa. Es como absolver a un culpable. La probabilidad de cometerlo es $\beta$, que depende del tamaÃ±o del efecto real y del tamaÃ±o muestral.

**Poder estadÃ­stico**: $1 - \beta$ es la probabilidad de detectar un efecto real cuando existe. Un estudio con poder de 0.80 detectarÃ¡ el efecto en 80% de las rÃ©plicas.

```{r}
#| label: fig-errores
#| fig-cap: "VisualizaciÃ³n de errores Tipo I y Tipo II"
#| code-fold: true

library(ggplot2)

# Crear datos para dos distribuciones
x <- seq(-4, 8, length.out = 1000)
h0 <- dnorm(x, mean = 0, sd = 1)  # DistribuciÃ³n bajo H0
h1 <- dnorm(x, mean = 3, sd = 1)  # DistribuciÃ³n bajo H1 (efecto real)

datos <- data.frame(
  x = rep(x, 2),
  densidad = c(h0, h1),
  hipotesis = rep(c("H0: No hay efecto", "H1: Hay efecto real"), each = 1000)
)

# Valor crÃ­tico para alpha = 0.05 (una cola)
valor_critico <- qnorm(0.95, mean = 0, sd = 1)

ggplot(datos, aes(x = x, y = densidad, color = hipotesis, fill = hipotesis)) +
  geom_line(linewidth = 1) +
  geom_area(data = subset(datos, hipotesis == "H0: No hay efecto" & x > valor_critico),
            alpha = 0.4) +
  geom_area(data = subset(datos, hipotesis == "H1: Hay efecto real" & x < valor_critico),
            alpha = 0.4) +
  geom_vline(xintercept = valor_critico, linetype = "dashed", color = "black") +
  annotate("text", x = valor_critico + 0.3, y = 0.35,
           label = "Valor crÃ­tico", hjust = 0, size = 3) +
  annotate("text", x = 2.5, y = 0.05,
           label = "Error Tipo I\n(Î±)", size = 3, color = "#E41A1C") +
  annotate("text", x = 0.5, y = 0.05,
           label = "Error Tipo II\n(Î²)", size = 3, color = "#377EB8") +
  scale_color_manual(values = c("#E41A1C", "#377EB8")) +
  scale_fill_manual(values = c("#E41A1C", "#377EB8")) +
  labs(x = "EstadÃ­stico de prueba", y = "Densidad",
       color = "", fill = "") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

::: {.callout-tip}
## AnalogÃ­a judicial

Piensa en un juicio criminal:

- **$H_0$**: El acusado es inocente (presunciÃ³n de inocencia)
- **$H_1$**: El acusado es culpable
- **Error Tipo I**: Condenar a un inocente (grave)
- **Error Tipo II**: Absolver a un culpable (tambiÃ©n malo, pero el sistema prefiere este error)
- **$\alpha$ bajo**: Exigimos mucha evidencia para condenar, protegiendo a inocentes

El sistema judicial prefiere errores Tipo II sobre Tipo I ("mejor 10 culpables libres que un inocente preso"). En investigaciÃ³n, la elecciÃ³n de $\alpha$ refleja una decisiÃ³n similar sobre quÃ© error es mÃ¡s costoso.
:::

## Prueba t para una media

La prueba t evalÃºa si la media de una poblaciÃ³n difiere de un valor especÃ­fico. Se usa cuando la desviaciÃ³n estÃ¡ndar poblacional es desconocida (el caso habitual).

### Ejemplo: SatisfacciÃ³n con la democracia

Supongamos que queremos evaluar si los chilenos tienen una satisfacciÃ³n con la democracia diferente al promedio latinoamericano, que segÃºn datos regionales es 5.0 en una escala de 1 a 10. Recopilamos una muestra de 150 personas.

```{r}
# Simulamos datos de una encuesta
set.seed(2024)
satisfaccion <- rnorm(150, mean = 4.2, sd = 2.1)
satisfaccion <- pmax(1, pmin(10, satisfaccion))  # Limitar a escala 1-10
```

**Paso 1: Formular hipÃ³tesis**

- $H_0: \mu = 5.0$ (satisfacciÃ³n igual al promedio regional)
- $H_1: \mu \neq 5.0$ (satisfacciÃ³n diferente al promedio regional)

**Paso 2: Calcular estadÃ­stico de prueba**

$$t = \frac{\bar{x} - \mu_0}{s / \sqrt{n}}$$

```{r}
# CÃ¡lculo manual
media_muestral <- mean(satisfaccion)
desv_estandar <- sd(satisfaccion)
n <- length(satisfaccion)
mu_0 <- 5.0

t_calculado <- (media_muestral - mu_0) / (desv_estandar / sqrt(n))

cat("Media muestral:", round(media_muestral, 2), "\n")
cat("DesviaciÃ³n estÃ¡ndar:", round(desv_estandar, 2), "\n")
cat("EstadÃ­stico t:", round(t_calculado, 2), "\n")
```

**Paso 3: Obtener valor p**

```{r}
# Valor p (bilateral)
valor_p <- 2 * pt(abs(t_calculado), df = n - 1, lower.tail = FALSE)
cat("Valor p:", round(valor_p, 4), "\n")
```

**Paso 4: Usar la funciÃ³n `t.test()` de R**

```{r}
# Forma directa en R
resultado <- t.test(satisfaccion, mu = 5.0)
resultado
```

**Paso 5: Interpretar resultados**

```{r}
#| echo: false
if(resultado$p.value < 0.05) {
  cat("ConclusiÃ³n: Con p =", round(resultado$p.value, 4), "< 0.05, rechazamos H0.\n")
  cat("Hay evidencia estadÃ­stica de que la satisfacciÃ³n promedio difiere de 5.0.\n")
  cat("El intervalo de confianza al 95% es [", round(resultado$conf.int[1], 2),
      ",", round(resultado$conf.int[2], 2), "].\n")
} else {
  cat("ConclusiÃ³n: Con p =", round(resultado$p.value, 4), ">= 0.05, no rechazamos H0.\n")
  cat("No hay evidencia suficiente de diferencia.\n")
}
```

## Prueba t para dos muestras independientes

Frecuentemente queremos comparar medias entre dos grupos. Por ejemplo: Â¿hay diferencia en confianza institucional entre hombres y mujeres?

```{r}
# Simulamos datos de encuesta sobre confianza en el Congreso (1-10)
set.seed(2024)
confianza_hombres <- rnorm(120, mean = 3.8, sd = 1.8)
confianza_mujeres <- rnorm(130, mean = 3.2, sd = 1.9)

# Limitar a escala 1-10
confianza_hombres <- pmax(1, pmin(10, confianza_hombres))
confianza_mujeres <- pmax(1, pmin(10, confianza_mujeres))
```

**HipÃ³tesis:**

- $H_0: \mu_H = \mu_M$ (no hay diferencia entre gÃ©neros)
- $H_1: \mu_H \neq \mu_M$ (hay diferencia)

```{r}
# Prueba t para dos muestras
resultado_2muestras <- t.test(confianza_hombres, confianza_mujeres)
resultado_2muestras
```

```{r}
#| label: fig-boxplot-genero
#| fig-cap: "Confianza en el Congreso por gÃ©nero"
#| code-fold: true

# VisualizaciÃ³n
datos_genero <- data.frame(
  confianza = c(confianza_hombres, confianza_mujeres),
  genero = factor(c(rep("Hombres", length(confianza_hombres)),
                    rep("Mujeres", length(confianza_mujeres))))
)

ggplot(datos_genero, aes(x = genero, y = confianza, fill = genero)) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(width = 0.2, alpha = 0.3, size = 1) +
  stat_summary(fun = mean, geom = "point", shape = 18, size = 4, color = "red") +
  scale_fill_manual(values = c("#4ECDC4", "#FF6B6B")) +
  labs(x = "", y = "Confianza en el Congreso (1-10)",
       caption = "El diamante rojo indica la media de cada grupo") +
  theme_minimal() +
  theme(legend.position = "none")
```

## Prueba chi-cuadrado para independencia

Cuando ambas variables son categÃ³ricas, usamos la prueba chi-cuadrado ($\chi^2$) para evaluar si estÃ¡n asociadas.

### Ejemplo: Voto y nivel educativo

Â¿Existe asociaciÃ³n entre nivel educativo y preferencia de voto?

```{r}
# Crear tabla de contingencia
set.seed(2024)
voto_educacion <- matrix(c(
  45, 35, 20,   # EducaciÃ³n bÃ¡sica: Izquierda, Centro, Derecha
  40, 45, 35,   # EducaciÃ³n media
  25, 40, 50    # EducaciÃ³n superior
), nrow = 3, byrow = TRUE)

rownames(voto_educacion) <- c("BÃ¡sica", "Media", "Superior")
colnames(voto_educacion) <- c("Izquierda", "Centro", "Derecha")

# Mostrar tabla
voto_educacion
```

**HipÃ³tesis:**

- $H_0$: Nivel educativo y preferencia de voto son independientes
- $H_1$: Existe asociaciÃ³n entre nivel educativo y preferencia de voto

```{r}
# Prueba chi-cuadrado
resultado_chi <- chisq.test(voto_educacion)
resultado_chi
```

```{r}
#| label: fig-mosaico
#| fig-cap: "RelaciÃ³n entre nivel educativo y preferencia de voto"
#| code-fold: true

# Convertir a data frame para visualizaciÃ³n
library(tidyr)
datos_voto <- as.data.frame(as.table(voto_educacion))
names(datos_voto) <- c("Educacion", "Voto", "Frecuencia")

ggplot(datos_voto, aes(x = Educacion, y = Frecuencia, fill = Voto)) +
  geom_bar(stat = "identity", position = "fill") +
  scale_fill_manual(values = c("#E41A1C", "#984EA3", "#377EB8")) +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "Nivel educativo", y = "ProporciÃ³n", fill = "Preferencia") +
  theme_minimal()
```

```{r}
# Residuos estandarizados (quÃ© celdas contribuyen mÃ¡s)
cat("Residuos estandarizados:\n")
round(resultado_chi$residuals, 2)
```

::: {.callout-note}
## Interpretando residuos

Los residuos estandarizados mayores a 2 (o menores a -2) indican celdas donde hay mÃ¡s (o menos) casos de los esperados bajo independencia. En este ejemplo, personas con educaciÃ³n bÃ¡sica votan mÃ¡s por la izquierda de lo esperado, mientras personas con educaciÃ³n superior votan mÃ¡s por la derecha.
:::

## Significancia estadÃ­stica vs. sustantiva

::: {.callout-important}
## La distinciÃ³n mÃ¡s importante del capÃ­tulo

**Significancia estadÃ­stica** ($p < 0.05$) solo indica que el efecto probablemente no es cero. No dice nada sobre si el efecto es *importante* o *relevante*.

**Significancia sustantiva** pregunta: Â¿el efecto es lo suficientemente grande como para importar en la prÃ¡ctica?
:::

Consideremos un ejemplo. Supongamos que un programa de educaciÃ³n cÃ­vica aumenta el conocimiento polÃ­tico de 50.0 a 50.5 puntos (en escala de 0-100). Con una muestra de 10,000 personas, este efecto de 0.5 puntos podrÃ­a ser estadÃ­sticamente significativo ($p < 0.001$). Pero Â¿importa prÃ¡cticamente una diferencia de medio punto en 100?

```{r}
# DemostraciÃ³n: efecto pequeÃ±o pero "significativo" con n grande
set.seed(2024)
control <- rnorm(5000, mean = 50, sd = 15)
tratamiento <- rnorm(5000, mean = 50.5, sd = 15)  # Diferencia de 0.5 puntos

t.test(tratamiento, control)
```

El resultado es "significativo" ($p < 0.05$), pero la diferencia de medias es solo 0.5 puntos. Esto ilustra por quÃ© siempre debemos reportar:

1. El **tamaÃ±o del efecto** (diferencia de medias, odds ratio, etc.)
2. El **intervalo de confianza** (rango plausible del efecto)
3. La **significancia prÃ¡ctica** (Â¿este efecto importa en el mundo real?)

::: {.callout-note .callout-avanzado collapse="true"}
## ðŸŽ“ MÃ©todos Cuantitativos Avanzados

### TamaÃ±o del efecto: d de Cohen

Una medida estandarizada del tamaÃ±o del efecto es la **d de Cohen**:

$$d = \frac{\bar{x}_1 - \bar{x}_2}{s_{pooled}}$$

- $d = 0.2$: efecto pequeÃ±o
- $d = 0.5$: efecto mediano
- $d = 0.8$: efecto grande

```{r}
# Calcular d de Cohen
diferencia <- mean(tratamiento) - mean(control)
s_pooled <- sqrt((var(tratamiento) + var(control)) / 2)
d_cohen <- diferencia / s_pooled

cat("d de Cohen:", round(d_cohen, 3), "\n")
cat("InterpretaciÃ³n: efecto",
    ifelse(abs(d_cohen) < 0.2, "trivial",
           ifelse(abs(d_cohen) < 0.5, "pequeÃ±o",
                  ifelse(abs(d_cohen) < 0.8, "mediano", "grande"))))
```
:::

## Errores comunes y malas prÃ¡cticas

::: {.callout-caution}
## Errores que debes evitar

| Error | Por quÃ© es problema |
|-------|---------------------|
| p = 0.03 significa "3% que $H_0$ sea cierta" | El valor p es $P(\text{datos}|H_0)$, NO $P(H_0|\text{datos})$ |
| Dicotomizar en significativo/no | p = 0.049 y p = 0.051 son prÃ¡cticamente idÃ©nticos |
| P-hacking | Probar muchos anÃ¡lisis y reportar solo los significativos |
| "No significativo" = "no hay efecto" | Ausencia de evidencia â‰  evidencia de ausencia |
| Ignorar tamaÃ±o del efecto | Un efecto significativo puede ser irrelevante |
:::

::: {.callout-note .callout-avanzado collapse="true"}
## ðŸŽ“ MÃ©todos Cuantitativos Avanzados

### El problema de las comparaciones mÃºltiples

Si pruebas 20 hipÃ³tesis independientes con $\alpha = 0.05$, esperarÃ­as encontrar 1 resultado "significativo" por azar puro, incluso si todas las $H_0$ son ciertas.

```{r}
# SimulaciÃ³n: 20 pruebas cuando H0 es siempre cierta
set.seed(2024)
valores_p <- replicate(20, {
  x <- rnorm(50)  # Datos puramente aleatorios
  y <- rnorm(50)
  t.test(x, y)$p.value
})

cat("Valores p de 20 pruebas (H0 siempre cierta):\n")
round(sort(valores_p), 3)
cat("\n\nNÃºmero de 'significativos' (p < 0.05):", sum(valores_p < 0.05))
```

**CorrecciÃ³n de Bonferroni**: Si haces $m$ pruebas, usa $\alpha' = \alpha / m$. Para 20 pruebas con $\alpha = 0.05$, usarÃ­as $\alpha' = 0.0025$.

**Otras correcciones**: Holm, Benjamini-Hochberg (FDR), que son menos conservadoras que Bonferroni.
:::

## Resumen {.unnumbered}

| Concepto | DescripciÃ³n |
|----------|-------------|
| **$H_0$ (hipÃ³tesis nula)** | No hay efecto/diferencia (lo que buscamos rechazar) |
| **$H_1$ (hipÃ³tesis alternativa)** | Existe efecto/diferencia |
| **Valor p** | Probabilidad de observar datos tan extremos si $H_0$ fuera cierta |
| **$\alpha$ (nivel de significancia)** | Umbral para rechazar $H_0$ (tÃ­picamente 0.05) |
| **Error Tipo I** | Rechazar $H_0$ cuando es cierta (falso positivo) |
| **Error Tipo II** | No rechazar $H_0$ cuando es falsa (falso negativo) |
| **Poder** | Capacidad de detectar efectos reales ($1-\beta$) |

| Prueba | Uso | FunciÃ³n en R |
|--------|-----|--------------|
| **Prueba t** | Comparar medias | `t.test()` |
| **Chi-cuadrado** | AsociaciÃ³n entre categÃ³ricas | `chisq.test()` |
| **Prueba z** | Proporciones (n grande) | `prop.test()` |

**Importante:** Significancia estadÃ­stica $\neq$ significancia prÃ¡ctica. Siempre reportar tamaÃ±o del efecto e intervalos de confianza.

## Lecturas recomendadas {.unnumbered}

**Fundamentos de pruebas de hipÃ³tesis:**

Agresti, A., & Finlay, B. (2009). *Statistical Methods for the Social Sciences* (4th ed.). Pearson.  
â†’ CapÃ­tulo 6 ofrece explicaciÃ³n rigurosa pero accesible de la lÃ³gica de pruebas de significancia estadÃ­stica.

**Aplicaciones en ciencias sociales:**

Llaudet, E., & Imai, K. (2022). *Data Analysis for Social Science: A Friendly and Practical Introduction*. Princeton University Press.  
â†’ SecciÃ³n 7.5 conecta pruebas de hipÃ³tesis con aplicaciones prÃ¡cticas en investigaciÃ³n social y polÃ­tica.

**Sobre problemas y mal uso de valores p:**

Wasserstein, R. L., & Lazar, N. A. (2016). The ASA's statement on p-values: Context, process, and purpose. *The American Statistician*, 70(2), 129-133.  
â†’ DeclaraciÃ³n oficial de la AsociaciÃ³n Americana de EstadÃ­stica sobre interpretaciÃ³n correcta de valores p y errores comunes.


## Ejercicios {.unnumbered}

::: {.ejercicios}

**1. FormulaciÃ³n de hipÃ³tesis**

Para cada escenario, formula $H_0$ y $H_1$ apropiadas. Indica si la prueba deberÃ­a ser unilateral o bilateral.

a) Un programa de becas pretende aumentar la asistencia escolar, actualmente en 85%
b) Una nueva ley electoral busca modificar la participaciÃ³n (sin expectativa de direcciÃ³n)
c) Un investigador cree que la desigualdad ha aumentado respecto al nivel de 2015 (Gini = 0.48)

**2. Prueba t para una muestra**

Un Ã­ndice de satisfacciÃ³n democrÃ¡tica tiene media latinoamericana de 5.0 (escala 1-10). Con datos de Chile:

```{r eval=FALSE}
set.seed(123)
satisfaccion_chile <- rnorm(120, mean = 4.3, sd = 2.1)
satisfaccion_chile <- pmax(1, pmin(10, satisfaccion_chile))
```

a) Formula las hipÃ³tesis
b) Realiza prueba t con `t.test()`
c) Interpreta el valor p
d) Â¿CuÃ¡l es el IC 95% para la media chilena?
e) Escribe una conclusiÃ³n en lenguaje no tÃ©cnico

**3. Prueba chi-cuadrado**

Datos de preferencia polÃ­tica segÃºn nivel educativo:

```{r eval=FALSE}
tabla <- matrix(c(
  45, 30, 25,  # EducaciÃ³n bÃ¡sica
  35, 40, 45,  # EducaciÃ³n media
  20, 50, 60   # EducaciÃ³n superior
), nrow = 3, byrow = TRUE)
rownames(tabla) <- c("BÃ¡sica", "Media", "Superior")
colnames(tabla) <- c("Izquierda", "Centro", "Derecha")
```

a) Formula las hipÃ³tesis
b) Realiza prueba chi-cuadrado
c) Examina los residuos estandarizados: Â¿quÃ© celdas contribuyen mÃ¡s al estadÃ­stico $\chi^2$?
d) Interpreta los resultados sustantivamente

**4. Errores tipo I y II**

Un investigador rechaza $H_0$ con $p = 0.048$.

a) Â¿QuÃ© tipo de error podrÃ­a estar cometiendo?
b) Si $\alpha = 0.01$, Â¿cambiarÃ­a la conclusiÃ³n?
c) Si la decisiÃ³n fuera importante (ej: aprobar una polÃ­tica costosa), Â¿quÃ© nivel de $\alpha$ recomendarÃ­as?
d) Â¿CÃ³mo podrÃ­a el investigador aumentar el poder estadÃ­stico?

**5. Significancia estadÃ­stica vs. sustantiva**

Un programa aumenta el conocimiento polÃ­tico de 50 a 50.8 puntos (escala 0-100). Con n=5000, $p < 0.001$.

a) Â¿El resultado es estadÃ­sticamente significativo?
b) Calcula el tamaÃ±o del efecto (d de Cohen, asumiendo SD = 15)
c) Â¿El resultado es sustantivamente importante? Argumenta
d) Â¿QuÃ© informaciÃ³n adicional necesitarÃ­as para evaluar si el programa vale la pena?

**6. AnÃ¡lisis crÃ­tico de resultados publicados**

Busca un artÃ­culo de ciencia polÃ­tica que reporte pruebas de hipÃ³tesis. Para uno de los resultados principales:

a) Identifica: $H_0$, $H_1$, estadÃ­stico de prueba, valor p
b) Â¿Reportan tamaÃ±o del efecto? Si no, Â¿puedes calcularlo?
c) Â¿Reportan IC ademÃ¡s del valor p?
d) EvalÃºa: Â¿el resultado es solo estadÃ­sticamente significativo, o tambiÃ©n sustantivamente importante?
e) Â¿QuÃ© limitaciones mencionan los autores sobre sus inferencias?

:::

::: {#refs}
:::
