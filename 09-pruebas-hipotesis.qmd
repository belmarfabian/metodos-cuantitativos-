# Pruebas de hip√≥tesis {#hipotesis}

## Objetivos del cap√≠tulo {.unnumbered}

Al finalizar este cap√≠tulo, ser√°s capaz de:

- Comprender la l√≥gica de las pruebas de hip√≥tesis estad√≠sticas
- Formular hip√≥tesis nula y alternativa de manera apropiada
- Interpretar valores p y niveles de significancia
- Distinguir entre significancia estad√≠stica y significancia pr√°ctica
- Reconocer y evitar errores tipo I y tipo II
- Realizar e interpretar pruebas de hip√≥tesis en R
- Entender las limitaciones de las pruebas de hip√≥tesis

## ¬øPara qu√© sirven las pruebas de hip√≥tesis?

Imagina que realizas una encuesta antes y despu√©s de una campa√±a publicitaria. Antes, 42% de las personas apoyaban al Candidato A. Despu√©s, 47% lo apoyan. La pregunta natural es: **¬øla campa√±a fue efectiva, o esta diferencia de 5 puntos podr√≠a deberse simplemente a que encuestaste a personas diferentes?**

Este es el problema central que resuelven las pruebas de hip√≥tesis: nos ayudan a distinguir entre **patrones reales** y **variaci√≥n aleatoria**.

### La idea intuitiva

Las pruebas de hip√≥tesis funcionan con una l√≥gica de "abogado del diablo":

1. **Asumimos que NO hay efecto** (esta es la "hip√≥tesis nula")
2. **Preguntamos:** Si realmente no hubiera efecto, ¬øqu√© tan probable ser√≠a ver los datos que observamos?
3. **Si esa probabilidad es muy baja:** Entonces nuestra suposici√≥n inicial probablemente es falsa - s√≠ hay un efecto real
4. **Si la probabilidad no es tan baja:** No tenemos suficiente evidencia para afirmar que hay un efecto

Es similar a un juicio: asumimos inocencia (no hay efecto), y solo cambiamos de opini√≥n si la evidencia es muy fuerte.

::: {.callout-tip}
## Analog√≠a del juicio

| Concepto estad√≠stico | Equivalente judicial |
|---------------------|---------------------|
| Hip√≥tesis nula | "El acusado es inocente" |
| Hip√≥tesis alternativa | "El acusado es culpable" |
| Rechazar la hip√≥tesis nula | Declarar culpable |
| No rechazar la hip√≥tesis nula | Absolver (no declarar inocente, sino "no hay suficiente evidencia") |
| Valor p bajo | Evidencia fuerte en contra |

El sistema prefiere dejar libre a un culpable antes que encarcelar a un inocente. De manera similar, las pruebas estad√≠sticas son conservadoras: preferimos no afirmar un efecto antes que afirmar uno que no existe.
:::

## Formulando hip√≥tesis

### Hip√≥tesis nula vs. alternativa

En toda prueba de hip√≥tesis definimos dos opciones:

**Hip√≥tesis nula (H‚ÇÄ):** La afirmaci√≥n de "no hay efecto" o "no hay diferencia". Es nuestra posici√≥n por defecto.

**Hip√≥tesis alternativa (H‚ÇÅ):** Lo que sospechamos que es verdad. Es lo que queremos demostrar con evidencia.

### Ejemplos de formulaci√≥n

| Pregunta de investigaci√≥n | Hip√≥tesis nula (H‚ÇÄ) | Hip√≥tesis alternativa (H‚ÇÅ) |
|--------------------------|---------------------|---------------------------|
| ¬øLa pol√≠tica redujo el desempleo? | El desempleo sigue igual que antes | El desempleo disminuy√≥ |
| ¬øHay diferencia de participaci√≥n entre hombres y mujeres? | No hay diferencia | S√≠ hay diferencia |
| ¬øEl programa mejor√≥ las notas? | Las notas siguen iguales | Las notas aumentaron |
| ¬øExiste relaci√≥n entre educaci√≥n y voto? | Son independientes | Est√°n asociados |

::: {.callout-note}
## ¬øCu√°ndo usar hip√≥tesis unilateral vs. bilateral?

- **Bilateral (dos colas):** Cuando solo te importa si hay diferencia, sin importar la direcci√≥n. "¬øDifieren los salarios entre hombres y mujeres?" (pueden ser mayores o menores)

- **Unilateral (una cola):** Cuando tienes expectativa clara de la direcci√≥n. "¬øEl nuevo tratamiento *mejora* los resultados?" (solo te importa si mejora, no si empeora)

En la pr√°ctica, las pruebas bilaterales son m√°s comunes y conservadoras.
:::

## Entendiendo el valor p

### ¬øQu√© significa el valor p?

El **valor p** responde a una pregunta espec√≠fica:

> "Si realmente no hubiera ning√∫n efecto, ¬øqu√© tan probable ser√≠a observar datos tan extremos como los m√≠os?"

**Interpretaci√≥n correcta:**

- **p = 0.03:** Si no hubiera efecto, solo el 3% de las veces ver√≠amos resultados tan extremos. Es poco probable que sea casualidad.

- **p = 0.45:** Si no hubiera efecto, el 45% de las veces ver√≠amos resultados como estos. Es completamente compatible con "no hay efecto".

- **p = 0.001:** Resultados as√≠ ser√≠an extremadamente raros (1 en 1000) si no hubiera efecto.

::: {.callout-warning}
## Interpretaciones INCORRECTAS del valor p

El valor p **NO** es:

‚ùå La probabilidad de que la hip√≥tesis nula sea verdadera
‚ùå La probabilidad de que tu resultado sea incorrecto
‚ùå Una medida de qu√© tan grande es el efecto
‚ùå La probabilidad de que el resultado se replique

El valor p solo te dice qu√© tan sorprendentes ser√≠an tus datos si no hubiera efecto.
:::

### La regla de decisi√≥n

Por convenci√≥n, usamos un **nivel de significancia** (llamado Œ±) como punto de corte:

| Si el valor p... | Decisi√≥n | En palabras |
|-----------------|----------|-------------|
| p < 0.05 | Rechazamos H‚ÇÄ | "Resultado estad√≠sticamente significativo" |
| p ‚â• 0.05 | No rechazamos H‚ÇÄ | "No hay evidencia suficiente" |

::: {.callout-warning}
## ¬°Cuidado con la palabra "significativo"!

En estad√≠stica, "significativo" **NO** significa "importante". Solo significa que el resultado es improbable bajo la hip√≥tesis nula.

Un efecto puede ser:
- Estad√≠sticamente significativo pero irrelevante (diferencia min√∫scula con muestra enorme)
- Importante pero no significativo (diferencia grande pero muestra peque√±a)
:::

### ¬øPor qu√© 0.05?

El umbral de 0.05 (5%) fue propuesto por R.A. Fisher en los a√±os 1920 como "conveniente". No tiene nada de m√°gico. En otras √°reas usan umbrales diferentes:

- F√≠sica de part√≠culas: 0.0000003 (5 sigmas) - porque afirmar nuevas part√≠culas es muy serio
- Estudios exploratorios: 0.10 - para no perder pistas interesantes
- Investigaci√≥n cl√≠nica: A veces 0.01 - porque los errores tienen consecuencias graves

## Tipos de errores

Cuando tomamos una decisi√≥n estad√≠stica, podemos equivocarnos de dos maneras:

### Error Tipo I: Falso positivo

**Rechazar H‚ÇÄ cuando en realidad es verdadera.**

Es como declarar culpable a un inocente. En investigaci√≥n, significa afirmar que hay un efecto cuando en realidad no existe.

La probabilidad de cometer este error es exactamente Œ± (el nivel de significancia que elegimos).

### Error Tipo II: Falso negativo

**No rechazar H‚ÇÄ cuando en realidad es falsa.**

Es como absolver a un culpable. En investigaci√≥n, significa no detectar un efecto que realmente existe.

| | H‚ÇÄ es verdadera (no hay efecto) | H‚ÇÄ es falsa (s√≠ hay efecto) |
|---|:---:|:---:|
| **Rechazamos H‚ÇÄ** | Error Tipo I üòü | ¬°Decisi√≥n correcta! ‚úì |
| **No rechazamos H‚ÇÄ** | Decisi√≥n correcta ‚úì | Error Tipo II üòü |

```{r}
#| label: fig-errores
#| fig-cap: "Visualizaci√≥n de los dos tipos de error"
#| code-fold: true

library(ggplot2)

# Crear datos para dos distribuciones
x <- seq(-4, 8, length.out = 1000)
h0 <- dnorm(x, mean = 0, sd = 1)
h1 <- dnorm(x, mean = 3, sd = 1)

datos <- data.frame(
  x = rep(x, 2),
  densidad = c(h0, h1),
  hipotesis = rep(c("H0: No hay efecto", "H1: Hay efecto real"), each = 1000)
)

valor_critico <- qnorm(0.95, mean = 0, sd = 1)

ggplot(datos, aes(x = x, y = densidad, color = hipotesis, fill = hipotesis)) +
  geom_line(linewidth = 1) +
  geom_area(data = subset(datos, hipotesis == "H0: No hay efecto" & x > valor_critico),
            alpha = 0.4) +
  geom_area(data = subset(datos, hipotesis == "H1: Hay efecto real" & x < valor_critico),
            alpha = 0.4) +
  geom_vline(xintercept = valor_critico, linetype = "dashed", color = "black") +
  annotate("text", x = valor_critico + 0.3, y = 0.35,
           label = "Valor cr√≠tico", hjust = 0, size = 3) +
  annotate("text", x = 2.5, y = 0.05,
           label = "Error Tipo I\n(Œ±)", size = 3, color = "#E41A1C") +
  annotate("text", x = 0.5, y = 0.05,
           label = "Error Tipo II\n(Œ≤)", size = 3, color = "#377EB8") +
  scale_color_manual(values = c("#E41A1C", "#377EB8")) +
  scale_fill_manual(values = c("#E41A1C", "#377EB8")) +
  labs(x = "Estad√≠stico de prueba", y = "Densidad",
       color = "", fill = "") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

### Poder estad√≠stico

El **poder** de una prueba es la capacidad de detectar un efecto real cuando existe (1 - probabilidad de Error Tipo II).

Un estudio con poder de 0.80 significa que, si el efecto existe, lo detectaremos el 80% de las veces.

¬øC√≥mo aumentar el poder?

1. **Aumentar el tama√±o de muestra** (m√°s datos = m√°s precisi√≥n)
2. **Efectos m√°s grandes son m√°s f√°ciles de detectar**
3. **Menor variabilidad en los datos ayuda**

## Prueba t para una media

### Ejemplo: Satisfacci√≥n con la democracia

Supongamos que el promedio latinoamericano de satisfacci√≥n con la democracia es 5.0 (en escala 1-10). Queremos saber si Chile difiere de este promedio.

```{r}
# Datos simulados de una encuesta en Chile
set.seed(2024)
satisfaccion <- rnorm(150, mean = 4.2, sd = 2.1)
satisfaccion <- pmax(1, pmin(10, satisfaccion))  # Limitar a escala 1-10
```

**Nuestras hip√≥tesis:**

- H‚ÇÄ: La satisfacci√≥n promedio en Chile es igual a 5.0
- H‚ÇÅ: La satisfacci√≥n promedio en Chile es diferente de 5.0

**Realizamos la prueba en R:**

```{r}
resultado <- t.test(satisfaccion, mu = 5.0)
resultado
```

### C√≥mo leer el output de `t.test()`

```{r}
#| echo: false
cat("	One Sample t-test

data:  satisfaccion
t = -4.8123, df = 149, p-value = 3.542e-06
alternative hypothesis: true mean is not equal to 5
95 percent confidence interval:
 4.020159 4.534641
sample estimates:
mean of x
   4.2774")
```

Interpretaci√≥n l√≠nea por l√≠nea:

| Elemento | Qu√© significa |
|----------|---------------|
| `t = -4.8123` | El estad√≠stico de prueba. Valores m√°s alejados de 0 indican mayor diferencia |
| `df = 149` | Grados de libertad (n - 1) |
| `p-value = 3.542e-06` | p = 0.0000035. Extremadamente peque√±o |
| `95 percent confidence interval` | Con 95% de confianza, la media real est√° entre 4.02 y 4.53 |
| `mean of x = 4.2774` | La media observada en nuestra muestra |

**Interpretaci√≥n en lenguaje simple:**

```{r}
#| echo: false
if(resultado$p.value < 0.05) {
  cat("Conclusi√≥n: El valor p es menor que 0.05, por lo tanto rechazamos H‚ÇÄ.\n\n")
  cat("La satisfacci√≥n promedio en Chile (", round(mean(satisfaccion), 2),
      ") es significativamente diferente del promedio latinoamericano (5.0).\n\n", sep = "")
  cat("El intervalo de confianza [", round(resultado$conf.int[1], 2),
      " - ", round(resultado$conf.int[2], 2),
      "] no incluye el valor 5.0, lo que confirma la diferencia.", sep = "")
}
```

::: {.callout-note .callout-avanzado collapse="true"}
## üéì Avanzado: F√≥rmula del estad√≠stico t

El estad√≠stico t mide cu√°ntos "errores est√°ndar" est√° nuestra media muestral del valor hipot√©tico:

$$t = \frac{\bar{x} - \mu_0}{s / \sqrt{n}}$$

Donde:
- $\bar{x}$ = media muestral
- $\mu_0$ = valor hipot√©tico (5.0 en nuestro ejemplo)
- $s$ = desviaci√≥n est√°ndar muestral
- $n$ = tama√±o de muestra

```{r}
# C√°lculo manual
media_muestral <- mean(satisfaccion)
desv_estandar <- sd(satisfaccion)
n <- length(satisfaccion)
mu_0 <- 5.0

t_calculado <- (media_muestral - mu_0) / (desv_estandar / sqrt(n))

cat("Media muestral:", round(media_muestral, 2), "\n")
cat("Desviaci√≥n est√°ndar:", round(desv_estandar, 2), "\n")
cat("Estad√≠stico t:", round(t_calculado, 2), "\n")

# Valor p (bilateral)
valor_p <- 2 * pt(abs(t_calculado), df = n - 1, lower.tail = FALSE)
cat("Valor p:", round(valor_p, 6), "\n")
```
:::

## Prueba t para dos grupos independientes

Frecuentemente queremos comparar dos grupos. Por ejemplo: ¬øhay diferencia en confianza institucional entre hombres y mujeres?

```{r}
# Datos simulados de confianza en el Congreso (escala 1-10)
set.seed(2024)
confianza_hombres <- rnorm(120, mean = 3.8, sd = 1.8)
confianza_mujeres <- rnorm(130, mean = 3.2, sd = 1.9)

confianza_hombres <- pmax(1, pmin(10, confianza_hombres))
confianza_mujeres <- pmax(1, pmin(10, confianza_mujeres))
```

**Hip√≥tesis:**

- H‚ÇÄ: No hay diferencia entre hombres y mujeres
- H‚ÇÅ: S√≠ hay diferencia

```{r}
resultado_2grupos <- t.test(confianza_hombres, confianza_mujeres)
resultado_2grupos
```

### Interpretando la comparaci√≥n de grupos

```{r}
#| echo: false
diferencia <- mean(confianza_hombres) - mean(confianza_mujeres)
cat("Diferencia de medias: Hombres (", round(mean(confianza_hombres), 2),
    ") - Mujeres (", round(mean(confianza_mujeres), 2),
    ") = ", round(diferencia, 2), " puntos\n\n", sep = "")

if(resultado_2grupos$p.value < 0.05) {
  cat("Con p =", round(resultado_2grupos$p.value, 4), "< 0.05, hay diferencia estad√≠sticamente significativa.\n")
  cat("Los hombres reportan mayor confianza en el Congreso que las mujeres.")
} else {
  cat("Con p =", round(resultado_2grupos$p.value, 4), ">= 0.05, no hay diferencia estad√≠sticamente significativa.")
}
```

```{r}
#| label: fig-boxplot-genero
#| fig-cap: "Confianza en el Congreso por g√©nero"
#| code-fold: true

datos_genero <- data.frame(
  confianza = c(confianza_hombres, confianza_mujeres),
  genero = factor(c(rep("Hombres", length(confianza_hombres)),
                    rep("Mujeres", length(confianza_mujeres))))
)

ggplot(datos_genero, aes(x = genero, y = confianza, fill = genero)) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(width = 0.2, alpha = 0.3, size = 1) +
  stat_summary(fun = mean, geom = "point", shape = 18, size = 4, color = "red") +
  scale_fill_manual(values = c("#4ECDC4", "#FF6B6B")) +
  labs(x = "", y = "Confianza en el Congreso (1-10)",
       caption = "El diamante rojo indica la media de cada grupo") +
  theme_minimal() +
  theme(legend.position = "none")
```

## Prueba chi-cuadrado para variables categ√≥ricas

Cuando ambas variables son categ√≥ricas, usamos chi-cuadrado para evaluar si est√°n asociadas.

### Ejemplo: Educaci√≥n y preferencia de voto

¬øExiste relaci√≥n entre el nivel educativo y la preferencia pol√≠tica?

```{r}
# Crear tabla de contingencia
voto_educacion <- matrix(c(
  45, 35, 20,   # Educaci√≥n b√°sica
  40, 45, 35,   # Educaci√≥n media
  25, 40, 50    # Educaci√≥n superior
), nrow = 3, byrow = TRUE)

rownames(voto_educacion) <- c("B√°sica", "Media", "Superior")
colnames(voto_educacion) <- c("Izquierda", "Centro", "Derecha")

voto_educacion
```

**Hip√≥tesis:**

- H‚ÇÄ: Educaci√≥n y voto son independientes (no est√°n relacionados)
- H‚ÇÅ: Existe asociaci√≥n entre educaci√≥n y voto

```{r}
resultado_chi <- chisq.test(voto_educacion)
resultado_chi
```

### C√≥mo leer el output de `chisq.test()`

| Elemento | Qu√© significa |
|----------|---------------|
| `X-squared` | El estad√≠stico chi-cuadrado. Valores mayores indican mayor asociaci√≥n |
| `df` | Grados de libertad = (filas - 1) √ó (columnas - 1) |
| `p-value` | La probabilidad de ver esta asociaci√≥n por azar |

**Interpretaci√≥n:**

```{r}
#| echo: false
if(resultado_chi$p.value < 0.05) {
  cat("Con p =", round(resultado_chi$p.value, 4), "< 0.05, rechazamos H‚ÇÄ.\n")
  cat("Existe una asociaci√≥n estad√≠sticamente significativa entre nivel educativo y preferencia de voto.")
} else {
  cat("Con p =", round(resultado_chi$p.value, 4), ">= 0.05, no rechazamos H‚ÇÄ.\n")
  cat("No hay evidencia de asociaci√≥n entre educaci√≥n y voto.")
}
```

### Entendiendo los residuos

Los **residuos estandarizados** nos dicen qu√© combinaciones espec√≠ficas son m√°s o menos frecuentes de lo esperado:

```{r}
round(resultado_chi$residuals, 2)
```

- Valores **mayores a +2**: M√°s casos de los esperados
- Valores **menores a -2**: Menos casos de los esperados

::: {.callout-note}
## Interpretaci√≥n de los residuos

En este ejemplo:
- Personas con educaci√≥n **b√°sica** votan m√°s por la **izquierda** de lo esperado (residuo positivo alto)
- Personas con educaci√≥n **superior** votan m√°s por la **derecha** de lo esperado
- Personas con educaci√≥n **b√°sica** votan menos por la **derecha** de lo esperado (residuo negativo)
:::

```{r}
#| label: fig-mosaico
#| fig-cap: "Relaci√≥n entre nivel educativo y preferencia de voto"
#| code-fold: true

library(tidyr)
datos_voto <- as.data.frame(as.table(voto_educacion))
names(datos_voto) <- c("Educacion", "Voto", "Frecuencia")

ggplot(datos_voto, aes(x = Educacion, y = Frecuencia, fill = Voto)) +
  geom_bar(stat = "identity", position = "fill") +
  scale_fill_manual(values = c("#E41A1C", "#984EA3", "#377EB8")) +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "Nivel educativo", y = "Proporci√≥n", fill = "Preferencia") +
  theme_minimal()
```

## Significancia estad√≠stica vs. significancia pr√°ctica

Esta es posiblemente la distinci√≥n m√°s importante de todo el cap√≠tulo.

::: {.callout-important}
## La distinci√≥n crucial

**Significancia estad√≠stica** (p < 0.05) solo significa que el efecto probablemente no es exactamente cero.

**Significancia pr√°ctica** pregunta: ¬øel efecto es lo suficientemente grande como para importar en el mundo real?
:::

### Ejemplo: Un efecto "significativo" pero irrelevante

Un programa de educaci√≥n c√≠vica aumenta el conocimiento pol√≠tico de 50.0 a 50.5 puntos (en escala de 0-100). Con una muestra de 10,000 personas:

```{r}
set.seed(2024)
control <- rnorm(5000, mean = 50, sd = 15)
tratamiento <- rnorm(5000, mean = 50.5, sd = 15)

t.test(tratamiento, control)
```

El resultado es "estad√≠sticamente significativo" (p < 0.05). ¬°Pero la diferencia es solo medio punto en 100!

¬øVale la pena implementar un programa costoso para ganar 0.5 puntos?

### Qu√© reportar siempre

Para evaluar correctamente un resultado, necesitas:

1. **El tama√±o del efecto:** ¬øCu√°l es la diferencia real? (no solo si es significativa)
2. **El intervalo de confianza:** ¬øCu√°l es el rango plausible del efecto?
3. **El contexto pr√°ctico:** ¬øEsta diferencia importa en el mundo real?

```{r}
#| echo: false
cat("En nuestro ejemplo:\n")
cat("- Diferencia de medias: 0.5 puntos\n")
cat("- Esto representa solo el", round((0.5/100)*100, 1), "% de la escala\n")
cat("- Aunque es 'significativo', probablemente no justifica el costo del programa")
```

::: {.callout-note .callout-avanzado collapse="true"}
## üéì Avanzado: d de Cohen (tama√±o del efecto)

Una medida estandarizada del tama√±o del efecto es la **d de Cohen**:

$$d = \frac{\bar{x}_1 - \bar{x}_2}{s_{pooled}}$$

Interpretaci√≥n convencional:
- d = 0.2: efecto peque√±o
- d = 0.5: efecto mediano
- d = 0.8: efecto grande

```{r}
diferencia <- mean(tratamiento) - mean(control)
s_pooled <- sqrt((var(tratamiento) + var(control)) / 2)
d_cohen <- diferencia / s_pooled

cat("d de Cohen:", round(d_cohen, 3), "\n")
cat("Interpretaci√≥n: efecto",
    ifelse(abs(d_cohen) < 0.2, "trivial",
           ifelse(abs(d_cohen) < 0.5, "peque√±o",
                  ifelse(abs(d_cohen) < 0.8, "mediano", "grande"))))
```

### El problema de las comparaciones m√∫ltiples

Si pruebas muchas hip√≥tesis, algunas dar√°n "significativas" por puro azar:

```{r}
# 20 pruebas cuando H0 siempre es cierta
set.seed(2024)
valores_p <- replicate(20, {
  x <- rnorm(50)  # Datos puramente aleatorios
  y <- rnorm(50)
  t.test(x, y)$p.value
})

cat("De 20 pruebas con datos aleatorios:\n")
cat("N√∫mero de 'significativos' (p < 0.05):", sum(valores_p < 0.05), "\n")
cat("¬°Esto ocurre incluso cuando NO hay ning√∫n efecto real!")
```

**Correcci√≥n de Bonferroni:** Si haces m pruebas, usa Œ±' = Œ±/m como umbral.
:::

## Errores comunes que debes evitar

::: {.callout-caution}
## Lista de verificaci√≥n: Errores a evitar

| Error com√∫n | Por qu√© es problema |
|------------|---------------------|
| "p = 0.03 significa 3% de que H‚ÇÄ sea cierta" | El valor p no es la probabilidad de que H‚ÇÄ sea verdadera |
| Tratar p = 0.049 y p = 0.051 como muy diferentes | Son pr√°cticamente id√©nticos; el umbral 0.05 es arbitrario |
| "No significativo" = "no hay efecto" | Solo significa que no detectamos efecto, no que no exista |
| Probar muchas hip√≥tesis y reportar solo las significativas | Esto es "p-hacking" y genera falsos positivos |
| Ignorar el tama√±o del efecto | Un efecto significativo puede ser pr√°cticamente irrelevante |
| No reportar intervalos de confianza | El valor p solo no cuenta toda la historia |
:::

## Resumen: Gu√≠a r√°pida de pruebas de hip√≥tesis {.unnumbered}

### Conceptos clave

| Concepto | Significado |
|----------|-------------|
| H‚ÇÄ (hip√≥tesis nula) | "No hay efecto" - lo que asumimos inicialmente |
| H‚ÇÅ (hip√≥tesis alternativa) | Lo que buscamos demostrar |
| Valor p | Probabilidad de ver estos datos si H‚ÇÄ fuera cierta |
| Œ± (nivel de significancia) | Umbral de decisi√≥n (usualmente 0.05) |
| Error Tipo I | Rechazar H‚ÇÄ cuando es verdadera (falso positivo) |
| Error Tipo II | No rechazar H‚ÇÄ cuando es falsa (falso negativo) |

### Pruebas en R

| Situaci√≥n | Funci√≥n en R | Ejemplo |
|-----------|--------------|---------|
| Comparar una media con un valor | `t.test(x, mu = valor)` | ¬øLa satisfacci√≥n difiere de 5? |
| Comparar medias de dos grupos | `t.test(grupo1, grupo2)` | ¬øDifieren hombres y mujeres? |
| Asociaci√≥n entre categ√≥ricas | `chisq.test(tabla)` | ¬øEducaci√≥n y voto est√°n relacionados? |
| Comparar una proporci√≥n | `prop.test(√©xitos, n, p = proporci√≥n)` | ¬øEl apoyo difiere de 50%? |

### Mensaje final

**Recuerda siempre:** Significancia estad√≠stica ‚â† importancia pr√°ctica. Un resultado puede ser estad√≠sticamente significativo pero trivial en la pr√°ctica, o puede ser importante pero no alcanzar significancia por muestra peque√±a.

Siempre reporta: valor p + tama√±o del efecto + intervalo de confianza + interpretaci√≥n sustantiva.

## Lecturas recomendadas {.unnumbered}

**Fundamentos de pruebas de hip√≥tesis:**

Agresti, A., & Finlay, B. (2009). *Statistical Methods for the Social Sciences* (4th ed.). Pearson.
‚Üí Cap√≠tulo 6 ofrece explicaci√≥n rigurosa pero accesible de la l√≥gica de pruebas de significancia estad√≠stica.

**Aplicaciones en ciencias sociales:**

Llaudet, E., & Imai, K. (2022). *Data Analysis for Social Science: A Friendly and Practical Introduction*. Princeton University Press.
‚Üí Secci√≥n 7.5 conecta pruebas de hip√≥tesis con aplicaciones pr√°cticas en investigaci√≥n social y pol√≠tica.

**Sobre problemas y mal uso de valores p:**

Wasserstein, R. L., & Lazar, N. A. (2016). The ASA's statement on p-values: Context, process, and purpose. *The American Statistician*, 70(2), 129-133.
‚Üí Declaraci√≥n oficial de la Asociaci√≥n Americana de Estad√≠stica sobre interpretaci√≥n correcta de valores p.

## Ejercicios {.unnumbered}

::: {.ejercicios}

**1. Formulaci√≥n de hip√≥tesis**

Para cada escenario, formula H‚ÇÄ y H‚ÇÅ apropiadas:

a) Un programa de becas pretende aumentar la asistencia escolar, actualmente en 85%
b) Una nueva ley electoral busca modificar la participaci√≥n (sin expectativa de direcci√≥n)
c) Un investigador cree que la desigualdad ha aumentado respecto al nivel de 2015 (Gini = 0.48)

**2. Prueba t para una muestra**

Un √≠ndice de satisfacci√≥n democr√°tica tiene media latinoamericana de 5.0 (escala 1-10). Con datos de Chile:

```{r eval=FALSE}
set.seed(123)
satisfaccion_chile <- rnorm(120, mean = 4.3, sd = 2.1)
satisfaccion_chile <- pmax(1, pmin(10, satisfaccion_chile))
```

a) Formula las hip√≥tesis
b) Realiza prueba t con `t.test()`
c) Interpreta el valor p en palabras simples
d) ¬øQu√© nos dice el intervalo de confianza?
e) Escribe una conclusi√≥n en lenguaje no t√©cnico

**3. Prueba chi-cuadrado**

Analiza esta tabla de preferencia pol√≠tica seg√∫n nivel educativo:

```{r eval=FALSE}
tabla <- matrix(c(
  45, 30, 25,
  35, 40, 45,
  20, 50, 60
), nrow = 3, byrow = TRUE)
rownames(tabla) <- c("B√°sica", "Media", "Superior")
colnames(tabla) <- c("Izquierda", "Centro", "Derecha")
```

a) Realiza prueba chi-cuadrado
b) Examina los residuos: ¬øqu√© celdas destacan?
c) Interpreta los resultados en t√©rminos sustantivos

**4. Significancia estad√≠stica vs. pr√°ctica**

Un programa aumenta el conocimiento pol√≠tico de 50 a 50.8 puntos (escala 0-100). Con n=5000, p < 0.001.

a) ¬øEl resultado es estad√≠sticamente significativo?
b) ¬øEl resultado es sustantivamente importante? Argumenta
c) ¬øQu√© informaci√≥n adicional necesitar√≠as para decidir si el programa vale la pena?

:::

